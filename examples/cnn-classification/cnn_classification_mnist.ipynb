{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple MNIST multiclass classification (using CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T12:50:36.876531200Z",
     "start_time": "2024-11-15T12:50:27.529079800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from neuralnetlib.activations import ReLU\n",
    "from neuralnetlib.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Activation\n",
    "from neuralnetlib.models import Sequential\n",
    "from neuralnetlib.preprocessing import one_hot_encode\n",
    "from neuralnetlib.metrics import accuracy_score, recall_score, f1_score \n",
    "from neuralnetlib.utils import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading a dataset (in this case, MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T12:50:37.029895400Z",
     "start_time": "2024-11-15T12:50:36.878530300Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T12:50:37.123596400Z",
     "start_time": "2024-11-15T12:50:37.031895600Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 1, 28, 28) / 255.0  # Normalization and reshaping of the images for CNN\n",
    "x_test = x_test.reshape(-1, 1, 28, 28) / 255.0  # Normalization and reshaping of the images for CNN\n",
    "x_val = x_val.reshape(-1, 1, 28, 28) / 255.0  # Normalization and reshaping of the images for CNN\n",
    "y_train = one_hot_encode(y_train, num_classes=10)  # One-hot encoding of the labels\n",
    "y_test = one_hot_encode(y_test, num_classes=10)  # One-hot encoding of the labels\n",
    "y_val = one_hot_encode(y_val, num_classes=10)  # One-hot encoding of the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T12:54:21.952185200Z",
     "start_time": "2024-11-15T12:54:21.937522900Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(input_shape=(1, 28, 28)))\n",
    "model.add(Conv2D(filters=8, kernel_size=(3, 3), random_state=42))\n",
    "model.add(Activation(ReLU()))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), random_state=42))\n",
    "model.add(Activation(ReLU()))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, random_state=42))\n",
    "model.add(Activation(ReLU()))\n",
    "model.add(Dense(10, random_state=42, activation=\"softmax\"))  # Yeah, you can also use strings for the activation functions, or directly the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T12:54:23.755437500Z",
     "start_time": "2024-11-15T12:54:23.744908800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(temperature=1.0, gradient_clip_threshold=5.0, enable_padding=False, padding_size=32, random_state=1731675261936522700)\n",
      "-------------------------------------------------\n",
      "Layer 1: Input(input_shape=(1, 28, 28))\n",
      "Layer 2: Conv2D(num_filters=8, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
      "Layer 3: Activation(ReLU)\n",
      "Layer 4: MaxPooling2D(pool_size=(2, 2), stride=(2, 2), padding=valid)\n",
      "Layer 5: Conv2D(num_filters=16, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
      "Layer 6: Activation(ReLU)\n",
      "Layer 7: MaxPooling2D(pool_size=(2, 2), stride=(2, 2), padding=valid)\n",
      "Layer 8: Flatten\n",
      "Layer 9: Dense(units=32)\n",
      "Layer 10: Activation(ReLU)\n",
      "Layer 11: Dense(units=10)\n",
      "Layer 12: Activation(Softmax)\n",
      "-------------------------------------------------\n",
      "Loss function: CategoricalCrossentropy\n",
      "Optimizer: Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, clip_norm=None, clip_value=None)\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss_function=\"cce\", optimizer=\"adam\")  # You can also use strings for the loss function and the optimizer\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T12:56:34.642119500Z",
     "start_time": "2024-11-15T12:54:25.501099600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================] 100% Epoch 1/10 - loss: 0.3072 - accuracy: 0.9037 - 40.59s - val_accuracy: 0.9709\n",
      "[==============================] 100% Epoch 2/10 - loss: 0.1016 - accuracy: 0.9692 - 38.35s - val_accuracy: 0.9798\n",
      "[==============================] 100% Epoch 3/10 - loss: 0.0802 - accuracy: 0.9765 - 38.06s - val_accuracy: 0.9822\n",
      "[======------------------------] 20% Epoch 4/10 - loss: 0.0693 - accuracy: 0.9793 - 7.30s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43maccuracy\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m42\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Programming\\Python\\neuralnetlib\\neuralnetlib\\models.py:338\u001B[0m, in \u001B[0;36mSequential.fit\u001B[1;34m(self, x_train, y_train, epochs, batch_size, verbose, metrics, random_state, validation_data, callbacks, plot_decision_boundary)\u001B[0m\n\u001B[0;32m    336\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_batch\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    337\u001B[0m     y_batch \u001B[38;5;241m=\u001B[39m y_batch\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m--> 338\u001B[0m error \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_on_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    339\u001B[0m predictions_list\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictions)\n\u001B[0;32m    340\u001B[0m y_true_list\u001B[38;5;241m.\u001B[39mappend(y_batch)\n",
      "File \u001B[1;32m~\\Documents\\Programming\\Python\\neuralnetlib\\neuralnetlib\\models.py:240\u001B[0m, in \u001B[0;36mSequential.train_on_batch\u001B[1;34m(self, x_batch, y_batch)\u001B[0m\n\u001B[0;32m    237\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], (LSTM, Bidirectional, GRU)) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mreturn_sequences:\n\u001B[0;32m    238\u001B[0m     error \u001B[38;5;241m=\u001B[39m error\u001B[38;5;241m.\u001B[39mreshape(error\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], error\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m--> 240\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward_pass\u001B[49m\u001B[43m(\u001B[49m\u001B[43merror\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    241\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32m~\\Documents\\Programming\\Python\\neuralnetlib\\neuralnetlib\\models.py:189\u001B[0m, in \u001B[0;36mSequential.backward_pass\u001B[1;34m(self, error)\u001B[0m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    188\u001B[0m     error \u001B[38;5;241m=\u001B[39m clip_gradients(error)\n\u001B[1;32m--> 189\u001B[0m     error \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward_pass\u001B[49m\u001B[43m(\u001B[49m\u001B[43merror\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    191\u001B[0m layer_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m i\n\u001B[0;32m    193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(layer, LSTM):\n",
      "File \u001B[1;32m~\\Documents\\Programming\\Python\\neuralnetlib\\neuralnetlib\\layers.py:547\u001B[0m, in \u001B[0;36mMaxPooling2D.backward_pass\u001B[1;34m(self, output_error)\u001B[0m\n\u001B[0;32m    546\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackward_pass\u001B[39m(\u001B[38;5;28mself\u001B[39m, output_error: np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[1;32m--> 547\u001B[0m     input_error \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pool_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    548\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_error\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpool_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    549\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m input_error\n",
      "File \u001B[1;32m~\\Documents\\Programming\\Python\\neuralnetlib\\neuralnetlib\\layers.py:617\u001B[0m, in \u001B[0;36mMaxPooling2D._pool_backward\u001B[1;34m(output_error, input_data, pool_size, stride, padding)\u001B[0m\n\u001B[0;32m    613\u001B[0m         input_slice \u001B[38;5;241m=\u001B[39m padded_input[:, :, i \u001B[38;5;241m*\u001B[39m stride[\u001B[38;5;241m0\u001B[39m]:i \u001B[38;5;241m*\u001B[39m stride[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m pool_size[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    614\u001B[0m                       j \u001B[38;5;241m*\u001B[39m stride[\u001B[38;5;241m1\u001B[39m]:j \u001B[38;5;241m*\u001B[39m stride[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m+\u001B[39m pool_size[\u001B[38;5;241m1\u001B[39m]]\n\u001B[0;32m    615\u001B[0m         mask \u001B[38;5;241m=\u001B[39m (input_slice \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mmax(\n\u001B[0;32m    616\u001B[0m             input_slice, axis\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m), keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[1;32m--> 617\u001B[0m         d_input[:, :, i \u001B[38;5;241m*\u001B[39m stride[\u001B[38;5;241m0\u001B[39m]:i \u001B[38;5;241m*\u001B[39m stride[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m pool_size[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    618\u001B[0m         j \u001B[38;5;241m*\u001B[39m stride[\u001B[38;5;241m1\u001B[39m]:j \u001B[38;5;241m*\u001B[39m stride[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m+\u001B[39m pool_size[\u001B[38;5;241m1\u001B[39m]] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m output_error[:, :, i, j][:, :, np\u001B[38;5;241m.\u001B[39mnewaxis,\n\u001B[0;32m    619\u001B[0m                                                        np\u001B[38;5;241m.\u001B[39mnewaxis] \u001B[38;5;241m*\u001B[39m mask\n\u001B[0;32m    621\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m padding \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msame\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    622\u001B[0m     d_input \u001B[38;5;241m=\u001B[39m d_input[:, :, pad_height:\u001B[38;5;241m-\u001B[39m\n\u001B[0;32m    623\u001B[0m     pad_height, pad_width:\u001B[38;5;241m-\u001B[39mpad_width]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=64, metrics=[\n",
    "            \"accuracy\"], random_state=42, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T12:56:34.644121400Z",
     "start_time": "2024-11-15T12:56:34.644121400Z"
    }
   },
   "outputs": [],
   "source": [
    "loss, _ = model.evaluate(x_val, y_val)\n",
    "print(f'Test loss: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T12:56:34.644121400Z",
     "start_time": "2024-11-15T12:56:34.644121400Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Printing some metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-15T12:50:37.141693Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"accuracy:\", accuracy_score(y_pred, y_val))\n",
    "print(\"f1_score:\", f1_score(y_pred, y_val))\n",
    "print(\"recall_score\", recall_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Plot the first 10 test images, their predicted labels, and the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T12:50:37.143692700Z",
     "start_time": "2024-11-15T12:50:37.142692500Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(5, 2, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(x_val[i].reshape(28, 28), cmap='gray')\n",
    "    ax.set_title(f\"Predicted: {np.argmax(y_pred[i])}, Actual: {np.argmax(y_val[i])}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T12:50:37.171752600Z",
     "start_time": "2024-11-15T12:50:37.143692700Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"my_mnist_model.npz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
