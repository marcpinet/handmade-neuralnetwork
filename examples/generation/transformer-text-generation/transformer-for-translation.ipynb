{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a036f9b8eee0491",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T00:29:31.303382900Z",
     "start_time": "2024-11-12T00:29:31.023112900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from neuralnetlib.models import Transformer\n",
    "from neuralnetlib.preprocessing import Tokenizer, pad_sequences\n",
    "from neuralnetlib.losses import SequenceCrossEntropy\n",
    "from neuralnetlib.optimizers import Adam\n",
    "from neuralnetlib.callbacks import EarlyStopping, Callback, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfcb1593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text, transformer, fr_tokenizer, en_tokenizer, temperature: float = 1.0):\n",
    "    sequence = fr_tokenizer.texts_to_sequences([text], add_special_tokens=True)[0]\n",
    "\n",
    "    encoder_input = pad_sequences([sequence], max_length=transformer.max_sequence_length, padding='post', pad_value=transformer.PAD_IDX)\n",
    "    \n",
    "    output_sequence = transformer.predict(encoder_input, max_length=transformer.max_sequence_length, temperature=temperature)\n",
    "\n",
    "    translated_text = en_tokenizer.sequences_to_texts([output_sequence[0].tolist()[1:]])[0]  # remove the start token with [1:]\n",
    "    \n",
    "    return translated_text\n",
    "\n",
    "class DebugCallback(Callback):\n",
    "    def __init__(self, model, fr_tokenizer, en_tokenizer):\n",
    "        self.model = model\n",
    "        self.fr_tokenizer = fr_tokenizer\n",
    "        self.en_tokenizer = en_tokenizer\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch} details:\")\n",
    "        print(f\"Loss: {logs['loss']:.4f}\")\n",
    "        \n",
    "        test_sent = \"bonjour\"\n",
    "        translation = translate(test_sent, self.model, self.fr_tokenizer, self.en_tokenizer)\n",
    "        print(f\"Test translation: {test_sent} -> {translation}\")\n",
    "\n",
    "test_sentences = [\n",
    "    \"je vais bien\",\n",
    "    \"comment allez-vous ?\",\n",
    "    \"bonjour\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be237a3421e586a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T00:29:31.319383Z",
     "start_time": "2024-11-12T00:29:31.304382500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fr_sentences = [\n",
    "    \"bonjour.\",\n",
    "    \"au revoir.\",\n",
    "    \"merci beaucoup.\",\n",
    "    \"s'il vous plaît.\",\n",
    "    \"comment allez-vous ?\",\n",
    "    \"je vais bien.\",\n",
    "    \"je suis fatigué.\",\n",
    "    \"je suis content.\",\n",
    "    \"quel est votre nom ?\",\n",
    "    \"mon nom est Jean.\",\n",
    "    \"enchanté de vous rencontrer.\",\n",
    "    \"bonne journée.\",\n",
    "    \"bonne soirée.\",\n",
    "    \"à demain.\",\n",
    "    \"j'aime le café.\",\n",
    "    \"je n'aime pas le thé.\",\n",
    "    \"quelle heure est-il ?\",\n",
    "    \"il est trois heures.\",\n",
    "    \"où est la gare ?\",\n",
    "    \"la gare est près d'ici.\",\n",
    "    \"combien ça coûte ?\",\n",
    "    \"c'est trop cher.\",\n",
    "    \"parlez-vous anglais ?\",\n",
    "    \"un peu.\",\n",
    "    \"je ne comprends pas.\",\n",
    "    \"pouvez-vous répéter ?\",\n",
    "    \"je suis désolé.\",\n",
    "    \"pas de problème.\",\n",
    "    \"bon appétit.\",\n",
    "    \"à votre santé.\",\n",
    "    \"j'ai faim.\",\n",
    "    \"j'ai soif.\",\n",
    "    \"il fait beau aujourd'hui.\",\n",
    "    \"il pleut.\",\n",
    "    \"il fait froid.\",\n",
    "    \"il fait chaud.\",\n",
    "    \"je travaille ici.\",\n",
    "    \"où habitez-vous ?\",\n",
    "    \"j'habite à Paris.\",\n",
    "    \"quel âge avez-vous ?\",\n",
    "    \"j'ai vingt-cinq ans.\",\n",
    "    \"avez-vous des frères et soeurs ?\",\n",
    "    \"j'ai une soeur.\",\n",
    "    \"j'ai un chat.\",\n",
    "    \"j'aime voyager.\",\n",
    "    \"je suis étudiant.\",\n",
    "    \"je suis professeur.\",\n",
    "    \"au secours !\",\n",
    "    \"joyeux anniversaire !\",\n",
    "    \"félicitations !\"\n",
    "]\n",
    "\n",
    "en_sentences = [\n",
    "    \"hello.\",\n",
    "    \"goodbye.\",\n",
    "    \"thank you very much.\",\n",
    "    \"please.\",\n",
    "    \"how are you?\",\n",
    "    \"i am fine.\",\n",
    "    \"i am tired.\",\n",
    "    \"i am happy.\",\n",
    "    \"what is your name?\",\n",
    "    \"my name is John.\",\n",
    "    \"nice to meet you.\",\n",
    "    \"have a nice day.\",\n",
    "    \"have a good evening.\",\n",
    "    \"see you tomorrow.\",\n",
    "    \"i like coffee.\",\n",
    "    \"i don't like tea.\",\n",
    "    \"what time is it?\",\n",
    "    \"it is three o'clock.\",\n",
    "    \"where is the train station?\",\n",
    "    \"the station is nearby.\",\n",
    "    \"how much is it?\",\n",
    "    \"it's too expensive.\",\n",
    "    \"do you speak english?\",\n",
    "    \"a little.\",\n",
    "    \"i don't understand.\",\n",
    "    \"can you repeat?\",\n",
    "    \"i am sorry.\",\n",
    "    \"no problem.\",\n",
    "    \"enjoy your meal.\",\n",
    "    \"cheers.\",\n",
    "    \"i am hungry.\",\n",
    "    \"i am thirsty.\",\n",
    "    \"the weather is nice today.\",\n",
    "    \"it's raining.\",\n",
    "    \"it's cold.\",\n",
    "    \"it's hot.\",\n",
    "    \"i work here.\",\n",
    "    \"where do you live?\",\n",
    "    \"i live in Paris.\",\n",
    "    \"how old are you?\",\n",
    "    \"i am twenty-five years old.\",\n",
    "    \"do you have brothers and sisters?\",\n",
    "    \"i have a sister.\",\n",
    "    \"i have a cat.\",\n",
    "    \"i like to travel.\",\n",
    "    \"i am a student.\",\n",
    "    \"i am a teacher.\",\n",
    "    \"help!\",\n",
    "    \"happy birthday!\",\n",
    "    \"congratulations!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4c0d8598f0ba7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T00:29:31.350386300Z",
     "start_time": "2024-11-12T00:29:31.320384Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fr_tokenizer = Tokenizer(filters=\"\")  # else the tokenizer would remove the special characters including ponctuation\n",
    "en_tokenizer = Tokenizer(filters=\"\")  # else the tokenizer would remove the special characters including ponctuation\n",
    "\n",
    "fr_tokenizer.fit_on_texts(fr_sentences, preprocess_ponctuation=True)\n",
    "en_tokenizer.fit_on_texts(en_sentences, preprocess_ponctuation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67338439",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = fr_tokenizer.texts_to_sequences(fr_sentences, preprocess_ponctuation=True, add_special_tokens=True)\n",
    "y_train = en_tokenizer.texts_to_sequences(en_sentences, preprocess_ponctuation=True, add_special_tokens=True)\n",
    "\n",
    "max_len_x = max(len(seq) for seq in x_train)\n",
    "max_len_y = max(len(seq) for seq in y_train)\n",
    "max_seq_len = max(max_len_x, max_len_y)\n",
    "\n",
    "vocab_size_fr = len(fr_tokenizer.word_index)\n",
    "vocab_size_en = len(en_tokenizer.word_index)\n",
    "max_vocab_size = max(vocab_size_fr, vocab_size_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5501a2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size_en: 95, vocab_size_fr: 107\n",
      "max_len_x: 10, max_len_y: 10, max_vocab_size: 107, max_seq_len: 10\n",
      "French sentences:\n",
      "['bonjour.', 'au revoir.', 'merci beaucoup.', \"s'il vous plaît.\", 'comment allez-vous ?', 'je vais bien.', 'je suis fatigué.', 'je suis content.', 'quel est votre nom ?', 'mon nom est Jean.', 'enchanté de vous rencontrer.', 'bonne journée.', 'bonne soirée.', 'à demain.', \"j'aime le café.\", \"je n'aime pas le thé.\", 'quelle heure est-il ?', 'il est trois heures.', 'où est la gare ?', \"la gare est près d'ici.\", 'combien ça coûte ?', \"c'est trop cher.\", 'parlez-vous anglais ?', 'un peu.', 'je ne comprends pas.', 'pouvez-vous répéter ?', 'je suis désolé.', 'pas de problème.', 'bon appétit.', 'à votre santé.', \"j'ai faim.\", \"j'ai soif.\", \"il fait beau aujourd'hui.\", 'il pleut.', 'il fait froid.', 'il fait chaud.', 'je travaille ici.', 'où habitez-vous ?', \"j'habite à Paris.\", 'quel âge avez-vous ?', \"j'ai vingt-cinq ans.\", 'avez-vous des frères et soeurs ?', \"j'ai une soeur.\", \"j'ai un chat.\", \"j'aime voyager.\", 'je suis étudiant.', 'je suis professeur.', 'au secours !', 'joyeux anniversaire !', 'félicitations !']\n",
      "English sentences:\n",
      "['hello.', 'goodbye.', 'thank you very much.', 'please.', 'how are you?', 'i am fine.', 'i am tired.', 'i am happy.', 'what is your name?', 'my name is John.', 'nice to meet you.', 'have a nice day.', 'have a good evening.', 'see you tomorrow.', 'i like coffee.', \"i don't like tea.\", 'what time is it?', \"it is three o'clock.\", 'where is the train station?', 'the station is nearby.', 'how much is it?', \"it's too expensive.\", 'do you speak english?', 'a little.', \"i don't understand.\", 'can you repeat?', 'i am sorry.', 'no problem.', 'enjoy your meal.', 'cheers.', 'i am hungry.', 'i am thirsty.', 'the weather is nice today.', \"it's raining.\", \"it's cold.\", \"it's hot.\", 'i work here.', 'where do you live?', 'i live in Paris.', 'how old are you?', 'i am twenty-five years old.', 'do you have brothers and sisters?', 'i have a sister.', 'i have a cat.', 'i like to travel.', 'i am a student.', 'i am a teacher.', 'help!', 'happy birthday!', 'congratulations!']\n",
      "French tokenizer:\n",
      "{'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3, '.': 4, '?': 5, 'je': 6, 'vous': 7, '-': 8, \"j'\": 9, 'il': 10, 'est': 11, 'suis': 12, 'ai': 13, 'à': 14, 'aime': 15, 'pas': 16, 'fait': 17, '!': 18, 'au': 19, 'quel': 20, 'votre': 21, 'nom': 22, 'de': 23, 'bonne': 24, 'le': 25, 'où': 26, 'la': 27, 'gare': 28, 'ici': 29, 'un': 30, 'avez': 31, 'bonjour': 32, 'revoir': 33, 'merci': 34, 'beaucoup': 35, \"s'\": 36, 'plaît': 37, 'comment': 38, 'allez': 39, 'vais': 40, 'bien': 41, 'fatigué': 42, 'content': 43, 'mon': 44, 'jean': 45, 'enchanté': 46, 'rencontrer': 47, 'journée': 48, 'soirée': 49, 'demain': 50, 'café': 51, \"n'\": 52, 'thé': 53, 'quelle': 54, 'heure': 55, 'trois': 56, 'heures': 57, 'près': 58, \"d'\": 59, 'combien': 60, 'ça': 61, 'coûte': 62, \"c'\": 63, 'trop': 64, 'cher': 65, 'parlez': 66, 'anglais': 67, 'peu': 68, 'ne': 69, 'comprends': 70, 'pouvez': 71, 'répéter': 72, 'désolé': 73, 'problème': 74, 'bon': 75, 'appétit': 76, 'santé': 77, 'faim': 78, 'soif': 79, 'beau': 80, \"aujourd'hui\": 81, 'pleut': 82, 'froid': 83, 'chaud': 84, 'travaille': 85, 'habitez': 86, 'habite': 87, 'paris': 88, 'âge': 89, 'vingt': 90, 'cinq': 91, 'ans': 92, 'des': 93, 'frères': 94, 'et': 95, 'soeurs': 96, 'une': 97, 'soeur': 98, 'chat': 99, 'voyager': 100, 'étudiant': 101, 'professeur': 102, 'secours': 103, 'joyeux': 104, 'anniversaire': 105, 'félicitations': 106}\n",
      "English tokenizer:\n",
      "{'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3, '.': 4, 'i': 5, '?': 6, 'you': 7, 'am': 8, 'is': 9, 'a': 10, 'have': 11, \"it's\": 12, 'how': 13, 'nice': 14, 'like': 15, 'it': 16, 'the': 17, 'do': 18, '!': 19, 'much': 20, 'are': 21, 'happy': 22, 'what': 23, 'your': 24, 'name': 25, 'to': 26, \"don't\": 27, 'where': 28, 'station': 29, 'live': 30, 'old': 31, 'hello': 32, 'goodbye': 33, 'thank': 34, 'very': 35, 'please': 36, 'fine': 37, 'tired': 38, 'my': 39, 'john': 40, 'meet': 41, 'day': 42, 'good': 43, 'evening': 44, 'see': 45, 'tomorrow': 46, 'coffee': 47, 'tea': 48, 'time': 49, 'three': 50, \"o'\": 51, 'clock': 52, 'train': 53, 'nearby': 54, 'too': 55, 'expensive': 56, 'speak': 57, 'english': 58, 'little': 59, 'understand': 60, 'can': 61, 'repeat': 62, 'sorry': 63, 'no': 64, 'problem': 65, 'enjoy': 66, 'meal': 67, 'cheers': 68, 'hungry': 69, 'thirsty': 70, 'weather': 71, 'today': 72, 'raining': 73, 'cold': 74, 'hot': 75, 'work': 76, 'here': 77, 'in': 78, 'paris': 79, 'twenty': 80, '-': 81, 'five': 82, 'years': 83, 'brothers': 84, 'and': 85, 'sisters': 86, 'sister': 87, 'cat': 88, 'travel': 89, 'student': 90, 'teacher': 91, 'help': 92, 'birthday': 93, 'congratulations': 94}\n"
     ]
    }
   ],
   "source": [
    "# Verify all data\n",
    "print(f\"vocab_size_en: {vocab_size_en}, vocab_size_fr: {vocab_size_fr}\")\n",
    "print(f\"max_len_x: {max_len_x}, max_len_y: {max_len_y}, max_vocab_size: {max_vocab_size}, max_seq_len: {max_seq_len}\")\n",
    "print(\"French sentences:\")\n",
    "print(fr_sentences)\n",
    "print(\"English sentences:\")\n",
    "print(en_sentences)\n",
    "print(\"French tokenizer:\")\n",
    "print(fr_tokenizer.word_index)\n",
    "print(\"English tokenizer:\")\n",
    "print(en_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d2884d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  src_vocab_size=107,\n",
      "  tgt_vocab_size=95,\n",
      "  d_model=128,\n",
      "  n_heads=4,\n",
      "  n_encoder_layers=2,\n",
      "  n_decoder_layers=2,\n",
      "  d_ff=512,\n",
      "  dropout_rate=0.1,\n",
      "  max_sequence_length=10\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(\n",
    "    src_vocab_size=vocab_size_fr,\n",
    "    tgt_vocab_size=vocab_size_en,\n",
    "    d_model=128,\n",
    "    n_heads=4,\n",
    "    n_encoder_layers=2,\n",
    "    n_decoder_layers=2,\n",
    "    d_ff=512,\n",
    "    dropout_rate=0.1,\n",
    "    max_sequence_length=max_seq_len,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss_function=SequenceCrossEntropy(\n",
    "        label_smoothing=0.1,\n",
    "    ),\n",
    "    optimizer=Adam(\n",
    "        learning_rate=0.0001,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.98,\n",
    "        epsilon=1e-9,\n",
    "        clip_norm=1.0,\n",
    "    ),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3bdab93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial learning rate: 0.000100\n",
      "[==============================] 100% Epoch 1/50 - loss: 10.1493 -  - 0.30s\n",
      "Epoch 0 details:\n",
      "Loss: 10.1493\n",
      "Test translation: bonjour -> a ! <UNK> train please goodbye don't ! travel\n",
      "\n",
      "[==============================] 100% Epoch 2/50 - loss: 8.8985 -  - 0.28s\n",
      "Epoch 1 details:\n",
      "Loss: 8.8985\n",
      "Test translation: bonjour -> a ! understand train please goodbye don't ! travel\n",
      "\n",
      "[==============================] 100% Epoch 3/50 - loss: 7.3460 -  - 0.28s\n",
      "Epoch 2 details:\n",
      "Loss: 7.3460\n",
      "Test translation: bonjour -> a ! understand train please goodbye don't ! work\n",
      "\n",
      "[==============================] 100% Epoch 4/50 - loss: 5.7090 -  - 0.28s\n",
      "Epoch 3 details:\n",
      "Loss: 5.7090\n",
      "Test translation: bonjour -> a ! <UNK> train please goodbye don't ! work\n",
      "\n",
      "[==============================] 100% Epoch 5/50 - loss: 4.0713 -  - 0.29s\n",
      "Epoch 4 details:\n",
      "Loss: 4.0713\n",
      "Test translation: bonjour -> hungry don't <UNK> understand please a don't don't work\n",
      "\n",
      "[==============================] 100% Epoch 6/50 - loss: 3.6026 -  - 0.28s\n",
      "Epoch 5 details:\n",
      "Loss: 3.6026\n",
      "Test translation: bonjour -> a don't <UNK> understand please a don't don't work\n",
      "\n",
      "[==============================] 100% Epoch 7/50 - loss: 4.1277 -  - 0.28s\n",
      "Epoch 6 details:\n",
      "Loss: 4.1277\n",
      "Test translation: bonjour -> a don't <UNK> work please a don't don't work\n",
      "\n",
      "[==============================] 100% Epoch 8/50 - loss: 3.2000 -  - 0.28s\n",
      "Epoch 7 details:\n",
      "Loss: 3.2000\n",
      "Test translation: bonjour -> a don't <UNK> work please a don't i work\n",
      "\n",
      "[==============================] 100% Epoch 9/50 - loss: 3.5087 -  - 0.28s\n",
      "Epoch 8 details:\n",
      "Loss: 3.5087\n",
      "Test translation: bonjour -> a don't <UNK> a . a don't don't work\n",
      "\n",
      "[==============================] 100% Epoch 10/50 - loss: 3.7320 -  - 0.27s\n",
      "Epoch 9 details:\n",
      "Loss: 3.7320\n",
      "Test translation: bonjour -> a don't <UNK> a <UNK> a don't <UNK> work\n",
      "\n",
      "[==============================] 100% Epoch 11/50 - loss: 2.4294 -  - 0.26s\n",
      "Epoch 10 details:\n",
      "Loss: 2.4294\n",
      "Test translation: bonjour -> a don't <UNK> a <UNK> a don't <UNK> work\n",
      "\n",
      "[==============================] 100% Epoch 12/50 - loss: 2.8622 -  - 0.26s\n",
      "Epoch 11 details:\n",
      "Loss: 2.8622\n",
      "Test translation: bonjour -> a don't <UNK> a a a work <UNK> work\n",
      "\n",
      "[==============================] 100% Epoch 13/50 - loss: 2.0545 -  - 0.27s\n",
      "Epoch 12 details:\n",
      "Loss: 2.0545\n",
      "Test translation: bonjour -> a <UNK> <UNK> work <UNK> a work work work\n",
      "\n",
      "[==============================] 100% Epoch 14/50 - loss: 1.4897 -  - 0.27s\n",
      "Epoch 13 details:\n",
      "Loss: 1.4897\n",
      "Test translation: bonjour -> a <UNK> <UNK> work <UNK> a work work work\n",
      "\n",
      "[==============================] 100% Epoch 15/50 - loss: 1.4126 -  - 0.26s\n",
      "Epoch 14 details:\n",
      "Loss: 1.4126\n",
      "Test translation: bonjour -> work <UNK> <UNK> work work a work work work\n",
      "\n",
      "[==============================] 100% Epoch 16/50 - loss: 0.9722 -  - 0.28s\n",
      "Epoch 15 details:\n",
      "Loss: 0.9722\n",
      "Test translation: bonjour -> work <UNK> <UNK> work work a work work work\n",
      "\n",
      "[==============================] 100% Epoch 17/50 - loss: 0.7151 -  - 0.26s\n",
      "Epoch 16 details:\n",
      "Loss: 0.7151\n",
      "Test translation: bonjour -> work work work work work work work work work\n",
      "\n",
      "[==============================] 100% Epoch 18/50 - loss: 0.7346 -  - 0.27s\n",
      "Epoch 17 details:\n",
      "Loss: 0.7346\n",
      "Test translation: bonjour -> work work work work work work work work work\n",
      "\n",
      "[==============================] 100% Epoch 19/50 - loss: 0.6401 -  - 0.26s\n",
      "Epoch 18 details:\n",
      "Loss: 0.6401\n",
      "Test translation: bonjour -> work work work work work work work old work\n",
      "\n",
      "[==============================] 100% Epoch 20/50 - loss: 0.4304 -  - 0.25s\n",
      "Epoch 19 details:\n",
      "Loss: 0.4304\n",
      "Test translation: bonjour -> work work old work old work work old work\n",
      "\n",
      "[==============================] 100% Epoch 21/50 - loss: 0.4553 -  - 0.25s\n",
      "Epoch 20 details:\n",
      "Loss: 0.4553\n",
      "Test translation: bonjour -> old old old work old work work old work\n",
      "\n",
      "[==============================] 100% Epoch 22/50 - loss: 0.2841 -  - 0.25s\n",
      "Epoch 21 details:\n",
      "Loss: 0.2841\n",
      "Test translation: bonjour -> old old old work old work work old work\n",
      "\n",
      "[==============================] 100% Epoch 23/50 - loss: 0.2369 -  - 0.25s\n",
      "Epoch 22 details:\n",
      "Loss: 0.2369\n",
      "Test translation: bonjour -> old old old work old old old old work\n",
      "\n",
      "[==============================] 100% Epoch 24/50 - loss: 0.2137 -  - 0.25s\n",
      "Epoch 23 details:\n",
      "Loss: 0.2137\n",
      "Test translation: bonjour -> old old old old old old old old work\n",
      "\n",
      "[==============================] 100% Epoch 25/50 - loss: 0.1860 -  - 0.25s\n",
      "Epoch 24 details:\n",
      "Loss: 0.1860\n",
      "Test translation: bonjour -> old old old work old work work old work\n",
      "\n",
      "[==============================] 100% Epoch 26/50 - loss: 0.1587 -  - 0.25s\n",
      "Epoch 25 details:\n",
      "Loss: 0.1587\n",
      "Test translation: bonjour -> work work work work work work work work work\n",
      "\n",
      "[==============================] 100% Epoch 27/50 - loss: 0.1386 -  - 0.25s\n",
      "Epoch 26 details:\n",
      "Loss: 0.1386\n",
      "Test translation: bonjour -> work work work work work work work work work\n",
      "\n",
      "[==============================] 100% Epoch 28/50 - loss: 0.1211 -  - 0.25s\n",
      "Epoch 27 details:\n",
      "Loss: 0.1211\n",
      "Test translation: bonjour -> work work work work work work work work work\n",
      "\n",
      "[==============================] 100% Epoch 29/50 - loss: 0.1071 -  - 0.26s\n",
      "Epoch 28 details:\n",
      "Loss: 0.1071\n",
      "Test translation: bonjour -> work work work work work work work work work\n",
      "\n",
      "[==============================] 100% Epoch 30/50 - loss: 0.0931 -  - 0.27s\n",
      "Epoch 29 details:\n",
      "Loss: 0.0931\n",
      "Test translation: bonjour -> work work work work work work work work work\n",
      "\n",
      "[==============================] 100% Epoch 31/50 - loss: 0.0794 -  - 0.27s\n",
      "Epoch 30 details:\n",
      "Loss: 0.0794\n",
      "Test translation: bonjour -> work work work work work work work work work\n",
      "\n",
      "[==============================] 100% Epoch 32/50 - loss: 0.0664 -  - 0.26s\n",
      "Epoch 31 details:\n",
      "Loss: 0.0664\n",
      "Test translation: bonjour -> work work work work work work work work work\n",
      "\n",
      "[==============================] 100% Epoch 33/50 - loss: 0.0578 -  - 0.25s\n",
      "Epoch 32 details:\n",
      "Loss: 0.0578\n",
      "Test translation: bonjour -> work work work work work work work work work\n",
      "\n",
      "[==============================] 100% Epoch 34/50 - loss: 0.0524 -  - 0.26s\n",
      "Epoch 33 details:\n",
      "Loss: 0.0524\n",
      "Test translation: bonjour -> work work work work work work work work work\n",
      "\n",
      "[==============================] 100% Epoch 35/50 - loss: 0.0479 -  - 0.24s\n",
      "Epoch 34 details:\n",
      "Loss: 0.0479\n",
      "Test translation: bonjour -> work work work work work work work work work\n",
      "\n",
      "[==============================] 100% Epoch 36/50 - loss: 0.0450 -  - 0.25s\n",
      "Epoch 35 details:\n",
      "Loss: 0.0450\n",
      "Test translation: bonjour -> work work work work work work work work work\n",
      "\n",
      "[==============================] 100% Epoch 37/50 - loss: 0.0418 -  - 0.26s\n",
      "Epoch 36 details:\n",
      "Loss: 0.0418\n",
      "Test translation: bonjour -> work work work work work work work work work\n",
      "\n",
      "[==============================] 100% Epoch 38/50 - loss: 0.0396 -  - 0.26s\n",
      "Epoch 37 details:\n",
      "Loss: 0.0396\n",
      "Test translation: bonjour -> work work work work work work work work work\n",
      "\n",
      "[==============================] 100% Epoch 39/50 - loss: 0.0368 -  - 0.27s\n",
      "Epoch 38 details:\n",
      "Loss: 0.0368\n",
      "Test translation: bonjour -> work work work work work work work work work\n",
      "\n",
      "[==============================] 100% Epoch 40/50 - loss: 0.0343 -  - 0.25s\n",
      "Epoch 39 details:\n",
      "Loss: 0.0343\n",
      "Test translation: bonjour -> work work . work . work work work work\n",
      "\n",
      "[==============================] 100% Epoch 41/50 - loss: 0.0327 -  - 0.27s\n",
      "Epoch 40 details:\n",
      "Loss: 0.0327\n",
      "Test translation: bonjour -> . . . . . . . . .\n",
      "\n",
      "[==============================] 100% Epoch 42/50 - loss: 0.0318 -  - 0.26s\n",
      "Epoch 41 details:\n",
      "Loss: 0.0318\n",
      "Test translation: bonjour -> . . . . . . . . .\n",
      "\n",
      "[==============================] 100% Epoch 43/50 - loss: 0.0309 -  - 0.28s\n",
      "Epoch 42 details:\n",
      "Loss: 0.0309\n",
      "Test translation: bonjour -> . . . . . . . . .\n",
      "\n",
      "[==============================] 100% Epoch 44/50 - loss: 0.0284 -  - 0.24s\n",
      "Epoch 43 details:\n",
      "Loss: 0.0284\n",
      "Test translation: bonjour -> . . . . . . . . .\n",
      "\n",
      "[==============================] 100% Epoch 45/50 - loss: 0.0268 -  - 0.24s\n",
      "Epoch 44 details:\n",
      "Loss: 0.0268\n",
      "Test translation: bonjour -> . . . . . . . . .\n",
      "\n",
      "[==============================] 100% Epoch 46/50 - loss: 0.0253 -  - 0.24s\n",
      "Epoch 45 details:\n",
      "Loss: 0.0253\n",
      "Test translation: bonjour -> . . . . . . . . .\n",
      "\n",
      "[==============================] 100% Epoch 47/50 - loss: 0.0237 -  - 0.25s\n",
      "Epoch 46 details:\n",
      "Loss: 0.0237\n",
      "Test translation: bonjour -> . . . . . . . . .\n",
      "\n",
      "[==============================] 100% Epoch 48/50 - loss: 0.0231 -  - 0.24s\n",
      "Epoch 47 details:\n",
      "Loss: 0.0231\n",
      "Test translation: bonjour -> . . . . . . . . .\n",
      "\n",
      "[==============================] 100% Epoch 49/50 - loss: 0.0222 -  - 0.24s\n",
      "Epoch 48 details:\n",
      "Loss: 0.0222\n",
      "Test translation: bonjour -> . . . . . . . . .\n",
      "\n",
      "[==============================] 100% Epoch 50/50 - loss: 0.0208 -  - 0.25s\n",
      "Epoch 49 details:\n",
      "Loss: 0.0208\n",
      "Test translation: bonjour -> . . . . . . . . .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=12,\n",
    "    verbose=True,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='loss', patience=20),\n",
    "        LearningRateScheduler(schedule=\"warmup_cosine\", initial_learning_rate=0.0001, verbose=True),\n",
    "        DebugCallback(model, fr_tokenizer, en_tokenizer)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1dc335b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary sizes:\n",
      "French vocab size: 107\n",
      "English vocab size: 95\n",
      "\n",
      "==================================================\n",
      "Testing: je vais bien\n",
      "Translation: . . . . . . . . .\n",
      "\n",
      "==================================================\n",
      "Testing: comment allez-vous ?\n",
      "Translation: . . . . . . . . .\n",
      "\n",
      "==================================================\n",
      "Testing: bonjour\n",
      "Translation: . . . . . . . . .\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary sizes:\")\n",
    "print(f\"French vocab size: {len(fr_tokenizer.word_index)}\")\n",
    "print(f\"English vocab size: {len(en_tokenizer.word_index)}\")\n",
    "\n",
    "for sent in test_sentences:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Testing: {sent}\")\n",
    "    translation = translate(sent, model, fr_tokenizer, en_tokenizer, temperature=0.8)\n",
    "    print(f\"Translation: {translation}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
