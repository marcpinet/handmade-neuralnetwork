{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a036f9b8eee0491",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T00:29:31.303382900Z",
     "start_time": "2024-11-12T00:29:31.023112900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from neuralnetlib.models import Transformer\n",
    "from neuralnetlib.preprocessing import Tokenizer, pad_sequences\n",
    "from neuralnetlib.utils import train_test_split\n",
    "from neuralnetlib.losses import CrossEntropyWithLabelSmoothing\n",
    "from neuralnetlib.optimizers import Adam\n",
    "from neuralnetlib.callbacks import EarlyStopping, Callback, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfcb1593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text, transformer, fr_tokenizer, en_tokenizer, temperature: float = 1.0):\n",
    "    sequence = fr_tokenizer.texts_to_sequences([text], add_special_tokens=True)[0]\n",
    "\n",
    "    encoder_input = pad_sequences([sequence], max_length=transformer.max_sequence_length, padding='post', pad_value=transformer.PAD_IDX)\n",
    "    \n",
    "    output_sequence = transformer.predict(encoder_input, max_length=transformer.max_sequence_length, temperature=temperature)\n",
    "\n",
    "    output_tokens = output_sequence.tolist()\n",
    "    translated_text = en_tokenizer.sequences_to_texts(output_tokens)[0]\n",
    "    \n",
    "    return translated_text\n",
    "\n",
    "\n",
    "test_sentences = [\n",
    "    \"je suis fatigué\",\n",
    "    \"il fait froid\",\n",
    "    \"merci beaucoup\"\n",
    "]\n",
    "\n",
    "\n",
    "class DebugCallback(Callback):\n",
    "    def __init__(self, model, fr_tokenizer, en_tokenizer):\n",
    "        self.model = model\n",
    "        self.fr_tokenizer = fr_tokenizer\n",
    "        self.en_tokenizer = en_tokenizer\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch} details:\")\n",
    "        print(f\"Loss: {logs['loss']:.4f}\")\n",
    "        \n",
    "        for test in test_sentences:\n",
    "            translation = translate(test, self.model, self.fr_tokenizer, self.en_tokenizer)\n",
    "            print(f\"Test translation: {test} -> {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be237a3421e586a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T00:29:31.319383Z",
     "start_time": "2024-11-12T00:29:31.304382500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset.tsv\", sep=\"\\t\")\n",
    "df.iloc[:, 1] = df.iloc[:, 1].apply(lambda x: re.sub(r'\\\\x[a-fA-F0-9]{2}|\\\\u[a-fA-F0-9]{4}|\\xa0|\\u202f', ' ', x))  # remove unicode characters\n",
    "\n",
    "LIMIT = 1000\n",
    "fr_sentences = df.iloc[:, 1].values.tolist()[0:LIMIT]\n",
    "en_sentences = df.iloc[:, 3].values.tolist()[0:LIMIT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4c0d8598f0ba7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T00:29:31.350386300Z",
     "start_time": "2024-11-12T00:29:31.320384Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fr_tokenizer = Tokenizer(filters=\"\")  # else the tokenizer would remove the special characters including ponctuation\n",
    "en_tokenizer = Tokenizer(filters=\"\")  # else the tokenizer would remove the special characters including ponctuation\n",
    "\n",
    "fr_tokenizer.fit_on_texts(fr_sentences, preprocess_ponctuation=True)\n",
    "en_tokenizer.fit_on_texts(en_sentences, preprocess_ponctuation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67338439",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fr_tokenizer.texts_to_sequences(fr_sentences, preprocess_ponctuation=True, add_special_tokens=True)\n",
    "y = en_tokenizer.texts_to_sequences(en_sentences, preprocess_ponctuation=True, add_special_tokens=True)\n",
    "\n",
    "max_len_x = max(len(seq) for seq in X)\n",
    "max_len_y = max(len(seq) for seq in y)\n",
    "max_seq_len = max(max_len_x, max_len_y)\n",
    "\n",
    "vocab_size_fr = len(fr_tokenizer.word_index)\n",
    "vocab_size_en = len(en_tokenizer.word_index)\n",
    "max_vocab_size = max(vocab_size_fr, vocab_size_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5501a2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size_en: 1968, vocab_size_fr: 2251\n",
      "max_len_x: 95, max_len_y: 84, max_vocab_size: 2251, max_seq_len: 95\n",
      "French sentences:\n",
      "[\"Lorsqu'il a demandé qui avait cassé la fenêtre, tous les garçons ont pris un air innocent.\", 'Je ne supporte pas ce type.', 'Je ne supporte pas ce type.', 'Je ne supporte pas ce type.', 'Pour une fois dans ma vie je fais un bon geste... Et ça ne sert à rien.', \"Ne tenez aucun compte de ce qu'il dit.\", 'Essayons quelque chose !', \"Qu'est-ce que tu fais ?\", \"Qu'est-ce que c'est ?\", \"Qu'est-ce que c'est ?\", \"Qu'est-ce que c'est ?\", \"Aujourd'hui nous sommes le 18 juin et c'est l'anniversaire de Muiriel !\", 'Joyeux anniversaire Muiriel !', 'Muiriel a 20 ans maintenant.', 'Muiriel a 20 ans maintenant.', 'Le mot de passe est « Muiriel ».', 'Je serai bientôt de retour.', 'Je ne sais pas.', 'Je ne sais pas.', \"J'en perds mes mots.\", 'Ça ne va jamais finir.', 'Je ne sais simplement pas quoi dire...', 'Je ne sais simplement pas quoi dire...', 'C’était un méchant lapin.', \"J'étais dans les montagnes.\", \"Est-ce que c'est une photo récente ?\", \"Je ne sais pas si j'ai le temps.\", \"Pour une certaine raison le microphone ne marchait pas tout à l'heure.\", 'Tout le monde doit apprendre par soi-même en fin de compte.', \"L'éducation dans ce monde me déçoit.\", \"L'apprentissage ne devrait pas être forcé. L'apprentissage devrait être encouragé.\", \"C'est une tâche difficile, choisir ce qui est « bon » ou « mauvais », mais il faut le faire.\", 'Ça ne changera rien.', 'Ça ne changera rien.', 'Ça ne changera rien.', 'Ça coûtera 30 €.', 'Je gagne 100 € par jour.', 'Je gagne 100 € par jour.', \"Il se peut que j'abandonne bientôt et fasse une sieste à la place.\", \"C'est parce que tu ne veux pas être seul.\", \"Ça n'arrivera pas.\", 'Parfois il peut être un gars bizarre.', 'Je ferai de mon mieux pour ne pas perturber tes révisions.', \"Je ne peux que me demander si c'est la même chose pour tous les autres.\", \"Je suppose que c'est différent quand tu y penses à long terme.\", \"Ne t'inquiète pas.\", 'Tu me manques.', 'Je les appellerai demain quand je reviendrai.', 'Je les appellerai demain quand je reviendrai.', \"J'ai toujours plus apprécié les personnages mystérieux.\", 'Tu devrais dormir.', \"Je leur ai dit de m'envoyer un autre ticket.\", 'Tu es tellement impatiente avec moi.', 'Je ne peux pas vivre comme ça.', 'Il fut un temps où je voulais être astrophysicien.', \"Je n'ai jamais aimé la biologie.\", \"La dernière personne à qui j'ai raconté mon idée a pensé que j'étais cinglé.\", \"Si le monde n'était pas dans l'état où il est maintenant, je pourrais faire confiance à n'importe qui.\", \"C'est malheureusement vrai.\", \"C'est malheureusement vrai.\", \"Ils sont trop occupés à se battre entre eux pour s'occuper d'idéaux communs.\", 'La plupart des gens pensent que je suis fou.', \"Non je ne le suis pas, c'est toi qui l'es !\", \"C'est ma réplique !\", \"C'est ma réplique !\", 'Il me donne des coups de pied !', 'Est-ce que tu es sûr ?', 'Est-ce que tu es sûr ?', 'Alors il y a un problème...', 'Oh, il y a un papillon !', 'Dépêche-toi !', 'Dépêche-toi !', 'Dépêche-toi !', 'Ça ne me surprend pas.', 'Si je pouvais être comme ça...', \"Pour une raison que j'ignore, je me sens plus vivant la nuit.\", 'Ça dépend du contexte.', 'Est-ce que tu te fous de moi ? !', \"C'est la chose la plus stupide que j'ai jamais dite.\", 'Je ne veux pas être lamentable, je veux être cool ! !', 'Je ne veux pas être lamentable, je veux être cool ! !', 'Quand je serai grand, je veux être roi.', \"L'Amérique est un endroit charmant pour vivre, si c'est pour gagner de l'argent.\", 'Je suis si gros.', 'Je suis si gros.', 'Je suis si gros.', 'Et alors ?', 'Et alors ?', 'Et alors ?', 'Je vais le descendre.', \"Je ne suis pas un vrai poisson, je ne suis qu'une simple peluche.\", 'Je ne fais que parler !', \"C'était probablement ce qui a influencé leur décision.\", \"Je me suis toujours demandé ce que ça ferait d'avoir des frères et sœurs.\", \"C'est ce que j'aurais dit.\", \"Ça me prendrait l'éternité pour tout expliquer.\", \"C'est parce que tu es une fille.\", \"Parfois je ne peux pas m'empêcher de montrer des émotions.\", \"C'est un mot pour lequel j'aimerais trouver un substitut.\", \"Ce serait quelque chose qu'il faudrait que je programme.\", \"Il n'est pas dans mon intention d'être égoïste.\", 'Réfléchissons au pire qui pourrait arriver.', \"Combien d'amis proches est-ce que tu as ?\", 'Il se peut que je sois antisocial, mais ça ne veut pas dire pas que je ne parle pas aux gens.', \"C'est toujours tel que ça a été.\", \"Je pense que c'est mieux de ne pas être impoli.\", 'On peut toujours trouver du temps.', 'Je serais malheureux, mais je ne me suiciderais pas.', \"À l'époque du lycée je me levais à 6h tous les matins.\", \"Quand je me suis réveillé j'étais triste.\", 'Je pensais que tu aimais apprendre de nouvelles choses.', 'La plupart des gens écrivent à propos de leur vie quotidienne.', \"Si je pouvais t'envoyer un marshmallow, Trang, je le ferais.\", 'Pour faire cela, il te faut prendre des risques.', \"Chaque personne qui est seule est seule parce qu'elle a peur des autres.\", 'Pourquoi demandes-tu ?', 'Je ne peux pas lui dire maintenant. Ce n’est pas si simple.', 'Je ne peux pas lui dire maintenant. Ce n’est pas si simple.', 'Je suis une personne qui a des défauts, mais ces défauts peuvent être facilement corrigés.', \"Chaque fois que je trouve quelque chose que j'aime, c'est trop cher.\", 'Combien de temps es-tu restée ?', 'Peut-être que ce sera la même chose pour lui.', \"L'innocence est une belle chose.\", \"Les humains n'ont jamais été faits pour vivre éternellement.\", \"Je ne veux pas perdre mes idées, même si certaines d'entre elles sont un peu extrêmes.\", \"Je pense que j'ai une théorie à ce sujet.\", \"C'est intrigant.\", \"C'est intrigant.\", 'Tu es en train de dire que tu caches intentionnellement ta beauté ?', 'Je n’ai pas de compte sur ces forums.', \"Si quelqu'un devait demander quel est le but de l'histoire, je ne saurais vraiment pas.\", \"Je ne savais pas d'où ça venait.\", \"Je pense que le fait que j'ai vécu avec toi a influencé la façon dont tu vis.\", \"Je pense que le fait que j'ai vécu avec toi a influencé la façon dont tu vis.\", \"Ce n'est pas important.\", \"Ce n'est pas important.\", \"Je n'ai pas aimé.\", 'Elle demande comment c’est possible.', 'Tu ne fais que fuir les problèmes de la vie.', 'Si tu regardes les paroles, elles ne signifient pas vraiment grand-chose.', 'Il y a un problème que tu ne vois pas.', 'Tu peux le faire !', \"Mon prof de physique s'en fiche si je sèche les cours.\", \"J'aimerais bien pouvoir aller au Japon.\", 'Je déteste ça quand il y a trop de gens.', 'Je dois aller au lit.', \"Après ça, je pars, mais je me rends compte que j'ai oublié mon sac chez eux.\", \"Je ne t'en demanderai pas plus pour aujourd'hui.\", \"Il se peut qu'il gèle la semaine prochaine.\", \"Il se peut qu'il gèle la semaine prochaine.\", \"Même s'il s'est excusé, je suis encore en colère.\", 'La police vous fera trouver les balles.', \"Merci de m'avoir expliqué finalement pourquoi on me prend pour une imbécile.\", \"Ce n'était pas mon intention.\", \"Ce n'était pas mon intention.\", \"Ce n'était pas mon intention.\", 'Merci pour ton explication.', 'Théoriquement, je suis en train de faire des maths.', \"Qu'est-ce qui s'est passé ?\", \"Ça m'a presque fait peur de ne pas te voir connectée pendant toute une journée.\", 'Je ne sais pas ce que tu veux dire.', 'Il faut bien que mon ordinateur me serve à quelque chose.', 'Tu voulais me parler de liberté ?', \"Euh, là c'est vraiment bizarre...\", \"Si je voulais te faire peur, je te raconterais ce dont j'ai rêvé il y a quelques semaines.\", 'On ne peut pas tout attendre des écoles.', 'Il y a beaucoup de mots que je ne comprends pas.', \"Je n'aime pas quand les mathématiciens qui en savent beaucoup plus que moi ne savent pas s'exprimer explicitement.\", \"T'es vraiment pas bête.\", 'Je dois te poser une question idiote.', \"Je ne sais pas comment le démontrer vu que c'est trop évident !\", \"J'aurais pas imaginé qu'un jour j'irais chercher « viagra » dans Wikipédia.\", \"Est-ce qu'on peut formuler ça d'une autre manière ?\", 'Personne ne saura.', 'Personne ne saura.', \"J'ai trouvé une solution, mais je l'ai trouvée tellement vite que ça peut pas être la bonne.\", 'Ça me paraît intéressant !', \"Sauf que là, c'est pas si simple.\", \"Moi, j'aime bien la lumière des bougies.\", \"Qu'est-ce que tu as répondu ?\", \"Non, c'est pas mon nouveau petit ami.\", \"C'est dommage que je n'aie pas besoin de maigrir.\", \"T'as jamais cours ou quoi ? !\", 'Je vais donc jouer au Sudoku au lieu de continuer de te déranger.', 'Où est le problème ?', \"Je ne peux qu'attendre.\", \"Je ne peux qu'attendre.\", \"Ce n'est pas tellement une surprise, non ?\", \"Je t'aime !\", \"Je t'aime !\", \"Je t'aime !\", \"Je ne t'aime plus.\", \"Je ne t'aime plus.\", \"Je ne t'aime plus.\", \"Je ne t'aime plus.\", 'Je suis curieux.', 'Je suis curieux.', 'Félicitations.', 'Je ne veux pas attendre aussi longtemps.', 'Pourquoi ne viens-tu pas nous voir ?', 'Mais la possibilité semble improbable.', \"Je n'aurais pas dû me déconnecter.\", \"C'est inévitable que j'aille en France un jour, je ne sais juste pas quand.\", 'Je déteste la chimie.', 'Je ne voulais pas que ça arrive.', 'Je ne voulais pas que ça arrive.', 'Tu devines probablement ce qui va arriver.', 'Avant même que tu ne le saches, tu seras dans les journaux.', 'Quelles autres options ai-je ?', 'Quelles autres options ai-je ?', 'Je ne suis pas un grand voyageur.', \"Je n'ai rien de mieux à faire.\", \"Je ne peux pas l'expliquer non plus.\", \"Je ne peux pas l'expliquer non plus.\", 'Tout le monde a ses forces et ses faiblesses.', \"Mais sérieusement, l'épisode 21 m'a presque fait pleurer de rire.\", \"Ça montre seulement que tu n'es pas un robot.\", 'Comment pourrais-je être un robot ? Les robots ne rêvent pas.', \"« Je n'y ai jamais pensé », dit le vieil homme. « Que devrions-nous faire ? »\", \"Ce n'est pas quelque chose que n'importe qui peut faire.\", \"Je ne sais pas si je l'ai encore.\", \"Qu'est-ce que tu crois que j'étais en train de faire ?\", 'Ne sous-estime pas ma puissance.', 'Ne sous-estime pas ma puissance.', 'Ma maman ne parle pas très bien anglais.', 'Je ne parle pas assez bien français !', \"Je me demandais si tu allais venir aujourd'hui.\", \"C'est là que réside le problème.\", \"C'est là que réside le problème.\", \"Comment trouves-tu de la nourriture dans l'espace ?\", \"Vous n'avez rien à faire sauf vous faire confiance.\", 'Tout le monde veut te rencontrer, tu es célèbre !', \"Pourquoi es-tu désolée pour quelque chose que tu n'as pas fait ?\", \"Je déteste absolument l'écriture formelle !\", \"Les étrangers m'intriguent.\", 'Quoi que je fasse, elle dit que je peux faire mieux.', \"Qu'est-ce qui te retient éveillé si tard ?\", 'Tu serais surprise de ce que tu peux apprendre en une semaine.', \"Je n'ai personne qui veuille voyager avec moi.\", 'La vie est dure, mais je suis encore plus dur.', 'Supporter peut être insupportable.', \"Arrête ! Tu la mets mal à l'aise !\", \"Rien n'est beau que le vrai.\", 'Demain, il va alunir.', 'Je ne parle pas japonais.', 'C’est un jeu de mots.', 'Personne ne me comprend.', \"J'ai appris à vivre sans elle.\", 'Ça ne sert plus à rien de continuer à réfléchir.', \"J'ai trop de choses dans la tête ces jours-ci.\", 'Je voulais juste vérifier mes emails.', 'Est-ce que tu as vraiment besoin de poser la question pour connaître la réponse ?', 'Tu peux pas attendre de moi que je pense toujours à tout !', \"Je suppose que derrière chaque chose que l'on doit faire, il y a quelque chose que l'on veut faire...\", \"T'as vraiment pas les bonnes priorités !\", \"N'attends pas que les autres pensent pour toi !\", \"Tu n'as jamais le temps pour les choses importantes !\", \"Ce n'est pas la peine de faire semblant de me faire croire que je crois des choses que tu ne crois pas !\", \"Ça me prendrait trop de temps pour t'expliquer pourquoi ça ne va pas marcher.\", \"Je suis trop bête... J'essaie de t'expliquer des choses que je ne comprends pas moi-même.\", \"Arrête de me considérer comme quelqu'un de « normal » !\", \"Tu pourrais au moins essayer d'être un peu plus poli, même si ce n'est pas dans ta nature.\", \"Il y aura toujours des choses que je n'apprendrai jamais, je n'ai pas l'éternité devant moi !\", \"C'est pas possible !\", \"J'aimerais pouvoir m'inquiéter plus pour mes notes mais il semblerait qu'à un certain moment de ma vie, j'ai décidé que cela n'était finalement pas si important.\", \"« Pierre qui roule n'amasse pas mousse » est un proverbe.\", \"« Pierre qui roule n'amasse pas mousse » est un proverbe.\", 'Veux-tu quelque chose à boire ?', 'Veux-tu quelque chose à boire ?', \"« Qui est-ce ? » « C'est ta mère. »\", \"« Quand vas-tu revenir ? » « Tout dépend du temps qu'il fera. »\", \"« Qu'est-ce qui ne va pas ? » demanda le petit lapin blanc.\", \"« Qu'est-ce qu'il se passe dans la grotte ? Je suis curieux. » « Je n'en ai aucune idée. »\", \"« Qu'est-ce qu'il se passe dans la grotte ? Je suis curieux. » « Je n'en ai aucune idée. »\", 'Nous devons apprendre à vivre ensemble comme des frères, ou nous périrons ensemble comme des idiots.', 'Euh... Comment ça marche ?', 'Euh... Comment ça marche ?', \"« Pour être franc, j'ai le vertige. » « Tu es un trouillard ! »\", '« Fais-moi confiance », dit-il.', \"« C'est ce que j'étais en train de chercher », s'exclama-t-il.\", '« Ça semble très intéressant », dit Hiroshi.', 'Il se peut que leur communication soit beaucoup plus complexe que nous le pensions.', '« Le téléphone sonne. » « Je vais répondre. »', \"« C'est très gentil de votre part », répondit Willie.\", \"« Merci de m'aider. » « Il n'y a pas de quoi. »\", 'Un jour je courrai comme le vent.', '« Elle aime la musique. » « Moi aussi. »', \"S'il te plaît, ne pleure pas.\", \"Fais-moi savoir s'il y a quoi que ce soit que je puisse faire.\", \"Fais-moi savoir s'il y a quoi que ce soit que je puisse faire.\", 'Il se peut que le bonheur qui nous attend là-bas ne soit pas du tout le genre de bonheur que nous voudrions.', \"C'est à toi de décider si nous allons là-bas ou non.\", 'Ça ne commence pas avant huit heures trente.', 'Ça ne commence pas avant huit heures trente.', \"Je veux un bateau qui m'emmènera loin d'ici.\", \"Je veux un bateau qui m'emmènera loin d'ici.\", \"« J'ai envie de jouer aux cartes. » « Moi aussi. »\", \"« Ne nous sommes-nous pas rencontrés quelque part avant ? » demanda l'étudiant.\", 'Un Japonais ne ferait jamais une telle chose.', 'Allen est un poète.', \"L'archer tua le cerf.\", 'Le communisme ne sera jamais atteint de mon vivant.', 'Le seigle était appelé le grain de la pauvreté.', 'Dans les années 50, on citait les Finnois comme ayant les régimes alimentaires les moins sains du monde.', \"Si tu vois une faute alors corrige-la s'il te plaît.\", 'Place le jeu de cartes sur la table en bois de chêne.', 'Les Allemands sont très ingénieux.', 'Si on ne mange pas, on meurt.', 'Si on ne mange pas, on meurt.', 'Comment épelles-tu \"pretty\" ?', 'Et si nous retournions à la maison ?', \"Je m'excuse, je ne peux pas rester longtemps.\", '10 ans est une longue période à attendre.', \"« Pourquoi tu n'y vas pas ? » « Parce que je ne veux pas. »\", 'Un million de personnes ont perdu la vie pendant la guerre.', 'Je suis venu à Tokyo il y a trois ans et ai vécu ici depuis.', \"J'ai vécu plus d'un mois à Nagoya.\", \"J'ai vécu plus d'un mois à Nagoya.\", \"Ce n'est pas rare du tout de vivre plus de 90 ans.\", \"Ce n'est pas rare du tout de vivre plus de 90 ans.\", \"D'abord, je vais faire un schéma de mon nouveau site internet.\", \"La démocratie est la pire forme de gouvernement, mis à part toutes les autres que l'on a essayées.\", 'Quand on commence à ressembler à la photo de son passeport, on devrait partir en vacances.', 'Quand on commence à ressembler à la photo de son passeport, on devrait partir en vacances.', \"C'était pas moi, commissaire !\", 'Oh, mon pantalon blanc ! Il était neuf.', 'Avec autant de personnes autour de lui, il devint naturellement un peu nerveux.', \"En quittant la gare, j'ai vu un homme.\", 'Et personne ne vous a aidé ?', 'Et personne ne vous a aidé ?', \"T'es un ange !\", \"T'es un ange !\", 'Ils sont fous ces Madrilènes.', 'Ils sont fous ces Madrilènes.', \"Eh bien, la nuit est très longue, n'est-ce pas ?\", \"T'as eu de la chance parce qu'il ne t'a pas mordu.\", \"Je t'ai manqué ?\", 'Sont-ils tous identiques ?', 'Merci beaucoup !', 'Merci beaucoup !', 'Merci beaucoup !', 'Merci beaucoup !', 'Merci beaucoup !', \"S'il vous plaît, où sont les œufs ?\", 'Je le prends.', 'Je le prends.', \"C'est une surprise.\", 'C’est une bonne idée !', 'Aller-retour ? Aller simple seulement.', \"C'est dommage quand quelqu'un meurt.\", 'Ils restèrent bouche bée.', \"Putain ! C'est pas mal !\", 'Remettre en forme après lavage.', 'Laver avant de porter pour la première fois.', \"Ne pas ouvrir avant l'arrêt du train.\", \"Ne pas ouvrir avant l'arrêt du train.\", \"Ne pas ouvrir avant l'arrêt du train.\", 'Ceux qui habitent des maisons de verre ne devraient pas lancer de pierres.', \"On dit que l'amour est aveugle.\", 'Oh, je suis désolée.', \"Les maths sont comme l'amour - une idée simple, mais ça peut devenir compliqué.\", 'Les seules réponses utiles sont celles qui posent de nouvelles questions.', \"Douter de soi est le premier signe d'intelligence.\", \"Un pauvre n'est pas celui qui a trop peu, mais celui qui veut trop.\", \"Vu que tu n'es pas surpris, je pense que tu étais au courant.\", 'Combien de temps cela prend-il pour arriver à la station ?', 'Combien de temps cela prend-il pour arriver à la station ?', 'Ça sera un bon souvenir de mon voyage à travers les États-Unis.', \"Excusez-moi, permettez-moi de signaler trois erreurs dans l'article ci-dessus.\", \"C'est difficile d'entretenir une conversation avec quelqu'un qui ne dit que « oui » et « non ».\", 'Est-ce que tu parles italien ?', 'Je ne peux pas réfléchir avec ce bruit, dit-elle, en fixant des yeux la machine à écrire.', 'On dit que \"Hamlet\" est la pièce la plus intéressante qui ait jamais été écrite.', '« Maman, est-ce que je peux manger un biscuit ? » « Non. Il ne faut pas manger entre les repas. »', 'Puis-je poser une question ?', 'Comment te sens-tu ? demanda-t-il.', \"C'est assez difficile de maîtriser le français en 2, 3 ans.\", \"C'est impossible pour moi de te l'expliquer.\", 'Je ne veux pas passer le reste de ma vie à le regretter.', 'Ça serait marrant de voir comment les choses changent au fil des ans.', \"Je ne l'aurais jamais deviné.\", \"L'imagination affecte tous les aspects de notre vie.\", \"Tu m'oublieras un jour.\", \"C'est assez inattendu.\", 'Je me demande combien de temps ça va prendre.', 'Je ne peux pas vivre sans télé.', 'Je ne peux pas vivre sans télé.', \"Je n'aurais pas pu le faire sans toi. Merci.\", \"Rien n'est accompli sans effort.\", 'Beaucoup de gens vagabondent à travers la vie sans but.', \"Une vie sans amour n'a absolument aucun sens.\", \"Faites-moi savoir si j'ai besoin de faire des changements.\", \"Je pense que les examens ruinent l'éducation.\", 'Nous ne pouvons pas dormir à cause du bruit.', 'Est-ce que tu as un préservatif ?', 'Un chat ? demanda le vieil homme.', \"Fais tout ce qu'il te dit.\", \"Je peux aller à l'école à pied en 10 minutes.\", \"Je peux aller à l'école à pied en 10 minutes.\", \"Cela m'a pris plus de 2 heures pour traduire quelques pages d'anglais.\", 'Il est déjà 11 heures.', 'Puis-je parler à Mlle Brown ?', \"Oui, du jus d'orange s'il vous plait, dit Mike.\", 'Ah ! est une interjection.', 'Que veux-tu ?', \"Le caractère obligatoire de la scolarité est rarement analysé dans la multitude d'ouvrages consacrés à l'étude des divers moyens de développer chez les enfants un désir d'apprendre.\", 'Tu crains mon vieux ! Je dois tout te dire !', 'On a un compte à régler.', \"As-tu besoin que je te donne de l'argent ?\", 'Paris est la ville la plus belle du monde.', \"J'ai toujours pensé qu'avoir une crise cardiaque est la manière qu'a la nature de te dire que tu dois mourir.\", \"Eh, j'ai peut-être pas d'argent, mais j'ai toujours ma fierté.\", \"J'ai un rêve.\", \"C'est mon amie Rachel, nous sommes allées au lycée ensemble.\", 'Le coût de la vie a augmenté radicalement.', 'Le coût de la vie a augmenté radicalement.', 'Tout ce qui est inventé est vrai.', \"Se surprendre, s'étonner, c'est commencer à comprendre.\", \"Pas de doute : l'univers est infini.\", \"Il ne lui manquait qu'un seul défaut pour être parfaite.\", 'Et pourtant, le contraire aussi est toujours vrai.', 'Nous ne voyons pas les choses comme elles sont, mais comme nous sommes.', 'Le monde est une cage à fous.', 'Aucun écolier ne se plaint jamais d\\'avoir \"mal au lobe frontal de l\\'hémisphère gauche\" !', \"Tu m'as ouvert les yeux sur ce que c'est, lorsque tout va bien.\", \"Tu m'as trouvée où personne ne cherchait.\", 'Tu es à mes côtés, maintenant tout va bien.', 'Comment ça, tu ne sais pas ? !', \"T'as l'air stupide.\", \"Je pense que j'vais aller dormir.\", \"Je m'appelle Jack.\", \"Je m'appelle Jack.\", 'Ça me plaît beaucoup.', 'On se voit demain ?', 'On se voit demain ?', \"Comment est-ce qu'on dit ça en italien ?\", 'Je dois aller faire les courses, je reviens dans une heure.', \"Tu n'es pas assez rapide.\", \"C'est loin d'ici ?\", 'Ce ne sont pas mes affaires !', \"Merci, c'est tout.\", \"Merci, c'est tout.\", 'Veux-tu danser avec moi ?', 'Quelle heure est-il ?', \"Tu viens d'où ?\", \"Tu viens d'où ?\", \"Comment est-ce que tu t'appelles ?\", \"Comment est-ce que tu t'appelles ?\", \"Comment est-ce que tu t'appelles ?\", \"Comment est-ce que tu t'appelles ?\", \"L'Italie est un très beau pays.\", \"Ce n'est pas ma faute !\", 'J’aimerais rester pour une nuit.', 'Pourriez-vous composer le numéro pour moi ? Le téléphone est placé trop haut.', \"Est-ce qu'il y a une auberge de jeunesse près d'ici ?\", 'Où sont les douches ?', 'Ouvrez la bouche !', \"C'est grave ?\", \"C'est grave ?\", \"J'ai perdu mon portefeuille.\", \"J'ai perdu mon portefeuille.\", \"L'amour n'est jamais un gaspillage.\", \"La vie c'est ce qui se passe pendant que tu es occupé à faire d'autres plans.\", 'Ne pas désirer équivaut à posséder.', 'Il est très sexy.', 'Fiche-moi la paix !', \"« Passez-moi le sel s'il vous plaît. » « Tenez. »\", 'Il y a trop de choses à faire !', 'Quel âge as-tu ?', 'Quel âge as-tu ?', \"Allez, joue avec moi, j'm'ennuie trop !\", 'Ne songe même pas à manger mon chocolat !', 'Arrête de me demander à boire ! Va te servir toi-même.', \"Grâce à toi j'ai perdu mon appétit.\", \"J'ai vraiment besoin de frapper quelqu'un.\", 'Qui est-ce qui ne connaît pas ce problème ? !', 'Ça fait si longtemps depuis la dernière fois que je suis allée à Disneyland avec ma famille.', \"Mes parents n'arrêtent pas de se disputer sur des choses stupides. C'est tellement énervant !\", \"Si tu ne veux pas mettre de crème solaire c'est ton problème, mais ne viens pas te plaindre quand t'auras des coups de soleil.\", 'Mes amis disent toujours que je suis trop calme, mais ma famille dit toujours que je suis trop agaçante.', \"Je déteste ces araignées, elles sont toujours là pour me ficher la trouille quand j'fais le ménage.\", \"Trop énervant... J'peux même plus utiliser un ordinateur sans avoir mal à la tête maintenant !\", \"Il fait tellement chaud qu'on pourrait faire cuire des œufs sur le capot des voitures.\", \"Il fait tellement chaud qu'on pourrait faire cuire des œufs sur le capot des voitures.\", \"Aujourd'hui, il fait très chaud.\", \"Personne n'est venu.\", \"Personne n'est venu.\", \"Je n'ai jamais vu de réfrigérateur rouge.\", \"Je n'ai jamais vu de réfrigérateur rouge.\", \"Il n'a pas tenu sa parole.\", \"Il n'a pas tenu sa parole.\", \"Il n'a pas tenu sa parole.\", \"Il vaut mieux être détesté pour ce que l'on est, qu'aimé pour ce que l'on n'est pas.\", 'Ne sois pas inquiet, sois heureux !', \"L'écurie est bien vide depuis que le cheval est mort.\", \"Les mathématiques sont la partie des sciences qu'on pourrait continuer à faire si on se réveillait demain et découvrait que l'univers avait disparu.\", 'Mes yeux sont un océan dans lequel se reflètent mes rêves.', 'Vous connaissez la phrase, « on récolte ce que l’on sème. » Moi, j’ai semé le vent, maintenant voilà ma tempête.', 'Regarde-moi quand je te parle !', 'Que serait le monde sans les femmes ?', 'Et si tu faisais un discours et que personne ne venait ?', 'Je ne sais pas quoi dire pour te consoler.', \"Ce n'est pas mon type.\", \"J'essayais de tuer le temps.\", 'Comment en es-tu venu à cette idée folle ?', 'Je suis fatigué !', 'Je suis fatigué !', 'Je suis fatigué !', 'Qui veut du chocolat chaud ?', 'Qui veut du chocolat chaud ?', \"Parlez plus lentement s'il vous plaît !\", 'Je ne comprends pas.', 'Je ne comprends pas.', 'Je ne comprends pas.', 'Dans combien de temps arrivons-nous ?', 'Dans combien de temps arrivons-nous ?', \"L'addition s'il vous plaît.\", \"Et qu'est-ce que nous allons faire ?\", 'Où peut-on téléphoner ?', 'Je dois vous avouer que je ronfle...', \"Ce soir nous allons à l'église.\", 'Comment vas-tu ? As-tu fait un bon voyage ?', 'Je ne me sens pas bien.', 'Je ne me sens pas bien.', 'Je ne me sens pas bien.', 'Appelez la police !', \"C'est trop cher !\", \"Elle fait semblant de dormir, c'est pour ça qu'elle ne ronfle pas.\", \"Mes chaussures sont trop petites, j'en ai besoin de nouvelles.\", \"On s'tire d'ici, les flics arrivent.\", 'Joyeux Noël !', 'Ça serait trop cool si je pouvais parler dix langues !', \"« Si t'es fatigué, pourquoi ne vas-tu pas dormir ? » « Parce que si j'vais dormir tout de suite, je me réveillerai trop tôt. »\", \"Tu aurais dû m'écouter.\", \"C'est une pagaille totale, et ça me tape sur les nerfs.\", \"Quand le corps est touché, des récepteurs dans la peau envoient des messages au cerveau causant la libération de produits chimiques tels que l'endorphine.\", \"Qu'est-ce que cela implique ?\", \"On s'attend à ce que cent cinquante mille couples se marient à Shanghai en 2006.\", 'Ceux qui seront sélectionnés devront faire face à de considérables tests médicaux et psychologiques.', \"Un demi-million d'enfants font encore face à la malnutrition au Niger.\", 'Cela prendra cinq à dix ans avant que la technologie ne soit prête.', 'Cela prendra cinq à dix ans avant que la technologie ne soit prête.', \"Les bicyclettes sont un outil pour la préservation de l'environnement urbain.\", \"Le gouvernement français a lancé un jeu en ligne qui défie les contribuables d'équilibrer le budget national.\", \"Il serait ravi d'entendre ça.\", 'Que croyez-vous être vrai bien que vous ne puissiez le prouver ?', 'Les ordinateurs rendent les gens stupides.', \"Ne demandez pas ce qu'ils pensent. Demandez ce qu'ils font.\", \"Quand vous essayez de prouver quelque chose, ça aide de savoir que c'est vrai.\", \"Ce qui change le monde, c'est la communication, pas l'information.\", \"La plupart des avancées scientifiques ne sont rien d'autre que la découverte d'une évidence.\", \"Si vous ne comprenez pas quelque chose, c'est parce que vous n'êtes pas conscient de son contexte.\", 'On ne peut que connaître le passé, pas le changer. On ne peut que changer le futur, pas le connaître.', \"La question clé n'est pas qu'est-ce que je peux gagner mais qu'est-ce que j'ai à perdre.\", 'Tout ce qui peut être mal compris le sera.', 'Tout univers suffisamment simple pour être compris est trop simple pour produire un esprit capable de le comprendre.', 'Pourquoi la vie est-elle si remplie de souffrance ?', \"Malgré l'importance du sommeil, son intérêt est un mystère.\", \"Qu'est-ce que cela signifie d'avoir un esprit éduqué au XXIe siècle ?\", 'La passion crée de la souffrance.', 'Le train venant de Genève va entrer en gare.', 'Je voudrais lui offrir un cadeau pour son anniversaire.', 'Je meurs de faim !', 'Je meurs de faim !', 'Est-ce que tu as des copains en Antigua ?', 'Un mètre cube correspond à 1000 litres.', \"J'ai tellement de travail que je reste une heure de plus.\", \"Je suis mariée et j'ai deux enfants.\", 'Il joue très bien du piano.', 'Je le vois rarement.', 'Je le vois rarement.', \"J'aimerais faire mes études à Paris.\", 'Vous ne savez pas qui je suis.', 'Pourquoi est-ce que tu ne manges pas de légumes ?', 'Pourquoi est-ce que les gens vont au cinéma ?', 'Pourquoi est-ce que les gens vont au cinéma ?', 'Je me déshabille.', 'Je me déshabille.', \"La voiture s'écrasa contre le mur.\", \"Il n'y a pas de visions réelles.\", \"Ça ne sert à rien de me dire « Salut, comment ça va ? » si tu n'as rien d'autre à dire.\", 'Dans un dictionnaire comme celui-ci il devrait y avoir au moins deux phrases avec « réfrigérateur ».', 'Le créationnisme est une pseudo-science.', \"Le vent s'est calmé.\", \"Le vent s'est calmé.\", \"Le vent s'est calmé.\", \"Jeter le bébé avec l'eau du bain.\", 'Je ne veux pas demander ta main !', \"Donne-moi du temps pour te donner tout ce que j'ai !\", 'Un démocrate est un citoyen libre qui se plie à la volonté de la majorité.', \"Vouloir c'est pouvoir.\", 'Qui cherche, trouve.', \"Rome ne s'est pas faite en un jour.\", 'Qui ne dit mot consent.', \"« As-tu fini ? » « Au contraire, je n'ai même pas encore commencé. »\", '« Bonjour », dit Tom avec un sourire.', \"Pourquoi est-ce qu'on dit « Bonjour ! » quand le jour n'est pas bon ?\", \"Le vin, c'est de la poésie en bouteille.\", \"C'était le plus beau jour de ma vie.\", \"Je ne comprends pas l'allemand.\", \"J'ai pris ma décision.\", 'Je te donne ma parole.', 'Tu es le grand amour de ma vie.', 'On appelle « être objectif » le fait de ne pas divulguer le côté duquel on est.', 'Nous avons un Pape.', 'Un mathématicien est un homme qui ne comprend pas seulement une pensée qui lui est exposée, mais qui voit aussi sur quelle erreur de raisonnement elle est fondée.', 'Le tout vaut plus que la somme de ses parties.', 'Les mathématiques ne portent pas atteinte au désir.', \"Une vérité mathématique n'est ni simple ni compliquée, elle est.\", \"Les mathématiciens sont des poètes, sauf qu'ils doivent démontrer ce que leur fantaisie crée.\", 'Les mathématiques sont comme la logique de la physique.', 'Les mathématiciens sont comme les Français : quoi que vous leur disiez ils le traduisent dans leur propre langue et le transforment en quelque chose de totalement différent.', 'Les mathématiciens sont comme les Français : quoi que vous leur disiez ils le traduisent dans leur propre langue et le transforment en quelque chose de totalement différent.', \"Un expert est quelqu'un qui connaît quelques-unes des pires erreurs qui peuvent être faites dans son domaine, et comment les éviter.\", \"Faire des maths, c'est la seule façon socialement acceptable de se masturber en public.\", 'Il y a 10 sortes de gens dans le monde : ceux qui comprennent le binaire et ceux qui ne le comprennent pas.', 'Je ne pense pas, donc je ne suis pas.', 'Je ne pense pas, donc je ne suis pas.', 'De nos jours nous désirons que nos enfants prennent leurs propres décisions, mais nous voulons que ces décisions nous conviennent.', 'Je trouve les langues étrangères très intéressantes.', \"Je n'aime pas apprendre les verbes irréguliers.\", 'Prends un livre et lis-le !', 'Affronte la vie en souriant !', 'La plupart des écoles ont été conçues non pas pour transformer la société, mais pour la reproduire.', 'Tu me fais rêver.', 'Je suis fou de joie.', \"C'est déjà un homme.\", 'Les vacances sont finies maintenant.', \"J'ai peur de tomber.\", 'Une tenue de soirée est souhaitée.', \"C'est la pure vérité.\", 'Il fait froid.', 'Il fait froid.', \"J'ai soif.\", \"J'ai soif.\", \"Quand je demande aux gens ce qu'ils regrettent le plus concernant le lycée, ils répondent presque tous la même chose : qu'ils ont perdu tellement de temps.\", 'Quand on ne peut pas faire ce que l’on veut, on fait ce que l’on peut.', 'Donnez-lui la main, il vous prendra le bras.', 'Donnez-lui la main, il vous prendra le bras.', 'Tu as raison.', 'Tu as raison.', 'Tu as fait ça intentionnellement !', 'Tu ne lui as rien dit ?', 'Tu ne lui as rien dit ?', \"Tu m'as fait perdre la tête.\", 'Tu es mon type.', \"T'es irrésistible.\", \"Est-ce que tu pourrais retéléphoner plus tard s'il te plaît ?\", 'Je parle avec qui ?', \"J'accepte, mais à une condition.\", 'Souris maintenant, pleure plus tard !', 'À six ans il avait appris à se servir d’une machine à écrire et dit au maître qu’il n’avait pas besoin d’apprendre à écrire à la main !', 'La vie est belle.', 'Ne me gâche pas mon plaisir après tout le mal que je me suis donné.', \"Il y a des jours où j'ai l'impression que mon cerveau veut m'abandonner.\", 'Je ne peux pas me couper les ongles et faire le repassage en même temps !', \"Je n'en peux plus ! Ça fait trois jours que je n'ai pas dormi !\", \"Il n'a pas envie que tu lui racontes ta vie sexuelle.\", 'Tu as déjà mangé de la tarte à la banane ?', 'Pourquoi se marier avec une femme quand on aime les hommes ?', \"Si tu ne peux pas avoir d'enfants, tu peux toujours en adopter.\", \"Es-tu pour ou contre l'avortement ?\", \"Qu'est-ce qui t'a fait changer d'avis ?\", 'Eh regarde, un singe à trois têtes !', \"C'est dommage qu'on ne puisse pas acheter des miracles comme on achète des pommes de terre.\", \"J'adore les lasagnes.\", \"Quand on sait que quelque chose de désagréable va se passer, qu'on va aller chez le dentiste par exemple, ou en France, ce n'est pas bien.\", \"En fait, un demi-œil est très utile, parce qu'avec un demi-œil, un animal peut voir la moitié d'un autre animal qui veut le dévorer et s'écarter de son chemin, et il dévorera lui-même l'animal qui n'a qu'un demi-œil ou 49% d'un œil parce que celui-ci ne se sera pas écarté de son chemin assez vite, et l'animal qui a été dévoré n'aura pas de petits parce qu'il est mort.\", \"Les nombres premiers sont comme la vie, ils sont tout à fait logiques, mais il est impossible d'en trouver les règles, même si on consacre tout son temps à y réfléchir.\", \"Si on lève un sourcil, ça peut signifier « J'ai envie d'avoir des relations sexuelles avec toi » mais aussi « Je trouve que ce que tu viens de dire est complètement idiot. »\", \"Le cerveau n'est qu'une machine compliquée.\", \"Un emploi du temps, c'est une carte d'identité du temps, seulement, si on n'a pas d'emploi du temps, le temps n'est pas là.\", \"Ne désespère pas, tout n'est pas encore perdu.\", \"Je suis à l'hôpital. J'ai été frappé par la foudre.\", \"J'ai besoin que tu m'aides.\", 'Ce bébé pingouin est trop mignon !', \"Soyons réalistes, c'est impossible. On va jamais y arriver.\", \"Quelle est votre plus grande source d'inspiration ?\", \"On ne se marie pas avec quelqu'un avec qui on peut vivre - on se marie avec la personne sans qui on ne peut pas vivre.\", \"En théorie, il n'y a pas de différence entre la théorie et la pratique. Mais, en pratique, il y en a.\", \"Ne restez pas au lit, à moins que vous ne puissiez gagner de l'argent au lit.\", 'Il y a des gens dans le monde si affamés que Dieu ne peut pas leur apparaître, sauf sous forme de pain.', 'Tout ce qui est trop stupide pour être dit est chanté.', 'Tout ce qui est trop stupide pour être dit est chanté.', \"Il faut de la sagesse pour comprendre la sagesse : la musique n'est rien si le public est sourd.\", \"Je relisais les lettres que tu m'as envoyées.\", \"Je ne veux pas aller à l'école.\", \"C'est fini entre nous, rends-moi ma bague !\", 'Il pleut.', 'Il pleut.', \"J'avais prévu d'aller à la plage aujourd'hui, mais il a commencé à pleuvoir.\", \"Elle est vraiment intelligente, n'est-ce pas ?\", \"Une opinion n'est choquante que lorsque c'est une conviction.\", 'Les gens qui aiment ne doutent de rien, ou doutent de tout.', 'La justice coûte cher.', 'La liberté consiste à pouvoir faire tout ce qui ne nuit pas à autrui.', 'Le plus lent à promettre est toujours le plus fidèle à tenir.', \"Toute opinion est un mélange de vérité et d'erreur.\", 'La vie est une maladie mortelle sexuellement transmissible.', \"Si deux hommes ont toujours la même opinion, l'un d'eux est inutile.\", 'Notre opinion est une idée que nous avons ; notre conviction, une idée qui nous a.', 'Demain, je vais étudier à la bibliothèque.', 'Trop tard.', 'Je suis allée au zoo hier.', 'Nous avons gagné la bataille.', \"Allô ? T'es toujours là ?\", 'Je prépare le déjeuner tous les jours.', \"J'ai regardé la télé ce matin.\", \"J'ai lu un livre en mangeant.\", \"J'ai un peu dormi pendant la pause déjeuner parce que j'étais trop fatigué.\", \"J'ai commencé à apprendre le chinois la semaine dernière.\", \"C'est plus facile de draguer les gens sur internet que dans la rue.\", \"J'habite près de la mer donc j'ai souvent l'occasion d'aller à la plage.\", \"Un jour j'achèterai une machine à barbe-à-papa.\", \"C'est pratique d'avoir un ordinateur portable.\", 'Tes lunettes sont tombées par terre.', 'Combien de fois par jour te regardes-tu dans le miroir ?', \"Nous sommes allés à Londres l'année dernière.\", 'Elle ne veut pas en parler.', \"J'ai perdu mon inspiration.\", \"J'ai besoin de plus de temps.\", \"Si tu n'as rien à faire, regarde le plafond de ta chambre.\", 'Ça veut rien dire !', \"Sois patient s'il te plaît, ça prend du temps.\", 'Ferme la porte en sortant.', 'C’est une histoire tellement triste.', \"S'il n'y a pas de solution, alors il n'y a pas de problème.\", 'Mon petit frère regarde la télé.', 'Mon petit frère regarde la télé.', 'Il est présomptueux pour les humains de présumer que notre tâche est de faire ce que seul Dieu peut faire.', \"Un fin lecteur devrait être disposé à considérer tout ce qu'il lit, y compris les sources anonymes.\", \"Déniant qu'elle était une anarchiste, Katja soutenait qu'elle souhaitait seulement faire des changements dans notre gouvernement, pas le détruire.\", \"La cécité est responsable d'un nombre sidérant de problèmes de santé, de souffrance, et de perte de dignité et de diminution de la qualité de vie de personnes dans le monde entier.\", 'La formation et le mouvement des ouragans sont capricieux, même avec notre technologie contemporaine.', 'Quand on envoie un télégramme, la brièveté est essentielle car on est facturé à chaque mot.', \"David a un vif intérêt pour l'esthétique - les qualités qui rendent une peinture, une sculpture, une composition musicale ou un poème agréable à l'œil, à l'oreille ou à l'esprit.\", \"En dépit des déclarations d'amour régulières de Trang, Spenser a encore peur qu'elle cesse un jour de l'aimer.\", \"Tu l'as rencontré à l'université ?\", 'Aaah ! ! Mon ordinateur est cassé !', 'Les facultés et universités privées des États-Unis sont autonomes.', \"Chaque fois que je rejoins une partie de Warcraft, je suis opposé à une nouvelle équipe d'adversaires.\", \"Depuis que je sais que l'université existe, je veux y aller.\", 'Mon apathie pour le vote vient de mon aversion pour la politique.', 'L’ascendant des monarques est ce qui empêche une rébellion de leurs sujets.', 'Sarah était assez perspicace pour se rendre compte que ses amis essayaient de lui faire une farce.', \"L'orchestre produit des notes dissonantes lorsqu'il s'accorde.\", 'Oui, ça arrive de temps en temps.', \"J'ai une grande peur d'être méprisé par ceux que j'aime et à qui je tiens.\", \"La plupart des gens ont une grande réticence à sortir de leurs lits tôt, même s'ils le doivent.\", \"La plupart des gens ne veulent qu'entendre leur propre vérité.\", 'Le public a acclamé les acteurs pour leur représentation.', \"C'est bien d'avoir des idéaux... tu ne penses pas ?\", \"L'étudiant décida d'abréger son rapport en enlevant les détails inutiles.\", \"Les gens dans le monde se battent toujours pour plus de liberté et d'égalité.\", 'Les politiciens sont toujours sanctionnés pour leur comportement scandaleux ou déplacé.', 'Mme Eichler avait la fameuse réputation d’être austère avec ses élèves.', 'Si vous ne nous écoutez pas, il nous faudra avoir recours à la coercition.', \"Lorsque j'ai la migraine, l'aspirine ne soulage pas la douleur pour moi.\", \"Les remarques sarcastiques et de plaisanterie de Spenser sont souvent mal interprétées comme signes d'ambivalence et souvent prises trop au sérieux.\", 'Ma mère préfère la sélection arbitraire des machines de loterie à mes chiffres fétiches.', 'Pour lui, la faim était un concept abstrait ; il avait toujours suffisamment à manger.', 'La guerre en Irak est un sujet explosif de débat politique ; un mot de travers et une dispute enflammée pourrait éclater.', \"Mon voisin d'à côté est un virtuose dont les talents au piano lui ont valu un nom chez les experts musicaux.\", \"Il en avait assez d'être sans cesse diffamé par des gens qui étaient jaloux de ses capacités.\", \"Même les gens qui ne croient pas en l'église catholique vénèrent le Pape comme un leader symbolique.\", \"Ne sachant avec quel prétendant elle voulait se marier, la princesse hésitait, nommant tantôt l'un, tantôt l'autre.\", \"Avec le roi sans héritier devenant fou et la famille royale empoisonnée, le général de l'armée avait enfin sa chance d'usurper le trône.\", \"Au fur et à mesure que l'avion s'approchait de turbulences, le pilote demanda aux passagers à bord de l'avion d'attacher leurs ceintures de sécurité.\", \"Bien que son séjour en Europe fut éphémère, Spenser sentait qu'il avait beaucoup plus appris sur les interactions avec les autres en voyageant qu'il ne l'avait fait à l'université.\", \"Jason était un individu taciturne, c'était donc toujours une réelle surprise quand il disait quoique ce soit.\", 'Le roi en avait assez de ses courtisans le flattant toujours alors il les a renvoyés.', 'Si Spenser ne continue pas d’ajouter et de traduire des phrases, les autres contributeurs vont sûrement le dépasser.', 'Il y avait toujours trop de passages superficiels dans ses rédactions.', 'Sa rédaction ne donnait qu’une analyse superficielle du problème, donc ce fut pour lui une réelle surprise lorsqu’il obtint la meilleure note de la classe.', 'Cela dépend de ce que tu veux dire par « croire » en Dieu.', 'Les professeurs devraient tout expliquer en détail, ne pas être succincts et toujours dire à leurs étudiants de lire leurs livres quand ils rentrent chez eux.', \"Si je n’avais donné aucune réponse, je n'aurais pas parlé.\", \"Les gens qui viennent à l'émission de Maury Povich font souvent des déclarations prétentieuses sur leur partenaire les trompant.\", \"C'est une croyance répandue, d'après un sondage national aux États-Unis, que les musulmans sont liés au terrorisme.\", \"Les idées de Freud sur le comportement humain l'ont amené à être honoré en tant que profond penseur.\", \"Les boissons et la nourriture étaient servies avec une telle profusion au mariage que les jeunes mariés commencèrent à se demander s'ils n'auraient pas dû inviter plus de convives.\", \"La prolifération de l'utilisation d'Internet a donné naissance à une nouvelle génération de jeunes.\", 'Mes amis disent que je suis un écrivain prolifique, mais je n’ai rien écrit depuis des mois.', \"Les aveugles développent parfois une aptitude compensatoire à sentir la proximité des objets autour d'eux.\", \"Un avare amasse de l'argent non pas parce qu'il est prudent mais parce qu'il est avide.\", 'Lorsque les deux filles annoncèrent à John qu’elles avaient des sentiments envers lui, il ne savait pas avec quelle fille il devrait sortir.', \"Même maintenant, des années après la Guerre Froide, il y a encore beaucoup de rancoeur entre les Russes et les Allemands, en particulier dans les régions autrefois occupées par l'Union Soviétique.\", \"Johnson est un reclus ; il préfère s'isoler du reste des élèves de notre classe.\", 'Les professeurs doivent être fatigués de rectifier encore et encore les mêmes erreurs dans les copies de leurs élèves.', 'Les professeurs doivent être fatigués de rectifier encore et encore les mêmes erreurs dans les copies de leurs élèves.', 'Les bouteilles de bière que j’avais apporté à la fête étaient de trop ; la famille de notre hôte possédait une brasserie.', 'Les témoins ont pu réfuter le faux témoignage du suspect.', \"Jeanne d'Arc refusa de renoncer à sa conviction que les voix qu'elle entendait étaient de Dieu et nulle autre.\", \"Jeanne d'Arc refusa de renoncer à sa conviction que les voix qu'elle entendait étaient de Dieu et nulle autre.\", 'Choqués par les évènements du 11 septembre, des politiciens partout dans le monde condamnèrent les terroristes pour leur acte répréhensible.', 'James avait une grande peur de faire des erreurs en classe et d’être réprimandé.', \"Le proviseur réprouvait sévèrement les élèves chaque fois qu'ils mettaient le désordre dans le couloir.\", \"Mes parents renieraient mon frère s'ils venaient à découvrir qu'il était gay.\", 'Je voudrais revenir sur ma déclaration précédente.', 'Pour conquérir son audience, l’orateur a eu recours à des techniques rhétoriques qu’il a apprises dans ses cours de communication.', \"Son père n'aurait jamais approuvé ses fiançailles avec une fille qui ne partageait pas les mêmes croyances religieuses que sa famille.\", 'Tim est un énorme fan de comédie satirique.', \"La mère de Spenser le scrute souvent pour toutes les petites erreurs qu'il commet.\", 'Tous les sujets du roi, craignant son courroux, se comportaient souvent de manière très servile.', 'Les gens sont assez souvent sceptiques sur les choses sauf si on leur fournit une preuve crédible.', \"D'après l'expression sinistre du docteur, il était clair qu'il avait de sombres nouvelles pour le patient.\", 'Il a parfois des difficultés à exprimer clairement ses opinions.', 'Peter était un joueur de jeux vidéo altruiste ; il donnait des objets aux gens qui en avaient besoin, plutôt que de les vendre par intérêt personnel.', 'Jimmy essaya de persuader ses parents de le laisser traverser le pays en voiture avec ses amis.', \"Les artistes de pop prospèrent sur l'adulation de leurs fans fidèles.\", \"Nous devons apprendre à affronter l'adversité avec grâce.\", \"Bill Clinton parla dans un langage ambigu lorsqu'on lui a demandé de décrire sa relation avec Monica Lewinsky.\", \"C'était un vieil homme bienveillant qui se portait volontaire pour tondre la pelouse de ses voisins gratuitement.\", 'Son ton sévère et sa voix forte masquaient sa sensibilité intérieure et sa nature attentionnée.', \"La statue du Minute Man rend hommage aux vaillants soldats qui ont combattu pendant la guerre d'indépendance.\", 'Confus face aux remarques obscures de Sherlock Holmes, Watson se demandait si Holmes dissimulait intentionnellement ses vues sur le crime.', 'Quel critère avez-vous utilisé pour élire cet essai en tant que gagnant ?', 'Je ne sais pas danser un pas de salsa.', 'Même si tes phrases étaient effectivement vides de sens, au moins tu as la chance de savoir faire de belles phrases.', \"J'aime beaucoup mon travail.\", \"J'aime beaucoup mon travail.\", \"Ray était prêt à corroborer l'histoire de Gary, mais la police n'était toujours pas convaincue que l'un d'eux dise la vérité.\", 'Le meurtrier fut déclaré coupable et condamné à un emprisonnement à vie.', 'Parfois, les joueurs de hockey se provoquent tellement les uns les autres que des bagarres éclatent.', \"Il y avait une sensation de retenue dans la pièce ; personne n'osait dire au roi à quel point sa décision était insensée.\", \"Le consensus indique que nous sommes opposés à l'idée proposée.\", 'Un petit feu de forêt peut facilement se répandre et rapidement devenir un grand incendie.', 'Je trouve que les mots ayant des définitions précises sont les plus simples à retenir.', \"Il était encore furieux à propos de l'accident malgré les mots conciliants de sa femme.\", \"Un examen sommaire de ses dents indiqua qu'il avait la gingivite.\", 'Ce fut une surprise de voir tous les étudiants se comporter avec convenance le soir du bal de fin d’année.', \"L'article de journal décrivait l'accusé comme un coupable, bien qu'il avait été prouvé innocent.\", 'Le politicien fit pression pour une réforme en dénonçant la corruption des responsables gouvernementaux.', 'La dépravation du roi amena les gens à croire qu’il n’était rien d’autre qu’un tyran qu’il fallait renverser.', \"J'ai rêvé de toi.\", \"J'ai rêvé de toi.\", 'Il me faut un nouvel ordinateur.', 'Je ne perdrai pas !', \"J'étais en retard à l'école.\", 'Les cours reprennent bientôt.', 'Je crois que je vais éternuer... Passe-moi un mouchoir.', \"Pendant un moment, j'ai cru qu'il était devenu fou.\", 'Cette journée n’a été qu’un gâchis de temps et d’argent.', \"Ça m'a surpris, je ne savais pas quoi faire.\", \"Mais tu ne m'as jamais dit ça !\", \"J'ai changé la disposition de mon site.\", 'Quand on est petit, tout nous paraît si grand...', 'Il ne me battra pas.', \"Je dois faire le linge tant qu'il y a encore du soleil.\", \"Je me suis promenée, histoire de prendre l'air.\", \"Désolée, je ne pense pas que j'vais pouvoir.\", \"T'avais plein de temps.\", 'Arrête de me critiquer !', 'Allez ! Parle-moi Trang.', \"J'ai presque fini.\", \"J'ai presque fini.\", \"Prends l'autre chaise !\", 'Combien de sandwichs restent-ils ?', 'Je ne suis plus inspirée.', \"Je ne m'abaisserai pas à son niveau.\", \"Je ne m'abaisserai pas à son niveau.\", 'On pouvait voir le coucher du soleil depuis la fenêtre.', 'Ça me rend fou.', 'Ça me rend fou.', 'As-tu dit que je ne pourrais jamais gagner ?', 'Il fait tout noir dehors.', 'Il fait tout noir dehors.', \"Qu'est-ce qu'il s'est passé ? Il y a de l'eau partout dans l'appartement.\", 'Pendant les vacances d’été, je prenais mon dîner à minuit.', 'Tu peux finir ta rédaction maintenant.', 'Tu diras et feras des choses que tes parents disaient et faisaient, même si tu avais juré de ne jamais le faire.', 'Je suis vivant, bien que je ne donne pas signe de vie.', \"N'essaie jamais de mourir.\", 'Je suis trop vieux pour ce monde.', 'Je suis trop vieux pour ce monde.', 'La vie commence quand on se rend compte qui on est réellement.', 'La vie commence quand on décide ce qu’on attend d’elle.', 'La vie commence quand on paie des impôts.', 'Ce que tu n’as pas est mieux que ce que tu as.', 'La vie commence lorsque tu es prêt à la vivre.', \"Il n'est jamais trop tard pour apprendre.\", \"Il n'est jamais trop tard pour apprendre.\", 'Qui sont les idiots qui ont dit que les enseignants devraient préconiser plus de devoirs à la maison car les élèves ne travaillent pas assez ?', \"Il n'est que 5h du matin, et pourtant il fait jour.\", \"Il m'a raconté l'histoire de sa vie.\", \"Il m'a raconté l'histoire de sa vie.\", \"Je n'ai jamais dit que j'étais fragile.\", 'Je me demande si je suis faite pour ce monde.', 'De quoi parles-tu ?', 'De quoi parles-tu ?', 'De quoi parles-tu ?', 'Je veux un bonbon.', \"Je savais qu'aujourd'hui serait amusant.\", 'Un enfant n’est pas un vase à remplir, mais un feu à allumer.', \"Malheureusement, beaucoup de gens croiront des choses qu'on leur aura dites via un e-mail qu'ils ne trouveraient pas plausibles en face à face.\", 'Cela pourrait sembler tiré par les cheveux, mais c’est un réel problème.', 'La police est douée pour comprendre que quelqu\\'un a volé ma carte de crédit et a amassé plein d\\'argent. C\\'est beaucoup plus dur de leur faire avaler que \"quelqu\\'un a volé mon épée magique\".', \"Quand est-ce qu'on mange ? J'ai faim !\", \"Je n'aime pas l'école.\", \"J'ai cours demain.\", \"Je n'arrive pas à le croire !\", '« Merci. » « De rien. »', 'Comment tu prononces « pronounce » ?', 'L’hiver est ma saison préférée.', 'L’hiver est ma saison préférée.', \"C’est difficile d'avoir des idées géniales.\", 'De quel pays viens-tu ?', 'Les données suggèrent que la durée optimale d’un cours magistral serait de 30 au lieu de 60 minutes.', 'J’ai tendance à regarder les images avant de lire le texte.', \"J'ai beaucoup appris de toi.\", 'Nous avons beaucoup marché.', 'J’ai passé douze heures dans le train.', 'Elle est tombée malade ce week-end.', 'Attends, quelqu’un frappe à ma porte.', \"Il est riche, il n’a pas besoin d'argent !\", \"Ils font trop de bruit, je n'arrive pas à me concentrer.\", \"J’ai envie d’un massage. J'ai besoin de me détendre.\", 'Tu es malade, tu dois te reposer.', 'Il y a un passage secret à gauche.', \"Je n'ai pas que ça à faire.\", \"Smith a passé des années à étudier l'effet du sommeil et du manque de sommeil sur la mémoire et l'apprentissage.\", \"Elle demande l'impossible.\", 'Il a disparu sans laisser de trace.', 'Je peux placer la paume des mains sur le sol sans plier les genoux.', 'Il ne peut pas y avoir de progrès sans communication.', 'Tout le monde aimerait croire que les rêves peuvent devenir réalité.', 'La meilleure façon de réaliser ses rêves est de se réveiller.', 'Le monde ne tourne pas autour de toi.', 'Le monde est plein d’imbéciles.', 'Es-tu en train de dire que ma vie est en danger ?', 'As-tu une idée de ce à quoi ma vie ressemble ?', \"L'atmosphère de cet endroit est mystérieuse.\", 'J’attends avec impatience d’entendre votre opinion sur ce sujet.', 'Mais qu’est-ce que ça peut faire si je suis gay ? Est-ce que c’est un crime ?', 'Ma vie est vide sans lui.', 'Ma vie est vide sans lui.', 'Je ne veux pas louper mes examens.', 'Ma mère a acheté deux bouteilles de jus d’orange.', 'Elle portait un chapeau noir.', 'Nous avons fait des crêpes pour le petit-déjeuner.', \"Qu’as-tu mangé au déjeuner aujourd'hui ?\", \"Qu’as-tu mangé au déjeuner aujourd'hui ?\", 'J’ai passé tout l’après-midi à bavarder avec des amis.', 'Je veux être plus indépendant.', 'Est-ce que tu vas juste rester là debout toute la journée ?', 'Un lapin a de longues oreilles et une petite queue.', 'Mon cœur était rempli de joie.', 'Il souhaite effacer de mauvais souvenirs.', 'Monsieur, vous n’avez pas le droit de garer votre voiture ici.', \"Nous devons l'emmener d'urgence à l'hôpital, il est gravement blessé !\", 'Ton secret sera bien gardé.', \"Je ne veux plus t'entendre te plaindre.\", \"Dis-leur de m'appeler avant qu'ils ne partent.\", 'Tu aurais dû refuser une proposition aussi injuste.', 'Tu aurais dû refuser une proposition aussi injuste.', \"Je n'ai pas la force de continuer à essayer.\", 'Les mathématiques ne sont pas juste de la mémorisation de formules.', 'Je n’avais pas l’intention de te donner cette impression.', 'Je n’avais pas l’intention de te donner cette impression.', 'Ouais ! J’ai gagné deux fois de suite !', \"J'en ai marre de manger du fast-food.\", \"J'en ai marre d'en avoir marre.\", \"J'ai hâte de partir en vacances.\", 'Les chambres de cet hôtel sont vraiment très mal insonorisées. J’arrive à entendre mon voisin mâcher son chewing-gum !', 'L’essence des mathématiques, c’est la liberté.', 'Est-ce que tu peux imaginer ce que notre vie serait sans électricité ?', 'Un, deux, trois, quatre, cinq, six, sept, huit, neuf, dix.', 'Où sont les toilettes ?', 'Où sont les toilettes ?', 'Où sont les toilettes ?', 'Où sont les toilettes ?', 'Où sont les toilettes ?', 'Où sont les toilettes ?', 'L’essence de la liberté sont les mathématiques.', \"De combien d'heures de sommeil as-tu besoin ?\", 'Chaque personne est un monde.', 'La température du corps humain tourne en moyenne autour de 37°C.', \"Évite d’ouvrir la fenêtre, je n'ai pas trop envie de sentir de courants d’air dans mon dos.\", 'J’ai la nationalité française mais je suis d’origine vietnamienne.', 'Cette association humanitaire recherche des bénévoles pour distribuer des repas aux sans-abris pendant le mois de décembre.', \"C'est très frustrant d'essayer de retrouver ses lunettes quand on ne voit rien sans lunettes.\", \"Tu penses qu'un jour les hommes coloniseront la lune ?\", 'Quelles chansons célèbres auriez-vous aimé avoir composées, et pourquoi ?', 'Je vais m’acheter un nouvel appareil photo, numérique, cette fois.', 'Je suis fou de toi.', 'Je ne sais pas ce qui est pire.', \"La vie en prison est pire que la vie d'un animal.\", 'Je suis fier de faire partie de ce projet.', \"Est-il nécessaire d'élargir la connaissance de l'Homme à travers l'exploration de l'espace ?\", 'La beauté réside dans les yeux de celui qui regarde.', \"Qui achète ce genre d'œuvre d'art ?\", \"La NASA dit qu'elle possède déjà les informations suffisantes pour affirmer qu'une visite humaine de la planète rouge est faisable.\", 'Les vraies femmes ont des rondeurs.', 'Pourquoi ne pouvons-nous pas nous chatouiller nous-mêmes ?', 'La réponse nous mène à un cercle vicieux.', \"J'ai la flemme de faire mes devoirs.\", 'Quoi... ? Tu ne sais toujours pas conduire ?', 'Quoi... ? Tu ne sais toujours pas conduire ?', \"Demain c'est la rentrée ! Pour une fois, je suis pressé de retourner à l'école.\", 'Et avec moi nous sommes déjà un de plus.']\n",
      "English sentences:\n",
      "['Then, when he asked who had broken the window, all the boys acted innocent.', \"I can't abide that fellow.\", \"I can't bear that fellow.\", \"I can't stand that guy.\", \"For once in my life I'm doing a good deed... And it is useless.\", \"Don't take any notice of what he says.\", \"Let's try something.\", 'What are you doing?', 'What is it?', 'What is this?', \"What's this?\", \"Today is June 18th and it is Muiriel's birthday!\", 'Happy birthday, Muiriel!', 'Muiriel is 20 now.', 'Muiriel is 20, now.', 'The password is \"Muiriel\".', 'I will be back soon.', \"I don't know.\", \"I haven't got a clue.\", \"I'm at a loss for words.\", 'This is never going to end.', \"I just don't know what to say.\", \"I simply don't know what to say...\", 'That was an evil bunny.', 'I was in the mountains.', 'Is it a recent picture?', \"I don't know if I have the time.\", \"For some reason the microphone didn't work earlier.\", 'Everyone must learn on their own in the end.', 'Education in this world disappoints me.', 'Learning should not be forced. Learning should be encouraged.', 'It is a difficult task, choosing what is \"right\" or \"wrong\", but you have to do it.', \"That won't change anything.\", 'That will change nothing.', \"That doesn't change anything.\", 'This will cost €30.', 'I make €100 a day.', 'I make 100 euros per day.', 'I may give up soon and just nap instead.', \"It's because you don't want to be alone.\", \"That won't happen.\", 'Sometimes he can be a strange guy.', \"I'll do my best not to disturb your studying.\", 'I can only wonder if this is the same for everyone else.', \"I suppose it's different when you think about it over the long term.\", \"Don't worry.\", 'I miss you.', \"I'll call them tomorrow when I come back.\", \"I'll call them tomorrow when I return home.\", 'I always liked mysterious characters more.', 'You should sleep.', 'I told them to send me another ticket.', \"You're so impatient with me.\", \"I can't live that kind of life.\", 'I once wanted to be an astrophysicist.', 'I never liked biology.', 'The last person I told my idea to thought I was nuts.', \"If the world weren't in the shape it is now, I could trust anyone.\", 'It is unfortunately true.', \"Unfortunately, it's true.\", 'They are too busy fighting against each other to care for common ideals.', \"Most people think I'm crazy.\", \"No I'm not; you are!\", \"That's MY line!\", \"That's my line!\", \"He's kicking me!\", 'Are you sure?', 'Do you think so?', 'Then there is a problem...', \"Oh, there's a butterfly!\", 'Hurry up.', 'Hurry!', 'Make haste.', \"It doesn't surprise me.\", 'If I could be like that...', 'For some reason I feel more alive at night.', 'It depends on the context.', 'Are you freaking kidding me?!', \"That's the stupidest thing I've ever said.\", \"I don't want to be lame; I want to be cool!!\", \"I don't want to be lame, I want to be cool!!\", 'When I grow up, I want to be a king.', 'America is a lovely place to be, if you are here to earn money.', \"I'm so fat.\", \"I'm very fat.\", \"I'm extremely fat.\", 'So what?', 'Then what?', 'And then?', \"I'm gonna shoot him.\", \"I'm not a real fish, I'm just a mere plushy.\", \"I'm just saying!\", 'That was probably what influenced their decision.', \"I've always wondered what it'd be like to have siblings.\", 'This is what I would have said.', 'It would take forever for me to explain everything.', \"That's because you're a girl.\", \"Sometimes I can't help showing emotions.\", \"It's a word I'd like to find a substitute for.\", \"It would be something I'd have to program.\", \"I don't intend to be selfish.\", \"Let's consider the worst that could happen.\", 'How many close friends do you have?', \"I may be antisocial, but it doesn't mean I don't talk to people.\", 'This is always the way it has been.', 'I think it is best not to be impolite.', 'One can always find time.', \"I'd be unhappy, but I wouldn't kill myself.\", 'Back in high school, I got up at 6 a.m. every morning.', 'When I woke up, I was sad.', 'I thought you liked to learn new things.', 'Most people write about their daily life.', 'If I could send you a marshmallow, Trang, I would.', 'In order to do that, you have to take risks.', 'Every person who is alone is alone because they are afraid of others.', 'Why do you ask?', \"I can't tell her now. It's not that simple.\", \"I can't tell him now. It's not that simple.\", 'I am a flawed person, but these are flaws that can easily be fixed.', \"Whenever I find something I like, it's too expensive.\", 'How long did you stay?', 'Maybe it will be exactly the same for him.', 'Innocence is a beautiful thing.', 'Humans were never meant to live forever.', \"I don't want to lose my ideas, even though some of them are a bit extreme.\", 'I think I have a theory about that.', 'That is intriguing.', \"That's interesting.\", 'You are saying you intentionally hide your good looks?', 'I do not have an account in these forums.', \"If anyone was to ask what the point of the story is, I really don't know.\", \"I didn't know where it came from.\", 'I think my living with you has influenced your way of living.', 'I think that our living together has influenced your habits.', 'This is not important.', \"It's not important.\", \"I didn't like it.\", \"She's asking how that's possible.\", \"You're just running away from life's problems.\", \"If you look at the lyrics, they don't really mean much.\", \"There's a problem there that you don't see.\", 'You can do it.', \"My physics teacher doesn't care if I skip classes.\", 'I wish I could go to Japan.', 'I hate it when there are a lot of people.', 'I have to go to bed.', 'After that, I left, but then I realized that I forgot my backpack at their house.', \"I won't ask you anything else today.\", 'It may freeze next week.', 'We might have frost next week.', \"Even though he apologized, I'm still furious.\", 'The police will get you to find the bullets.', 'Thanks for having explained to me at last why people take me for an idiot.', \"That wasn't my intention.\", \"I didn't mean it.\", 'It was not my intention.', 'Thanks for your explanation.', \"Theoretically, I'm doing math.\", 'What happened?', 'It almost scared me not to see you online for a whole day.', \"I don't know what you mean.\", 'My computer has got to be useful for something.', 'You wanted to tell me about freedom?', \"Uh, now it's really weird...\", 'If I wanted to scare you, I would tell you what I dreamt about a few weeks ago.', \"One can't expect everything from schools.\", \"There are many words that I don't understand.\", \"I don't like it when mathematicians who know much more than I do can't express themselves explicitly.\", \"You're really not stupid.\", 'I need to ask you a silly question.', \"I don't know how to demonstrate it, since it's too obvious!\", 'I wouldn\\'t have thought I would someday look up \"Viagra\" in Wikipedia.', 'Can it be phrased in another way?', 'No one will know.', 'Nobody will know.', \"I found a solution, but I found it so fast that it can't be the right solution.\", 'It seems interesting to me.', \"Except that here, it's not so simple.\", 'I like candlelight.', 'What did you answer?', \"No, he's not my new boyfriend.\", \"It's too bad that I don't need to lose weight.\", 'You never have class or what?!', 'I will play Sudoku then instead of continuing to bother you.', 'Where is the problem?', 'I can only wait.', 'I can but wait.', \"It's not much of a surprise, is it?\", 'I love you.', 'I do love you.', 'I love you!', \"I don't like you anymore.\", \"I don't love you anymore.\", 'I no longer love you.', 'I no longer like you.', 'I am curious.', \"I'm curious.\", 'Congratulations!', \"I don't want to wait that long.\", \"Why don't you come visit us?\", 'But the possibility seems unlikely.', \"I shouldn't have logged off.\", \"It is inevitable that I go to France someday, I just don't know when.\", 'I hate chemistry.', \"I didn't want this to happen.\", \"I didn't want it to happen.\", 'You can probably guess what happens though.', \"Next thing you know, you'll be in the papers.\", 'What other options do I have?', 'What options do I have left?', 'I am not much of a traveller.', 'I have nothing better to do.', \"I can't explain it either.\", 'Neither can I explain it.', 'Everyone has strengths and weaknesses.', 'Seriously though, episode 21 made me almost cry while laughing.', \"It only shows you're not a robot.\", \"How could I be a robot? Robots don't dream.\", 'I have never thought about it, said the old man. \"What should we do?\"', \"It's not something anyone can do.\", \"I don't know if I still have it.\", \"What do you think I've been doing?\", \"Don't underestimate my power.\", 'Do not underestimate my power.', \"My mom doesn't speak English very well.\", \"I don't speak French well enough!\", 'I was wondering if you were going to show up today.', 'Therein lies the problem.', \"That's where the problem is.\", 'How do you find food in outer space?', 'All you can do is trust one another.', \"Everyone wants to meet you. You're famous!\", \"Why are you sorry for something you haven't done?\", 'I utterly despise formal writing!', 'Foreign people intrigue me.', 'Whatever I do, she says I can do better.', 'What keeps you up so late?', \"You'd be surprised what you can learn in a week.\", \"I don't have anyone who'd travel with me.\", 'Life is hard, but I am harder.', 'Bearing can be unbearable.', \"Stop it! You're making her feel uncomfortable!\", 'Nothing is beautiful but the truth.', 'Tomorrow, he will land on the moon.', \"I don't speak Japanese.\", 'This is a pun.', 'Nobody understands me.', 'I learned to live without her.', \"It's useless to keep on thinking any more.\", 'I have too many things on my mind these days.', 'I just wanted to check my email.', 'Do you really need to ask the question to know the answer?', \"You can't expect me to always think of everything!\", \"I suppose that behind each thing we have to do, there's something we want to do...\", \"You really don't have the right priorities!\", \"Don't expect others to think for you!\", 'You never have time for important things!', \"It's no use pretending to make me believe that I believe things you don't believe!\", \"It would take me too much time to explain to you why it's not going to work.\", \"I'm so dumb... I'm trying to explain things to you that I don't understand myself.\", 'Stop seeing me as a \"normal\" person!', \"You could at least try to be a bit more polite, even though it's not like you.\", \"There will always be things I will never learn, I don't have eternity before me!\", \"It can't be!\", \"I wish I could care more about my grades but it seems that, at a certain point of my life, I decided they wouldn't be so important anymore.\", 'A rolling stone gathers no moss is a proverb.', 'A rolling stone gathers no moss is a saying.', 'Would you like something to drink?', 'Want to drink something?', 'Who is it? \"It\\'s your mother.\"', 'When will you be back? \"It all depends on the weather.\"', \"What's the matter? asked the little white rabbit.\", 'What\\'s going on in the cave? I\\'m curious. \"I have no idea.\"', 'What\\'s happening in the cave? I\\'m curious. \"I have no idea.\"', 'We must learn to live together as brothers, or we will perish together as fools.', \"Uh... How's that working?\", 'Uh...how does this work?', 'To tell you the truth, I am scared of heights. \"You are a coward!\"', 'Trust me, he said.', 'This is what I was looking for! he exclaimed.', 'This looks pretty interesting, Hiroshi says.', 'Their communication may be much more complex than we thought.', 'The phone is ringing. \"I\\'ll get it.\"', \"That's very nice of you, Willie answered.\", 'Thank you for helping me. \"Don\\'t mention it.\"', \"Someday I'll run like the wind.\", 'She likes music. \"So do I.\"', \"Please don't cry.\", 'Let me know if there is anything I can do.', \"Let me know if there's anything I can do.\", 'It may be that the happiness awaiting us is not at all the sort of happiness we would want.', 'It is up to you to decide whether we will go there or not.', \"It doesn't start before eight thirty.\", \"It won't start before eight-thirty.\", 'I want a boat that will take me far away from here.', \"I want a boat that'll take me far away from here.\", 'I feel like playing cards. \"So do I.\"', \"Haven't we met somewhere before? asked the student.\", 'A Japanese would never do such a thing.', 'Allen is a poet.', 'The archer killed the deer.', 'Communism will never be reached in my lifetime.', 'Rye was called the grain of poverty.', \"In the 1950's, the Finns were cited as having one of the least healthy diets in the world.\", 'If you see a mistake, then please correct it.', 'Place the deck of cards on the oaken table.', 'The Germans are very crafty.', \"If you don't eat, you die.\", \"If you don't eat, you'll die.\", 'How do you spell \"pretty\"?', \"Why don't we go home?\", \"I'm sorry, I can't stay long.\", 'Ten years is a long time to wait.', 'Why aren\\'t you going? \"Because I don\\'t want to.\"', 'One million people lost their lives in the war.', 'I came to Tokyo three years ago and have been living here ever since.', 'I lived for more than a month in Nagoya.', 'I lived in Nagoya for over a month.', 'It is not rare at all to live over ninety years.', \"It's not at all rare to live to be over ninety years old.\", \"First, I'm going to do an outline of my new website.\", 'Democracy is the worst form of government, except all the others that have been tried.', \"When you're beginning to look like the photo in your passport, you should go on a holiday.\", \"When you start to look like the photo in your passport, it's time to go on vacation.\", \"It wasn't me, commissioner!\", 'Oh, my white pants! And they were new.', 'With so many people around he naturally became a bit nervous.', 'When I left the train station, I saw a man.', 'And no one helped you?', 'And nobody helped you?', \"You're an angel!\", \"You're an angel.\", 'People from Madrid are weird.', 'The people from Madrid are lunatics.', \"Well, the night is quite long, isn't it?\", \"You're lucky because he didn't bite you.\", 'Did you miss me?', 'Are they all the same?', 'Thank you very much!', 'Many thanks.', 'Thanks a lot!', 'Thank you very much.', 'Thanks very much.', 'Where are the eggs, please?', \"I'll take him.\", \"I'll take it.\", \"It's a surprise.\", \"That's a good idea!\", 'Round trip? Only one-way.', \"It's a pity when somebody dies.\", 'They were left speechless.', \"Damn! It's not bad!\", 'Pull into shape after washing.', 'Wash before first wearing.', \"Don't open before the train stops.\", 'Do not open while the train is in motion.', 'Do not open before the train stops.', 'Those who live in glass houses should not throw stones.', 'They say love is blind.', \"Oh, I'm sorry.\", 'Math is like love: a simple idea, but it can get complicated.', 'The only useful answers are those that raise new questions.', 'To have doubts about oneself is the first sign of intelligence.', 'Poor is not the one who has too little, but the one who wants too much.', \"Seeing that you're not surprised, I think you must have known.\", 'How long does it take to get to the station?', 'How long does it take to get to the train station?', 'This will be a good souvenir of my trip around the United States.', 'Excuse me; allow me to point out three errors in the above article.', 'It is difficult to keep up a conversation with someone who only says \"yes\" and \"no\".', 'Do you speak Italian?', \"I can't think with that noise, she said, as she stared at the typewriter.\", 'It is said that \"Hamlet\" is the most interesting play ever written.', 'Mom, please can I have a biscuit? \"No, you can\\'t; you shouldn\\'t eat between meals.\"', 'May I ask a question?', 'How do you feel? he inquired.', \"It's quite difficult to master French in 2 or 3 years.\", \"It's impossible for me to explain it to you.\", \"I don't want to spend the rest of my life regretting it.\", 'It would be fun to see how things change over the years.', 'I would never have guessed that.', 'Imagination affects every aspect of our lives.', \"You'll forget about me someday.\", 'That is rather unexpected.', \"I wonder how long it's going to take.\", \"I can't live without a TV.\", \"I can't live without TV.\", \"I couldn't have done it without you. Thank you.\", 'Nothing is achieved without effort.', 'Many people drift through life without a purpose.', 'Life without love is just totally pointless.', 'Let me know if I need to make any changes.', 'I think exams are ruining education.', \"We can't sleep because of the noise.\", 'Do you have a condom?', 'A cat? asked the old man.', 'Do whatever he tells you.', 'I can walk to school in 10 minutes.', 'I can walk to school in ten minutes.', 'It took me more than two hours to translate a few pages of English.', 'It is already eleven.', 'May I talk to Ms. Brown?', 'Yes, orange juice please, says Mike.', 'Ah! is an interjection.', 'What do you want?', 'The mandatory character of schooling is rarely analyzed in the multitude of works dedicated to the study of the various ways to develop within children the desire to learn.', 'You suck dude! I have to tell you everything!', 'I have a bone to pick with you.', 'Do you need me to give you some money?', 'Paris is the most beautiful city in the world.', 'I always thought that having a heart attack was the way nature told you to die.', 'Hey, I may have no money, but I still have my pride.', 'I have a dream.', 'This is my friend Rachel. We went to high school together.', 'The cost of life increased drastically.', 'The cost of living has increased drastically.', 'All that which is invented, is true.', 'To be surprised, to wonder, is to begin to understand.', \"There's no doubt: the universe is infinite.\", 'To be perfect she lacked just one defect.', 'And yet, the contrary is always true as well.', \"We don't see things as they are, but as we are.\", 'The world is a den of crazies.', 'No student has ever complained of pains in the front lobe of the left side of the brain.', \"You opened up my eyes to what it's like when everything is right.\", 'You found me where no one else was looking.', \"You're by my side; everything's fine now.\", \"What do you mean you don't know?!\", 'You look stupid.', \"I think I'm gonna go to sleep.\", 'My name is Jack.', \"My name's Jack.\", 'I like it very much.', \"We're meeting up tomorrow?\", 'Shall we meet tomorrow?', 'How do you say that in Italian?', \"I have to go shopping. I'll be back in an hour.\", \"You're not fast enough.\", 'Is it far from here?', \"These things aren't mine!\", \"Thanks, that's all.\", \"Thanks, that's everything.\", 'Do you want to dance with me?', 'What time is it?', 'Where do you come from?', 'Where are you from?', 'What is your name?', \"What's your name?\", 'What are you called?', 'What do we call you?', 'Italy is a very beautiful country.', \"It's not my fault!\", \"I'd like to stay for one night.\", 'Could you dial for me? The telephone is too high.', 'Is there a youth hostel near here?', 'Where are the showers?', 'Open your mouth!', 'Is it bad?', 'Is it important?', 'I have lost my wallet.', 'I lost my wallet.', 'Love is never wasted.', \"Life is what happens to you while you're busy making other plans.\", 'Not wanting is the same as having.', \"He's very sexy.\", 'Leave me alone!', 'Pass me the salt, please. \"Here you are.\"', 'There are too many things to do!', 'What is your age?', 'How old are you?', \"Come on, play with me, I'm so bored!\", \"Don't you even think of eating my chocolate!\", 'Stop asking me for a drink! Go get it yourself.', \"Thanks to you I've lost my appetite.\", 'I really need to hit somebody.', \"Who doesn't know this problem?!\", 'It has been so long since I last went to Disneyland with my family.', \"My parents keep arguing about stupid things. It's so annoying!\", \"If you don't want to put on sunscreen, that's your problem. Just don't come complaining to me when you get a sunburn.\", \"My friends always say I'm too calm, but my family always says I'm too annoying.\", \"I hate those spiders. They're always there to freak me out when I'm cleaning.\", 'So annoying... Now I get a headache whenever I use the computer!', \"It's so hot that you could cook an egg on the hood of a car.\", \"It's so hot outside, you could fry an egg.\", 'It is very hot today.', 'Nobody came.', 'No one came.', 'I never saw a red fridge.', 'I have never seen a red refrigerator.', 'He broke his word.', 'He did not keep his word.', \"He didn't keep his word.\", \"Better to be hated for who you are than loved for who you're not.\", \"Don't worry, be happy!\", \"It's lonely in the saddle since the horse died.\", 'Mathematics is the part of science you could continue to do if you woke up tomorrow and discovered the universe was gone.', 'My eyes are an ocean in which my dreams are reflected.', 'You know the phrase, we reap what we sow. I have sown the wind and this is my storm.', 'Look at me when I talk to you!', 'What would the world be without women?', 'What if you gave a speech and nobody came?', \"I don't know what to say to make you feel better.\", 'This is not my type.', 'I was trying to kill time.', 'How did you come up with this crazy idea?', \"I'm tired.\", 'I am tired.', 'I am tired!', 'Who wants some hot chocolate?', 'Who wants hot chocolate?', 'Speak more slowly, please!', \"I don't get it.\", 'I do not understand.', \"I don't understand.\", 'When do we arrive?', 'When will we arrive?', 'The check, please.', 'And what are we going to do?', 'Where can one make a phone call?', 'I must admit that I snore.', \"Tonight we're going to church.\", 'How are you? Did you have a good trip?', \"I don't feel well.\", \"I'm not feeling well.\", 'I feel unwell.', 'Call the police!', \"It's too expensive!\", \"She's faking sleep. That's why she's not snoring.\", 'My shoes are too small. I need new ones.', \"We're getting out of here. The cops are coming.\", 'Merry Christmas!', 'It would be so cool if I could speak ten languages!', 'If you\\'re tired, why don\\'t you go to sleep? \"Because if I go to sleep now I will wake up too early.\"', 'You should have listened to me.', \"It's a complete mess, and it's getting on my nerves.\", 'When the body is touched, receptors in the skin send messages to the brain causing the release of chemicals such as endorphins.', 'What does it involve?', 'One hundred and fifty thousand couples are expected to get married in Shanghai in 2006.', 'Those selected will have to face extensive medical and psychological tests.', 'Half a million children still face malnutrition in Niger.', 'It will take five to ten years for the technology to be ready.', 'It will be five or ten years before the technology is ready.', 'Bicycles are tools for urban sustainability.', 'The French government has launched an online game that challenges taxpayers to balance the national budget.', 'He would be glad to hear that.', 'What do you believe is true even though you cannot prove it?', 'Computers make people stupid.', \"Don't ask what they think. Ask what they do.\", \"When you're trying to prove something, it helps to know it's true.\", 'What changes the world is communication, not information.', 'Most scientific breakthroughs are nothing else than the discovery of the obvious.', \"If you don't understand something, it's because you aren't aware of its context.\", 'The past can only be known, not changed. The future can only be changed, not known.', 'The key question is not what can I gain but what do I have to lose.', 'Anything that can be misunderstood will be.', 'Any universe simple enough to be understood is too simple to produce a mind able to understand it.', 'Why is life so full of suffering?', 'Despite the importance of sleep, its purpose is a mystery.', 'What does it mean to have an educated mind in the 21st century?', 'Passion creates suffering.', 'The train from Geneva will arrive at the station.', 'I would like to give him a present for his birthday.', \"I'm starving!\", \"I'm starved.\", 'Do you have friends in Antigua?', 'A cubic meter corresponds to 1000 liters.', 'I have so much work that I will stay for one more hour.', 'I am married and have two children.', 'He plays the piano very well.', 'I see it rarely.', 'I seldom see him.', \"I'd like to study in Paris.\", \"You don't know who I am.\", \"Why don't you eat vegetables?\", 'Why do people go to the movies?', 'Why do people go to the cinema?', \"I'm undressing.\", 'I am undressing.', 'The car crashed into the wall.', 'There are no real visions.', 'There\\'s no point saying \"Hi, how are you?\" to me if you have nothing else to say.', 'In a dictionary like this one there should be at least two sentences with \"fridge\".', 'Creationism is a pseudo-science.', 'The wind calmed down.', 'The wind died away.', 'The wind has died down.', 'To throw the baby out with the bath-water.', \"I don't want to propose to you!\", 'Give me time to give you everything I have!', 'A democrat is a free citizen who yields to the will of the majority.', \"Where there's a will, there's a way.\", 'Who searches, finds.', \"Rome wasn't built in a day.\", 'Silence gives consent.', 'Have you finished? \"On the contrary, I have not even begun yet.\"', 'Good morning, said Tom with a smile.', 'Why does one say \"Good day\" when the day is not good?', 'Wine is poetry in bottles.', 'That was the best day of my life.', \"I don't understand German.\", 'I made my decision.', 'I give you my word.', 'You are the great love of my life.', 'Being objective means not telling everybody whose side you are on.', 'We have a Pope.', 'A mathematician is a man who not only understands the idea put forth before him, but who sees as well the error in its foundations.', 'The whole is greater than the sum of the parts.', 'Mathematics is not detrimental to the appetite.', 'A mathematical truth is neither simple nor complicated; it is.', 'Mathematicians are poets, except that they have to prove what their fantasy creates.', 'Mathematics is like the logic of physics.', 'Mathematicians are like French people: whatever you tell them they translate it into their own language and turn it into something totally different.', \"Mathematicians have this in common with the French: whatever you're trying to say to them, they take it and translate it in their own way and turn it around into something completely different.\", 'An expert is someone who knows some of the worst mistakes that can be made in his field, and how to avoid them.', 'Doing math is the only socially acceptable way to masturbate in public.', \"There are 10 types of people in the world: those who understand binary, and those who don't.\", \"I don't think, therefore I am not.\", \"I don't think, therefore I do not follow.\", 'Nowadays we want our children to make their own decisions, but we expect those decisions to please us.', 'I find foreign languages very interesting.', \"I don't like learning irregular verbs.\", 'Take a book and read it.', 'Face life with a smile!', 'Most schools were designed not to transform society, but to reproduce it.', 'You make me dream.', \"I'm beside myself with joy.\", \"He's already a man.\", 'The vacation is over now.', \"I'm afraid to fall.\", 'Evening dress is desired.', \"That's the absolute truth.\", \"It's cold.\", 'It is cold.', \"I'm thirsty.\", 'I am thirsty.', 'When I ask people what they regret most about high school, they nearly all say the same thing: that they wasted so much time.', \"When you can't do what you want, you do what you can.\", \"Give him an inch and he'll take a yard.\", \"If you give him an inch, he'll take a mile.\", \"You're right.\", 'You are right.', 'You did this intentionally!', \"You didn't tell him anything?\", \"You didn't tell her anything?\", 'You made me lose my mind.', \"You're my type.\", \"You're irresistible.\", 'Could you call again later, please?', 'Who am I talking with?', 'I accept, but only under one condition.', 'Smile now, cry later!', 'At the age of six he had learned to use the typewriter and told the teacher that he did not need to learn to write by hand.', 'Life is beautiful.', \"Don't ruin my fun after all the pain that I put myself through.\", 'There are days where I feel like my brain wants to abandon me.', \"I can't cut my nails and do the ironing at the same time!\", \"I can't take it anymore! I haven't slept for three days!\", \"He doesn't want you to tell him about your sex life.\", 'Have you ever eaten a banana pie?', 'Why would you marry a woman if you like men?', \"If you can't have children, you could always adopt.\", 'Are you for or against abortions?', 'What made you change your mind?', 'Hey, look, a three-headed monkey!', \"It's a pity that you can't buy miracles like you would buy potatoes.\", 'I love lasagna.', 'If you know that something unpleasant will happen, that you will go to the dentist for example, or to France, then that is not good.', 'Half an eye is very useful actually, because an animal can see half of another animal, which wants to eat it, and can get out of the way, and it will eat the animal, which has only one-half eye or only 49% of an eye, because this to it will not be enough, and the animal, which was eaten up, will have no children, because it is dead.', 'Prime numbers are like life; they are completely logical, but impossible to find the rules for, even if you spend all your time thinking about it.', 'If you raise an eyebrow, it can mean \"I want to have sex with you\", but also \"I find that what you just said is completely idiotic.\"', 'The brain is just a complicated machine.', \"A schedule is an identity card for time, but, if you don't have a schedule, the time isn't there.\", 'Do not despair, all is not yet lost.', \"I'm at the hospital. I got struck by lightning.\", 'I need your help.', 'This baby penguin is too cute!', \"Let's face it, it's impossible. We're never gonna make it.\", 'What is your greatest source of inspiration?', \"You don't marry someone you can live with — you marry the person whom you cannot live without.\", 'In theory, there is no difference between theory and practice. But, in practice, there is.', \"Don't stay in bed, unless you can make money in bed.\", 'There are people in the world so hungry, that God cannot appear to them except in the form of bread.', 'Anything that is too stupid to be spoken is sung.', 'Everything that is too stupid to say, is sung.', 'It requires wisdom to understand wisdom: the music is nothing if the audience is deaf.', 'I was rereading the letters you sent to me.', \"I don't want to go to school.\", \"It's over between us. Give me back my ring!\", 'It is raining.', \"It's raining.\", 'I was planning on going to the beach today, but then it started to rain.', \"She's really smart, isn't she?\", 'An opinion is shocking only if it is a conviction.', 'People who love doubt nothing, or doubt everything.', 'Justice is expensive.', 'Liberty consists of being able to make everything as harmless as possible.', 'The slowest one to make a promise is the most faithful one in keeping it.', 'Every opinion is a mixture of truth and mistakes.', 'Life is a fatal sexually transmitted disease.', 'If two men always have the same opinion, one of them is unnecessary.', 'Our opinion is an idea which we have; our conviction an idea which has us.', \"Tomorrow, I'm going to study at the library.\", 'Too late.', 'I went to the zoo yesterday.', 'We won the battle.', 'Hello? Are you still here?', 'I make lunch every day.', 'I watched TV this morning.', 'I read a book while eating.', 'I slept a little during lunch break because I was so tired.', 'I started learning Chinese last week.', 'It is easier to hit on people on the Internet than in the street.', 'I live near the sea, so I often get to go to the beach.', 'Someday I will buy a cotton candy machine.', \"It's practical to have a laptop.\", 'Your glasses fell on the floor.', 'How many times a day do you look at yourself in the mirror?', 'We went to London last year.', \"She doesn't want to talk about it.\", 'I lost my inspiration.', 'I need more time.', \"If you don't have anything to do, look at the ceiling of your room.\", \"It doesn't mean anything!\", 'Be patient please. It takes time.', 'Close the door when you leave.', 'This is such a sad story.', \"If there's no solution, then there's no problem.\", 'My little brother is watching TV.', 'My younger brother is watching TV.', \"It's presumptuous for humans to assume that our task is to do what only God can do.\", 'An astute reader should be willing to weigh everything they read, including anonymous sources.', 'Denying she was an anarchist, Katja maintained she wished only to make changes in our government, not to destroy it.', 'Blindness is responsible for a staggering toll of poor health, suffering, and loss of dignity and diminution in the quality of lives of people worldwide.', 'The formation and movement of hurricanes are capricious, even with our present-day technology.', 'When you send a telegram, brevity is essential because you will be charged for every word.', 'David has a keen interest in aesthetics — the qualities that make a painting, sculpture, musical composition, or poem pleasing to the eye, ear, or mind.', \"Despite Trang's constant affirmations of love, Spenser is still afraid someday she will fall out of love with him.\", 'You met him at the university?', 'Aaah!! My computer is broken!', 'The private colleges and universities of the United States are autonomous.', 'Every time I join a new game of Warcraft, I am pitted against a new team of adversaries.', \"From the moment that I knew that the university existed, I've wanted to go there.\", 'My apathy for voting comes from my distaste for politics.', 'The ascendancy of monarchs is what keeps their subjects from rebellion.', 'Sarah was discerning enough to realize that her friends were trying to prank her.', 'The orchestra makes discordant noises when tuning up.', 'Yes, it happens from time to time.', 'I have a great fear of being disdained by those I love and care about.', 'Most people have a great disinclination to get out of bed early, even if they have to.', 'Most people only want to hear their own truth.', 'The audience acclaimed the actors for their performance.', \"It is good to have ideals... don't you think?\", 'The student decided to abridge his paper by taking out unnecessary details.', 'People in the world are always advocating for more freedom and equality.', 'Politicians are always censured for outrageous or inappropriate behavior.', 'Ms. Eichler had a notorious reputation for being austere to her students.', \"If you don't listen to us, we will have to resort to coercion.\", \"When I have migraines, aspirin doesn't alleviate the pain for me.\", \"Spenser's sarcastic and joking remarks are often misinterpreted as signs of ambivalence and often taken too seriously.\", 'My mother prefers the arbitrary selection of the lottery machines over my lucky numbers.', 'To him, hunger was an abstract concept; he always had enough to eat.', 'The war on Iraq is a volatile subject of political debate; any wrong word and a heated argument could spark.', 'My next door neighbor is a virtuoso whose skills with the piano have earned him a name among music experts.', 'He was sick of being vilified all the time by people who were jealous of his ability.', \"Even people who don't believe in the Catholic church venerate the Pope as a symbolic leader.\", 'Unsure of which suitor she wanted to marry, the princess vacillated, saying now one, now the other.', 'With the heirless king going crazy and royal family poisoned, the general of the army finally had his chance to usurp the throne.', 'As the plane was approaching turbulence, the pilot asked the passengers aboard the plane to fasten their seat belts.', 'Though his stay in Europe was transient, Spenser felt he had learned much more about interactions with other people from traveling than he did at college.', 'Jason was a taciturn individual, so it was always a real surprise when he said anything.', 'The king was tired of his sycophants always praising him, so he sent them away.', \"If Spenser doesn't keep adding and translating sentences, the other contributors will surely surpass him.\", 'There was always too much superfluous writing in his essays.', 'His essay gave only a superficial analysis of the problem, so it was a real surprise to him when he got the highest grade in the class.', 'It depends what you mean by \"believe\" in God.', 'Professors should explain everything in detail, not be succinct and always tell students to go home and read their books.', 'If I gave no answer, I would not have spoken.', 'The people who come on the Maury Povich show often make pretentious claims about their lovers cheating on them.', 'It is a prevalent belief, according to a nationwide poll in the United States, that Muslims are linked with terrorism.', \"Freud's insights into human behavior led to him being honored as a profound thinker.\", 'Food and drink were served in such profusion at the wedding that the bride and groom began to wonder if they should not have invited more guests.', 'The proliferation of Internet usage has given birth to a new generation of young people.', \"My friends say I'm a prolific writer, but I haven't written anything for months.\", 'Blind people sometimes develop a compensatory ability to sense the proximity of objects around them.', 'A miser hoards money not because he is prudent but because he is greedy.', 'When both girls told John they had feelings for him, he was in a quandary as to which girl he should be with.', 'Even now, many years after the Cold War, there is still much rancor between the Russians and the Germans, especially in areas once occupied by the Soviet Union.', 'Johnson is a recluse; he prefers to isolate himself from the rest of the students in our class.', \"Teachers must get tired of rectifying the same mistakes over and over again in their students' papers.\", \"Teachers must be tired of correcting the same mistakes over and over again in their students' papers.\", \"The bottles of beer that I brought to the party were redundant; the host's family owned a brewery.\", 'The witnesses were able to refute the false testimony of the suspect.', 'Joan of Arc refused to renounce her belief that the voice she heard was from God and none other.', 'Joan of Arc refused to attribute the voices she could hear to anything other than the Word of the Lord.', 'Shocked by the events of September 11th, politicians all over the world condemned the terrorists for their reprehensible deed.', 'James had a great fear of making mistakes in class and being reprimanded.', 'The principal severely reproved the students whenever they made a mess in the hallway.', 'My parents would repudiate my brother if they ever found out he was gay.', 'I would like to retract my previous statement.', 'To win his audience, the speaker resorted to using rhetorical techniques he learned from his communication courses.', 'His father would never sanction his engagement to a girl who did not share the same religious beliefs as their family.', 'Tim is a huge fan of satirical comedy.', \"Spenser's mother often scrutinizes him for every small mistake he makes.\", \"All the king's subjects, fearing his wrath, often acted quite servile.\", 'People are often quite skeptical about things unless given believable proof.', \"From the doctor's grim expression, it was clear he had somber news for the patient.\", 'Sometimes he has difficulty being articulate about his views.', 'Peter was an altruistic video game player; he would give items to people who needed them, rather than selling them for personal profit.', 'Jimmy tried to cajole his parents into letting him drive across the country with his friends.', 'Pop artists thrive on the adulation of their loyal fans.', 'We must learn to meet adversity gracefully.', 'Bill Clinton spoke in ambiguous language when asked to describe his relationship with Monica Lewinsky.', \"He was a benevolent old man who volunteered to mow his neighbors' lawns for free.\", 'His stern tone and loud voice belied his inner sensitivity and caring nature.', 'The statue of the Minute Man commemorates the valiant soldiers who fought in the Revolutionary War.', \"Baffled by Sherlock Holmes' cryptic remarks, Watson wondered whether Holmes was intentionally concealing his thoughts about the crime.\", 'What criterion did you use when you elected this essay as the winner?', 'I cannot dance one single step of Salsa.', 'Even if your sentences were actually senseless, you at least have the luck to be able to form beautiful sentences.', 'I like my job very much.', 'I really like my job.', \"Ray was willing to corroborate Gary's story, but the police were still unconvinced that either of them were telling the truth.\", 'The murderer was convicted and sentenced to life in prison.', 'Sometimes hockey players get so competitive that fights break out.', 'There was a feeling of constraint in the room; no one dared to tell the king how foolish his decision was.', 'The consensus indicates that we are opposed to the proposed idea.', 'A small forest fire can easily spread and quickly become a great conflagration.', 'I find words with concise definitions to be the easiest to remember.', \"He was still mad about the accident despite his wife's conciliatory words.\", 'A cursory examination of his teeth indicated that he had gingivitis.', 'It was a surprise to see all the students behaving with decorum on prom night.', 'The news article painted the defendant as a guilty man, even though he had been proven innocent.', 'The politician pushed for reform by denouncing the corruption of the government officials.', \"The depravity of the king's deeds led the people to believe he was nothing more than a tyrant that needed to be overthrown.\", 'I dreamt about you.', 'I dreamed about you.', 'I have to get a new computer.', \"I won't lose!\", 'I was late to school.', 'Classes are starting again soon.', \"I think I'm gonna sneeze. Give me a tissue.\", 'For a moment there, I thought he had gone mad.', 'This day was just a waste of time and money.', \"It caught me off guard; I didn't know what to do.\", \"But you've never told me about this!\", \"I've changed my website's layout.\", 'When we are small, everything seems so big.', \"He won't beat me.\", \"I have to do laundry while it's still sunny.\", 'I went for a walk to get some air.', \"Sorry, I don't think I'm gonna be able to.\", 'You had plenty of time.', 'Stop criticizing me!', 'Come on! Talk to me, Trang.', \"I'm almost done.\", 'I am almost ready.', 'Take the other chair!', 'How many sandwiches are there left?', \"I'm not inspired anymore.\", \"I won't lower myself to his level.\", \"I won't stoop down to his level.\", 'We could see the sunset from the window.', \"It's driving me crazy.\", 'This is driving me crazy.', 'Did you say that I could never win?', \"It's all dark outside.\", \"It's totally dark outside.\", \"What happened? There's water all over the apartment.\", 'During summer breaks, I ate dinner at midnight.', 'You can finish your essay now.', 'You will say and do things your parents said and did, even if you swore you would never do them.', 'I am alive even though I am not giving any sign of life.', 'Never try to die.', 'I am too old for this world.', \"I'm too old for this world.\", 'Life begins when we realize who we really are.', 'Life starts when you decide what you are expecting from it.', 'Life begins when you pay taxes.', \"What you don't have is better than what you do have.\", \"Life begins when you're ready to live it.\", 'It is never too late to learn.', \"It's never too late to learn.\", \"Who are the idiots who said that teachers should push for larger amounts of homework, seeing as the students don't work enough?\", \"It's just five in the morning, but nevertheless it is light out.\", 'He told me the story of his life.', \"He told me his life's story.\", 'I never said I was fragile.', 'I wonder if I am made for this world.', 'What are you talking about?', 'What are you talking about!?', \"What're you talking about?\", 'I want a piece of candy.', 'I knew that today would be fun.', 'A child is not a vessel for filling, but a fire to light.', 'Sadly many people will believe things told to them via an email which they would find implausible face-to-face.', 'It might sound far-fetched, but this is a real problem.', 'The police are really good at understanding \"Someone stole my credit card and ran up a lot of charges.\" It\\'s a lot harder to get them to buy into \"Someone stole my magic sword.\"', \"When are we eating? I'm hungry!\", \"I don't like school.\", 'I have class tomorrow.', \"I can't believe it!\", 'Thank you. \"You\\'re welcome.\"', 'How do you pronounce \"pronounce\"?', 'Winter is my favorite season.', 'Winter is my favourite season.', \"It's difficult to have great ideas.\", 'Which country are you from?', 'The data suggest that the optimum length of a lecture may be 30 instead of 60 minutes.', 'I tend to look at the pictures before reading the text.', 'I learned a lot from you.', 'We walked a lot.', 'I spent twelve hours on the train.', 'She got sick this weekend.', 'Hold on, someone is knocking at my door.', \"He's rich. He doesn't need money!\", \"They're making too much noise. I can't concentrate.\", 'I want a massage. I need to relax.', \"You're sick. You have to rest.\", \"There's a secret path on the left.\", 'I have not only that to do.', 'Smith has spent years studying the effects of sleep and sleep loss on memory and learning.', \"She's asking for the impossible.\", 'He disappeared without a trace.', 'I can place the palms of my hands on the floor without bending my knees.', 'There cannot be progress without communication.', 'Everyone would like to believe that dreams can come true.', 'The best way to make your dreams come true is to wake up.', \"The world doesn't revolve around you.\", 'The world is full of fools.', 'Are you saying my life is in danger?', 'Do you have any idea what my life is like?', 'This place has a mysterious atmosphere to it.', 'I eagerly await hearing your opinion on this subject.', 'So what if I am gay? Is it a crime?', 'My life is hollow without him.', 'My life is empty without him.', \"I don't want to fail my exams.\", 'My mother bought two bottles of orange juice.', 'She was wearing a black hat.', 'We made pancakes for breakfast.', 'What did you eat for lunch today?', 'What did you have for lunch today?', 'I spent the whole afternoon chatting with friends.', 'I want to be more independent.', 'Are you just going to stand there all day?', 'A rabbit has long ears and a short tail.', 'My heart was filled with happiness.', 'He wishes to erase bad memories.', 'Sir, you are not allowed to park your car here.', 'We have to take him to the hospital immediately; he is seriously injured!', 'Your secret will be safe with me.', \"I don't want to hear any more of your complaining.\", 'Tell them to call me before they leave.', 'You should have refused such an unfair proposal.', \"You should've rejected such an unfair proposal.\", \"I don't have the strength to keep trying.\", 'Mathematics is not just the memorization of formulas.', \"I didn't mean to give you that impression.\", \"I didn't mean to give that impression.\", 'Yes! I won twice in a row!', \"I'm tired of eating fast food.\", \"I'm sick and tired of being sick and tired.\", \"I can't wait to go on a vacation.\", 'The rooms in this hotel are really very bad at muffling sounds. I can hear my neighbor chewing his gum!', 'The essence of mathematics is liberty.', 'Can you imagine what our lives would be like without electricity?', 'One, two, three, four, five, six, seven, eight, nine, ten.', 'Where is the bathroom?', \"Where's the restroom?\", \"Where's the toilet?\", \"Where's the bathroom?\", 'Where are the toilets?', \"Where's the loo?\", 'The essence of liberty is mathematics.', 'How many hours of sleep do you need?', 'Each person is a world.', 'The temperature of the human body hovers around 37°C.', 'Avoid opening the window; I have no great desire to feel air currents on my back.', 'I have French nationality but Vietnamese origins.', 'This humanitarian group looks for volunteers to distribute meals to the homeless during the month of December.', \"It's very frustrating to try to find your glasses when you can't see anything without glasses.\", 'Do you think mankind will someday colonize the Moon?', 'What famous songs do you wish you had composed, and why?', \"I'm going to buy myself a new camera, digital this time.\", \"I'm crazy about you.\", \"I don't know what is worse.\", 'Life in prison is worse than the life of an animal.', 'I am proud to be a part of this project.', 'Is it necessary to expand human knowledge with space exploration?', 'Beauty lies in the eyes of the one who sees.', 'Who buys this type of art?', 'NASA says it has sufficient information to say that a human visit to the red planet is feasible.', 'Real women have curves.', \"Why can't we tickle ourselves?\", 'The answer leads us to a vicious circle.', \"I'm too lazy to do my homework.\", \"What... you still don't know how to drive?\", \"What? You don't know how to drive a car yet?\", \"Tomorrow is back-to-school day! For once, I'm anxious to go back.\", 'And with me, we are yet one more.']\n",
      "French tokenizer:\n",
      "{'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3, '.': 4, 'de': 5, 'je': 6, ',': 7, 'pas': 8, 'est': 9, 'que': 10, 'ne': 11, 'la': 12, '-': 13, 'à': 14, '?': 15, 'le': 16, 'les': 17, 'tu': 18, 'un': 19, 'ce': 20, \"l'\": 21, 'il': 22, '!': 23, \"j'\": 24, \"n'\": 25, 'ai': 26, \"c'\": 27, \"d'\": 28, 'des': 29, 'a': 30, 'une': 31, 'qui': 32, 'en': 33, 'pour': 34, 'et': 35, 'ça': 36, '«': 37, '»': 38, 'si': 39, 'on': 40, 'faire': 41, 'suis': 42, 'me': 43, 'plus': 44, 'dans': 45, 'sont': 46, 'nous': 47, 'mon': 48, 'du': 49, 'tout': 50, 'être': 51, 'se': 52, 'vie': 53, 'y': 54, \"s'\": 55, 'as': 56, 'avec': 57, 'trop': 58, 'mais': 59, \"t'\": 60, 'au': 61, 'peut': 62, 'quand': 63, 'moi': 64, 'te': 65, 'ma': 66, 'peux': 67, \"m'\": 68, 'dit': 69, 'es': 70, 'vous': 71, 'temps': 72, 'veux': 73, 'toujours': 74, 'fait': 75, 'jamais': 76, 'était': 77, \"qu'il\": 78, 'même': 79, 'gens': 80, 'rien': 81, 'chose': 82, 'monde': 83, 'lui': 84, 'comment': 85, 'bien': 86, 'sans': 87, 'leur': 88, 'comme': 89, 'sur': 90, \"qu'est\": 91, 'dire': 92, 'beaucoup': 93, 'ses': 94, 'son': 95, 'mes': 96, 'quoi': 97, 'où': 98, 'toi': 99, 'aime': 100, 'avait': 101, 'sais': 102, 'personne': 103, 'sa': 104, 'quelque': 105, 'ils': 106, 'avoir': 107, 'pourquoi': 108, 'elle': 109, 'va': 110, 'par': 111, 'jour': 112, 'encore': 113, 'très': 114, 'ont': 115, 'parce': 116, 'choses': 117, 'aller': 118, 'besoin': 119, 'maintenant': 120, 'vivre': 121, 'merci': 122, 'avant': 123, 'ans': 124, 'ou': 125, 'veut': 126, 'pense': 127, 'cela': 128, 'fois': 129, 'fais': 130, 'apprendre': 131, 'autres': 132, 'tellement': 133, 'idée': 134, 'non': 135, 'problème': 136, 'vais': 137, 'combien': 138, 'train': 139, 'là': 140, \"qu'on\": 141, 'assez': 142, 'tous': 143, 'étais': 144, 'demain': 145, 'autre': 146, 'simple': 147, 'aurais': 148, 'aux': 149, \"quelqu'un\": 150, 'vraiment': 151, 'plaît': 152, 'notre': 153, 'leurs': 154, 'vrai': 155, 'serait': 156, 'été': 157, \"qu'elle\": 158, 'c’est': 159, 'dois': 160, 'pendant': 161, 'aussi': 162, 'mal': 163, 'commence': 164, '\"': 165, \"qu'ils\": 166, 'compte': 167, \"aujourd'hui\": 168, 'sommes': 169, 'devrait': 170, 'fou': 171, 'alors': 172, 'sens': 173, 'argent': 174, 'expliquer': 175, 'parle': 176, 'chaque': 177, 'peur': 178, 'ces': 179, 'ta': 180, 'quel': 181, 'petit': 182, 'homme': 183, 'soit': 184, 'ici': 185, 'perdu': 186, 'j’ai': 187, 'deux': 188, ';': 189, 'souvent': 190, 'faut': 191, 'mieux': 192, 'dormir': 193, 'voulais': 194, 'entre': 195, 'eux': 196, 'plupart': 197, 'grand': 198, 'roi': 199, 'pourrait': 200, 'amis': 201, 'sera': 202, 'histoire': 203, 'cours': 204, 'après': 205, 'passé': 206, 'voir': 207, 'comprends': 208, 'donc': 209, 'surprise': 210, 'viens': 211, 'tard': 212, 'heures': 213, 'depuis': 214, 'amour': 215, 'erreurs': 216, 'école': 217, ':': 218, 'mathématiques': 219, 'regarde': 220, 'cette': 221, 'élèves': 222, 'étaient': 223, 'toilettes': 224, 'type': 225, 'bon': 226, 'muiriel': 227, 'mot': 228, 'passe': 229, 'mots': 230, 'parfois': 231, 'demander': 232, 'fut': 233, 'pourrais': 234, 'donne': 235, 'parler': 236, 'arriver': 237, 'trouve': 238, 'peu': 239, 'vécu': 240, 'demande': 241, 'pouvoir': 242, 'chez': 243, 'presque': 244, 'ordinateur': 245, 'liberté': 246, 'vu': 247, 'sauf': 248, 'dû': 249, 'arrive': 250, 'seulement': 251, 'français': 252, 'jours': 253, 'croire': 254, 'moins': 255, 'vas': 256, 'demanda': 257, 'vent': 258, 'savoir': 259, 'envie': 260, 'trois': 261, 'vacances': 262, 'ceux': 263, 'celui': 264, 'manger': 265, 'télé': 266, 'déjà': 267, 'enfants': 268, 'lorsque': 269, 'famille': 270, 'chaud': 271, 'fatigué': 272, 'face': 273, 'avons': 274, 'vérité': 275, 'œil': 276, 'animal': 277, 'dieu': 278, 'opinion': 279, 'déjeuner': 280, 'spenser': 281, 'photo': 282, 'raison': 283, 'heure': 284, 'difficile': 285, 'tes': 286, 'dernière': 287, 'nuit': 288, 'fous': 289, 'stupide': 290, 'gagner': 291, 'aimerais': 292, 'trouver': 293, 'intention': 294, 'pire': 295, 'sois': 296, 'nouvelles': 297, 'elles': 298, 'façon': 299, 'dont': 300, 'vois': 301, 'déteste': 302, 'lit': 303, 'semaine': 304, 'police': 305, 'prend': 306, 'ton': 307, 'attendre': 308, 'mathématiciens': 309, 'question': 310, \"qu'un\": 311, 'continuer': 312, 'curieux': 313, 'juste': 314, 'crois': 315, 'arrête': 316, 'appris': 317, 'ci': 318, 'mère': 319, 'communication': 320, 'votre': 321, '10': 322, 'guerre': 323, 'venu': 324, 'mois': 325, 'autour': 326, 'prends': 327, 'travers': 328, 'parles': 329, 'yeux': 330, 'machine': 331, 'impossible': 332, 'comprendre': 333, 'voit': 334, 'quelle': 335, 'appelles': 336, 'parents': 337, 'parole': 338, 'dix': 339, 'demi': 340, 'font': 341, 'prendra': 342, 'sommeil': 343, 'faim': 344, 'phrases': 345, 'main': 346, 'fini': 347, 'doivent': 348, 'qu’il': 349, 'grande': 350, 'conviction': 351, 'mêmes': 352, 'rend': 353, 'demandé': 354, 'fenêtre': 355, 'pris': 356, 'air': 357, 'supporte': 358, 'sert': 359, 'aucun': 360, 'anniversaire': 361, 'bientôt': 362, 'lapin': 363, 'fin': 364, 'apprentissage': 365, 'changera': 366, '€': 367, 'seul': 368, 'différent': 369, 'penses': 370, 'aimé': 371, 'raconté': 372, 'pensé': 373, 'confiance': 374, 'malheureusement': 375, 'pensent': 376, 'pied': 377, 'oh': 378, 'dépêche': 379, 'pouvais': 380, 'vivant': 381, 'dépend': 382, 'cool': 383, 'gros': 384, \"qu'une\": 385, 'influencé': 386, 'décision': 387, 'fille': 388, 'lycée': 389, 'trang': 390, 'prendre': 391, 'seule': 392, 'n’est': 393, 'peuvent': 394, 'cher': 395, 'belle': 396, 'perdre': 397, 'idées': 398, 'théorie': 399, 'sujet': 400, 'intentionnellement': 401, 'savais': 402, 'important': 403, 'maths': 404, 'toute': 405, 'journée': 406, 'euh': 407, 'rêvé': 408, 'quelques': 409, 'poser': 410, 'manière': 411, 'dommage': 412, 'longtemps': 413, 'quelles': 414, 'vieil': 415, 'sous': 416, 'réside': 417, 'désolée': 418, 'beau': 419, 'jeu': 420, 'réfléchir': 421, 'tête': 422, 'connaître': 423, 'réponse': 424, 'essayer': 425, 'nature': 426, 'aura': 427, 'amasse': 428, 'boire': 429, 'aucune': 430, 'devons': 431, 'ensemble': 432, 'part': 433, 'puisse': 434, 'attend': 435, 'allons': 436, 'huit': 437, 'loin': 438, 'années': 439, 'mange': 440, 'meurt': 441, 'rester': 442, 'personnes': 443, 'internet': 444, 'forme': 445, 'gouvernement': 446, 'partir': 447, 'eh': 448, 'chance': 449, 'œufs': 450, 'ouvrir': 451, 'arrêt': 452, 'devraient': 453, 'devenir': 454, 'états': 455, 'unis': 456, 'oui': 457, 'bruit': 458, 'écrire': 459, 'reste': 460, 'minutes': 461, 'rarement': 462, 'vieux': 463, 'univers': 464, 'appelle': 465, 'pays': 466, 'chocolat': 467, 'soleil': 468, 'réfrigérateur': 469, 'rouge': 470, 'tenu': 471, 'vide': 472, 'partie': 473, 'rêves': 474, 'l’on': 475, 'cerveau': 476, 'cinq': 477, 'technologie': 478, 'entendre': 479, 'changer': 480, 'compris': 481, 'esprit': 482, 'souffrance': 483, 'intérêt': 484, 'travail': 485, 'vont': 486, 'voiture': 487, 'calmé': 488, 'donner': 489, 'commencé': 490, 'propre': 491, 'public': 492, 'donné': 493, 'impression': 494, 'mangé': 495, 'hommes': 496, 'pratique': 497, 'avais': 498, 'lunettes': 499, 'frère': 500, 'université': 501, 'classe': 502, 'professeurs': 503, 'n’avais': 504, 'tant': 505, 'voix': 506, 'cet': 507, 'plein': 508, 'noir': 509, 'marre': 510, \"lorsqu'il\": 511, 'cassé': 512, 'innocent': 513, 'tenez': 514, 'joyeux': 515, '20': 516, 'serai': 517, 'retour': 518, 'finir': 519, 'simplement': 520, 'doit': 521, 'soi': 522, 'éducation': 523, 'tâche': 524, 'mauvais': 525, '30': 526, 'gagne': 527, '100': 528, 'fasse': 529, 'place': 530, 'bizarre': 531, 'suppose': 532, 'appellerai': 533, 'reviendrai': 534, 'envoyer': 535, 'importe': 536, 'idéaux': 537, 'réplique': 538, 'coups': 539, 'sûr': 540, 'contexte': 541, 'lamentable': 542, 'endroit': 543, 'probablement': 544, 'ferait': 545, 'frères': 546, 'prendrait': 547, 'éternité': 548, 'lequel': 549, 'serais': 550, 'triste': 551, 'propos': 552, 'défauts': 553, 'facilement': 554, 'humains': 555, 'intrigant': 556, 'beauté': 557, 'n’ai': 558, 'but': 559, 'venait': 560, 'vis': 561, 'possible': 562, 'problèmes': 563, 'regardes': 564, 'physique': 565, 'fiche': 566, 'rends': 567, 'gèle': 568, 'prochaine': 569, 'fera': 570, 'finalement': 571, 'écoles': 572, 'savent': 573, 'exprimer': 574, 'bête': 575, 'démontrer': 576, 'chercher': 577, 'saura': 578, 'solution': 579, 'trouvée': 580, 'vite': 581, 'bonne': 582, 'paraît': 583, 'intéressant': 584, 'nouveau': 585, 'jouer': 586, 'lieu': 587, \"qu'attendre\": 588, 'semble': 589, 'france': 590, 'options': 591, 'robot': 592, 'estime': 593, 'puissance': 594, 'maman': 595, 'anglais': 596, 'nourriture': 597, 'espace': 598, 'avez': 599, 'absolument': 600, 'dur': 601, 'japonais': 602, 'comprend': 603, 'attends': 604, 'semblant': 605, 'essaie': 606, 'considérer': 607, 'notes': 608, 'moment': 609, 'pierre': 610, 'roule': 611, 'mousse': 612, 'proverbe': 613, 'revenir': 614, 'blanc': 615, 'grotte': 616, 'idiots': 617, 'marche': 618, 't': 619, 'téléphone': 620, 'musique': 621, 'pleure': 622, 'bonheur': 623, 'bas': 624, 'genre': 625, 'trente': 626, 'bateau': 627, 'emmènera': 628, 'cartes': 629, 'étudiant': 630, 'telle': 631, 'ayant': 632, 'faute': 633, 'allemands': 634, 'maison': 635, 'longue': 636, 'million': 637, 'nagoya': 638, 'rare': 639, '90': 640, 'site': 641, 'toutes': 642, 'ressembler': 643, 'passeport': 644, 'neuf': 645, 'gare': 646, 'aidé': 647, 'ange': 648, 'madrilènes': 649, 'eu': 650, 'bouche': 651, 'signe': 652, 'surpris': 653, 'station': 654, 'voyage': 655, 'article': 656, 'italien': 657, 'pièce': 658, 'repas': 659, 'puis': 660, '2': 661, 'passer': 662, 'pu': 663, 'faites': 664, 'changements': 665, 'examens': 666, 'pouvons': 667, 'traduire': 668, '11': 669, 'jus': 670, 'désir': 671, 'paris': 672, 'mourir': 673, 'coût': 674, 'augmenté': 675, 'radicalement': 676, 'pourtant': 677, 'contraire': 678, 'gauche': 679, 'jack': 680, 'danser': 681, 'près': 682, 'grave': 683, 'portefeuille': 684, 'âge': 685, 'allez': 686, 'joue': 687, 'servir': 688, 'grâce': 689, 'connaît': 690, 'allée': 691, 'stupides': 692, 'énervant': 693, 'plaindre': 694, 'disent': 695, 'cuire': 696, 'capot': 697, 'voitures': 698, 'vaut': 699, 'mort': 700, 'disparu': 701, 'femmes': 702, 'arrivons': 703, 'ronfle': 704, 'soir': 705, 'église': 706, 'petites': 707, 'langues': 708, 'suite': 709, 'tôt': 710, 'corps': 711, 'prête': 712, 'national': 713, 'puissiez': 714, 'prouver': 715, 'rendent': 716, 'demandez': 717, 'suffisamment': 718, 'malgré': 719, 'crée': 720, 'voudrais': 721, 'meurs': 722, 'piano': 723, 'cinéma': 724, 'déshabille': 725, 'contre': 726, 'bébé': 727, 'eau': 728, 'faite': 729, 'bonjour': 730, 'côté': 731, 'pape': 732, 'erreur': 733, 'ni': 734, 'compliquée': 735, 'disiez': 736, 'traduisent': 737, 'langue': 738, 'transforment': 739, 'totalement': 740, 'comprennent': 741, 'nos': 742, 'décisions': 743, 'livre': 744, 'joie': 745, 'froid': 746, 'soif': 747, 'donnez': 748, 'bras': 749, 'six': 750, 'dormi': 751, 'marier': 752, 'femme': 753, 'achète': 754, 'terre': 755, 'chemin': 756, 'emploi': 757, 'carte': 758, 'hôpital': 759, 'inspiration': 760, 'marie': 761, 'chanté': 762, 'sagesse': 763, 'pleut': 764, 'plage': 765, 'doutent': 766, 'étudier': 767, 'gagné': 768, 'matin': 769, 'patient': 770, 'porte': 771, 'car': 772, 'déclarations': 773, 'cesse': 774, 'nouvelle': 775, 'politique': 776, 'sujets': 777, 'sortir': 778, 'politiciens': 779, 'comportement': 780, 'd’être': 781, 'recours': 782, 'remarques': 783, 'préfère': 784, 'voisin': 785, 'tantôt': 786, 'avion': 787, 'réelle': 788, 'rédaction': 789, 'donnait': 790, 'meilleure': 791, 'étudiants': 792, 'lire': 793, 'humain': 794, 'jeunes': 795, 'sentir': 796, 'objets': 797, 'avaient': 798, 'fatigués': 799, 'rectifier': 800, 'copies': 801, 'bouteilles': 802, 'jeanne': 803, 'arc': 804, 'refusa': 805, 'renoncer': 806, 'entendait': 807, 'nulle': 808, 'partout': 809, 'gay': 810, 'laisser': 811, 'portait': 812, 'holmes': 813, 'crime': 814, 'prêt': 815, 'coupable': 816, 'feu': 817, 'qu’un': 818, 'nouvel': 819, 'n’a': 820, 'abaisserai': 821, 'niveau': 822, 'dehors': 823, 'devoirs': 824, 'volé': 825, 'l’hiver': 826, 'saison': 827, 'préférée': 828, 'd’un': 829, 'malade': 830, 'secret': 831, 'tourne': 832, 'qu’as': 833, 'refuser': 834, 'proposition': 835, 'injuste': 836, 'l’intention': 837, 'l’essence': 838, 'conduire': 839, 'garçons': 840, 'geste': 841, 'essayons': 842, '18': 843, 'juin': 844, 'perds': 845, 'c’était': 846, 'méchant': 847, 'montagnes': 848, 'récente': 849, 'certaine': 850, 'microphone': 851, 'marchait': 852, 'déçoit': 853, 'forcé': 854, 'encouragé': 855, 'choisir': 856, 'coûtera': 857, 'abandonne': 858, 'sieste': 859, 'arrivera': 860, 'gars': 861, 'ferai': 862, 'perturber': 863, 'révisions': 864, 'long': 865, 'terme': 866, 'inquiète': 867, 'manques': 868, 'apprécié': 869, 'personnages': 870, 'mystérieux': 871, 'devrais': 872, 'ticket': 873, 'impatiente': 874, 'astrophysicien': 875, 'biologie': 876, 'cinglé': 877, 'état': 878, 'occupés': 879, 'battre': 880, 'occuper': 881, 'communs': 882, 'papillon': 883, 'surprend': 884, 'ignore': 885, 'dite': 886, 'amérique': 887, 'charmant': 888, 'descendre': 889, 'poisson': 890, 'peluche': 891, 'sœurs': 892, 'empêcher': 893, 'montrer': 894, 'émotions': 895, 'substitut': 896, 'faudrait': 897, 'programme': 898, 'égoïste': 899, 'réfléchissons': 900, 'proches': 901, 'antisocial': 902, 'tel': 903, 'impoli': 904, 'malheureux': 905, 'suiciderais': 906, 'époque': 907, 'levais': 908, '6h': 909, 'matins': 910, 'réveillé': 911, 'pensais': 912, 'aimais': 913, 'écrivent': 914, 'quotidienne': 915, 'marshmallow': 916, 'ferais': 917, 'risques': 918, 'demandes': 919, 'corrigés': 920, 'restée': 921, 'innocence': 922, 'faits': 923, 'éternellement': 924, 'certaines': 925, 'extrêmes': 926, 'caches': 927, 'forums': 928, 'devait': 929, 'saurais': 930, 'fuir': 931, 'paroles': 932, 'signifient': 933, 'prof': 934, 'sèche': 935, 'japon': 936, 'pars': 937, 'oublié': 938, 'sac': 939, 'demanderai': 940, 'excusé': 941, 'colère': 942, 'balles': 943, 'expliqué': 944, 'imbécile': 945, 'explication': 946, 'théoriquement': 947, 'connectée': 948, 'serve': 949, 'raconterais': 950, 'semaines': 951, 'explicitement': 952, 'idiote': 953, 'évident': 954, 'imaginé': 955, 'irais': 956, 'viagra': 957, 'wikipédia': 958, 'formuler': 959, 'trouvé': 960, 'lumière': 961, 'bougies': 962, 'répondu': 963, 'ami': 964, 'aie': 965, 'maigrir': 966, 'sudoku': 967, 'déranger': 968, 'félicitations': 969, 'possibilité': 970, 'improbable': 971, 'déconnecter': 972, 'inévitable': 973, 'aille': 974, 'chimie': 975, 'devines': 976, 'saches': 977, 'seras': 978, 'journaux': 979, 'voyageur': 980, 'forces': 981, 'faiblesses': 982, 'sérieusement': 983, 'épisode': 984, '21': 985, 'pleurer': 986, 'rire': 987, 'montre': 988, 'robots': 989, 'rêvent': 990, 'devrions': 991, 'demandais': 992, 'allais': 993, 'venir': 994, 'trouves': 995, 'rencontrer': 996, 'célèbre': 997, 'écriture': 998, 'formelle': 999, 'étrangers': 1000, 'intriguent': 1001, 'retient': 1002, 'éveillé': 1003, 'veuille': 1004, 'voyager': 1005, 'dure': 1006, 'supporter': 1007, 'insupportable': 1008, 'mets': 1009, 'aise': 1010, 'alunir': 1011, 'vérifier': 1012, 'emails': 1013, 'derrière': 1014, 'bonnes': 1015, 'priorités': 1016, 'importantes': 1017, 'peine': 1018, 'marcher': 1019, 'normal': 1020, 'poli': 1021, 'apprendrai': 1022, 'devant': 1023, 'inquiéter': 1024, 'semblerait': 1025, \"qu'à\": 1026, 'certain': 1027, 'décidé': 1028, 'périrons': 1029, 'franc': 1030, 'vertige': 1031, 'trouillard': 1032, 'exclama': 1033, 'hiroshi': 1034, 'complexe': 1035, 'pensions': 1036, 'sonne': 1037, 'répondre': 1038, 'gentil': 1039, 'répondit': 1040, 'willie': 1041, 'aider': 1042, 'courrai': 1043, 'voudrions': 1044, 'décider': 1045, 'rencontrés': 1046, 'allen': 1047, 'poète': 1048, 'archer': 1049, 'tua': 1050, 'cerf': 1051, 'communisme': 1052, 'atteint': 1053, 'seigle': 1054, 'appelé': 1055, 'grain': 1056, 'pauvreté': 1057, '50': 1058, 'citait': 1059, 'finnois': 1060, 'régimes': 1061, 'alimentaires': 1062, 'sains': 1063, 'corrige': 1064, 'table': 1065, 'bois': 1066, 'chêne': 1067, 'ingénieux': 1068, 'épelles': 1069, 'pretty': 1070, 'retournions': 1071, 'excuse': 1072, 'période': 1073, 'tokyo': 1074, 'abord': 1075, 'schéma': 1076, 'démocratie': 1077, 'mis': 1078, 'essayées': 1079, 'commissaire': 1080, 'pantalon': 1081, 'autant': 1082, 'devint': 1083, 'naturellement': 1084, 'nerveux': 1085, 'quittant': 1086, 'mordu': 1087, 'manqué': 1088, 'identiques': 1089, 'restèrent': 1090, 'bée': 1091, 'putain': 1092, 'remettre': 1093, 'lavage': 1094, 'laver': 1095, 'porter': 1096, 'première': 1097, 'habitent': 1098, 'maisons': 1099, 'verre': 1100, 'lancer': 1101, 'pierres': 1102, 'aveugle': 1103, 'compliqué': 1104, 'seules': 1105, 'réponses': 1106, 'utiles': 1107, 'celles': 1108, 'posent': 1109, 'questions': 1110, 'douter': 1111, 'premier': 1112, 'intelligence': 1113, 'pauvre': 1114, 'courant': 1115, 'souvenir': 1116, 'excusez': 1117, 'permettez': 1118, 'signaler': 1119, 'dessus': 1120, 'entretenir': 1121, 'conversation': 1122, 'fixant': 1123, 'hamlet': 1124, 'intéressante': 1125, 'ait': 1126, 'écrite': 1127, 'biscuit': 1128, 'maîtriser': 1129, '3': 1130, 'regretter': 1131, 'marrant': 1132, 'changent': 1133, 'fil': 1134, 'deviné': 1135, 'imagination': 1136, 'affecte': 1137, 'aspects': 1138, 'oublieras': 1139, 'inattendu': 1140, 'accompli': 1141, 'effort': 1142, 'vagabondent': 1143, 'ruinent': 1144, 'cause': 1145, 'préservatif': 1146, 'chat': 1147, 'pages': 1148, 'mlle': 1149, 'brown': 1150, 'orange': 1151, 'plait': 1152, 'mike': 1153, 'ah': 1154, 'interjection': 1155, 'caractère': 1156, 'obligatoire': 1157, 'scolarité': 1158, 'analysé': 1159, 'multitude': 1160, 'ouvrages': 1161, 'consacrés': 1162, 'étude': 1163, 'divers': 1164, 'moyens': 1165, 'développer': 1166, 'crains': 1167, 'régler': 1168, 'ville': 1169, \"qu'avoir\": 1170, 'crise': 1171, 'cardiaque': 1172, \"qu'a\": 1173, 'fierté': 1174, 'rêve': 1175, 'amie': 1176, 'rachel': 1177, 'allées': 1178, 'inventé': 1179, 'surprendre': 1180, 'étonner': 1181, 'commencer': 1182, 'doute': 1183, 'infini': 1184, 'manquait': 1185, 'défaut': 1186, 'parfaite': 1187, 'voyons': 1188, 'cage': 1189, 'écolier': 1190, 'plaint': 1191, 'lobe': 1192, 'frontal': 1193, 'hémisphère': 1194, 'ouvert': 1195, 'cherchait': 1196, 'côtés': 1197, 'courses': 1198, 'reviens': 1199, 'rapide': 1200, 'affaires': 1201, 'italie': 1202, 'j’aimerais': 1203, 'pourriez': 1204, 'composer': 1205, 'numéro': 1206, 'placé': 1207, 'haut': 1208, 'auberge': 1209, 'jeunesse': 1210, 'douches': 1211, 'ouvrez': 1212, 'gaspillage': 1213, 'occupé': 1214, 'plans': 1215, 'désirer': 1216, 'équivaut': 1217, 'posséder': 1218, 'sexy': 1219, 'paix': 1220, 'passez': 1221, 'sel': 1222, \"m'ennuie\": 1223, 'songe': 1224, 'appétit': 1225, 'frapper': 1226, 'disneyland': 1227, 'arrêtent': 1228, 'disputer': 1229, 'mettre': 1230, 'crème': 1231, 'solaire': 1232, 'auras': 1233, 'calme': 1234, 'agaçante': 1235, 'araignées': 1236, 'ficher': 1237, 'trouille': 1238, 'ménage': 1239, 'utiliser': 1240, 'détesté': 1241, \"qu'aimé\": 1242, 'inquiet': 1243, 'heureux': 1244, 'écurie': 1245, 'cheval': 1246, 'sciences': 1247, 'réveillait': 1248, 'découvrait': 1249, 'océan': 1250, 'reflètent': 1251, 'connaissez': 1252, 'phrase': 1253, 'récolte': 1254, 'sème': 1255, 'semé': 1256, 'voilà': 1257, 'tempête': 1258, 'faisais': 1259, 'discours': 1260, 'consoler': 1261, 'essayais': 1262, 'tuer': 1263, 'folle': 1264, 'parlez': 1265, 'lentement': 1266, 'addition': 1267, 'téléphoner': 1268, 'avouer': 1269, 'appelez': 1270, 'chaussures': 1271, 'tire': 1272, 'flics': 1273, 'arrivent': 1274, 'noël': 1275, 'réveillerai': 1276, 'écouter': 1277, 'pagaille': 1278, 'totale': 1279, 'tape': 1280, 'nerfs': 1281, 'touché': 1282, 'récepteurs': 1283, 'peau': 1284, 'envoient': 1285, 'messages': 1286, 'causant': 1287, 'libération': 1288, 'produits': 1289, 'chimiques': 1290, 'tels': 1291, 'endorphine': 1292, 'implique': 1293, 'cent': 1294, 'cinquante': 1295, 'mille': 1296, 'couples': 1297, 'marient': 1298, 'shanghai': 1299, '2006': 1300, 'seront': 1301, 'sélectionnés': 1302, 'devront': 1303, 'considérables': 1304, 'tests': 1305, 'médicaux': 1306, 'psychologiques': 1307, 'malnutrition': 1308, 'niger': 1309, 'bicyclettes': 1310, 'outil': 1311, 'préservation': 1312, 'environnement': 1313, 'urbain': 1314, 'lancé': 1315, 'ligne': 1316, 'défie': 1317, 'contribuables': 1318, 'équilibrer': 1319, 'budget': 1320, 'ravi': 1321, 'croyez': 1322, 'ordinateurs': 1323, 'essayez': 1324, 'aide': 1325, 'change': 1326, 'information': 1327, 'avancées': 1328, 'scientifiques': 1329, 'découverte': 1330, 'évidence': 1331, 'comprenez': 1332, 'êtes': 1333, 'conscient': 1334, 'futur': 1335, 'clé': 1336, 'produire': 1337, 'capable': 1338, 'remplie': 1339, 'importance': 1340, 'mystère': 1341, 'signifie': 1342, 'éduqué': 1343, 'xxie': 1344, 'siècle': 1345, 'passion': 1346, 'venant': 1347, 'genève': 1348, 'entrer': 1349, 'offrir': 1350, 'cadeau': 1351, 'copains': 1352, 'antigua': 1353, 'mètre': 1354, 'cube': 1355, 'correspond': 1356, '1000': 1357, 'litres': 1358, 'mariée': 1359, 'études': 1360, 'savez': 1361, 'manges': 1362, 'légumes': 1363, 'écrasa': 1364, 'mur': 1365, 'visions': 1366, 'réelles': 1367, 'salut': 1368, 'dictionnaire': 1369, 'créationnisme': 1370, 'pseudo': 1371, 'science': 1372, 'jeter': 1373, 'bain': 1374, 'démocrate': 1375, 'citoyen': 1376, 'libre': 1377, 'plie': 1378, 'volonté': 1379, 'majorité': 1380, 'vouloir': 1381, 'cherche': 1382, 'rome': 1383, 'consent': 1384, 'tom': 1385, 'sourire': 1386, 'vin': 1387, 'poésie': 1388, 'bouteille': 1389, 'allemand': 1390, 'objectif': 1391, 'divulguer': 1392, 'duquel': 1393, 'mathématicien': 1394, 'pensée': 1395, 'exposée': 1396, 'raisonnement': 1397, 'fondée': 1398, 'somme': 1399, 'parties': 1400, 'portent': 1401, 'atteinte': 1402, 'mathématique': 1403, 'poètes': 1404, 'fantaisie': 1405, 'logique': 1406, 'expert': 1407, 'unes': 1408, 'pires': 1409, 'domaine': 1410, 'éviter': 1411, 'socialement': 1412, 'acceptable': 1413, 'masturber': 1414, 'sortes': 1415, 'binaire': 1416, 'désirons': 1417, 'prennent': 1418, 'propres': 1419, 'voulons': 1420, 'conviennent': 1421, 'étrangères': 1422, 'intéressantes': 1423, 'verbes': 1424, 'irréguliers': 1425, 'lis': 1426, 'affronte': 1427, 'souriant': 1428, 'conçues': 1429, 'transformer': 1430, 'société': 1431, 'reproduire': 1432, 'rêver': 1433, 'finies': 1434, 'tomber': 1435, 'tenue': 1436, 'soirée': 1437, 'souhaitée': 1438, 'pure': 1439, 'regrettent': 1440, 'concernant': 1441, 'répondent': 1442, 'irrésistible': 1443, 'retéléphoner': 1444, 'accepte': 1445, 'condition': 1446, 'souris': 1447, 'd’une': 1448, 'maître': 1449, 'n’avait': 1450, 'd’apprendre': 1451, 'gâche': 1452, 'plaisir': 1453, 'abandonner': 1454, 'couper': 1455, 'ongles': 1456, 'repassage': 1457, 'racontes': 1458, 'sexuelle': 1459, 'tarte': 1460, 'banane': 1461, 'adopter': 1462, 'avortement': 1463, 'avis': 1464, 'singe': 1465, 'têtes': 1466, 'acheter': 1467, 'miracles': 1468, 'pommes': 1469, 'adore': 1470, 'lasagnes': 1471, 'sait': 1472, 'désagréable': 1473, 'dentiste': 1474, 'exemple': 1475, 'utile': 1476, \"qu'avec\": 1477, 'moitié': 1478, 'dévorer': 1479, 'écarter': 1480, 'dévorera': 1481, '49': 1482, '%': 1483, 'écarté': 1484, 'dévoré': 1485, 'petits': 1486, 'nombres': 1487, 'premiers': 1488, 'logiques': 1489, 'règles': 1490, 'consacre': 1491, 'lève': 1492, 'sourcil': 1493, 'signifier': 1494, 'relations': 1495, 'sexuelles': 1496, 'complètement': 1497, 'idiot': 1498, 'identité': 1499, 'désespère': 1500, 'frappé': 1501, 'foudre': 1502, 'aides': 1503, 'pingouin': 1504, 'mignon': 1505, 'soyons': 1506, 'réalistes': 1507, 'source': 1508, 'différence': 1509, 'restez': 1510, 'affamés': 1511, 'apparaître': 1512, 'pain': 1513, 'sourd': 1514, 'relisais': 1515, 'lettres': 1516, 'envoyées': 1517, 'bague': 1518, 'prévu': 1519, 'pleuvoir': 1520, 'intelligente': 1521, 'choquante': 1522, 'aiment': 1523, 'justice': 1524, 'coûte': 1525, 'consiste': 1526, 'autrui': 1527, 'lent': 1528, 'promettre': 1529, 'fidèle': 1530, 'tenir': 1531, 'mélange': 1532, 'maladie': 1533, 'mortelle': 1534, 'sexuellement': 1535, 'transmissible': 1536, 'inutile': 1537, 'bibliothèque': 1538, 'zoo': 1539, 'hier': 1540, 'bataille': 1541, 'allô': 1542, 'prépare': 1543, 'regardé': 1544, 'lu': 1545, 'mangeant': 1546, 'pause': 1547, 'chinois': 1548, 'facile': 1549, 'draguer': 1550, 'rue': 1551, 'habite': 1552, 'mer': 1553, 'occasion': 1554, 'achèterai': 1555, 'barbe': 1556, 'papa': 1557, 'portable': 1558, 'tombées': 1559, 'miroir': 1560, 'allés': 1561, 'londres': 1562, 'année': 1563, 'plafond': 1564, 'chambre': 1565, 'ferme': 1566, 'sortant': 1567, 'présomptueux': 1568, 'présumer': 1569, 'lecteur': 1570, 'disposé': 1571, 'sources': 1572, 'anonymes': 1573, 'déniant': 1574, 'anarchiste': 1575, 'katja': 1576, 'soutenait': 1577, 'souhaitait': 1578, 'détruire': 1579, 'cécité': 1580, 'responsable': 1581, 'nombre': 1582, 'sidérant': 1583, 'santé': 1584, 'perte': 1585, 'dignité': 1586, 'diminution': 1587, 'qualité': 1588, 'entier': 1589, 'formation': 1590, 'mouvement': 1591, 'ouragans': 1592, 'capricieux': 1593, 'contemporaine': 1594, 'envoie': 1595, 'télégramme': 1596, 'brièveté': 1597, 'essentielle': 1598, 'facturé': 1599, 'david': 1600, 'vif': 1601, 'esthétique': 1602, 'qualités': 1603, 'peinture': 1604, 'sculpture': 1605, 'composition': 1606, 'musicale': 1607, 'poème': 1608, 'agréable': 1609, 'oreille': 1610, 'dépit': 1611, 'régulières': 1612, 'aimer': 1613, 'rencontré': 1614, 'aaah': 1615, 'facultés': 1616, 'universités': 1617, 'privées': 1618, 'autonomes': 1619, 'rejoins': 1620, 'warcraft': 1621, 'opposé': 1622, 'équipe': 1623, 'adversaires': 1624, 'existe': 1625, 'apathie': 1626, 'vote': 1627, 'vient': 1628, 'aversion': 1629, 'l’ascendant': 1630, 'monarques': 1631, 'empêche': 1632, 'rébellion': 1633, 'sarah': 1634, 'perspicace': 1635, 'rendre': 1636, 'essayaient': 1637, 'farce': 1638, 'orchestre': 1639, 'produit': 1640, 'dissonantes': 1641, 'accorde': 1642, 'méprisé': 1643, 'tiens': 1644, 'réticence': 1645, 'lits': 1646, 'veulent': 1647, \"qu'entendre\": 1648, 'acclamé': 1649, 'acteurs': 1650, 'représentation': 1651, 'décida': 1652, 'abréger': 1653, 'rapport': 1654, 'enlevant': 1655, 'détails': 1656, 'inutiles': 1657, 'battent': 1658, 'égalité': 1659, 'sanctionnés': 1660, 'scandaleux': 1661, 'déplacé': 1662, 'mme': 1663, 'eichler': 1664, 'fameuse': 1665, 'réputation': 1666, 'austère': 1667, 'écoutez': 1668, 'faudra': 1669, 'coercition': 1670, 'migraine': 1671, 'aspirine': 1672, 'soulage': 1673, 'douleur': 1674, 'sarcastiques': 1675, 'plaisanterie': 1676, 'interprétées': 1677, 'signes': 1678, 'ambivalence': 1679, 'prises': 1680, 'sérieux': 1681, 'sélection': 1682, 'arbitraire': 1683, 'machines': 1684, 'loterie': 1685, 'chiffres': 1686, 'fétiches': 1687, 'concept': 1688, 'abstrait': 1689, 'irak': 1690, 'explosif': 1691, 'débat': 1692, 'dispute': 1693, 'enflammée': 1694, 'éclater': 1695, 'virtuose': 1696, 'talents': 1697, 'valu': 1698, 'nom': 1699, 'experts': 1700, 'musicaux': 1701, 'diffamé': 1702, 'jaloux': 1703, 'capacités': 1704, 'croient': 1705, 'catholique': 1706, 'vénèrent': 1707, 'leader': 1708, 'symbolique': 1709, 'sachant': 1710, 'prétendant': 1711, 'voulait': 1712, 'princesse': 1713, 'hésitait': 1714, 'nommant': 1715, 'héritier': 1716, 'devenant': 1717, 'royale': 1718, 'empoisonnée': 1719, 'général': 1720, 'armée': 1721, 'enfin': 1722, 'usurper': 1723, 'trône': 1724, 'fur': 1725, 'mesure': 1726, 'approchait': 1727, 'turbulences': 1728, 'pilote': 1729, 'passagers': 1730, 'bord': 1731, 'attacher': 1732, 'ceintures': 1733, 'sécurité': 1734, 'séjour': 1735, 'europe': 1736, 'éphémère': 1737, 'sentait': 1738, 'interactions': 1739, 'voyageant': 1740, 'jason': 1741, 'individu': 1742, 'taciturne': 1743, 'disait': 1744, 'quoique': 1745, 'courtisans': 1746, 'flattant': 1747, 'renvoyés': 1748, 'continue': 1749, 'd’ajouter': 1750, 'contributeurs': 1751, 'sûrement': 1752, 'dépasser': 1753, 'passages': 1754, 'superficiels': 1755, 'rédactions': 1756, 'qu’une': 1757, 'analyse': 1758, 'superficielle': 1759, 'lorsqu’il': 1760, 'obtint': 1761, 'note': 1762, 'détail': 1763, 'succincts': 1764, 'livres': 1765, 'rentrent': 1766, 'parlé': 1767, 'viennent': 1768, 'émission': 1769, 'maury': 1770, 'povich': 1771, 'prétentieuses': 1772, 'partenaire': 1773, 'trompant': 1774, 'croyance': 1775, 'répandue': 1776, 'sondage': 1777, 'musulmans': 1778, 'liés': 1779, 'terrorisme': 1780, 'freud': 1781, 'amené': 1782, 'honoré': 1783, 'profond': 1784, 'penseur': 1785, 'boissons': 1786, 'servies': 1787, 'profusion': 1788, 'mariage': 1789, 'mariés': 1790, 'commencèrent': 1791, 'auraient': 1792, 'inviter': 1793, 'convives': 1794, 'prolifération': 1795, 'utilisation': 1796, 'naissance': 1797, 'génération': 1798, 'écrivain': 1799, 'prolifique': 1800, 'écrit': 1801, 'aveugles': 1802, 'développent': 1803, 'aptitude': 1804, 'compensatoire': 1805, 'proximité': 1806, 'avare': 1807, 'prudent': 1808, 'avide': 1809, 'filles': 1810, 'annoncèrent': 1811, 'john': 1812, 'qu’elles': 1813, 'sentiments': 1814, 'envers': 1815, 'savait': 1816, 'froide': 1817, 'rancoeur': 1818, 'russes': 1819, 'particulier': 1820, 'régions': 1821, 'autrefois': 1822, 'occupées': 1823, 'union': 1824, 'soviétique': 1825, 'johnson': 1826, 'reclus': 1827, 'isoler': 1828, 'bière': 1829, 'j’avais': 1830, 'apporté': 1831, 'fête': 1832, 'hôte': 1833, 'possédait': 1834, 'brasserie': 1835, 'témoins': 1836, 'réfuter': 1837, 'faux': 1838, 'témoignage': 1839, 'suspect': 1840, 'choqués': 1841, 'évènements': 1842, 'septembre': 1843, 'condamnèrent': 1844, 'terroristes': 1845, 'acte': 1846, 'répréhensible': 1847, 'james': 1848, 'réprimandé': 1849, 'proviseur': 1850, 'réprouvait': 1851, 'sévèrement': 1852, 'mettaient': 1853, 'désordre': 1854, 'couloir': 1855, 'renieraient': 1856, 'venaient': 1857, 'découvrir': 1858, 'déclaration': 1859, 'précédente': 1860, 'conquérir': 1861, 'audience': 1862, 'l’orateur': 1863, 'techniques': 1864, 'rhétoriques': 1865, 'apprises': 1866, 'père': 1867, 'aurait': 1868, 'approuvé': 1869, 'fiançailles': 1870, 'partageait': 1871, 'croyances': 1872, 'religieuses': 1873, 'tim': 1874, 'énorme': 1875, 'fan': 1876, 'comédie': 1877, 'satirique': 1878, 'scrute': 1879, 'commet': 1880, 'craignant': 1881, 'courroux': 1882, 'comportaient': 1883, 'servile': 1884, 'sceptiques': 1885, 'fournit': 1886, 'preuve': 1887, 'crédible': 1888, 'expression': 1889, 'sinistre': 1890, 'docteur': 1891, 'clair': 1892, 'sombres': 1893, 'difficultés': 1894, 'clairement': 1895, 'opinions': 1896, 'peter': 1897, 'joueur': 1898, 'jeux': 1899, 'vidéo': 1900, 'altruiste': 1901, 'plutôt': 1902, 'vendre': 1903, 'personnel': 1904, 'jimmy': 1905, 'essaya': 1906, 'persuader': 1907, 'traverser': 1908, 'artistes': 1909, 'pop': 1910, 'prospèrent': 1911, 'adulation': 1912, 'fans': 1913, 'fidèles': 1914, 'affronter': 1915, 'adversité': 1916, 'bill': 1917, 'clinton': 1918, 'parla': 1919, 'langage': 1920, 'ambigu': 1921, \"lorsqu'on\": 1922, 'décrire': 1923, 'relation': 1924, 'monica': 1925, 'lewinsky': 1926, 'bienveillant': 1927, 'volontaire': 1928, 'tondre': 1929, 'pelouse': 1930, 'voisins': 1931, 'gratuitement': 1932, 'sévère': 1933, 'forte': 1934, 'masquaient': 1935, 'sensibilité': 1936, 'intérieure': 1937, 'attentionnée': 1938, 'statue': 1939, 'minute': 1940, 'man': 1941, 'hommage': 1942, 'vaillants': 1943, 'soldats': 1944, 'combattu': 1945, 'indépendance': 1946, 'confus': 1947, 'obscures': 1948, 'sherlock': 1949, 'watson': 1950, 'demandait': 1951, 'dissimulait': 1952, 'vues': 1953, 'critère': 1954, 'utilisé': 1955, 'élire': 1956, 'essai': 1957, 'gagnant': 1958, 'salsa': 1959, 'effectivement': 1960, 'vides': 1961, 'belles': 1962, 'ray': 1963, 'corroborer': 1964, 'gary': 1965, 'convaincue': 1966, 'dise': 1967, 'meurtrier': 1968, 'déclaré': 1969, 'condamné': 1970, 'emprisonnement': 1971, 'joueurs': 1972, 'hockey': 1973, 'provoquent': 1974, 'uns': 1975, 'bagarres': 1976, 'éclatent': 1977, 'sensation': 1978, 'retenue': 1979, 'osait': 1980, 'point': 1981, 'insensée': 1982, 'consensus': 1983, 'indique': 1984, 'opposés': 1985, 'proposée': 1986, 'forêt': 1987, 'répandre': 1988, 'rapidement': 1989, 'incendie': 1990, 'définitions': 1991, 'précises': 1992, 'simples': 1993, 'retenir': 1994, 'furieux': 1995, 'accident': 1996, 'conciliants': 1997, 'examen': 1998, 'sommaire': 1999, 'dents': 2000, 'indiqua': 2001, 'gingivite': 2002, 'comporter': 2003, 'convenance': 2004, 'bal': 2005, 'd’année': 2006, 'journal': 2007, 'décrivait': 2008, 'accusé': 2009, 'prouvé': 2010, 'politicien': 2011, 'fit': 2012, 'pression': 2013, 'réforme': 2014, 'dénonçant': 2015, 'corruption': 2016, 'responsables': 2017, 'gouvernementaux': 2018, 'dépravation': 2019, 'amena': 2020, 'n’était': 2021, 'd’autre': 2022, 'tyran': 2023, 'fallait': 2024, 'renverser': 2025, 'perdrai': 2026, 'retard': 2027, 'reprennent': 2028, 'éternuer': 2029, 'mouchoir': 2030, 'cru': 2031, 'devenu': 2032, 'gâchis': 2033, 'd’argent': 2034, 'changé': 2035, 'disposition': 2036, 'battra': 2037, 'linge': 2038, 'promenée': 2039, 'critiquer': 2040, 'chaise': 2041, 'sandwichs': 2042, 'restent': 2043, 'inspirée': 2044, 'pouvait': 2045, 'coucher': 2046, 'appartement': 2047, 'd’été': 2048, 'prenais': 2049, 'dîner': 2050, 'minuit': 2051, 'diras': 2052, 'feras': 2053, 'disaient': 2054, 'faisaient': 2055, 'juré': 2056, 'réellement': 2057, 'décide': 2058, 'qu’on': 2059, 'd’elle': 2060, 'paie': 2061, 'impôts': 2062, 'n’as': 2063, 'enseignants': 2064, 'préconiser': 2065, 'travaillent': 2066, '5h': 2067, 'fragile': 2068, 'bonbon': 2069, \"qu'aujourd'hui\": 2070, 'amusant': 2071, 'enfant': 2072, 'vase': 2073, 'remplir': 2074, 'allumer': 2075, 'croiront': 2076, 'dites': 2077, 'via': 2078, 'e': 2079, 'mail': 2080, 'trouveraient': 2081, 'plausibles': 2082, 'sembler': 2083, 'tiré': 2084, 'cheveux': 2085, 'réel': 2086, 'douée': 2087, 'crédit': 2088, 'amassé': 2089, 'avaler': 2090, 'épée': 2091, 'magique': 2092, 'prononces': 2093, 'pronounce': 2094, 'géniales': 2095, 'données': 2096, 'suggèrent': 2097, 'durée': 2098, 'optimale': 2099, 'magistral': 2100, '60': 2101, 'tendance': 2102, 'regarder': 2103, 'images': 2104, 'texte': 2105, 'marché': 2106, 'douze': 2107, 'tombée': 2108, 'week': 2109, 'end': 2110, 'quelqu’un': 2111, 'frappe': 2112, 'riche': 2113, 'concentrer': 2114, 'massage': 2115, 'détendre': 2116, 'reposer': 2117, 'passage': 2118, 'smith': 2119, 'effet': 2120, 'manque': 2121, 'mémoire': 2122, 'trace': 2123, 'placer': 2124, 'paume': 2125, 'mains': 2126, 'sol': 2127, 'plier': 2128, 'genoux': 2129, 'progrès': 2130, 'aimerait': 2131, 'réalité': 2132, 'réaliser': 2133, 'réveiller': 2134, 'd’imbéciles': 2135, 'danger': 2136, 'ressemble': 2137, 'atmosphère': 2138, 'mystérieuse': 2139, 'j’attends': 2140, 'impatience': 2141, 'd’entendre': 2142, 'qu’est': 2143, 'louper': 2144, 'acheté': 2145, 'd’orange': 2146, 'chapeau': 2147, 'crêpes': 2148, 'l’après': 2149, 'midi': 2150, 'bavarder': 2151, 'indépendant': 2152, 'debout': 2153, 'longues': 2154, 'oreilles': 2155, 'petite': 2156, 'queue': 2157, 'cœur': 2158, 'rempli': 2159, 'souhaite': 2160, 'effacer': 2161, 'souvenirs': 2162, 'monsieur': 2163, 'n’avez': 2164, 'droit': 2165, 'garer': 2166, 'emmener': 2167, 'urgence': 2168, 'gravement': 2169, 'blessé': 2170, 'gardé': 2171, 'dis': 2172, 'appeler': 2173, 'partent': 2174, 'force': 2175, 'mémorisation': 2176, 'formules': 2177, 'ouais': 2178, 'fast': 2179, 'food': 2180, 'hâte': 2181, 'chambres': 2182, 'hôtel': 2183, 'insonorisées': 2184, 'j’arrive': 2185, 'mâcher': 2186, 'chewing': 2187, 'gum': 2188, 'imaginer': 2189, 'électricité': 2190, 'quatre': 2191, 'sept': 2192, 'température': 2193, 'moyenne': 2194, '37°c': 2195, 'évite': 2196, 'd’ouvrir': 2197, 'courants': 2198, 'd’air': 2199, 'dos': 2200, 'nationalité': 2201, 'française': 2202, 'd’origine': 2203, 'vietnamienne': 2204, 'association': 2205, 'humanitaire': 2206, 'recherche': 2207, 'bénévoles': 2208, 'distribuer': 2209, 'abris': 2210, 'décembre': 2211, 'frustrant': 2212, 'retrouver': 2213, 'coloniseront': 2214, 'lune': 2215, 'chansons': 2216, 'célèbres': 2217, 'auriez': 2218, 'composées': 2219, 'm’acheter': 2220, 'appareil': 2221, 'numérique': 2222, 'prison': 2223, 'fier': 2224, 'projet': 2225, 'nécessaire': 2226, 'élargir': 2227, 'connaissance': 2228, 'exploration': 2229, 'œuvre': 2230, 'art': 2231, 'nasa': 2232, 'possède': 2233, 'informations': 2234, 'suffisantes': 2235, 'affirmer': 2236, 'visite': 2237, 'humaine': 2238, 'planète': 2239, 'faisable': 2240, 'vraies': 2241, 'rondeurs': 2242, 'chatouiller': 2243, 'mène': 2244, 'cercle': 2245, 'vicieux': 2246, 'flemme': 2247, 'rentrée': 2248, 'pressé': 2249, 'retourner': 2250}\n",
      "English tokenizer:\n",
      "{'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3, '.': 4, 'the': 5, 'i': 6, 'to': 7, ',': 8, 'you': 9, 'a': 10, 'is': 11, '?': 12, 'it': 13, 'of': 14, '!': 15, 'have': 16, 'in': 17, 'that': 18, 'my': 19, \"don't\": 20, 'are': 21, 'do': 22, 'what': 23, 'be': 24, 'not': 25, \"i'\": 26, 'and': 27, '\"': 28, 'me': 29, 'for': 30, \"it's\": 31, 'he': 32, 'm': 33, 'was': 34, 'if': 35, 'this': 36, 'when': 37, 'will': 38, 'we': 39, 'can': 40, 'with': 41, 'like': 42, 'who': 43, 'on': 44, 'but': 45, 'people': 46, 'an': 47, 'want': 48, 'his': 49, 'life': 50, 'so': 51, 'at': 52, 'one': 53, \"can't\": 54, 'know': 55, 'your': 56, 'about': 57, 'too': 58, 'would': 59, 'no': 60, 'they': 61, 'there': 62, 'how': 63, \"you're\": 64, 'him': 65, 'from': 66, 'time': 67, 'never': 68, 'think': 69, 'as': 70, 'all': 71, 'their': 72, 'am': 73, 'go': 74, 'take': 75, 'always': 76, 'has': 77, 'make': 78, 'up': 79, 'only': 80, 'them': 81, 'more': 82, 'could': 83, 'much': 84, 'get': 85, 'world': 86, ';': 87, 'very': 88, 'why': 89, 'just': 90, 'without': 91, 'now': 92, 'say': 93, 'anything': 94, 'because': 95, 'did': 96, 'even': 97, 'love': 98, 'she': 99, 'had': 100, 'something': 101, 'going': 102, 'should': 103, \"doesn't\": 104, 'over': 105, \"that's\": 106, 'things': 107, 'were': 108, 'than': 109, \"didn't\": 110, 'or': 111, 'day': 112, 'give': 113, 'live': 114, 'everything': 115, 'tell': 116, 'where': 117, 'need': 118, \"there's\": 119, 'said': 120, 'many': 121, 'really': 122, '-': 123, 'good': 124, 'long': 125, 'idea': 126, 'here': 127, 'find': 128, 'mean': 129, 'new': 130, 'see': 131, 'still': 132, 'before': 133, 'please': 134, 'out': 135, 'which': 136, 'by': 137, 'tired': 138, 'then': 139, 'learn': 140, 'same': 141, 'come': 142, 'sleep': 143, 'most': 144, 'problem': 145, 'way': 146, 'our': 147, 'look': 148, 'understand': 149, 'believe': 150, 'years': 151, 'back': 152, 'nothing': 153, 'may': 154, 'tomorrow': 155, 'told': 156, 'other': 157, 'feel': 158, 'school': 159, 'ask': 160, 'though': 161, 'being': 162, 'any': 163, 'today': 164, \"won't\": 165, 'll': 166, 'true': 167, 'word': 168, 'every': 169, 'her': 170, 'thanks': 171, 'made': 172, 'man': 173, 'well': 174, 'eat': 175, 'into': 176, 'those': 177, 'says': 178, 'some': 179, 'must': 180, 'call': 181, 'thought': 182, 'money': 183, 'explain': 184, 'friends': 185, 'simple': 186, 'left': 187, 'someday': 188, 'us': 189, 'old': 190, 'enough': 191, 'truth': 192, 'keep': 193, 'train': 194, ':': 195, 'great': 196, 'often': 197, 'asked': 198, 'got': 199, 'right': 200, 'wanted': 201, 'person': 202, 'crazy': 203, 'surprise': 204, 'thing': 205, 've': 206, 'ever': 207, 'real': 208, 'saying': 209, 'been': 210, 'myself': 211, 'stay': 212, 'beautiful': 213, 'lot': 214, 'stupid': 215, 'speak': 216, 'french': 217, 'wants': 218, 'mind': 219, 'trying': 220, 'does': 221, 'such': 222, 'ten': 223, 'lost': 224, 'around': 225, 'someone': 226, 'two': 227, 'children': 228, 'mathematics': 229, 'face': 230, 'students': 231, 'doing': 232, \"what's\": 233, \"haven't\": 234, 'work': 235, 'everyone': 236, 'own': 237, 'learning': 238, 'change': 239, 'happen': 240, 'sometimes': 241, 'wonder': 242, 'else': 243, 'last': 244, \"he's\": 245, 'gonna': 246, 'd': 247, 'talk': 248, 'lose': 249, 'interesting': 250, 'story': 251, 'came': 252, 'living': 253, 'important': 254, \"she's\": 255, 'away': 256, 'nobody': 257, 'bad': 258, 'class': 259, 'wait': 260, 'anymore': 261, 'better': 262, 'while': 263, 'late': 264, 'learned': 265, 'thank': 266, 'wind': 267, 'three': 268, 'tv': 269, 'went': 270, 'yet': 271, 'family': 272, 'hot': 273, 'hear': 274, 'cannot': 275, 'able': 276, 'mistakes': 277, 'buy': 278, 'animal': 279, 'opinion': 280, 'sick': 281, 'once': 282, 'try': 283, 'muiriel': 284, 'words': 285, 'difficult': 286, 'alone': 287, 'best': 288, 'send': 289, 'another': 290, 'anyone': 291, 'care': 292, 'night': 293, 'king': 294, 'place': 295, 'high': 296, 'morning': 297, 'these': 298, 'point': 299, 'together': 300, 'bed': 301, 'after': 302, 'next': 303, 'week': 304, 'police': 305, 'having': 306, 'almost': 307, 'computer': 308, 'expect': 309, 'mathematicians': 310, 'question': 311, 'since': 312, 'found': 313, 'seems': 314, 'except': 315, 'answer': 316, 'curious': 317, 'sorry': 318, 'whatever': 319, 'stop': 320, 'making': 321, 'use': 322, 'least': 323, 'drink': 324, 'mother': 325, 'little': 326, 'communication': 327, 'far': 328, 'die': 329, 'lives': 330, 'war': 331, 'government': 332, 'station': 333, 'quite': 334, 'open': 335, 'yes': 336, 'between': 337, 'impossible': 338, 'brain': 339, 'name': 340, \"we're\": 341, 'eating': 342, 'parents': 343, 'car': 344, 'small': 345, 'half': 346, 'five': 347, 'ready': 348, 'sentences': 349, 'read': 350, 'again': 351, 'talking': 352, 'marry': 353, 'eye': 354, 'god': 355, 'lunch': 356, 'human': 357, \"where's\": 358, 'window': 359, \"let's\": 360, 'birthday': 361, 'soon': 362, 'loss': 363, 'cost': 364, 'instead': 365, 'different': 366, 'home': 367, 'liked': 368, 'trust': 369, 'against': 370, 'each': 371, 'oh': 372, 'depends': 373, 'cool': 374, 'fat': 375, 'influenced': 376, 'decision': 377, 'girl': 378, 'worst': 379, \"wouldn't\": 380, 'afraid': 381, 'others': 382, 'whenever': 383, 'expensive': 384, 'bit': 385, 'theory': 386, 'intentionally': 387, 'looks': 388, 'asking': 389, 'wish': 390, 'hate': 391, \"wasn't\": 392, 'math': 393, 'whole': 394, 'useful': 395, 'uh': 396, 'solution': 397, 'fast': 398, 'play': 399, 'happens': 400, \"you'll\": 401, 'papers': 402, 'seriously': 403, 'cry': 404, 'dream': 405, 'food': 406, 'meet': 407, 'done': 408, 'surprised': 409, 'days': 410, 'seeing': 411, 'music': 412, 'let': 413, 'happiness': 414, 'start': 415, 'eight': 416, 'student': 417, \"aren't\": 418, 'month': 419, 'first': 420, 'form': 421, 'vacation': 422, \"isn't\": 423, 'trip': 424, 'complicated': 425, 'known': 426, 'united': 427, 'states': 428, 'noise': 429, 'rest': 430, 'fun': 431, 'totally': 432, 'changes': 433, 'walk': 434, 'minutes': 435, 'hours': 436, 'translate': 437, 'study': 438, 'doubt': 439, 'universe': 440, 'side': 441, 'eyes': 442, 'country': 443, 'leave': 444, 'chocolate': 445, 'annoying': 446, 'put': 447, 'outside': 448, 'red': 449, 'died': 450, 'dreams': 451, 'gave': 452, 'type': 453, 'arrive': 454, 'technology': 455, 'game': 456, 'prove': 457, 'its': 458, 'changed': 459, 'suffering': 460, 'despite': 461, 'down': 462, 'smile': 463, 'bottles': 464, 'completely': 465, 'cold': 466, 'audience': 467, 'liberty': 468, 'during': 469, 'glasses': 470, 'door': 471, 'brother': 472, 'spenser': 473, 'essay': 474, 'teachers': 475, 'refused': 476, 'drive': 477, 'begins': 478, 'spent': 479, 'broken': 480, 'acted': 481, 'innocent': 482, 'fellow': 483, 'stand': 484, 'guy': 485, 'deed': 486, 'useless': 487, 'happy': 488, '20': 489, 'end': 490, 'reason': 491, 'education': 492, 'task': 493, 'wrong': 494, 'studying': 495, 'suppose': 496, 'worry': 497, 'miss': 498, 'mysterious': 499, 'shape': 500, 'unfortunately': 501, 'busy': 502, 'common': 503, 'ideals': 504, 'line': 505, 'hurry': 506, 'alive': 507, 'context': 508, 'lame': 509, 'probably': 510, 'wondered': 511, 'forever': 512, 'help': 513, 'close': 514, 'kill': 515, 'woke': 516, 'sad': 517, 'write': 518, 'trang': 519, 'easily': 520, 'humans': 521, 'ideas': 522, 'possible': 523, \"life's\": 524, 'physics': 525, 'teacher': 526, 'classes': 527, 'might': 528, 'intention': 529, 'happened': 530, 'scared': 531, 'online': 532, 'freedom': 533, 'weird': 534, 'dreamt': 535, 'few': 536, 'ago': 537, 'schools': 538, 'obvious': 539, 'longer': 540, 'visit': 541, \"shouldn't\": 542, 'off': 543, 'france': 544, 'options': 545, 'either': 546, 'neither': 547, 'robot': 548, 'underestimate': 549, 'power': 550, 'mom': 551, 'english': 552, 'show': 553, 'lies': 554, 'space': 555, 'famous': 556, 'writing': 557, 'foreign': 558, 'keeps': 559, 'harder': 560, 'moon': 561, 'japanese': 562, 'understands': 563, 'thinking': 564, 'check': 565, 'email': 566, 'decided': 567, 'rolling': 568, 'stone': 569, 'gathers': 570, 'moss': 571, 'white': 572, 'rabbit': 573, 'cave': 574, 'fools': 575, 'looking': 576, 'pretty': 577, 'phone': 578, 'decide': 579, 'whether': 580, 'thirty': 581, 'boat': 582, 'cards': 583, 'met': 584, 'called': 585, 'mistake': 586, 'germans': 587, 'million': 588, 'lived': 589, 'nagoya': 590, 'rare': 591, 'ninety': 592, 'tried': 593, 'photo': 594, 'passport': 595, 'saw': 596, 'helped': 597, 'angel': 598, 'madrid': 599, 'lucky': 600, 'pity': 601, 'somebody': 602, 'wearing': 603, 'stops': 604, 'throw': 605, 'blind': 606, 'raise': 607, 'sign': 608, 'poor': 609, 'article': 610, 'italian': 611, 'typewriter': 612, 'written': 613, 'meals': 614, 'spend': 615, 'rather': 616, 'through': 617, 'purpose': 618, 'exams': 619, '10': 620, 'already': 621, 'ms': 622, 'orange': 623, 'juice': 624, 'rarely': 625, 'develop': 626, 'desire': 627, 'paris': 628, 'heart': 629, 'nature': 630, 'hey': 631, 'increased': 632, 'drastically': 633, 'contrary': 634, 'jack': 635, 'hour': 636, 'dance': 637, 'near': 638, 'wallet': 639, 'wasted': 640, 'age': 641, 'yourself': 642, 'appetite': 643, 'hit': 644, 'complaining': 645, \"they're\": 646, 'egg': 647, 'fridge': 648, 'part': 649, 'science': 650, 'gone': 651, 'women': 652, 'church': 653, 'feeling': 654, 'getting': 655, 'languages': 656, 'wake': 657, 'early': 658, 'mess': 659, 'body': 660, 'married': 661, 'information': 662, 'full': 663, 'creates': 664, 'present': 665, 'piano': 666, 'undressing': 667, 'baby': 668, 'water': 669, 'free': 670, 'telling': 671, 'whose': 672, 'pope': 673, 'sees': 674, 'language': 675, 'turn': 676, 'avoid': 677, 'therefore': 678, 'decisions': 679, 'book': 680, 'fall': 681, 'thirsty': 682, 'inch': 683, \"he'll\": 684, 'later': 685, 'six': 686, 'pain': 687, 'slept': 688, 'sex': 689, 'eaten': 690, 'men': 691, 'actually': 692, 'numbers': 693, 'machine': 694, 'schedule': 695, 'card': 696, 'hospital': 697, 'inspiration': 698, '—': 699, 'practice': 700, 'unless': 701, 'hungry': 702, 'spoken': 703, 'sung': 704, 'wisdom': 705, 'sent': 706, 'raining': 707, 'beach': 708, 'started': 709, 'conviction': 710, 'unnecessary': 711, 'won': 712, 'break': 713, 'internet': 714, 'candy': 715, 'floor': 716, 'room': 717, 'patient': 718, 'watching': 719, 'willing': 720, 'university': 721, 'moment': 722, 'knew': 723, 'subjects': 724, 'realize': 725, 'makes': 726, 'fear': 727, 'politicians': 728, 'behavior': 729, \"spenser's\": 730, 'remarks': 731, 'prefers': 732, 'subject': 733, 'neighbor': 734, 'ability': 735, 'plane': 736, 'belief': 737, 'led': 738, 'given': 739, \"students'\": 740, 'joan': 741, 'arc': 742, 'voice': 743, 'gay': 744, 'win': 745, \"king's\": 746, 'news': 747, 'needed': 748, 'crime': 749, 'job': 750, 'prison': 751, 'fire': 752, 'mad': 753, 'air': 754, 'level': 755, 'driving': 756, 'dark': 757, 'homework': 758, 'light': 759, 'stole': 760, 'pronounce': 761, 'winter': 762, 'season': 763, 'secret': 764, 'unfair': 765, 'proposal': 766, 'impression': 767, 'essence': 768, 'bathroom': 769, 'worse': 770, 'boys': 771, 'abide': 772, 'bear': 773, 'notice': 774, 'june': 775, '18th': 776, \"muiriel's\": 777, 'password': 778, 'clue': 779, 'simply': 780, 'evil': 781, 'bunny': 782, 'mountains': 783, 'recent': 784, 'picture': 785, 'microphone': 786, 'earlier': 787, 'disappoints': 788, 'forced': 789, 'encouraged': 790, 'choosing': 791, '€30': 792, '€100': 793, '100': 794, 'euros': 795, 'per': 796, 'nap': 797, 'strange': 798, 'disturb': 799, 'term': 800, 'return': 801, 'characters': 802, 'ticket': 803, 'impatient': 804, 'kind': 805, 'astrophysicist': 806, 'biology': 807, 'nuts': 808, \"weren't\": 809, 'fighting': 810, 'kicking': 811, 'sure': 812, 'butterfly': 813, 'haste': 814, 'freaking': 815, 'kidding': 816, 'stupidest': 817, 'grow': 818, 'america': 819, 'lovely': 820, 'earn': 821, 'extremely': 822, 'shoot': 823, 'fish': 824, 'mere': 825, 'plushy': 826, \"it'd\": 827, 'siblings': 828, 'showing': 829, 'emotions': 830, 'substitute': 831, 'program': 832, 'intend': 833, 'selfish': 834, 'consider': 835, 'antisocial': 836, 'impolite': 837, 'unhappy': 838, '6': 839, 'daily': 840, 'marshmallow': 841, 'order': 842, 'risks': 843, 'flawed': 844, 'flaws': 845, 'fixed': 846, 'maybe': 847, 'exactly': 848, 'innocence': 849, 'meant': 850, 'extreme': 851, 'intriguing': 852, 'hide': 853, 'account': 854, 'forums': 855, 'habits': 856, 'running': 857, 'problems': 858, 'lyrics': 859, 'skip': 860, 'japan': 861, 'realized': 862, 'forgot': 863, 'backpack': 864, 'house': 865, 'freeze': 866, 'frost': 867, 'apologized': 868, 'furious': 869, 'bullets': 870, 'explained': 871, 'idiot': 872, 'explanation': 873, 'theoretically': 874, 'scare': 875, 'weeks': 876, 'express': 877, 'themselves': 878, 'explicitly': 879, 'silly': 880, 'demonstrate': 881, 'viagra': 882, 'wikipedia': 883, 'phrased': 884, 'candlelight': 885, 'boyfriend': 886, 'weight': 887, 'sudoku': 888, 'continuing': 889, 'bother': 890, 'congratulations': 891, 'possibility': 892, 'unlikely': 893, 'logged': 894, 'inevitable': 895, 'chemistry': 896, 'guess': 897, 'traveller': 898, 'strengths': 899, 'weaknesses': 900, 'episode': 901, '21': 902, 'laughing': 903, 'shows': 904, 'robots': 905, 'wondering': 906, 'therein': 907, 'outer': 908, 'utterly': 909, 'despise': 910, 'formal': 911, 'intrigue': 912, \"you'd\": 913, \"who'd\": 914, 'travel': 915, 'hard': 916, 'bearing': 917, 'unbearable': 918, 'uncomfortable': 919, 'land': 920, 'pun': 921, 'behind': 922, 'priorities': 923, 'pretending': 924, 'dumb': 925, 'normal': 926, 'polite': 927, 'eternity': 928, 'grades': 929, 'certain': 930, 'proverb': 931, 'weather': 932, 'matter': 933, 'happening': 934, 'brothers': 935, 'perish': 936, \"how's\": 937, 'working': 938, 'heights': 939, 'coward': 940, 'exclaimed': 941, 'hiroshi': 942, 'complex': 943, 'ringing': 944, 'nice': 945, 'willie': 946, 'answered': 947, 'helping': 948, 'mention': 949, 'run': 950, 'likes': 951, 'awaiting': 952, 'sort': 953, \"that'll\": 954, 'playing': 955, 'somewhere': 956, 'allen': 957, 'poet': 958, 'archer': 959, 'killed': 960, 'deer': 961, 'communism': 962, 'reached': 963, 'lifetime': 964, 'rye': 965, 'grain': 966, 'poverty': 967, \"1950's\": 968, 'finns': 969, 'cited': 970, 'healthy': 971, 'diets': 972, 'correct': 973, 'deck': 974, 'oaken': 975, 'table': 976, 'crafty': 977, 'spell': 978, 'tokyo': 979, 'outline': 980, 'website': 981, 'democracy': 982, 'beginning': 983, 'holiday': 984, 'commissioner': 985, 'pants': 986, 'naturally': 987, 'became': 988, 'nervous': 989, 'lunatics': 990, 'bite': 991, 'eggs': 992, 'round': 993, 'dies': 994, 'speechless': 995, 'damn': 996, 'pull': 997, 'washing': 998, 'wash': 999, 'motion': 1000, 'glass': 1001, 'houses': 1002, 'stones': 1003, 'answers': 1004, 'questions': 1005, 'doubts': 1006, 'oneself': 1007, 'intelligence': 1008, 'souvenir': 1009, 'excuse': 1010, 'allow': 1011, 'errors': 1012, 'above': 1013, 'conversation': 1014, 'stared': 1015, 'hamlet': 1016, 'biscuit': 1017, 'inquired': 1018, 'master': 1019, '2': 1020, '3': 1021, 'regretting': 1022, 'guessed': 1023, 'imagination': 1024, 'affects': 1025, 'aspect': 1026, 'forget': 1027, 'unexpected': 1028, \"couldn't\": 1029, 'achieved': 1030, 'effort': 1031, 'drift': 1032, 'pointless': 1033, 'ruining': 1034, 'condom': 1035, 'cat': 1036, 'tells': 1037, 'took': 1038, 'pages': 1039, 'eleven': 1040, 'brown': 1041, 'mike': 1042, 'ah': 1043, 'interjection': 1044, 'mandatory': 1045, 'character': 1046, 'schooling': 1047, 'analyzed': 1048, 'multitude': 1049, 'works': 1050, 'dedicated': 1051, 'various': 1052, 'ways': 1053, 'within': 1054, 'suck': 1055, 'dude': 1056, 'bone': 1057, 'pick': 1058, 'city': 1059, 'attack': 1060, 'pride': 1061, 'friend': 1062, 'rachel': 1063, 'invented': 1064, 'begin': 1065, 'infinite': 1066, 'perfect': 1067, 'lacked': 1068, 'defect': 1069, 'den': 1070, 'crazies': 1071, 'complained': 1072, 'pains': 1073, 'front': 1074, 'lobe': 1075, 'opened': 1076, \"everything's\": 1077, 'fine': 1078, \"name's\": 1079, 'meeting': 1080, 'shall': 1081, 'shopping': 1082, 'mine': 1083, 'italy': 1084, 'fault': 1085, 'dial': 1086, 'telephone': 1087, 'youth': 1088, 'hostel': 1089, 'showers': 1090, 'mouth': 1091, 'plans': 1092, 'wanting': 1093, 'sexy': 1094, 'pass': 1095, 'salt': 1096, 'bored': 1097, 'disneyland': 1098, 'arguing': 1099, 'sunscreen': 1100, 'sunburn': 1101, 'calm': 1102, 'spiders': 1103, 'freak': 1104, 'cleaning': 1105, 'headache': 1106, 'cook': 1107, 'hood': 1108, 'fry': 1109, 'seen': 1110, 'refrigerator': 1111, 'broke': 1112, 'hated': 1113, 'loved': 1114, 'lonely': 1115, 'saddle': 1116, 'horse': 1117, 'continue': 1118, 'discovered': 1119, 'ocean': 1120, 'reflected': 1121, 'phrase': 1122, 'reap': 1123, 'sow': 1124, 'sown': 1125, 'storm': 1126, 'speech': 1127, 'slowly': 1128, 'admit': 1129, 'snore': 1130, 'tonight': 1131, 'unwell': 1132, 'faking': 1133, 'snoring': 1134, 'shoes': 1135, 'ones': 1136, 'cops': 1137, 'coming': 1138, 'merry': 1139, 'christmas': 1140, 'listened': 1141, 'complete': 1142, 'nerves': 1143, 'touched': 1144, 'receptors': 1145, 'skin': 1146, 'messages': 1147, 'causing': 1148, 'release': 1149, 'chemicals': 1150, 'endorphins': 1151, 'involve': 1152, 'hundred': 1153, 'fifty': 1154, 'thousand': 1155, 'couples': 1156, 'expected': 1157, 'shanghai': 1158, '2006': 1159, 'selected': 1160, 'extensive': 1161, 'medical': 1162, 'psychological': 1163, 'tests': 1164, 'malnutrition': 1165, 'niger': 1166, 'bicycles': 1167, 'tools': 1168, 'urban': 1169, 'sustainability': 1170, 'launched': 1171, 'challenges': 1172, 'taxpayers': 1173, 'balance': 1174, 'national': 1175, 'budget': 1176, 'glad': 1177, 'computers': 1178, 'helps': 1179, 'scientific': 1180, 'breakthroughs': 1181, 'discovery': 1182, 'aware': 1183, 'past': 1184, 'future': 1185, 'key': 1186, 'gain': 1187, 'misunderstood': 1188, 'understood': 1189, 'produce': 1190, 'importance': 1191, 'mystery': 1192, 'educated': 1193, '21st': 1194, 'century': 1195, 'passion': 1196, 'geneva': 1197, 'starving': 1198, 'starved': 1199, 'antigua': 1200, 'cubic': 1201, 'meter': 1202, 'corresponds': 1203, '1000': 1204, 'liters': 1205, 'plays': 1206, 'seldom': 1207, 'vegetables': 1208, 'movies': 1209, 'cinema': 1210, 'crashed': 1211, 'wall': 1212, 'visions': 1213, 'hi': 1214, 'dictionary': 1215, 'creationism': 1216, 'pseudo': 1217, 'calmed': 1218, 'bath': 1219, 'propose': 1220, 'democrat': 1221, 'citizen': 1222, 'yields': 1223, 'majority': 1224, 'searches': 1225, 'finds': 1226, 'rome': 1227, 'built': 1228, 'silence': 1229, 'gives': 1230, 'consent': 1231, 'finished': 1232, 'begun': 1233, 'tom': 1234, 'wine': 1235, 'poetry': 1236, 'german': 1237, 'objective': 1238, 'means': 1239, 'everybody': 1240, 'mathematician': 1241, 'forth': 1242, 'error': 1243, 'foundations': 1244, 'greater': 1245, 'sum': 1246, 'parts': 1247, 'detrimental': 1248, 'mathematical': 1249, 'nor': 1250, 'poets': 1251, 'fantasy': 1252, 'logic': 1253, 'expert': 1254, 'knows': 1255, 'field': 1256, 'socially': 1257, 'acceptable': 1258, 'masturbate': 1259, 'public': 1260, 'types': 1261, 'binary': 1262, 'follow': 1263, 'nowadays': 1264, 'irregular': 1265, 'verbs': 1266, 'designed': 1267, 'transform': 1268, 'society': 1269, 'reproduce': 1270, 'beside': 1271, 'joy': 1272, 'evening': 1273, 'dress': 1274, 'desired': 1275, 'absolute': 1276, 'regret': 1277, 'nearly': 1278, 'yard': 1279, 'mile': 1280, 'irresistible': 1281, 'accept': 1282, 'under': 1283, 'condition': 1284, 'hand': 1285, 'ruin': 1286, 'abandon': 1287, 'cut': 1288, 'nails': 1289, 'ironing': 1290, 'banana': 1291, 'pie': 1292, 'woman': 1293, 'adopt': 1294, 'abortions': 1295, 'headed': 1296, 'monkey': 1297, 'miracles': 1298, 'potatoes': 1299, 'lasagna': 1300, 'unpleasant': 1301, 'dentist': 1302, 'example': 1303, '49': 1304, '%': 1305, 'dead': 1306, 'prime': 1307, 'logical': 1308, 'rules': 1309, 'eyebrow': 1310, 'also': 1311, 'idiotic': 1312, 'identity': 1313, 'despair': 1314, 'struck': 1315, 'lightning': 1316, 'penguin': 1317, 'cute': 1318, 'greatest': 1319, 'source': 1320, 'whom': 1321, 'difference': 1322, 'appear': 1323, 'bread': 1324, 'requires': 1325, 'deaf': 1326, 'rereading': 1327, 'letters': 1328, 'ring': 1329, 'planning': 1330, 'rain': 1331, 'smart': 1332, 'shocking': 1333, 'justice': 1334, 'consists': 1335, 'harmless': 1336, 'slowest': 1337, 'promise': 1338, 'faithful': 1339, 'keeping': 1340, 'mixture': 1341, 'fatal': 1342, 'sexually': 1343, 'transmitted': 1344, 'disease': 1345, 'library': 1346, 'zoo': 1347, 'yesterday': 1348, 'battle': 1349, 'hello': 1350, 'watched': 1351, 'chinese': 1352, 'easier': 1353, 'street': 1354, 'sea': 1355, 'cotton': 1356, 'practical': 1357, 'laptop': 1358, 'fell': 1359, 'times': 1360, 'mirror': 1361, 'london': 1362, 'year': 1363, 'ceiling': 1364, 'takes': 1365, 'younger': 1366, 'presumptuous': 1367, 'assume': 1368, 'astute': 1369, 'reader': 1370, 'weigh': 1371, 'including': 1372, 'anonymous': 1373, 'sources': 1374, 'denying': 1375, 'anarchist': 1376, 'katja': 1377, 'maintained': 1378, 'wished': 1379, 'destroy': 1380, 'blindness': 1381, 'responsible': 1382, 'staggering': 1383, 'toll': 1384, 'health': 1385, 'dignity': 1386, 'diminution': 1387, 'quality': 1388, 'worldwide': 1389, 'formation': 1390, 'movement': 1391, 'hurricanes': 1392, 'capricious': 1393, 'telegram': 1394, 'brevity': 1395, 'essential': 1396, 'charged': 1397, 'david': 1398, 'keen': 1399, 'interest': 1400, 'aesthetics': 1401, 'qualities': 1402, 'painting': 1403, 'sculpture': 1404, 'musical': 1405, 'composition': 1406, 'poem': 1407, 'pleasing': 1408, 'ear': 1409, \"trang's\": 1410, 'constant': 1411, 'affirmations': 1412, 'aaah': 1413, 'private': 1414, 'colleges': 1415, 'universities': 1416, 'autonomous': 1417, 'join': 1418, 'warcraft': 1419, 'pitted': 1420, 'team': 1421, 'adversaries': 1422, 'existed': 1423, 'apathy': 1424, 'voting': 1425, 'comes': 1426, 'distaste': 1427, 'politics': 1428, 'ascendancy': 1429, 'monarchs': 1430, 'rebellion': 1431, 'sarah': 1432, 'discerning': 1433, 'prank': 1434, 'orchestra': 1435, 'discordant': 1436, 'noises': 1437, 'tuning': 1438, 'disdained': 1439, 'disinclination': 1440, 'acclaimed': 1441, 'actors': 1442, 'performance': 1443, 'abridge': 1444, 'paper': 1445, 'taking': 1446, 'details': 1447, 'advocating': 1448, 'equality': 1449, 'censured': 1450, 'outrageous': 1451, 'inappropriate': 1452, 'eichler': 1453, 'notorious': 1454, 'reputation': 1455, 'austere': 1456, 'listen': 1457, 'resort': 1458, 'coercion': 1459, 'migraines': 1460, 'aspirin': 1461, 'alleviate': 1462, 'sarcastic': 1463, 'joking': 1464, 'misinterpreted': 1465, 'signs': 1466, 'ambivalence': 1467, 'taken': 1468, 'arbitrary': 1469, 'selection': 1470, 'lottery': 1471, 'machines': 1472, 'hunger': 1473, 'abstract': 1474, 'concept': 1475, 'iraq': 1476, 'volatile': 1477, 'political': 1478, 'debate': 1479, 'heated': 1480, 'argument': 1481, 'spark': 1482, 'virtuoso': 1483, 'skills': 1484, 'earned': 1485, 'among': 1486, 'experts': 1487, 'vilified': 1488, 'jealous': 1489, 'catholic': 1490, 'venerate': 1491, 'symbolic': 1492, 'leader': 1493, 'unsure': 1494, 'suitor': 1495, 'princess': 1496, 'vacillated': 1497, 'heirless': 1498, 'royal': 1499, 'poisoned': 1500, 'general': 1501, 'army': 1502, 'finally': 1503, 'chance': 1504, 'usurp': 1505, 'throne': 1506, 'approaching': 1507, 'turbulence': 1508, 'pilot': 1509, 'passengers': 1510, 'aboard': 1511, 'fasten': 1512, 'seat': 1513, 'belts': 1514, 'europe': 1515, 'transient': 1516, 'felt': 1517, 'interactions': 1518, 'traveling': 1519, 'college': 1520, 'jason': 1521, 'taciturn': 1522, 'individual': 1523, 'sycophants': 1524, 'praising': 1525, 'adding': 1526, 'translating': 1527, 'contributors': 1528, 'surely': 1529, 'surpass': 1530, 'superfluous': 1531, 'essays': 1532, 'superficial': 1533, 'analysis': 1534, 'highest': 1535, 'grade': 1536, 'professors': 1537, 'detail': 1538, 'succinct': 1539, 'books': 1540, 'maury': 1541, 'povich': 1542, 'pretentious': 1543, 'claims': 1544, 'lovers': 1545, 'cheating': 1546, 'prevalent': 1547, 'according': 1548, 'nationwide': 1549, 'poll': 1550, 'muslims': 1551, 'linked': 1552, 'terrorism': 1553, \"freud's\": 1554, 'insights': 1555, 'honored': 1556, 'profound': 1557, 'thinker': 1558, 'served': 1559, 'profusion': 1560, 'wedding': 1561, 'bride': 1562, 'groom': 1563, 'began': 1564, 'invited': 1565, 'guests': 1566, 'proliferation': 1567, 'usage': 1568, 'birth': 1569, 'generation': 1570, 'young': 1571, 'prolific': 1572, 'writer': 1573, 'months': 1574, 'compensatory': 1575, 'sense': 1576, 'proximity': 1577, 'objects': 1578, 'miser': 1579, 'hoards': 1580, 'prudent': 1581, 'greedy': 1582, 'both': 1583, 'girls': 1584, 'john': 1585, 'feelings': 1586, 'quandary': 1587, 'rancor': 1588, 'russians': 1589, 'especially': 1590, 'areas': 1591, 'occupied': 1592, 'soviet': 1593, 'union': 1594, 'johnson': 1595, 'recluse': 1596, 'isolate': 1597, 'himself': 1598, 'rectifying': 1599, 'correcting': 1600, 'beer': 1601, 'brought': 1602, 'party': 1603, 'redundant': 1604, \"host's\": 1605, 'owned': 1606, 'brewery': 1607, 'witnesses': 1608, 'refute': 1609, 'false': 1610, 'testimony': 1611, 'suspect': 1612, 'renounce': 1613, 'heard': 1614, 'none': 1615, 'attribute': 1616, 'voices': 1617, 'lord': 1618, 'shocked': 1619, 'events': 1620, 'september': 1621, '11th': 1622, 'condemned': 1623, 'terrorists': 1624, 'reprehensible': 1625, 'james': 1626, 'reprimanded': 1627, 'principal': 1628, 'severely': 1629, 'reproved': 1630, 'hallway': 1631, 'repudiate': 1632, 'retract': 1633, 'previous': 1634, 'statement': 1635, 'speaker': 1636, 'resorted': 1637, 'using': 1638, 'rhetorical': 1639, 'techniques': 1640, 'courses': 1641, 'father': 1642, 'sanction': 1643, 'engagement': 1644, 'share': 1645, 'religious': 1646, 'beliefs': 1647, 'tim': 1648, 'huge': 1649, 'fan': 1650, 'satirical': 1651, 'comedy': 1652, 'scrutinizes': 1653, 'fearing': 1654, 'wrath': 1655, 'servile': 1656, 'skeptical': 1657, 'believable': 1658, 'proof': 1659, \"doctor's\": 1660, 'grim': 1661, 'expression': 1662, 'clear': 1663, 'somber': 1664, 'difficulty': 1665, 'articulate': 1666, 'views': 1667, 'peter': 1668, 'altruistic': 1669, 'video': 1670, 'player': 1671, 'items': 1672, 'selling': 1673, 'personal': 1674, 'profit': 1675, 'jimmy': 1676, 'cajole': 1677, 'letting': 1678, 'across': 1679, 'pop': 1680, 'artists': 1681, 'thrive': 1682, 'adulation': 1683, 'loyal': 1684, 'fans': 1685, 'adversity': 1686, 'gracefully': 1687, 'bill': 1688, 'clinton': 1689, 'spoke': 1690, 'ambiguous': 1691, 'describe': 1692, 'relationship': 1693, 'monica': 1694, 'lewinsky': 1695, 'benevolent': 1696, 'volunteered': 1697, 'mow': 1698, \"neighbors'\": 1699, 'lawns': 1700, 'stern': 1701, 'tone': 1702, 'loud': 1703, 'belied': 1704, 'inner': 1705, 'sensitivity': 1706, 'caring': 1707, 'statue': 1708, 'minute': 1709, 'commemorates': 1710, 'valiant': 1711, 'soldiers': 1712, 'fought': 1713, 'revolutionary': 1714, 'baffled': 1715, 'sherlock': 1716, \"holmes'\": 1717, 'cryptic': 1718, 'watson': 1719, 'holmes': 1720, 'concealing': 1721, 'thoughts': 1722, 'criterion': 1723, 'elected': 1724, 'winner': 1725, 'single': 1726, 'step': 1727, 'salsa': 1728, 'senseless': 1729, 'luck': 1730, 'ray': 1731, 'corroborate': 1732, \"gary's\": 1733, 'unconvinced': 1734, 'murderer': 1735, 'convicted': 1736, 'sentenced': 1737, 'hockey': 1738, 'players': 1739, 'competitive': 1740, 'fights': 1741, 'constraint': 1742, 'dared': 1743, 'foolish': 1744, 'consensus': 1745, 'indicates': 1746, 'opposed': 1747, 'proposed': 1748, 'forest': 1749, 'spread': 1750, 'quickly': 1751, 'become': 1752, 'conflagration': 1753, 'concise': 1754, 'definitions': 1755, 'easiest': 1756, 'remember': 1757, 'accident': 1758, \"wife's\": 1759, 'conciliatory': 1760, 'cursory': 1761, 'examination': 1762, 'teeth': 1763, 'indicated': 1764, 'gingivitis': 1765, 'behaving': 1766, 'decorum': 1767, 'prom': 1768, 'painted': 1769, 'defendant': 1770, 'guilty': 1771, 'proven': 1772, 'politician': 1773, 'pushed': 1774, 'reform': 1775, 'denouncing': 1776, 'corruption': 1777, 'officials': 1778, 'depravity': 1779, 'deeds': 1780, 'tyrant': 1781, 'overthrown': 1782, 'dreamed': 1783, 'starting': 1784, 'sneeze': 1785, 'tissue': 1786, 'waste': 1787, 'caught': 1788, 'guard': 1789, \"you've\": 1790, \"website's\": 1791, 'layout': 1792, 'big': 1793, 'beat': 1794, 'laundry': 1795, 'sunny': 1796, 'plenty': 1797, 'criticizing': 1798, 'chair': 1799, 'sandwiches': 1800, 'inspired': 1801, 'lower': 1802, 'stoop': 1803, 'sunset': 1804, 'apartment': 1805, 'summer': 1806, 'breaks': 1807, 'ate': 1808, 'dinner': 1809, 'midnight': 1810, 'finish': 1811, 'swore': 1812, 'giving': 1813, 'starts': 1814, 'expecting': 1815, 'pay': 1816, 'taxes': 1817, 'idiots': 1818, 'push': 1819, 'larger': 1820, 'amounts': 1821, 'nevertheless': 1822, 'fragile': 1823, \"what're\": 1824, 'piece': 1825, 'child': 1826, 'vessel': 1827, 'filling': 1828, 'sadly': 1829, 'via': 1830, 'implausible': 1831, 'sound': 1832, 'fetched': 1833, 'understanding': 1834, 'credit': 1835, 'ran': 1836, 'charges': 1837, 'magic': 1838, 'sword': 1839, 'welcome': 1840, 'favorite': 1841, 'favourite': 1842, 'data': 1843, 'suggest': 1844, 'optimum': 1845, 'length': 1846, 'lecture': 1847, '30': 1848, '60': 1849, 'tend': 1850, 'pictures': 1851, 'reading': 1852, 'text': 1853, 'walked': 1854, 'twelve': 1855, 'weekend': 1856, 'hold': 1857, 'knocking': 1858, 'rich': 1859, 'concentrate': 1860, 'massage': 1861, 'relax': 1862, 'path': 1863, 'smith': 1864, 'effects': 1865, 'memory': 1866, 'disappeared': 1867, 'trace': 1868, 'palms': 1869, 'hands': 1870, 'bending': 1871, 'knees': 1872, 'progress': 1873, 'revolve': 1874, 'danger': 1875, 'atmosphere': 1876, 'eagerly': 1877, 'await': 1878, 'hearing': 1879, 'hollow': 1880, 'empty': 1881, 'fail': 1882, 'bought': 1883, 'black': 1884, 'hat': 1885, 'pancakes': 1886, 'breakfast': 1887, 'afternoon': 1888, 'chatting': 1889, 'independent': 1890, 'ears': 1891, 'short': 1892, 'tail': 1893, 'filled': 1894, 'wishes': 1895, 'erase': 1896, 'memories': 1897, 'sir': 1898, 'allowed': 1899, 'park': 1900, 'immediately': 1901, 'injured': 1902, 'safe': 1903, \"should've\": 1904, 'rejected': 1905, 'strength': 1906, 'memorization': 1907, 'formulas': 1908, 'twice': 1909, 'row': 1910, 'rooms': 1911, 'hotel': 1912, 'muffling': 1913, 'sounds': 1914, 'chewing': 1915, 'gum': 1916, 'imagine': 1917, 'electricity': 1918, 'four': 1919, 'seven': 1920, 'nine': 1921, 'restroom': 1922, 'toilet': 1923, 'toilets': 1924, 'loo': 1925, 'temperature': 1926, 'hovers': 1927, '37°c': 1928, 'opening': 1929, 'currents': 1930, 'nationality': 1931, 'vietnamese': 1932, 'origins': 1933, 'humanitarian': 1934, 'group': 1935, 'volunteers': 1936, 'distribute': 1937, 'homeless': 1938, 'december': 1939, 'frustrating': 1940, 'mankind': 1941, 'colonize': 1942, 'songs': 1943, 'composed': 1944, 'camera': 1945, 'digital': 1946, 'proud': 1947, 'project': 1948, 'necessary': 1949, 'expand': 1950, 'knowledge': 1951, 'exploration': 1952, 'beauty': 1953, 'buys': 1954, 'art': 1955, 'nasa': 1956, 'sufficient': 1957, 'planet': 1958, 'feasible': 1959, 'curves': 1960, 'tickle': 1961, 'ourselves': 1962, 'leads': 1963, 'vicious': 1964, 'circle': 1965, 'lazy': 1966, 'anxious': 1967}\n"
     ]
    }
   ],
   "source": [
    "# Verify all data\n",
    "print(f\"vocab_size_en: {vocab_size_en}, vocab_size_fr: {vocab_size_fr}\")\n",
    "print(f\"max_len_x: {max_len_x}, max_len_y: {max_len_y}, max_vocab_size: {max_vocab_size}, max_seq_len: {max_seq_len}\")\n",
    "print(\"French sentences:\")\n",
    "print(fr_sentences)\n",
    "print(\"English sentences:\")\n",
    "print(en_sentences)\n",
    "print(\"French tokenizer:\")\n",
    "print(fr_tokenizer.word_index)\n",
    "print(\"English tokenizer:\")\n",
    "print(en_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1873ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(X, max_length=max_seq_len, padding='post', pad_value=fr_tokenizer.PAD_IDX)\n",
    "y = pad_sequences(y, max_length=max_seq_len, padding='post', pad_value=en_tokenizer.PAD_IDX)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68d2884d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  src_vocab_size=2251,\n",
      "  tgt_vocab_size=1968,\n",
      "  d_model=128,\n",
      "  n_heads=4,\n",
      "  n_encoder_layers=2,\n",
      "  n_decoder_layers=2,\n",
      "  d_ff=512,\n",
      "  dropout_rate=0.1,\n",
      "  max_sequence_length=95\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(\n",
    "    src_vocab_size=vocab_size_fr,\n",
    "    tgt_vocab_size=vocab_size_en,\n",
    "    d_model=128,\n",
    "    n_heads=4,\n",
    "    n_encoder_layers=2,\n",
    "    n_decoder_layers=2,\n",
    "    d_ff=512,\n",
    "    dropout_rate=0.1,\n",
    "    max_sequence_length=max_seq_len,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss_function=\"cels\",\n",
    "    optimizer=Adam(\n",
    "        learning_rate=0.001,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.98,\n",
    "        epsilon=1e-9,\n",
    "        clip_norm=1.0,\n",
    "    ),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3bdab93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial learning rate: 0.000100\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7048374249638296\n",
      "std: 0.4162313487793261\n",
      "min: -0.965257281206062\n",
      "max: 1.4142135056257261\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.029123917638447468\n",
      "std: 0.30617767715237026\n",
      "min: -0.965257281206062\n",
      "max: 1.4142134933222412\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0896358543417367\n",
      "std: 0.046872084506704874\n",
      "min: 0.013924295093179174\n",
      "max: 0.5518086422733423\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7730971196028815\n",
      "std: 0.3795976600505492\n",
      "min: -0.9019234383931494\n",
      "max: 1.4142135617098\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.17573064518320897\n",
      "std: 0.30686763937346495\n",
      "min: -0.9019234383931494\n",
      "max: 1.4142135614027513\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08963585434173671\n",
      "std: 0.04506666599376927\n",
      "min: 0.01345816124136328\n",
      "max: 0.4997990975523516\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7263849376140408\n",
      "std: 0.3997799516989645\n",
      "min: -0.9826104285423046\n",
      "max: 1.4142135056257261\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.03916215696968705\n",
      "std: 0.3095911577404142\n",
      "min: -0.9826104285423046\n",
      "max: 1.4142134941178208\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10709881979918971\n",
      "std: 0.069302867104745\n",
      "min: 0.015747100178332137\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.45947718873855053\n",
      "std: 0.3359986219490899\n",
      "min: -0.9920096828941304\n",
      "max: 1.301595839855777\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.07120257329314163\n",
      "std: 0.2843966142372154\n",
      "min: -0.9920096828941304\n",
      "max: 1.103697815960971\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0896358543417367\n",
      "std: 0.04052898077197768\n",
      "min: 0.013901051749738337\n",
      "max: 0.35713384715453933\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8785349827915749\n",
      "std: 0.2920411161685608\n",
      "min: -0.7229968914795181\n",
      "max: 1.4142135616513234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4388011641576125\n",
      "std: 0.28015696142439933\n",
      "min: -0.7229968914795181\n",
      "max: 1.4142135614355529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10709881979918971\n",
      "std: 0.06372000119016456\n",
      "min: 0.017625312454291425\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.27633437389690163\n",
      "std: 0.29898965458666904\n",
      "min: -1.0323228264447657\n",
      "max: 1.2129876159030395\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.04759164044345217\n",
      "std: 0.2772273731709768\n",
      "min: -0.9394309492275942\n",
      "max: 1.0783551178985729\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0896358543417367\n",
      "std: 0.0402443942346656\n",
      "min: 0.017122201529133595\n",
      "max: 0.3076723119067204\n",
      "[=-----------------------------] 4% Epoch 1/50 - loss: 26.4899 - bleu: 6.6829521967e-09 - 2.30s=== Attention Logits (before mask) ===\n",
      "mean: 0.7595327966476297\n",
      "std: 0.4231457810209308\n",
      "min: -0.9342351694924071\n",
      "max: 1.4142133182030368\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.06082357300153471\n",
      "std: 0.3049186421950672\n",
      "min: -0.9342351694924071\n",
      "max: 1.4142133182030368\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08963585434173668\n",
      "std: 0.04834410733989707\n",
      "min: 0.014563053891545956\n",
      "max: 0.512607770875837\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8675190560989995\n",
      "std: 0.39000367657410856\n",
      "min: -0.9651375915770871\n",
      "max: 1.4142133647359185\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.22257741986565002\n",
      "std: 0.31723825054571786\n",
      "min: -0.9635386567444676\n",
      "max: 1.4142133647359185\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0896358543417367\n",
      "std: 0.046718628143534134\n",
      "min: 0.013683924210828266\n",
      "max: 0.49710947720291015\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.6751022515241025\n",
      "std: 0.39368766302412966\n",
      "min: -0.951161138448275\n",
      "max: 1.41421345655595\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.020662704918099444\n",
      "std: 0.31439867624696316\n",
      "min: -0.9489485906056098\n",
      "max: 1.41421345655595\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10822356710573156\n",
      "std: 0.06895634839055781\n",
      "min: 0.021178621400337085\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.3951867076453084\n",
      "std: 0.3047915733544479\n",
      "min: -1.0472674094776018\n",
      "max: 1.2184272765169837\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.06015347151897073\n",
      "std: 0.28181698869678484\n",
      "min: -1.0472674094776018\n",
      "max: 1.042044231426389\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0896358543417367\n",
      "std: 0.041863065311776096\n",
      "min: 0.018539075463406048\n",
      "max: 0.4016089765820531\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8450360362675775\n",
      "std: 0.2950455713736612\n",
      "min: -0.685161091647587\n",
      "max: 1.4142135326097771\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4383457939496253\n",
      "std: 0.2816735201687344\n",
      "min: -0.685161091647587\n",
      "max: 1.414213530637729\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1082235671057316\n",
      "std: 0.06225578362023514\n",
      "min: 0.024807966938021443\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.14452359935671144\n",
      "std: 0.26791056207892167\n",
      "min: -0.9605541952535043\n",
      "max: 1.048852868989316\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.018581090341139236\n",
      "std: 0.2696829957450356\n",
      "min: -0.941051178166363\n",
      "max: 1.0152438632260214\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08963585434173668\n",
      "std: 0.04105316664054324\n",
      "min: 0.017843112767670952\n",
      "max: 0.3055841258959989\n",
      "[==----------------------------] 8% Epoch 1/50 - loss: 18.4930 - bleu: 6.5470530015e-09 - 4.64s=== Attention Logits (before mask) ===\n",
      "mean: 0.7965281423509366\n",
      "std: 0.41836152844128915\n",
      "min: -0.9107551120439675\n",
      "max: 1.414213009850232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.08380580954438954\n",
      "std: 0.31346040657728225\n",
      "min: -0.9107551120439675\n",
      "max: 1.414213009850232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0975609756097561\n",
      "std: 0.053775083812492956\n",
      "min: 0.0166388150393751\n",
      "max: 0.5819231148643887\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.941209788381934\n",
      "std: 0.3697845799470237\n",
      "min: -0.9015798725531798\n",
      "max: 1.4142127617265638\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3190950600487434\n",
      "std: 0.33634200490375116\n",
      "min: -0.9015798725531798\n",
      "max: 1.4142127617265638\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09756097560975613\n",
      "std: 0.05240853212957343\n",
      "min: 0.017100478778175054\n",
      "max: 0.5153049694906109\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.6771287384080372\n",
      "std: 0.3926007244486666\n",
      "min: -1.0454698240721676\n",
      "max: 1.41421337526553\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.015933390411053714\n",
      "std: 0.3249186885943761\n",
      "min: -1.044030072020781\n",
      "max: 1.41421337526553\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11549713156794955\n",
      "std: 0.07675742025025593\n",
      "min: 0.02131681749214331\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.34624564619720455\n",
      "std: 0.2856181616246366\n",
      "min: -1.0199872823724434\n",
      "max: 1.2357154006105424\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.10053291120383473\n",
      "std: 0.2779301649788527\n",
      "min: -1.0168470133961647\n",
      "max: 1.1065009600446634\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09756097560975611\n",
      "std: 0.04582124686265374\n",
      "min: 0.01903348305588757\n",
      "max: 0.4055649666285929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9051125329606484\n",
      "std: 0.28889475933384706\n",
      "min: -0.761320920118847\n",
      "max: 1.4142134154591404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4658994110143544\n",
      "std: 0.2958637794000365\n",
      "min: -0.761320920118847\n",
      "max: 1.4142134154591404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11549713156794955\n",
      "std: 0.07079569073519808\n",
      "min: 0.02400151226206505\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.09128048077553048\n",
      "std: 0.2659719584505305\n",
      "min: -1.010058735767684\n",
      "max: 1.0180416455567225\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.04342719134580818\n",
      "std: 0.26246660850101233\n",
      "min: -0.9764215630568983\n",
      "max: 0.9868052792966105\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0975609756097561\n",
      "std: 0.045661977577033296\n",
      "min: 0.020978257614426777\n",
      "max: 0.3467981816728066\n",
      "[===---------------------------] 12% Epoch 1/50 - loss: 13.3690 - bleu: 6.2765116348e-09 - 6.79s=== Attention Logits (before mask) ===\n",
      "mean: 0.7704433958052113\n",
      "std: 0.4446195416228109\n",
      "min: -1.0100323185909166\n",
      "max: 1.4142122893236702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.11899416670962853\n",
      "std: 0.32746803665681956\n",
      "min: -1.0100323185909166\n",
      "max: 1.4142122893236702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07547169811320753\n",
      "std: 0.03815051003511204\n",
      "min: 0.013184132144736932\n",
      "max: 0.5343841165439613\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9462532917467791\n",
      "std: 0.37827096807709965\n",
      "min: -0.917191555584435\n",
      "max: 1.4142107175293874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4124372155354457\n",
      "std: 0.3470334406880899\n",
      "min: -0.9133990780353104\n",
      "max: 1.4142107175293874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07547169811320754\n",
      "std: 0.03521120283329828\n",
      "min: 0.013434458612207035\n",
      "max: 0.4002245359963865\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.6496593104058063\n",
      "std: 0.41685193307821755\n",
      "min: -1.0907570212372861\n",
      "max: 1.41421331622643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.027395257351160163\n",
      "std: 0.3245431993991591\n",
      "min: -1.0905085976770315\n",
      "max: 1.41421331622643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09146158011914074\n",
      "std: 0.06257761235205926\n",
      "min: 0.01782620070250503\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.2581587880044944\n",
      "std: 0.27927951364587983\n",
      "min: -0.9959210441036164\n",
      "max: 1.1582670182493269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.10888736748099041\n",
      "std: 0.2671049570776125\n",
      "min: -0.9870960674017232\n",
      "max: 1.1011486724573718\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07547169811320754\n",
      "std: 0.029602171835189848\n",
      "min: 0.01723540222401846\n",
      "max: 0.3408531353029261\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.952289180021175\n",
      "std: 0.2838983370899946\n",
      "min: -0.6054252201106923\n",
      "max: 1.4142124137127712\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5587728015721312\n",
      "std: 0.27832470375734647\n",
      "min: -0.6054252201106923\n",
      "max: 1.4142124137127712\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09146158011914074\n",
      "std: 0.055599235825238874\n",
      "min: 0.020296571738343736\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.0398689439695386\n",
      "std: 0.25433878936130155\n",
      "min: -0.9830025413913407\n",
      "max: 1.0198041766378498\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.04894100981914179\n",
      "std: 0.24463029319223958\n",
      "min: -0.9534143403327028\n",
      "max: 1.0198041766378498\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07547169811320753\n",
      "std: 0.029340581006195052\n",
      "min: 0.02018746555011201\n",
      "max: 0.27759074449189647\n",
      "[====--------------------------] 16% Epoch 1/50 - loss: 10.6396 - bleu: 6.1511147052e-09 - 9.01s=== Attention Logits (before mask) ===\n",
      "mean: 0.8011923711468317\n",
      "std: 0.42769261051165847\n",
      "min: -0.9828661544919963\n",
      "max: 1.4142108148530492\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.1586323766879559\n",
      "std: 0.3431710208709635\n",
      "min: -0.9828661544919963\n",
      "max: 1.4142108148530492\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.04237731621411643\n",
      "min: 0.014665491478350978\n",
      "max: 0.44624948074265164\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9931621932689682\n",
      "std: 0.34621301997954745\n",
      "min: -0.8127910726742205\n",
      "max: 1.4142080340346073\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5035658148486136\n",
      "std: 0.35082174417834006\n",
      "min: -0.8127910726742205\n",
      "max: 1.4142080340346073\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.037905870576831625\n",
      "min: 0.014310213279182455\n",
      "max: 0.38302320030410497\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.6778160511385096\n",
      "std: 0.41158332354430816\n",
      "min: -1.1189559320183686\n",
      "max: 1.41421303445592\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.027930215807432046\n",
      "std: 0.3380121027092297\n",
      "min: -1.1189559320183686\n",
      "max: 1.41421303445592\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09830870226045337\n",
      "std: 0.06693845269299734\n",
      "min: 0.01596183776766707\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.197022609262358\n",
      "std: 0.26883107527364286\n",
      "min: -1.028351333450623\n",
      "max: 1.081558292646964\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.11507984820426809\n",
      "std: 0.27005689286761697\n",
      "min: -0.9953615483093868\n",
      "max: 1.0678932139096393\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.032168329888140196\n",
      "min: 0.01945159617390144\n",
      "max: 0.27492023951068023\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9971683209874186\n",
      "std: 0.2841331630416819\n",
      "min: -0.6541180772249902\n",
      "max: 1.414209693167177\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5837910347964341\n",
      "std: 0.3074734237756998\n",
      "min: -0.6519506294050517\n",
      "max: 1.414209693167177\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09830870226045338\n",
      "std: 0.0599341591092521\n",
      "min: 0.017162032704851445\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.053924386132853164\n",
      "std: 0.255173098922765\n",
      "min: -0.9948540827391124\n",
      "max: 1.007093440283207\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.07811721116832157\n",
      "std: 0.24598047524214664\n",
      "min: -0.8879115356268518\n",
      "max: 1.007093440283207\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.03174738299277753\n",
      "min: 0.020372631923487487\n",
      "max: 0.24969379964777186\n",
      "[======------------------------] 20% Epoch 1/50 - loss: 8.8866 - bleu: 6.0982822648e-09 - 11.21s=== Attention Logits (before mask) ===\n",
      "mean: 0.8288987713712676\n",
      "std: 0.41016405662622346\n",
      "min: -0.9667120949044821\n",
      "max: 1.4142093689014024\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.1898251444840241\n",
      "std: 0.356523977720029\n",
      "min: -0.9667120949044821\n",
      "max: 1.4142093689014024\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08648648648648648\n",
      "std: 0.050677099357800647\n",
      "min: 0.014606337068240395\n",
      "max: 0.5232986544572664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0360832965814284\n",
      "std: 0.3130768278685699\n",
      "min: -0.7793729698684712\n",
      "max: 1.4142027033998747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5939307460728426\n",
      "std: 0.35710477571941684\n",
      "min: -0.7793729698684712\n",
      "max: 1.4142027033998747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08648648648648646\n",
      "std: 0.04558669516549722\n",
      "min: 0.013766241703869078\n",
      "max: 0.44583874539224466\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.6987274034499247\n",
      "std: 0.40570260497558264\n",
      "min: -1.154911163184555\n",
      "max: 1.41421220938275\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.044074066759480605\n",
      "std: 0.3502740181099384\n",
      "min: -1.150530454751191\n",
      "max: 1.41421220938275\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10097319560235161\n",
      "std: 0.06985163850645242\n",
      "min: 0.014712961366638709\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.12671536939937403\n",
      "std: 0.2682966859842405\n",
      "min: -1.0100386475468703\n",
      "max: 1.0702960315099368\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.08974003464922647\n",
      "std: 0.262119644623598\n",
      "min: -0.9906237221411869\n",
      "max: 0.9795096216794206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08648648648648648\n",
      "std: 0.03994385398658302\n",
      "min: 0.017491688410714717\n",
      "max: 0.29548779150428006\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.010078402197936\n",
      "std: 0.2831023903026942\n",
      "min: -0.8072546875406917\n",
      "max: 1.414207517478272\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6014828187582046\n",
      "std: 0.33233114733533536\n",
      "min: -0.8072546875406917\n",
      "max: 1.414207517478272\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10097319560235161\n",
      "std: 0.0629319254361274\n",
      "min: 0.013608983245335052\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.05836886162805247\n",
      "std: 0.2540427872922595\n",
      "min: -0.9540123442356145\n",
      "max: 1.006009662947494\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.08692685345847624\n",
      "std: 0.24421474670060733\n",
      "min: -0.9540123442356145\n",
      "max: 1.006009662947494\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08648648648648649\n",
      "std: 0.039893748486337\n",
      "min: 0.018465629595873258\n",
      "max: 0.2943974426692269\n",
      "[=======-----------------------] 24% Epoch 1/50 - loss: 7.6282 - bleu: 6.2447533813e-09 - 13.37s=== Attention Logits (before mask) ===\n",
      "mean: 0.8432259065884715\n",
      "std: 0.39635551676795205\n",
      "min: -0.9674217519850827\n",
      "max: 1.414207153527031\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.22313758069698042\n",
      "std: 0.3645519893454365\n",
      "min: -0.9592371732612219\n",
      "max: 1.414207153527031\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0896358543417367\n",
      "std: 0.04920683466823328\n",
      "min: 0.01456889741059605\n",
      "max: 0.5807960994403163\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.058147464801724\n",
      "std: 0.2902659739742785\n",
      "min: -0.7581828060176738\n",
      "max: 1.4141984333687563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6664831801242148\n",
      "std: 0.3511259613320495\n",
      "min: -0.7581828060176738\n",
      "max: 1.4141984333687563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08963585434173668\n",
      "std: 0.04204819274253095\n",
      "min: 0.01489163751016281\n",
      "max: 0.5020632353621374\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7251072330432501\n",
      "std: 0.3929887516388523\n",
      "min: -1.1433988626463707\n",
      "max: 1.414211466952466\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.054484554506372976\n",
      "std: 0.3599975417372311\n",
      "min: -1.1413534307148012\n",
      "max: 1.414211466952466\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11054947452634639\n",
      "std: 0.07165438018645261\n",
      "min: 0.014795518235379139\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.06816078398666728\n",
      "std: 0.2634376809318007\n",
      "min: -0.9846219106726224\n",
      "max: 1.029022154881514\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.05563028413622046\n",
      "std: 0.2581858882851508\n",
      "min: -0.9846219106726224\n",
      "max: 1.004241504555698\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0896358543417367\n",
      "std: 0.03692198978328215\n",
      "min: 0.020201451148484525\n",
      "max: 0.3755128418108277\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0172806371064333\n",
      "std: 0.27297342133536157\n",
      "min: -0.6491220398176641\n",
      "max: 1.4141991637780065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6058428776482345\n",
      "std: 0.33060470079585325\n",
      "min: -0.6406308139737663\n",
      "max: 1.4141991637780065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1105494745263464\n",
      "std: 0.06268343875313392\n",
      "min: 0.018494838871500316\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.04386856065337873\n",
      "std: 0.23504358743030646\n",
      "min: -0.952120163995343\n",
      "max: 1.0349068025885497\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.08014007415233809\n",
      "std: 0.2356028456921381\n",
      "min: -0.952120163995343\n",
      "max: 1.0349068025885497\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0896358543417367\n",
      "std: 0.036758088384350844\n",
      "min: 0.0204433212832288\n",
      "max: 0.36083196148549834\n",
      "[========----------------------] 28% Epoch 1/50 - loss: 6.6646 - bleu: 6.2908564412e-09 - 15.56s=== Attention Logits (before mask) ===\n",
      "mean: 0.8310754917731797\n",
      "std: 0.4072409517811221\n",
      "min: -1.0024560847973907\n",
      "max: 1.4142053374081385\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.21863850406372823\n",
      "std: 0.3685478306529434\n",
      "min: -1.0024560847973907\n",
      "max: 1.4142053374081385\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08376963350785342\n",
      "std: 0.04321193617553946\n",
      "min: 0.012397271171794467\n",
      "max: 0.45482517693835206\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.077893406805985\n",
      "std: 0.2724397573593514\n",
      "min: -0.8322226350800624\n",
      "max: 1.414181508717258\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.7414803196208274\n",
      "std: 0.33424355156940727\n",
      "min: -0.826076693659755\n",
      "max: 1.414181508717258\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08376963350785341\n",
      "std: 0.03352854474295603\n",
      "min: 0.010947861594732877\n",
      "max: 0.34912924461389455\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7197985399579657\n",
      "std: 0.4008054872342385\n",
      "min: -1.1187773629485676\n",
      "max: 1.414210311010995\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.06521963013422302\n",
      "std: 0.35443463027911015\n",
      "min: -1.1187773629485676\n",
      "max: 1.414210311010995\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.101023527847933\n",
      "std: 0.06545669063595873\n",
      "min: 0.015633724229393752\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.03427394554284953\n",
      "std: 0.2616592787380126\n",
      "min: -1.0024184020849818\n",
      "max: 0.9748596591484981\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.03133742676579383\n",
      "std: 0.2538590108528805\n",
      "min: -0.9266427304465396\n",
      "max: 0.9423669336670081\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08376963350785342\n",
      "std: 0.029133171444013645\n",
      "min: 0.015826777392561258\n",
      "max: 0.2525845433269938\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0123979822198377\n",
      "std: 0.26574766089542007\n",
      "min: -0.5807562978298014\n",
      "max: 1.414195165747114\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6231534592304057\n",
      "std: 0.3001319020096144\n",
      "min: -0.5807562978298014\n",
      "max: 1.414195165747114\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10102352784793302\n",
      "std: 0.05543812376808058\n",
      "min: 0.02020563345131602\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.09658538126906532\n",
      "std: 0.21514407042644434\n",
      "min: -0.8328547769131959\n",
      "max: 0.991901171492827\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.11697620557725483\n",
      "std: 0.2259631304862294\n",
      "min: -0.7357270603175594\n",
      "max: 0.991901171492827\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08376963350785342\n",
      "std: 0.02872968335894859\n",
      "min: 0.016518251987671224\n",
      "max: 0.22833844714455453\n",
      "[=========---------------------] 32% Epoch 1/50 - loss: 5.9251 - bleu: 6.2849672107e-09 - 17.77s=== Attention Logits (before mask) ===\n",
      "mean: 0.7503957494637207\n",
      "std: 0.4593911769981859\n",
      "min: -1.0227192220833428\n",
      "max: 1.4141995743202327\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.1850853664606227\n",
      "std: 0.3655676201326226\n",
      "min: -1.0218308583924773\n",
      "max: 1.4141995743202327\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05850091407678245\n",
      "std: 0.0334608623645541\n",
      "min: 0.009439917296656525\n",
      "max: 0.4295797897528135\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0379868873406037\n",
      "std: 0.30913863300733596\n",
      "min: -0.702041674880404\n",
      "max: 1.414190404860138\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.7253170840257587\n",
      "std: 0.3456169425668604\n",
      "min: -0.702041674880404\n",
      "max: 1.414190404860138\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058500914076782456\n",
      "std: 0.026660313078527724\n",
      "min: 0.0095907525908753\n",
      "max: 0.31183291211703346\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.6730775713692476\n",
      "std: 0.43507404023035273\n",
      "min: -1.0670020831454285\n",
      "max: 1.4142105692417257\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.06924320389002613\n",
      "std: 0.34842420771786486\n",
      "min: -1.0670020831454285\n",
      "max: 1.4142105692417257\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0767521712785296\n",
      "std: 0.060633811638679924\n",
      "min: 0.010657644613403934\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.04412091861591942\n",
      "std: 0.26316579708014454\n",
      "min: -1.017662229735962\n",
      "max: 1.0224980850206111\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.047434248955433335\n",
      "std: 0.2589503046468663\n",
      "min: -0.9523575353322028\n",
      "max: 1.0224980850206111\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058500914076782456\n",
      "std: 0.023962832437078613\n",
      "min: 0.01459198745714285\n",
      "max: 0.22347269922096466\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.022933911308956\n",
      "std: 0.24661017726956477\n",
      "min: -0.5255431827477505\n",
      "max: 1.4141880341638464\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.7146225138042565\n",
      "std: 0.24964707724729587\n",
      "min: -0.5246314743929591\n",
      "max: 1.4141880341638464\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0767521712785296\n",
      "std: 0.05116738876460958\n",
      "min: 0.013104571177049324\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.163211017384775\n",
      "std: 0.19512335989067695\n",
      "min: -0.7635052142518356\n",
      "max: 1.0035657450754287\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.1730518992850397\n",
      "std: 0.21821126004166863\n",
      "min: -0.7635052142518356\n",
      "max: 1.0035657450754287\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05850091407678244\n",
      "std: 0.023763950561911683\n",
      "min: 0.015251522089147875\n",
      "max: 0.19685070540087574\n",
      "[==========--------------------] 36% Epoch 1/50 - loss: 5.3273 - bleu: 6.2698720088e-09 - 20.01s=== Attention Logits (before mask) ===\n",
      "mean: 0.8034462014940416\n",
      "std: 0.42694249653814376\n",
      "min: -0.9129022097663008\n",
      "max: 1.4142009165052774\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.2192756118415502\n",
      "std: 0.3676858148057766\n",
      "min: -0.9129022097663008\n",
      "max: 1.4142009165052774\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07095343680709534\n",
      "std: 0.036478467735586904\n",
      "min: 0.012750196754201705\n",
      "max: 0.4246420366617447\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0977469440939265\n",
      "std: 0.26167506858334183\n",
      "min: -0.9029481182102822\n",
      "max: 1.4141881511595935\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.8276238717264927\n",
      "std: 0.32447285805518283\n",
      "min: -0.9029481182102822\n",
      "max: 1.4141881511595935\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07095343680709534\n",
      "std: 0.02732106018193683\n",
      "min: 0.011383594062945543\n",
      "max: 0.3037453536716349\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7103120177469299\n",
      "std: 0.4162792387585911\n",
      "min: -1.0101196878441994\n",
      "max: 1.414208492597349\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.08693870878271595\n",
      "std: 0.3517561152019707\n",
      "min: -0.9932338670500602\n",
      "max: 1.414208492597349\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08623868826416271\n",
      "std: 0.06041100346019685\n",
      "min: 0.01557108386034435\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.026664462589691556\n",
      "std: 0.24965505337912983\n",
      "min: -0.9555826198569646\n",
      "max: 0.9565454358461843\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.03412007821721017\n",
      "std: 0.24579358593967565\n",
      "min: -0.9555826198569646\n",
      "max: 0.9565454358461843\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07095343680709537\n",
      "std: 0.02416583359063224\n",
      "min: 0.01967924311746046\n",
      "max: 0.19831797310127405\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0918046418805027\n",
      "std: 0.1990763755606526\n",
      "min: -0.22090778533172628\n",
      "max: 1.414159508448364\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.8340695001090099\n",
      "std: 0.22014771582481477\n",
      "min: -0.2172048629910231\n",
      "max: 1.414159508448364\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08623868826416271\n",
      "std: 0.047699683240809795\n",
      "min: 0.022048199317081386\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.21087351960871442\n",
      "std: 0.1812009622475049\n",
      "min: -0.6461044716143749\n",
      "max: 1.002208953793334\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.2056713402838567\n",
      "std: 0.21394264551394893\n",
      "min: -0.6361192929029806\n",
      "max: 0.9491973804796966\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07095343680709533\n",
      "std: 0.023864286482940558\n",
      "min: 0.020615093786248935\n",
      "max: 0.19839630294380653\n",
      "[============------------------] 40% Epoch 1/50 - loss: 4.8235 - bleu: 6.1153176890e-09 - 22.22s=== Attention Logits (before mask) ===\n",
      "mean: 0.871246171063304\n",
      "std: 0.38028504221824855\n",
      "min: -0.9094196058119928\n",
      "max: 1.4141875025489679\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.25536064559982014\n",
      "std: 0.38149391240033137\n",
      "min: -0.8983619842624745\n",
      "max: 1.4141875025489679\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09876543209876543\n",
      "std: 0.06143060796037058\n",
      "min: 0.014253659438349118\n",
      "max: 0.5264325715465351\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.170436557438134\n",
      "std: 0.2052524218142487\n",
      "min: -0.6514513822420106\n",
      "max: 1.4141583648425509\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9463536933570279\n",
      "std: 0.29870432589490414\n",
      "min: -0.6514513822420106\n",
      "max: 1.4141583648425509\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09876543209876543\n",
      "std: 0.04944167099525779\n",
      "min: 0.01385389526678724\n",
      "max: 0.343544026321109\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7660622162656094\n",
      "std: 0.3811683574399026\n",
      "min: -0.9871657229828803\n",
      "max: 1.4142095460092394\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.10463087592875127\n",
      "std: 0.3542091289522622\n",
      "min: -0.9494143125531262\n",
      "max: 1.4142095460092394\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10968789464189069\n",
      "std: 0.07563554838803463\n",
      "min: 0.016949878056521393\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.010498518088180035\n",
      "std: 0.24409376784872386\n",
      "min: -0.9683251686223607\n",
      "max: 0.9286322051200935\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.029341072119218884\n",
      "std: 0.24418485992579628\n",
      "min: -0.8737523234701722\n",
      "max: 0.8835798645975822\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09876543209876543\n",
      "std: 0.0478001800626372\n",
      "min: 0.022854326947547726\n",
      "max: 0.2749980259254587\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.167274651308081\n",
      "std: 0.14523074515015236\n",
      "min: -0.1497869775869722\n",
      "max: 1.4141631649673114\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.969638113847117\n",
      "std: 0.18328299678461557\n",
      "min: -0.1497869775869722\n",
      "max: 1.4141631649673114\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10968789464189067\n",
      "std: 0.059739029252515646\n",
      "min: 0.022598502280623996\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.25219901753170204\n",
      "std: 0.1804265126035987\n",
      "min: -0.6185493178482083\n",
      "max: 0.9246951410037287\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.24586566036555046\n",
      "std: 0.21691175219867315\n",
      "min: -0.6185493178482083\n",
      "max: 0.9246951410037287\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09876543209876543\n",
      "std: 0.04752009020470015\n",
      "min: 0.02391074145353542\n",
      "max: 0.27906622239100076\n",
      "[=============-----------------] 44% Epoch 1/50 - loss: 4.3996 - bleu: 5.9392780862e-09 - 24.45s=== Attention Logits (before mask) ===\n",
      "mean: 0.808496073195906\n",
      "std: 0.4282879637953019\n",
      "min: -1.04375701143717\n",
      "max: 1.4141987668657656\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.23304475359087534\n",
      "std: 0.3751675683383341\n",
      "min: -1.0382614156779617\n",
      "max: 1.4141987668657656\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06956521739130435\n",
      "std: 0.037986704868657795\n",
      "min: 0.012378022780292213\n",
      "max: 0.46608770387802195\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.167469236694747\n",
      "std: 0.2019805628437644\n",
      "min: -0.396608927652361\n",
      "max: 1.4141650692372854\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9956260699290773\n",
      "std: 0.2578877070543066\n",
      "min: -0.396608927652361\n",
      "max: 1.4141650692372854\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06956521739130435\n",
      "std: 0.027477500230425167\n",
      "min: 0.01301981192662905\n",
      "max: 0.2626000967694351\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7290287947721024\n",
      "std: 0.40948071768919214\n",
      "min: -0.9418786284642758\n",
      "max: 1.4142056848921045\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.1260760345219078\n",
      "std: 0.3462573113289676\n",
      "min: -0.9248938977965646\n",
      "max: 1.4142056848921045\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08361296000880138\n",
      "std: 0.062045248819148274\n",
      "min: 0.015555407703062907\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.03277636238826848\n",
      "std: 0.2397241560630058\n",
      "min: -0.9914167019059573\n",
      "max: 1.039990043761199\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.04817720647277034\n",
      "std: 0.24363717076587446\n",
      "min: -0.9256725614768994\n",
      "max: 0.9673808223773596\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06956521739130436\n",
      "std: 0.02647430005699615\n",
      "min: 0.02164507514453828\n",
      "max: 0.20476605720241128\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2033078092266818\n",
      "std: 0.1229252248145997\n",
      "min: 0.08475869596781443\n",
      "max: 1.4140857588224636\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0703800048120309\n",
      "std: 0.14836473769421302\n",
      "min: 0.08475869596781443\n",
      "max: 1.4140857588224636\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08361296000880136\n",
      "std: 0.04849170358991279\n",
      "min: 0.02823088988005396\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.2905445834798691\n",
      "std: 0.1807381074874725\n",
      "min: -0.6003374297097512\n",
      "max: 0.9866752596794829\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.2860009304709024\n",
      "std: 0.21695398900448062\n",
      "min: -0.6003374297097512\n",
      "max: 0.9750169199026788\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06956521739130435\n",
      "std: 0.026357910256803372\n",
      "min: 0.024131413768870333\n",
      "max: 0.18892667880627712\n",
      "[==============----------------] 48% Epoch 1/50 - loss: 4.0418 - bleu: 5.7849743824e-09 - 26.69s=== Attention Logits (before mask) ===\n",
      "mean: 0.8380161437775777\n",
      "std: 0.4043768505834713\n",
      "min: -1.0558151013890387\n",
      "max: 1.4141780604805188\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.26157350391425055\n",
      "std: 0.3696589113210105\n",
      "min: -1.0519542875018175\n",
      "max: 1.4141780604805188\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0778588807785888\n",
      "std: 0.040070196195283965\n",
      "min: 0.010694660244096793\n",
      "max: 0.48787987389638526\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2071330471497046\n",
      "std: 0.16194650119397563\n",
      "min: -0.09182687158274448\n",
      "max: 1.4140402945801342\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0840153626317723\n",
      "std: 0.21053827858007484\n",
      "min: -0.03997670691893772\n",
      "max: 1.4140402945801342\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0778588807785888\n",
      "std: 0.02807110668439831\n",
      "min: 0.014045883930129675\n",
      "max: 0.22300793331600147\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7553385540397108\n",
      "std: 0.40009339428370927\n",
      "min: -0.9704176422902958\n",
      "max: 1.4142044485475858\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.12147003395518434\n",
      "std: 0.3533528503818705\n",
      "min: -0.9631988892598596\n",
      "max: 1.4142044485475858\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09328300960446775\n",
      "std: 0.06493762256960545\n",
      "min: 0.01214965713904974\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.03864770154280263\n",
      "std: 0.23324775034881723\n",
      "min: -0.9025978710884571\n",
      "max: 1.0718930810082246\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.04920735434669875\n",
      "std: 0.235182046774301\n",
      "min: -0.900155842314409\n",
      "max: 1.0718930810082246\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07785888077858882\n",
      "std: 0.027859709135555105\n",
      "min: 0.01759979639093053\n",
      "max: 0.19214832854191286\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2347422313185497\n",
      "std: 0.1026364894026064\n",
      "min: 0.23453829393086703\n",
      "max: 1.4140858758059351\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1185245374753812\n",
      "std: 0.12883748065083755\n",
      "min: 0.23453829393086703\n",
      "max: 1.4140858758059351\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09328300960446777\n",
      "std: 0.049070885012115234\n",
      "min: 0.02174087826964107\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.29139539444146934\n",
      "std: 0.17691752808392625\n",
      "min: -0.5023464293841575\n",
      "max: 0.968842609488724\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.28897946545233494\n",
      "std: 0.20511468562357837\n",
      "min: -0.5023464293841575\n",
      "max: 0.968842609488724\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0778588807785888\n",
      "std: 0.027692262618532092\n",
      "min: 0.02102693131950988\n",
      "max: 0.18570088442164856\n",
      "[===============---------------] 52% Epoch 1/50 - loss: 3.7367 - bleu: 5.7299226727e-09 - 28.96s=== Attention Logits (before mask) ===\n",
      "mean: 0.8736120163387019\n",
      "std: 0.37928433802646233\n",
      "min: -1.0228827895748402\n",
      "max: 1.4141511164744616\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.280545127108862\n",
      "std: 0.3761242815769576\n",
      "min: -1.0125898390268413\n",
      "max: 1.4141511164744616\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09495548961424333\n",
      "std: 0.04534613637252803\n",
      "min: 0.014262364427136267\n",
      "max: 0.4618595056679592\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2447053336085083\n",
      "std: 0.12847959804353393\n",
      "min: 0.11215726899341429\n",
      "max: 1.4139725657077578\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1613510726103076\n",
      "std: 0.16830253982944118\n",
      "min: 0.17887750698656615\n",
      "max: 1.4139725657077578\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09495548961424331\n",
      "std: 0.030675363842731788\n",
      "min: 0.026426212079747338\n",
      "max: 0.2419068174952883\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7928952285654289\n",
      "std: 0.3699388492276377\n",
      "min: -0.8954986032483847\n",
      "max: 1.4142055102746782\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.1622481805009214\n",
      "std: 0.35473770083422856\n",
      "min: -0.8911731185700905\n",
      "max: 1.4142055102746782\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10699704350274532\n",
      "std: 0.07086801898826313\n",
      "min: 0.019583141879074648\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.050067922460458\n",
      "std: 0.23361216753662956\n",
      "min: -0.8560832748039008\n",
      "max: 1.0345240446834048\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.06480831565483097\n",
      "std: 0.2375196947315706\n",
      "min: -0.8410467605542947\n",
      "max: 0.9224833845975821\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09495548961424333\n",
      "std: 0.030839379180494442\n",
      "min: 0.0330104118297169\n",
      "max: 0.19720821125434024\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.263191021489803\n",
      "std: 0.08166952107386284\n",
      "min: 0.3427262131413948\n",
      "max: 1.414044358745078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.177179229986324\n",
      "std: 0.10858979356252876\n",
      "min: 0.3427262131413948\n",
      "max: 1.414044358745078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10699704350274532\n",
      "std: 0.053249384803799316\n",
      "min: 0.03581290290743946\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.30348607406092953\n",
      "std: 0.17846531037477015\n",
      "min: -0.508451516350417\n",
      "max: 0.9664045547106088\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.30059033131311913\n",
      "std: 0.20105224604410965\n",
      "min: -0.508451516350417\n",
      "max: 0.9490827062169146\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09495548961424334\n",
      "std: 0.030670855087310808\n",
      "min: 0.03563545673872579\n",
      "max: 0.19022340043727098\n",
      "[================--------------] 56% Epoch 1/50 - loss: 3.4733 - bleu: 5.6065914668e-09 - 31.22s=== Attention Logits (before mask) ===\n",
      "mean: 0.8423761256099289\n",
      "std: 0.3998282835358538\n",
      "min: -0.98171751441941\n",
      "max: 1.4141820465476553\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.25174916571416966\n",
      "std: 0.3665724277270786\n",
      "min: -0.9784298297919651\n",
      "max: 1.4141820465476553\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08184143222506393\n",
      "std: 0.04709707303398371\n",
      "min: 0.009024775845894293\n",
      "max: 0.5177630762644431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.244604594721237\n",
      "std: 0.13289150722454987\n",
      "min: 0.03753185381609535\n",
      "max: 1.4138217106593889\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1610318378916173\n",
      "std: 0.17120127016691417\n",
      "min: 0.10602476623059628\n",
      "max: 1.4138217106593889\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08184143222506395\n",
      "std: 0.036650322737600646\n",
      "min: 0.015972153810110485\n",
      "max: 0.2240465575537815\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7964504576703914\n",
      "std: 0.37257541043987313\n",
      "min: -1.0991653237477068\n",
      "max: 1.4141997710012815\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.1815066847549311\n",
      "std: 0.35375714997825936\n",
      "min: -1.0991653237477068\n",
      "max: 1.4141997710012815\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10145846544071022\n",
      "std: 0.07151734168940707\n",
      "min: 0.013320993104067126\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.07273157083099656\n",
      "std: 0.22721983408541432\n",
      "min: -0.8357227453312477\n",
      "max: 1.126775427061925\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.09391021571217742\n",
      "std: 0.23451420768823394\n",
      "min: -0.7861820977728861\n",
      "max: 1.0707856111617622\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08184143222506395\n",
      "std: 0.03699829159427379\n",
      "min: 0.022498949682545982\n",
      "max: 0.2184528444163693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2801180716399019\n",
      "std: 0.06878555738034872\n",
      "min: 0.6026791299755644\n",
      "max: 1.4140162200918884\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2155752143513285\n",
      "std: 0.08780539195242774\n",
      "min: 0.6026791299755644\n",
      "max: 1.4140162200918884\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10145846544071022\n",
      "std: 0.055263327629984815\n",
      "min: 0.026885585230199658\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.2943303417290937\n",
      "std: 0.15745974156741108\n",
      "min: -0.42421710610031516\n",
      "max: 0.9163408853821234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.2976986563842779\n",
      "std: 0.17624273222942044\n",
      "min: -0.42421710610031516\n",
      "max: 0.9163408853821234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08184143222506395\n",
      "std: 0.03695452149193419\n",
      "min: 0.024428505351868947\n",
      "max: 0.22562833657237252\n",
      "[==================------------] 60% Epoch 1/50 - loss: 3.2446 - bleu: 5.5702715412e-09 - 33.55s=== Attention Logits (before mask) ===\n",
      "mean: 0.8290821111996668\n",
      "std: 0.40412258689948355\n",
      "min: -1.0362989685068709\n",
      "max: 1.4141897652196047\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.2363769182237823\n",
      "std: 0.3648571683098914\n",
      "min: -1.0238363530744108\n",
      "max: 1.4141897652196047\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.04614907687529216\n",
      "min: 0.01171832234328979\n",
      "max: 0.4590115482231397\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2538028218606074\n",
      "std: 0.12900358626753064\n",
      "min: -0.029379164074903402\n",
      "max: 1.4139550568121186\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1831827026470683\n",
      "std: 0.16607728865853072\n",
      "min: 0.0008618396310474894\n",
      "max: 1.4139550568121186\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.036675046264472974\n",
      "min: 0.014974520926498801\n",
      "max: 0.21641840341944554\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7996455289163275\n",
      "std: 0.38685229075956745\n",
      "min: -0.9649566697275775\n",
      "max: 1.4141987382162386\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.1771331988389793\n",
      "std: 0.36386897279052466\n",
      "min: -0.9649566697275775\n",
      "max: 1.4141987382162386\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09672595373699451\n",
      "std: 0.07159264302073527\n",
      "min: 0.014114642464632648\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.1268961478691536\n",
      "std: 0.22425952504763866\n",
      "min: -1.017200104058924\n",
      "max: 1.1155358543745215\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.13999654991979055\n",
      "std: 0.2348934358491606\n",
      "min: -0.8809997498330466\n",
      "max: 0.9980934690694986\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07999999999999999\n",
      "std: 0.03708271631882368\n",
      "min: 0.024064210014852833\n",
      "max: 0.24353959375519812\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2970466006788943\n",
      "std: 0.058118414796935344\n",
      "min: 0.7073818315181123\n",
      "max: 1.414071321894394\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2461862048964305\n",
      "std: 0.07413810552356824\n",
      "min: 0.7073818315181123\n",
      "max: 1.414071321894394\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09672595373699448\n",
      "std: 0.055402901648425866\n",
      "min: 0.02941305379977248\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.30019351924710663\n",
      "std: 0.14256100166632582\n",
      "min: -0.32676767442295196\n",
      "max: 0.9318667732669565\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.30207289734812603\n",
      "std: 0.15454785809035015\n",
      "min: -0.32676767442295196\n",
      "max: 0.8569720871633684\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08000000000000002\n",
      "std: 0.03697434440327437\n",
      "min: 0.0249040978039897\n",
      "max: 0.21156263394652217\n",
      "[===================-----------] 64% Epoch 1/50 - loss: 3.0440 - bleu: 5.5728948706e-09 - 35.88s=== Attention Logits (before mask) ===\n",
      "mean: 0.8139302890116\n",
      "std: 0.4099619950929547\n",
      "min: -0.9211421001283262\n",
      "max: 1.4141452684465594\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.22683724275660327\n",
      "std: 0.3575974067620413\n",
      "min: -0.9072396303935724\n",
      "max: 1.4141452684465594\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07637231503579951\n",
      "std: 0.044200016802440026\n",
      "min: 0.011120422418208183\n",
      "max: 0.5083129048413786\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2644072498047203\n",
      "std: 0.12335439891027923\n",
      "min: 0.036739813688756284\n",
      "max: 1.413650522781301\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2079301219593541\n",
      "std: 0.1515281484679344\n",
      "min: 0.09535243555623708\n",
      "max: 1.413650522781301\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07637231503579953\n",
      "std: 0.03551329068643402\n",
      "min: 0.017673790635077628\n",
      "max: 0.24636749099495944\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8163205179309843\n",
      "std: 0.3814317691943313\n",
      "min: -1.035710861477622\n",
      "max: 1.4141962126632124\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.21070653008057158\n",
      "std: 0.36106924323867307\n",
      "min: -1.035710861477622\n",
      "max: 1.4141962126632124\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09493769713625433\n",
      "std: 0.07143700882605475\n",
      "min: 0.01053291459396335\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.18105897653991712\n",
      "std: 0.22243922802826008\n",
      "min: -0.7982902650985633\n",
      "max: 1.0248857695780405\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.1955042163399189\n",
      "std: 0.23461407640372836\n",
      "min: -0.7684241148706583\n",
      "max: 1.0248857695780405\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07637231503579951\n",
      "std: 0.035926764892147085\n",
      "min: 0.020237459036070805\n",
      "max: 0.25708532936993145\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3119739939184614\n",
      "std: 0.04759665729556586\n",
      "min: 0.8994753120031906\n",
      "max: 1.4139733918398079\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.275203834872277\n",
      "std: 0.05882632103209445\n",
      "min: 0.9041160416477144\n",
      "max: 1.4139733918398079\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09493769713625431\n",
      "std: 0.0560189683721377\n",
      "min: 0.02743122639352612\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.31988382188209546\n",
      "std: 0.13875258756589656\n",
      "min: -0.2487021157029281\n",
      "max: 0.884526659523386\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3251749701007122\n",
      "std: 0.14947281683087388\n",
      "min: -0.22473974348090045\n",
      "max: 0.8787475678615295\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07637231503579951\n",
      "std: 0.03589123889885519\n",
      "min: 0.02054012195429604\n",
      "max: 0.24097597367725482\n",
      "[====================----------] 68% Epoch 1/50 - loss: 2.8666 - bleu: 5.5431539101e-09 - 38.20s=== Attention Logits (before mask) ===\n",
      "mean: 0.8019543745324096\n",
      "std: 0.4147249203183866\n",
      "min: -1.0592407179506005\n",
      "max: 1.4141792167363052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.22173584577788233\n",
      "std: 0.34885628668348145\n",
      "min: -1.0357127389404672\n",
      "max: 1.4141792167363052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07390300230946881\n",
      "std: 0.03738907926969968\n",
      "min: 0.012780566329055556\n",
      "max: 0.43034734767138483\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2769908607734506\n",
      "std: 0.11455298247060414\n",
      "min: 0.21474839150439673\n",
      "max: 1.41358959977306\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2358456373894668\n",
      "std: 0.13221591325908527\n",
      "min: 0.2675369149567918\n",
      "max: 1.41358959977306\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07390300230946881\n",
      "std: 0.02807381119399692\n",
      "min: 0.02597018979189915\n",
      "max: 0.18393468348932868\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8272500286573489\n",
      "std: 0.3845952780014645\n",
      "min: -0.9551095591622948\n",
      "max: 1.4142019686199971\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.2330722591423487\n",
      "std: 0.36491850595529224\n",
      "min: -0.9551095591622948\n",
      "max: 1.4142019686199971\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09100161647608214\n",
      "std: 0.06532767875229394\n",
      "min: 0.016421843544465912\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.23436353263234852\n",
      "std: 0.2234108603933753\n",
      "min: -0.8858892676360215\n",
      "max: 1.1111024337854638\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.24550627193120922\n",
      "std: 0.2373497374986581\n",
      "min: -0.7545504040326044\n",
      "max: 1.103382194473185\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07390300230946882\n",
      "std: 0.028696002506848714\n",
      "min: 0.026683376370742126\n",
      "max: 0.20263543020099742\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3231293868936187\n",
      "std: 0.0406435358973326\n",
      "min: 0.9190536091154365\n",
      "max: 1.4139828328242081\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2950150722366254\n",
      "std: 0.04881695972794907\n",
      "min: 0.9190536091154365\n",
      "max: 1.4139828328242081\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09100161647608215\n",
      "std: 0.04985855257168865\n",
      "min: 0.039316243892405255\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.3323498912669901\n",
      "std: 0.14110342374785745\n",
      "min: -0.26881960631053914\n",
      "max: 0.9342039077173335\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3371727973658794\n",
      "std: 0.14997412787731904\n",
      "min: -0.25967828853172303\n",
      "max: 0.9201247683046891\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07390300230946882\n",
      "std: 0.02865233685109407\n",
      "min: 0.027467768796556626\n",
      "max: 0.18541624184903363\n",
      "[=====================---------] 72% Epoch 1/50 - loss: 2.7088 - bleu: 5.4858267375e-09 - 40.55s=== Attention Logits (before mask) ===\n",
      "mean: 0.8035616811118268\n",
      "std: 0.4109841929782101\n",
      "min: -1.083661536056283\n",
      "max: 1.4141478446774458\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.20586510032928093\n",
      "std: 0.3564036294241932\n",
      "min: -1.073550724080497\n",
      "max: 1.4141478446774458\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07920792079207921\n",
      "std: 0.04522680712929135\n",
      "min: 0.008938064848355416\n",
      "max: 0.47759583291425173\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.281981118628677\n",
      "std: 0.11885104225094346\n",
      "min: 0.12805465199238983\n",
      "max: 1.4136216581801082\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2415458124514773\n",
      "std: 0.14053705326146776\n",
      "min: 0.2113647593465214\n",
      "max: 1.4136216581801082\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07920792079207918\n",
      "std: 0.03648241255725985\n",
      "min: 0.020094958865680388\n",
      "max: 0.20006468463502675\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8591926952566151\n",
      "std: 0.3846993432915857\n",
      "min: -0.9705179469050335\n",
      "max: 1.4141958692747867\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.24394783710603082\n",
      "std: 0.3733363287496175\n",
      "min: -0.9705179469050335\n",
      "max: 1.4141958692747867\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09510104486016392\n",
      "std: 0.07027250275255517\n",
      "min: 0.00981652995270075\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.3141694179777986\n",
      "std: 0.22836087614759618\n",
      "min: -0.8856724846126246\n",
      "max: 1.1395667357503505\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3242392469923318\n",
      "std: 0.2425118467201406\n",
      "min: -0.8856724846126246\n",
      "max: 1.1395667357503505\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07920792079207921\n",
      "std: 0.03704429189551299\n",
      "min: 0.021531321342050495\n",
      "max: 0.21172104464662725\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3333315659726221\n",
      "std: 0.035311535167217654\n",
      "min: 1.0094986664635546\n",
      "max: 1.4140464482748418\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3105938004245352\n",
      "std: 0.042138662175502536\n",
      "min: 1.0130473875767825\n",
      "max: 1.4140464482748418\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09510104486016391\n",
      "std: 0.05397458303609529\n",
      "min: 0.028709344196899148\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.35824010883414514\n",
      "std: 0.14208475143287502\n",
      "min: -0.29647049297113703\n",
      "max: 0.9614447895614112\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36898543227764796\n",
      "std: 0.14608188458890597\n",
      "min: -0.22443566587642733\n",
      "max: 0.9614447895614112\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07920792079207922\n",
      "std: 0.037011155659644364\n",
      "min: 0.023208281289533346\n",
      "max: 0.20291702855660276\n",
      "[======================--------] 76% Epoch 1/50 - loss: 2.5670 - bleu: 5.4930778982e-09 - 42.89s=== Attention Logits (before mask) ===\n",
      "mean: 0.7633465443405782\n",
      "std: 0.42904910984387895\n",
      "min: -0.9766999732951148\n",
      "max: 1.4141616466719436\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.1756131423805638\n",
      "std: 0.34526015779373287\n",
      "min: -0.9746732949381622\n",
      "max: 1.4141616466719436\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07048458149779736\n",
      "std: 0.04715954317877149\n",
      "min: 0.010918445194100953\n",
      "max: 0.47889493674831124\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2708382390649486\n",
      "std: 0.14253444336819857\n",
      "min: -0.01652006337368141\n",
      "max: 1.4135844584099315\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2301443464552864\n",
      "std: 0.16828542574536415\n",
      "min: 0.08658721166314853\n",
      "max: 1.4134226269157146\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07048458149779736\n",
      "std: 0.0404859821039751\n",
      "min: 0.023599651222628706\n",
      "max: 0.2105895226789829\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.86753867200104\n",
      "std: 0.3993287195041049\n",
      "min: -0.9324205732656088\n",
      "max: 1.4141929222037264\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.2765575610959133\n",
      "std: 0.37308588846123075\n",
      "min: -0.9208447003845153\n",
      "max: 1.4141929222037264\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08405917323378957\n",
      "std: 0.0718409417363202\n",
      "min: 0.008705060395340074\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.3719374876493044\n",
      "std: 0.2411081576989407\n",
      "min: -0.8874659106316553\n",
      "max: 1.153508001945119\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3762573681597017\n",
      "std: 0.2562161540436768\n",
      "min: -0.8244852404402356\n",
      "max: 1.1360454156835\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07048458149779736\n",
      "std: 0.04091393206240887\n",
      "min: 0.021107679507814517\n",
      "max: 0.228313991056709\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3408642544745875\n",
      "std: 0.03220728465985314\n",
      "min: 1.0271133765247153\n",
      "max: 1.4140576491905708\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3238147329730419\n",
      "std: 0.037965094662251724\n",
      "min: 1.0271133765247153\n",
      "max: 1.4140576491905708\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08405917323378957\n",
      "std: 0.05772803627600671\n",
      "min: 0.022329381077174713\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.3905236980419087\n",
      "std: 0.1478300906354171\n",
      "min: -0.28318279683277\n",
      "max: 0.9739302196637921\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.403743231210199\n",
      "std: 0.1471723793976044\n",
      "min: -0.1869215371131392\n",
      "max: 0.9456883139784834\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07048458149779736\n",
      "std: 0.04087178744626826\n",
      "min: 0.02446232948317884\n",
      "max: 0.2152246911204017\n",
      "[========================------] 80% Epoch 1/50 - loss: 2.4395 - bleu: 5.4166438466e-09 - 45.26s=== Attention Logits (before mask) ===\n",
      "mean: 0.7068451244098726\n",
      "std: 0.45292920704400036\n",
      "min: -1.0192526671863895\n",
      "max: 1.4141810889788395\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.1552191444178765\n",
      "std: 0.34582303406356074\n",
      "min: -1.0107283781484486\n",
      "max: 1.4141810889788395\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.055172413793103454\n",
      "std: 0.04448392129390862\n",
      "min: 0.0032332890354008492\n",
      "max: 0.4909888285545818\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2539337165760782\n",
      "std: 0.1727436050668804\n",
      "min: -0.15946237721795312\n",
      "max: 1.4136378704802384\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2225391450465055\n",
      "std: 0.1943128280608733\n",
      "min: -0.05095086364105486\n",
      "max: 1.4135101867018303\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.055172413793103454\n",
      "std: 0.03979694762690285\n",
      "min: 0.006612734784824043\n",
      "max: 0.2020748647499633\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8687322656565574\n",
      "std: 0.4183028330326996\n",
      "min: -1.018164441251121\n",
      "max: 1.4141886798580823\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.2978131696807345\n",
      "std: 0.38011612819691365\n",
      "min: -1.018164441251121\n",
      "max: 1.4141886798580823\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07457560592679816\n",
      "std: 0.06900766076229431\n",
      "min: 0.003137953772258513\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.4188947852609362\n",
      "std: 0.24979782480601861\n",
      "min: -0.8021571534538076\n",
      "max: 1.2023712840759317\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.39326213873785454\n",
      "std: 0.2761124020114112\n",
      "min: -0.7390693780171387\n",
      "max: 1.2023712840759317\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05517241379310345\n",
      "std: 0.04009097611348395\n",
      "min: 0.006641866057934614\n",
      "max: 0.21180656416398136\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3468748533428994\n",
      "std: 0.02978917628241972\n",
      "min: 1.0875972725123846\n",
      "max: 1.414052686508124\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3351596452881749\n",
      "std: 0.03381790476953135\n",
      "min: 1.1095136157296133\n",
      "max: 1.414052686508124\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07457560592679817\n",
      "std: 0.056558347631701006\n",
      "min: 0.010416482991341491\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.4300912432372196\n",
      "std: 0.15231761869266303\n",
      "min: -0.3122166690251828\n",
      "max: 0.9910155904374729\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.44549842310947685\n",
      "std: 0.1487670746045584\n",
      "min: -0.1598860902346183\n",
      "max: 0.9910155904374729\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05517241379310345\n",
      "std: 0.04006369188238246\n",
      "min: 0.007659628722781534\n",
      "max: 0.20790015578774154\n",
      "[=========================-----] 84% Epoch 1/50 - loss: 2.3240 - bleu: 5.5733635494e-09 - 47.61s=== Attention Logits (before mask) ===\n",
      "mean: 0.7129727679386023\n",
      "std: 0.4480314736265101\n",
      "min: -1.0586422139901714\n",
      "max: 1.4141576338525776\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.11920146047656795\n",
      "std: 0.34732017847032187\n",
      "min: -1.0586422139901714\n",
      "max: 1.4141576338525776\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06881720430107527\n",
      "std: 0.039860135888079844\n",
      "min: 0.011004569706853389\n",
      "max: 0.5247063593524084\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.231474047787281\n",
      "std: 0.2128417366213911\n",
      "min: -0.6530756571510521\n",
      "max: 1.4136542775882537\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.17846455703347\n",
      "std: 0.26369051752676065\n",
      "min: -0.5481397856719133\n",
      "max: 1.4136542775882537\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06881720430107525\n",
      "std: 0.03300215822503167\n",
      "min: 0.018165425166227513\n",
      "max: 0.2561491367057314\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9172264788977647\n",
      "std: 0.4002528949316728\n",
      "min: -0.9761840513087533\n",
      "max: 1.4141906353999505\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3343970099143411\n",
      "std: 0.39153368867306104\n",
      "min: -0.9590250770437407\n",
      "max: 1.4141906353999505\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08278416208267522\n",
      "std: 0.0648784145974448\n",
      "min: 0.013926036758355112\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.4615896702059306\n",
      "std: 0.2556087073065557\n",
      "min: -0.7086547763131467\n",
      "max: 1.2165180941167264\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47545275177001073\n",
      "std: 0.2683204197725151\n",
      "min: -0.6497517889140981\n",
      "max: 1.2133562679513268\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06881720430107527\n",
      "std: 0.03338990189731675\n",
      "min: 0.022539694947711124\n",
      "max: 0.24913225219077118\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3519913300150599\n",
      "std: 0.02863918876803468\n",
      "min: 1.084334547112823\n",
      "max: 1.4140793737231174\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3416274911738233\n",
      "std: 0.03239355631890087\n",
      "min: 1.1035468518522615\n",
      "max: 1.4140793737231174\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08278416208267524\n",
      "std: 0.05009363449421354\n",
      "min: 0.037315211918785625\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.46814563897886685\n",
      "std: 0.1601770377061868\n",
      "min: -0.30696859652930364\n",
      "max: 1.0049826859229871\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4895310819084574\n",
      "std: 0.15817150773918667\n",
      "min: -0.1981307399309245\n",
      "max: 0.999479735670488\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06881720430107528\n",
      "std: 0.033344954429253386\n",
      "min: 0.02522904508201793\n",
      "max: 0.23669640284425558\n",
      "[==========================----] 88% Epoch 1/50 - loss: 2.2189 - bleu: 5.5962909856e-09 - 50.00s=== Attention Logits (before mask) ===\n",
      "mean: 0.6911564879229413\n",
      "std: 0.4521603328338359\n",
      "min: -0.9777085227519715\n",
      "max: 1.4141441911864383\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.10349583504809792\n",
      "std: 0.3424664790204097\n",
      "min: -0.9777085227519715\n",
      "max: 1.4141441911864383\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06680584551148226\n",
      "std: 0.03872602643824632\n",
      "min: 0.00772101415753496\n",
      "max: 0.4079573940516461\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1961900673809722\n",
      "std: 0.26978660321214354\n",
      "min: -0.8467451844912159\n",
      "max: 1.4137072034231888\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1231193396522408\n",
      "std: 0.3476075404931984\n",
      "min: -0.75839166262726\n",
      "max: 1.4134609645485618\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06680584551148225\n",
      "std: 0.032139283614695605\n",
      "min: 0.016432159742894574\n",
      "max: 0.19290403569701586\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9288562468029531\n",
      "std: 0.4028391647161901\n",
      "min: -0.899425164019267\n",
      "max: 1.4141738964323887\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3461691374831932\n",
      "std: 0.3930950791484622\n",
      "min: -0.8927739284834305\n",
      "max: 1.4141738964323887\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08174899830585959\n",
      "std: 0.06574576377598963\n",
      "min: 0.009492925409015697\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.4739698514999204\n",
      "std: 0.2613139272741602\n",
      "min: -0.7482522268492192\n",
      "max: 1.2479302226327644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4799361430716792\n",
      "std: 0.27752143357460335\n",
      "min: -0.7482522268492192\n",
      "max: 1.2479302226327644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06680584551148225\n",
      "std: 0.03243897556374363\n",
      "min: 0.01596584356958841\n",
      "max: 0.17832422807508158\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.354761210431742\n",
      "std: 0.02777267704509989\n",
      "min: 1.0834902850680102\n",
      "max: 1.4140954329633078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3462194865758517\n",
      "std: 0.031051844286885944\n",
      "min: 1.0834902850680102\n",
      "max: 1.4140954329633078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08174899830585959\n",
      "std: 0.05084688823957971\n",
      "min: 0.026655035761265437\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.4909798097856705\n",
      "std: 0.15926876178192892\n",
      "min: -0.3050048932962995\n",
      "max: 1.0174073740733285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5178969697662089\n",
      "std: 0.15175733808740613\n",
      "min: -0.1288350371098756\n",
      "max: 1.0174073740733285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06680584551148225\n",
      "std: 0.032435367627127794\n",
      "min: 0.018740346447888197\n",
      "max: 0.1663925518216825\n",
      "[===========================---] 92% Epoch 1/50 - loss: 2.1229 - bleu: 5.5960664539e-09 - 52.39s=== Attention Logits (before mask) ===\n",
      "mean: 0.6188320351304282\n",
      "std: 0.48226945244659186\n",
      "min: -1.0845137290375815\n",
      "max: 1.4141410019356466\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.07677573524345752\n",
      "std: 0.3405822686116458\n",
      "min: -1.0845137290375815\n",
      "max: 1.4141410019356466\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05414551607445008\n",
      "std: 0.02472503046923479\n",
      "min: 0.01051586678119093\n",
      "max: 0.32653562561141086\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.142717121754558\n",
      "std: 0.346197846951549\n",
      "min: -0.9743405241647793\n",
      "max: 1.4137409427523508\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0452536241125\n",
      "std: 0.44413871351524153\n",
      "min: -0.8861698932609111\n",
      "max: 1.4135093531454934\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05414551607445009\n",
      "std: 0.017100351445589808\n",
      "min: 0.019962924587658807\n",
      "max: 0.1352252331957619\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.882751477639132\n",
      "std: 0.4386241842964878\n",
      "min: -0.9108633071681593\n",
      "max: 1.4141661498452105\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3461090553097277\n",
      "std: 0.3895851336227868\n",
      "min: -0.8870250945240441\n",
      "max: 1.4141661498452105\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06459563979431389\n",
      "std: 0.052044052786473456\n",
      "min: 0.011586396479164011\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.473424483207575\n",
      "std: 0.2666466749540623\n",
      "min: -0.8281870637292053\n",
      "max: 1.2627931586689445\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49448199809694493\n",
      "std: 0.2799840497147257\n",
      "min: -0.7729102115357749\n",
      "max: 1.2627931586689445\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05414551607445008\n",
      "std: 0.01736025110389402\n",
      "min: 0.020360870596049706\n",
      "max: 0.1413048939141066\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.355580189231793\n",
      "std: 0.027577391657794232\n",
      "min: 1.1091716088464363\n",
      "max: 1.4141034045761354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.349092752056255\n",
      "std: 0.02978818991435042\n",
      "min: 1.1143509934538556\n",
      "max: 1.4141034045761354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0645956397943139\n",
      "std: 0.03967550126161579\n",
      "min: 0.03324490631037015\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.5135730216339588\n",
      "std: 0.16008430893745326\n",
      "min: -0.2812581922425378\n",
      "max: 1.0422116179479395\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5471243189243655\n",
      "std: 0.1493640915059207\n",
      "min: -0.1265559689781114\n",
      "max: 1.0326580131994094\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05414551607445008\n",
      "std: 0.01729276855085534\n",
      "min: 0.02350615981977334\n",
      "max: 0.12337163824006585\n",
      "[============================--] 96% Epoch 1/50 - loss: 2.0351 - bleu: 5.5960165641e-09 - 54.79s=== Attention Logits (before mask) ===\n",
      "mean: 0.5512232048904354\n",
      "std: 0.5030642282858638\n",
      "min: -1.0251586258749321\n",
      "max: 1.4141643221774303\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.05557141480070001\n",
      "std: 0.33829341857722955\n",
      "min: -1.0251586258749321\n",
      "max: 1.4141643221774303\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04519774011299435\n",
      "std: 0.020632348191534002\n",
      "min: 0.007997111753144768\n",
      "max: 0.35375659438587054\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0760123530539343\n",
      "std: 0.43063289458413306\n",
      "min: -1.0364923366932919\n",
      "max: 1.4137906602190111\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9556783886441492\n",
      "std: 0.538569763974981\n",
      "min: -0.9623460025073609\n",
      "max: 1.4134253403375003\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04519774011299434\n",
      "std: 0.013581142443513316\n",
      "min: 0.015279633262289722\n",
      "max: 0.15647939505799585\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8415189812759595\n",
      "std: 0.4604936802786974\n",
      "min: -1.01716625025406\n",
      "max: 1.4141885959045302\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3473279209931056\n",
      "std: 0.37906646142877\n",
      "min: -1.01716625025406\n",
      "max: 1.4141885959045302\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05451545800157808\n",
      "std: 0.04707034743019381\n",
      "min: 0.008929312568463339\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.4754217020232212\n",
      "std: 0.27205607442194424\n",
      "min: -0.7491623551498027\n",
      "max: 1.2871944276987248\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5012457770966239\n",
      "std: 0.286756278783904\n",
      "min: -0.7223110641267899\n",
      "max: 1.2871944276987248\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04519774011299436\n",
      "std: 0.01365578627503907\n",
      "min: 0.017774845315190448\n",
      "max: 0.1341774955201639\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.356777083558293\n",
      "std: 0.027704256706758936\n",
      "min: 1.0961089120195466\n",
      "max: 1.4141181510002594\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3510365277619973\n",
      "std: 0.02984740006886907\n",
      "min: 1.0961089120195466\n",
      "max: 1.4141181510002594\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05451545800157808\n",
      "std: 0.036662390144700165\n",
      "min: 0.025457231666861757\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.5319201102627467\n",
      "std: 0.16798213122517372\n",
      "min: -0.3217223355300533\n",
      "max: 1.0687764035051062\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5725111185566686\n",
      "std: 0.15329353526354547\n",
      "min: -0.10990871530785042\n",
      "max: 1.0292211834780105\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04519774011299435\n",
      "std: 0.01360928673109635\n",
      "min: 0.019757955518008328\n",
      "max: 0.11865935236407221\n",
      "[==============================] 100% Epoch 1/50 - loss: 1.9544 - bleu: 5.5959666765e-09 - 57.22s=== Attention Logits (before mask) ===\n",
      "mean: 0.6405248836443286\n",
      "std: 0.5188338782177201\n",
      "min: -1.033636217987406\n",
      "max: 1.4141550157655547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.041364337379316336\n",
      "std: 0.34396586283210834\n",
      "min: -1.033636217987406\n",
      "max: 1.4141550157655547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05351170568561872\n",
      "std: 0.025702733666578506\n",
      "min: 0.009613026651466641\n",
      "max: 0.39091824233365696\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1618812107853551\n",
      "std: 0.46700047847603765\n",
      "min: -1.0675093388620707\n",
      "max: 1.413667555407435\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9525598412057541\n",
      "std: 0.6292576318607811\n",
      "min: -0.9865743121394693\n",
      "max: 1.4132509510788287\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.053511705685618735\n",
      "std: 0.018264222321341922\n",
      "min: 0.022528891394271378\n",
      "max: 0.2136449096915915\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9582884162258276\n",
      "std: 0.4514218837190118\n",
      "min: -0.9221586798294403\n",
      "max: 1.4141724632337753\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.38888172342518706\n",
      "std: 0.4041826229557468\n",
      "min: -0.9036013826846462\n",
      "max: 1.4141724632337753\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06632630798097482\n",
      "std: 0.053541188145441475\n",
      "min: 0.012169892788508871\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.5439747915132396\n",
      "std: 0.26569806160334264\n",
      "min: -0.6988061571675962\n",
      "max: 1.2021226645057812\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5729391837255771\n",
      "std: 0.28086201185192583\n",
      "min: -0.6988061571675962\n",
      "max: 1.2021226645057812\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05351170568561873\n",
      "std: 0.017949497659609168\n",
      "min: 0.03075056016238794\n",
      "max: 0.12910101146914615\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4097064878757568\n",
      "std: 0.004359237180891467\n",
      "min: 1.3725424135913138\n",
      "max: 1.414094320641719\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4048603549141474\n",
      "std: 0.005364874142076541\n",
      "min: 1.3743171655296003\n",
      "max: 1.414094320641719\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06632630798097482\n",
      "std: 0.04057560742415538\n",
      "min: 0.035015997991889536\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.5945731484338113\n",
      "std: 0.15423168806611812\n",
      "min: 0.20481527381774878\n",
      "max: 0.8499252878591357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6398498423777625\n",
      "std: 0.12851129340350378\n",
      "min: 0.3413946768352521\n",
      "max: 0.8221176008645504\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05351170568561873\n",
      "std: 0.017949405972152496\n",
      "min: 0.030899869820598405\n",
      "max: 0.12835535901173067\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.770749126685745\n",
      "std: 0.45751523649993675\n",
      "min: -1.0020517153854829\n",
      "max: 1.4141221824519463\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.029460696298860375\n",
      "std: 0.35887274141962716\n",
      "min: -1.0006692959761865\n",
      "max: 1.4141221824519463\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0935672514619883\n",
      "std: 0.041905144145112594\n",
      "min: 0.015604507607694117\n",
      "max: 0.47177612384535866\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2647190065636653\n",
      "std: 0.30625041821819277\n",
      "min: -1.1081043348903385\n",
      "max: 1.4136107527271145\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0821446875471505\n",
      "std: 0.494269635243231\n",
      "min: -1.0258866450051025\n",
      "max: 1.4131912598943974\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0935672514619883\n",
      "std: 0.030868320533161412\n",
      "min: 0.03392708319634067\n",
      "max: 0.17255496174282622\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0720135751321298\n",
      "std: 0.35937730691872827\n",
      "min: -0.7982384045586854\n",
      "max: 1.4141818023146397\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48221975035291753\n",
      "std: 0.4317249614617629\n",
      "min: -0.7982384045586854\n",
      "max: 1.4141818023146397\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10313125487668351\n",
      "std: 0.07062429568920253\n",
      "min: 0.01164587092734783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.5793573919848726\n",
      "std: 0.258647102532209\n",
      "min: -0.5237235649811651\n",
      "max: 1.1993305400246967\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.599118625105544\n",
      "std: 0.2705921050529751\n",
      "min: -0.5237235649811651\n",
      "max: 1.1993305400246967\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0935672514619883\n",
      "std: 0.03058902330071582\n",
      "min: 0.0453739619243295\n",
      "max: 0.14776744978354137\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.410825024377158\n",
      "std: 0.003499829251926085\n",
      "min: 1.3709527325630304\n",
      "max: 1.4140916432183717\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4057785265054668\n",
      "std: 0.005413937049741509\n",
      "min: 1.371329930940792\n",
      "max: 1.4140916432183717\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10313125487668354\n",
      "std: 0.05114428262066065\n",
      "min: 0.037786441799363794\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.6054880571518326\n",
      "std: 0.14645646089627748\n",
      "min: 0.2279198440513935\n",
      "max: 0.843622755883907\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.638711490105119\n",
      "std: 0.12980634464056257\n",
      "min: 0.3664974820035347\n",
      "max: 0.8229446528124941\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0935672514619883\n",
      "std: 0.03058906544621789\n",
      "min: 0.046326837854187335\n",
      "max: 0.1457174857771392\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7277251100791319\n",
      "std: 0.4832232496488684\n",
      "min: -0.9428422338832677\n",
      "max: 1.41411194961711\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.03552299098947321\n",
      "std: 0.3550748261072299\n",
      "min: -0.9428422338832677\n",
      "max: 1.41411194961711\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0751173708920188\n",
      "std: 0.0379906109756071\n",
      "min: 0.010711919407369971\n",
      "max: 0.4157919463920229\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.236126361997374\n",
      "std: 0.35785267750078337\n",
      "min: -1.0327289146015357\n",
      "max: 1.4135834670667817\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0463186494281975\n",
      "std: 0.5401028404686847\n",
      "min: -0.9530749021637017\n",
      "max: 1.4132929849153104\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07511737089201877\n",
      "std: 0.02940688350068383\n",
      "min: 0.022384173254069436\n",
      "max: 0.16095637426602125\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0399593482494827\n",
      "std: 0.38885261385386816\n",
      "min: -0.8421437684409058\n",
      "max: 1.4141621840891725\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4518974564168715\n",
      "std: 0.4193809117704716\n",
      "min: -0.8390101121840732\n",
      "max: 1.4141621840891725\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08860907077066574\n",
      "std: 0.06509883808470401\n",
      "min: 0.01214332880192408\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.5752296807010352\n",
      "std: 0.2622070149938079\n",
      "min: -0.6087921273416331\n",
      "max: 1.207012286886691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5957099052945032\n",
      "std: 0.27399272623721926\n",
      "min: -0.5713128007241008\n",
      "max: 1.207012286886691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0751173708920188\n",
      "std: 0.029197784527565836\n",
      "min: 0.03218289259727887\n",
      "max: 0.14773455700181115\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4105659367739978\n",
      "std: 0.0037431496133991694\n",
      "min: 1.367390594691188\n",
      "max: 1.4140901573293652\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4056401074559208\n",
      "std: 0.0053869181568103885\n",
      "min: 1.367390594691188\n",
      "max: 1.4140901573293652\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08860907077066572\n",
      "std: 0.04836606023598035\n",
      "min: 0.0378255567421005\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.6041178001460538\n",
      "std: 0.14694195220242667\n",
      "min: 0.24542801637060738\n",
      "max: 0.8423021361127356\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6404176475378515\n",
      "std: 0.12778638346431273\n",
      "min: 0.342471961980083\n",
      "max: 0.8236114496836642\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0751173708920188\n",
      "std: 0.029198393101930915\n",
      "min: 0.033520646603205494\n",
      "max: 0.14482024967781376\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7405802584338401\n",
      "std: 0.47418104520081683\n",
      "min: -0.9795388245105174\n",
      "max: 1.4141195374075053\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.038113246400624766\n",
      "std: 0.3500510628493043\n",
      "min: -0.9795388245105174\n",
      "max: 1.4141195374075053\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07901234567901234\n",
      "std: 0.03978828688474251\n",
      "min: 0.007959253069831066\n",
      "max: 0.4215056197007521\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2470427705307718\n",
      "std: 0.34232954073457905\n",
      "min: -1.0388488761282635\n",
      "max: 1.4135907423725707\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0600027162254506\n",
      "std: 0.524906506222458\n",
      "min: -0.9469533422008566\n",
      "max: 1.4132477646849126\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07901234567901234\n",
      "std: 0.031199377195452908\n",
      "min: 0.015997028169383785\n",
      "max: 0.16477556207321808\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0466473417825746\n",
      "std: 0.3889889720119271\n",
      "min: -0.8888069918745183\n",
      "max: 1.4141802368035974\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4415277802059446\n",
      "std: 0.43457532960694606\n",
      "min: -0.8888069918745183\n",
      "max: 1.4141802368035974\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09320293098690866\n",
      "std: 0.06874676132268952\n",
      "min: 0.006545888300115018\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.5742431501551842\n",
      "std: 0.26054858027793587\n",
      "min: -0.5417892687337313\n",
      "max: 1.203911094688554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5887969946611713\n",
      "std: 0.27693248454909164\n",
      "min: -0.5292439431917341\n",
      "max: 1.203911094688554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07901234567901234\n",
      "std: 0.03101076754891681\n",
      "min: 0.02301504275555321\n",
      "max: 0.1468791564900054\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.410521975946649\n",
      "std: 0.003971178552800548\n",
      "min: 1.370854940057313\n",
      "max: 1.4141072784688626\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4051187529181304\n",
      "std: 0.005775835936224578\n",
      "min: 1.371085581969943\n",
      "max: 1.4141072784688626\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09320293098690866\n",
      "std: 0.0508209220102337\n",
      "min: 0.023409411705392128\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.603593528085874\n",
      "std: 0.14666244589075916\n",
      "min: 0.2432622578107505\n",
      "max: 0.8479686221335945\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6394806491952248\n",
      "std: 0.12840116417584024\n",
      "min: 0.3552193882710996\n",
      "max: 0.8344017353659109\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07901234567901234\n",
      "std: 0.031010738859750656\n",
      "min: 0.023134973943997068\n",
      "max: 0.14436552382370177\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.751399921998321\n",
      "std: 0.46579200201580995\n",
      "min: -0.9461910071789621\n",
      "max: 1.4141155596929684\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.041769644517869145\n",
      "std: 0.34677616242476145\n",
      "min: -0.9461910071789621\n",
      "max: 1.4141155596929684\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08376963350785341\n",
      "std: 0.03334133727018535\n",
      "min: 0.015439080642486799\n",
      "max: 0.39580744904607107\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2460850416659246\n",
      "std: 0.3392926885477662\n",
      "min: -0.9961247956724772\n",
      "max: 1.4136245967630687\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.050775611145358\n",
      "std: 0.5293859392242335\n",
      "min: -0.9103753866618134\n",
      "max: 1.4132822033625592\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08376963350785341\n",
      "std: 0.021546599496482875\n",
      "min: 0.03433462389005348\n",
      "max: 0.15678086922522963\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0617937918036378\n",
      "std: 0.36780131659622006\n",
      "min: -0.8767686449466179\n",
      "max: 1.4141621840891725\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4772649456452024\n",
      "std: 0.42541324990270385\n",
      "min: -0.8767686449466179\n",
      "max: 1.4141621840891725\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09716185118895425\n",
      "std: 0.06185321104622952\n",
      "min: 0.019799083542679254\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.5763382195874215\n",
      "std: 0.25790529599950807\n",
      "min: -0.6738498537060774\n",
      "max: 1.1918762184168192\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6031666586225194\n",
      "std: 0.2684127969017608\n",
      "min: -0.6190038594210016\n",
      "max: 1.1918762184168192\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08376963350785342\n",
      "std: 0.0212286050533672\n",
      "min: 0.04200889277723403\n",
      "max: 0.12796588607511056\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.410780026121335\n",
      "std: 0.0034736093667749384\n",
      "min: 1.3667079702124965\n",
      "max: 1.4140880734008663\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4059276382972408\n",
      "std: 0.00526284095147514\n",
      "min: 1.370953500331159\n",
      "max: 1.4140880734008663\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09716185118895423\n",
      "std: 0.042000039013162745\n",
      "min: 0.05792446566403455\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.602306521683594\n",
      "std: 0.14756312341993524\n",
      "min: 0.2651435954542645\n",
      "max: 0.8401906754807645\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6395748876033388\n",
      "std: 0.12860066545344506\n",
      "min: 0.35504263095864136\n",
      "max: 0.8210831072997178\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0837696335078534\n",
      "std: 0.02122972361230869\n",
      "min: 0.04244132727560106\n",
      "max: 0.12768034119918809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7284735716422385\n",
      "std: 0.48047713337590736\n",
      "min: -0.9711453785169073\n",
      "max: 1.4141344470000567\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.038454694550414566\n",
      "std: 0.34814946467136515\n",
      "min: -0.9675887819622844\n",
      "max: 1.4141344470000567\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07511737089201877\n",
      "std: 0.0395205106222848\n",
      "min: 0.010933427672706258\n",
      "max: 0.42454282193088005\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2285561382148886\n",
      "std: 0.3708003337437887\n",
      "min: -1.0750435066967678\n",
      "max: 1.4135978115834933\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.02094846336756\n",
      "std: 0.5629651776298442\n",
      "min: -0.9894410121896272\n",
      "max: 1.4132465966991803\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07511737089201878\n",
      "std: 0.031076403095654015\n",
      "min: 0.026806751901555112\n",
      "max: 0.17053017977077067\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0399200092466963\n",
      "std: 0.3836456541802501\n",
      "min: -0.8971234106291207\n",
      "max: 1.414182072972521\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46112340666100676\n",
      "std: 0.4044125378061066\n",
      "min: -0.8883973600652335\n",
      "max: 1.414182072972521\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08757273722417469\n",
      "std: 0.06699840534089183\n",
      "min: 0.014288992081305688\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.5717025800831032\n",
      "std: 0.25489315272667223\n",
      "min: -0.7181890031421253\n",
      "max: 1.1961636445157267\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5908107309907868\n",
      "std: 0.27052540623988625\n",
      "min: -0.7181890031421253\n",
      "max: 1.1961636445157267\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07511737089201877\n",
      "std: 0.030887860912345178\n",
      "min: 0.03949222861347439\n",
      "max: 0.14646802168114767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4105747406572526\n",
      "std: 0.003681097314085369\n",
      "min: 1.368574593452681\n",
      "max: 1.4140981595004254\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4057397795694027\n",
      "std: 0.00524804820516585\n",
      "min: 1.368574593452681\n",
      "max: 1.4140981595004254\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08757273722417469\n",
      "std: 0.05101188529301246\n",
      "min: 0.04113842656639718\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.6027816376228108\n",
      "std: 0.14824902915769053\n",
      "min: 0.2575938239528744\n",
      "max: 0.8444122799908624\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6406231464390005\n",
      "std: 0.12753881437854162\n",
      "min: 0.36114860852592745\n",
      "max: 0.8193142188953882\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07511737089201878\n",
      "std: 0.030888097525028822\n",
      "min: 0.040219399554377436\n",
      "max: 0.14568931172288765\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7306449329675461\n",
      "std: 0.47769620573847077\n",
      "min: -0.9785597332929777\n",
      "max: 1.4140995667463863\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.05140390505581319\n",
      "std: 0.35448902370944585\n",
      "min: -0.9785597332929777\n",
      "max: 1.4140995667463863\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07547169811320754\n",
      "std: 0.029256820041771117\n",
      "min: 0.015345062289398196\n",
      "max: 0.38004666578349694\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2517182730812324\n",
      "std: 0.33053814602581016\n",
      "min: -0.8927392509212977\n",
      "max: 1.4135190074565018\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0902580429351425\n",
      "std: 0.48714852652687823\n",
      "min: -0.7631433414087165\n",
      "max: 1.4131549347852526\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07547169811320754\n",
      "std: 0.01829151499962102\n",
      "min: 0.038818803540926435\n",
      "max: 0.12979357398352895\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0384642884050683\n",
      "std: 0.39096406569755005\n",
      "min: -0.7969034785810214\n",
      "max: 1.4141621840891725\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.454748753023834\n",
      "std: 0.42508533478013116\n",
      "min: -0.7969034785810214\n",
      "max: 1.4141621840891725\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08742666513286552\n",
      "std: 0.06402046713560844\n",
      "min: 0.01414283093923044\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.5735911825782634\n",
      "std: 0.2583789248447774\n",
      "min: -0.6380744646945408\n",
      "max: 1.1959759440741509\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5950438924858127\n",
      "std: 0.27026152305131695\n",
      "min: -0.6380744646945408\n",
      "max: 1.1959759440741509\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07547169811320754\n",
      "std: 0.01802273795569584\n",
      "min: 0.04584783948568606\n",
      "max: 0.11394985527928446\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4105989422285485\n",
      "std: 0.0036914539185996377\n",
      "min: 1.3730523076077294\n",
      "max: 1.4140915181844371\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4057235494508553\n",
      "std: 0.005362511624189874\n",
      "min: 1.3730523076077294\n",
      "max: 1.4140915181844371\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08742666513286551\n",
      "std: 0.046616228968066206\n",
      "min: 0.04674481651187965\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.6049052397159839\n",
      "std: 0.14483224703447417\n",
      "min: 0.2906370543727586\n",
      "max: 0.8273550438517288\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.638431138693655\n",
      "std: 0.1280199423868978\n",
      "min: 0.3624962224367124\n",
      "max: 0.8088604501535271\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07547169811320754\n",
      "std: 0.018022136002274394\n",
      "min: 0.04636501990587741\n",
      "max: 0.11264813591067507\n",
      " - val_bleu: 0.0\n",
      "Epoch 0 details:\n",
      "Loss: 1.9544\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.877871123972025\n",
      "std: 0.3568536679824961\n",
      "min: -0.7203301824213914\n",
      "max: 1.413273325417982\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.877871123972025\n",
      "std: 0.3568536679824961\n",
      "min: -0.7203301824213914\n",
      "max: 1.413273325417982\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.010526315789473682\n",
      "std: 0.0021200591511079574\n",
      "min: 0.0017767083071111738\n",
      "max: 0.055390010465975706\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1304981071696052\n",
      "std: 0.48888563951245645\n",
      "min: -1.0621021452671728\n",
      "max: 1.4139143269224166\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1304981071696052\n",
      "std: 0.48888563951245645\n",
      "min: -1.0621021452671728\n",
      "max: 1.4139143269224166\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.010526315789473684\n",
      "std: 0.002683550625118198\n",
      "min: 0.0010153844132494028\n",
      "max: 0.07382541652916746\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4113182340624673\n",
      "std: 0.0007336068564112406\n",
      "min: 1.4102557543740661\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4113182340624673\n",
      "std: 0.0007336068564112406\n",
      "min: 1.4102557543740661\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 1.0\n",
      "std: 0.0\n",
      "min: 1.0\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3047840343141431\n",
      "std: 0.33336391386074304\n",
      "min: -0.8489633537249607\n",
      "max: 0.8674392152848591\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.530983293813906\n",
      "std: 0.19305309536258722\n",
      "min: 0.10792864151306367\n",
      "max: 0.8674392152848591\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03286034093724654\n",
      "min: 0.12633828048437834\n",
      "max: 0.2602207285544561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4137715306183263\n",
      "std: 0.00013784481624428866\n",
      "min: 1.413649484955399\n",
      "max: 1.4139876647995064\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4137715306183263\n",
      "std: 0.00013784481624428866\n",
      "min: 1.413649484955399\n",
      "max: 1.4139876647995064\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 1.0\n",
      "std: 0.0\n",
      "min: 1.0\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2983078243582216\n",
      "std: 0.29518001594777604\n",
      "min: -0.7406020314333401\n",
      "max: 0.9118540924163263\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6392243615725102\n",
      "std: 0.19004968496653007\n",
      "min: 0.20138759636568906\n",
      "max: 0.9118540924163263\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999998\n",
      "std: 0.03275663941662369\n",
      "min: 0.13275135781679537\n",
      "max: 0.26472431744175123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1963623061909985\n",
      "std: 0.22168255608041917\n",
      "min: 0.8476747683893139\n",
      "max: 1.4123025686197597\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2650026332042277\n",
      "std: 0.2093357704790612\n",
      "min: 0.9124721050936906\n",
      "max: 1.4123025686197597\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.2518618548026998\n",
      "min: 0.37769058979187176\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3135986083368239\n",
      "std: 0.35502019981706745\n",
      "min: -0.9172042758451894\n",
      "max: 0.8674392152848591\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5209141561979923\n",
      "std: 0.184815432163503\n",
      "min: 0.1079286415130636\n",
      "max: 0.8674392152848591\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.031348511003407784\n",
      "min: 0.12633828048437834\n",
      "max: 0.2602207285544561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4096482816390383\n",
      "std: 0.004908598189741002\n",
      "min: 1.398163889097129\n",
      "max: 1.4139876647995064\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4107538184529778\n",
      "std: 0.004848929341262133\n",
      "min: 1.398163889097129\n",
      "max: 1.4139876647995064\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.23571075064852537\n",
      "min: 0.4961599026799401\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3072839625674793\n",
      "std: 0.2987983663281142\n",
      "min: -0.7711500576883218\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6284045027395974\n",
      "std: 0.18804483986449524\n",
      "min: 0.19278350690022822\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03289084950156747\n",
      "min: 0.1322140155191366\n",
      "max: 0.26472431744175123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9311392748460531\n",
      "std: 0.5200042157371114\n",
      "min: 0.06308843307539107\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.092094570120888\n",
      "std: 0.47992343647084595\n",
      "min: 0.0945946245166937\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.29976242841654843\n",
      "min: 0.2109675039341757\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.12827861141835117\n",
      "std: 0.34637218791108354\n",
      "min: -0.8489633537249607\n",
      "max: 1.003122612759425\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5512418388888556\n",
      "std: 0.20162991953539502\n",
      "min: 0.1079286415130636\n",
      "max: 1.003122612759425\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.025608493971078915\n",
      "min: 0.12633828048437834\n",
      "max: 0.2602207285544561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4023848197309958\n",
      "std: 0.011737280239661375\n",
      "min: 1.3849265438743343\n",
      "max: 1.4139876647995064\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4058824509774368\n",
      "std: 0.011422818864208697\n",
      "min: 1.3849265438743343\n",
      "max: 1.4139876647995064\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.23575314604815548\n",
      "min: 0.4928250628429676\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2791311893333246\n",
      "std: 0.3001495677406613\n",
      "min: -0.7406020314333398\n",
      "max: 0.9345062847359749\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6498645349612687\n",
      "std: 0.18660816832795238\n",
      "min: 0.20138759636568904\n",
      "max: 0.9345062847359749\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032117134276234804\n",
      "min: 0.1327513578167954\n",
      "max: 0.26472431744175123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8806036235418093\n",
      "std: 0.5638278344719377\n",
      "min: -0.07777795867923404\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0577907928586716\n",
      "std: 0.5233245226550282\n",
      "min: -0.057988019018108516\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.3092163277732682\n",
      "min: 0.18673836015167006\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2258161404182962\n",
      "std: 0.3102795275167076\n",
      "min: -0.8489633537249607\n",
      "max: 0.8674392152848591\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46262312103870007\n",
      "std: 0.2018994168121588\n",
      "min: 0.07867441433844201\n",
      "max: 0.8674392152848591\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.02788540058521975\n",
      "min: 0.12633828048437834\n",
      "max: 0.2602207285544561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3932972757614597\n",
      "std: 0.0208844889513787\n",
      "min: 1.3654193265848702\n",
      "max: 1.4140088846156442\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.400159513724577\n",
      "std: 0.019550167947107754\n",
      "min: 1.3667611415771097\n",
      "max: 1.4140088846156442\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.2358525125915557\n",
      "min: 0.48826060772174107\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30067352368882744\n",
      "std: 0.301633441679633\n",
      "min: -0.7406020314333398\n",
      "max: 0.9494609040688614\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.648064601267401\n",
      "std: 0.19485671844998165\n",
      "min: 0.18299889896716015\n",
      "max: 0.9494609040688614\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999998\n",
      "std: 0.03255128569953913\n",
      "min: 0.1327513578167954\n",
      "max: 0.26472431744175123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7506384432892446\n",
      "std: 0.66634164900538\n",
      "min: -0.09647691344892374\n",
      "max: 1.41412238185193\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9718514371427064\n",
      "std: 0.6265292132993461\n",
      "min: -0.09647691344892374\n",
      "max: 1.41412238185193\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.33393944927010755\n",
      "min: 0.18090931757814332\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.04087230875432389\n",
      "std: 0.35862485795328924\n",
      "min: -0.8489633537249607\n",
      "max: 0.8674392152848591\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.40799707447330374\n",
      "std: 0.22260413672835852\n",
      "min: -0.04265276900474725\n",
      "max: 0.8674392152848591\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.02567630038082669\n",
      "min: 0.12633828048437834\n",
      "max: 0.2602207285544561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3903422277291009\n",
      "std: 0.025031177332032632\n",
      "min: 1.352874622218575\n",
      "max: 1.414042720082241\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3984330587298583\n",
      "std: 0.02294360490501072\n",
      "min: 1.352874622218575\n",
      "max: 1.414042720082241\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.23590466496644186\n",
      "min: 0.4847127417227258\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.27238480951839955\n",
      "std: 0.2933339782168711\n",
      "min: -0.7406020314333398\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6337336173347782\n",
      "std: 0.1839295841021427\n",
      "min: 0.20138759636568904\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.031144916961951503\n",
      "min: 0.1327513578167954\n",
      "max: 0.26472431744175123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9475304910509217\n",
      "std: 0.49598639157536023\n",
      "min: 0.14882065172190437\n",
      "max: 1.4139660191470822\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1020825624054449\n",
      "std: 0.4584894060313398\n",
      "min: 0.19774675513078396\n",
      "max: 1.4139660191470822\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.29650993556226796\n",
      "min: 0.22873845357627537\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.28022998327859433\n",
      "std: 0.28481358761212944\n",
      "min: -0.8489633537249607\n",
      "max: 0.8674392152848591\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.39297395548700964\n",
      "std: 0.2513548382624725\n",
      "min: -0.1489147695764378\n",
      "max: 0.8674392152848591\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0266567845405895\n",
      "min: 0.12633828048437834\n",
      "max: 0.2602207285544561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3908710676417428\n",
      "std: 0.02542797782074781\n",
      "min: 1.3410010599221793\n",
      "max: 1.414053186576799\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.398304414428664\n",
      "std: 0.023739427941314447\n",
      "min: 1.3410010599221793\n",
      "max: 1.414053186576799\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.23591515840563518\n",
      "min: 0.4818201292335378\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3128025021651955\n",
      "std: 0.3001419991735382\n",
      "min: -0.7890529044380494\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6112893447152897\n",
      "std: 0.19643272814154636\n",
      "min: 0.13881134945386164\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03245578170115899\n",
      "min: 0.1327513578167954\n",
      "max: 0.26472431744175123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1748716814975388\n",
      "std: 0.21585164020611053\n",
      "min: 0.805551952401327\n",
      "max: 1.4123025686197597\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2284351063099628\n",
      "std: 0.21669056828450103\n",
      "min: 0.8544662153487507\n",
      "max: 1.4123025686197597\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.24861177813466626\n",
      "min: 0.23443909030689963\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3338715514757956\n",
      "std: 0.36971051572095476\n",
      "min: -0.9692143204523971\n",
      "max: 0.8674392152848591\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.513602795523811\n",
      "std: 0.18829779403226884\n",
      "min: 0.1079286415130636\n",
      "max: 0.8674392152848591\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03163993373884481\n",
      "min: 0.12633828048437834\n",
      "max: 0.2602207285544561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083811788163214\n",
      "std: 0.004835347190772529\n",
      "min: 1.3974052696972088\n",
      "max: 1.4139876647995064\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4093371350576698\n",
      "std: 0.005241045029566949\n",
      "min: 1.3974052696972088\n",
      "max: 1.4139876647995064\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.23570940160297177\n",
      "min: 0.3307168934838889\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3141786585437331\n",
      "std: 0.3021082496722392\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6226106327808192\n",
      "std: 0.18788214391468636\n",
      "min: 0.17035135315723135\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.03312843695648025\n",
      "min: 0.13132182403785084\n",
      "max: 0.2661520572948561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8749350193827582\n",
      "std: 0.4497770940866647\n",
      "min: 0.06308843307539107\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0047956294937386\n",
      "std: 0.45550345480441856\n",
      "min: 0.0945946245166937\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.2850626518997712\n",
      "min: 0.17007493119185874\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.20670773864474354\n",
      "std: 0.3892817409175347\n",
      "min: -0.988782477010917\n",
      "max: 1.003122612759425\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5468995056516872\n",
      "std: 0.19847154497027136\n",
      "min: 0.1079286415130636\n",
      "max: 1.003122612759425\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.027732039618975142\n",
      "min: 0.12633828048437834\n",
      "max: 0.2602207285544561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.399735608247258\n",
      "std: 0.013211328556027666\n",
      "min: 1.3732635842493497\n",
      "max: 1.4139876647995064\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4028394371658035\n",
      "std: 0.013150467384716846\n",
      "min: 1.3734429700939237\n",
      "max: 1.4139876647995064\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.23574903946460474\n",
      "min: 0.3254882212338145\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2922269787186395\n",
      "std: 0.30398646479000524\n",
      "min: -0.7867949373052624\n",
      "max: 0.9345062847359749\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6403328055012418\n",
      "std: 0.18680838368012864\n",
      "min: 0.18721340592649238\n",
      "max: 0.9345062847359749\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03245902822149341\n",
      "min: 0.13130008963219292\n",
      "max: 0.2655369219257794\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8109572123003389\n",
      "std: 0.5252062043159589\n",
      "min: -0.2941077066191615\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9558382248241438\n",
      "std: 0.5260365563866248\n",
      "min: -0.2941077066191615\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.2939262426839983\n",
      "min: 0.10266640668548715\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.282451568158638\n",
      "std: 0.35761315016543016\n",
      "min: -0.9889096609756228\n",
      "max: 0.8674392152848591\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4826184593982316\n",
      "std: 0.2008286464537213\n",
      "min: 0.07867441433844201\n",
      "max: 0.8674392152848591\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.02943177706593758\n",
      "min: 0.12633828048437834\n",
      "max: 0.2602207285544561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3912733194397588\n",
      "std: 0.022350386014656023\n",
      "min: 1.3400049256626838\n",
      "max: 1.4140088846156442\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3965187820227392\n",
      "std: 0.021931341923997018\n",
      "min: 1.3400049256626838\n",
      "max: 1.4140088846156442\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.23583809081647616\n",
      "min: 0.31886480642756204\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3126762220111558\n",
      "std: 0.3043775584248051\n",
      "min: -0.7898164726898776\n",
      "max: 0.9494609040688614\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6362187850859782\n",
      "std: 0.19444472841954488\n",
      "min: 0.17209756037823107\n",
      "max: 0.9494609040688614\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999998\n",
      "std: 0.0329307017999102\n",
      "min: 0.13103788546018574\n",
      "max: 0.26570527900511515\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9308050071691591\n",
      "std: 0.41965173401719086\n",
      "min: 0.1593609256324407\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0491273856700547\n",
      "std: 0.4186511356163475\n",
      "min: 0.1593609256324407\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.26706613930160994\n",
      "min: 0.1702328061857205\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2346516838000596\n",
      "std: 0.3495594724337724\n",
      "min: -0.9172042758451894\n",
      "max: 0.885170842952236\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5403903166013194\n",
      "std: 0.179024050650738\n",
      "min: 0.1079286415130636\n",
      "max: 0.885170842952236\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.027531828809646348\n",
      "min: 0.12633828048437834\n",
      "max: 0.2602207285544561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4040972502951226\n",
      "std: 0.008239546883392996\n",
      "min: 1.3891519286735188\n",
      "max: 1.4139876647995064\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4060264887657503\n",
      "std: 0.008782159389911148\n",
      "min: 1.3891519286735188\n",
      "max: 1.4139876647995064\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.23571614421103138\n",
      "min: 0.33023578784324975\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3006831405511961\n",
      "std: 0.3016820182476492\n",
      "min: -0.7711500576883218\n",
      "max: 0.9125577534895606\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6333345283428095\n",
      "std: 0.18663169816225103\n",
      "min: 0.19278350690022822\n",
      "max: 0.9125577534895606\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03280369474560594\n",
      "min: 0.1318856550948371\n",
      "max: 0.26472431744175123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7744623754352606\n",
      "std: 0.5495160597829207\n",
      "min: 0.023304721427690203\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9319499297900787\n",
      "std: 0.549781204669337\n",
      "min: 0.023304721427690203\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.28533765727765087\n",
      "min: 0.16508929563220068\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.28365167387250606\n",
      "std: 0.33635178308766506\n",
      "min: -0.9172042758451894\n",
      "max: 0.8674392152848591\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4789511843156488\n",
      "std: 0.18849491116620906\n",
      "min: 0.09427532191066498\n",
      "max: 0.8674392152848591\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999998\n",
      "std: 0.028773950066404538\n",
      "min: 0.12633828048437834\n",
      "max: 0.2602207285544561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3952881598540579\n",
      "std: 0.018978757625370254\n",
      "min: 1.3595639930680712\n",
      "max: 1.4139876647995064\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3996471310015224\n",
      "std: 0.018463876520612946\n",
      "min: 1.3608048072234427\n",
      "max: 1.4139876647995064\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.23574949545961793\n",
      "min: 0.32529015180273596\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31217873184143063\n",
      "std: 0.3040727648719515\n",
      "min: -0.7711500576883218\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6329291336005005\n",
      "std: 0.19097967328847948\n",
      "min: 0.15480168777656356\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03297307634062362\n",
      "min: 0.1322140155191366\n",
      "max: 0.26472431744175123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1708351085391293\n",
      "std: 0.1869859006572501\n",
      "min: 0.8055519524013274\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2127137458214494\n",
      "std: 0.19737938074259095\n",
      "min: 0.8544662153487502\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.22961736700686555\n",
      "min: 0.1853587758408729\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34880610949392676\n",
      "std: 0.3784736298367678\n",
      "min: -1.0393282332938176\n",
      "max: 0.8674392152848591\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5190860960186924\n",
      "std: 0.1966114901183888\n",
      "min: 0.0003616977723124115\n",
      "max: 0.8674392152848591\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032644576237874846\n",
      "min: 0.11878810475429609\n",
      "max: 0.26565002122661713\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4085181489221401\n",
      "std: 0.004171641488506083\n",
      "min: 1.397405269697209\n",
      "max: 1.4139876647995064\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4092735036705109\n",
      "std: 0.004656042499175503\n",
      "min: 1.397405269697209\n",
      "max: 1.4139876647995064\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.21985372779694373\n",
      "min: 0.24839880667944525\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31623857082455253\n",
      "std: 0.3036097395483303\n",
      "min: -0.7917247096695831\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6220411220594635\n",
      "std: 0.1876973558199349\n",
      "min: 0.16661994986758505\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0332334078564636\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8891511669698786\n",
      "std: 0.44689857501812136\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9878465316708818\n",
      "std: 0.45428587844210516\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.2589986821600784\n",
      "min: 0.08616557489792928\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2516279225288597\n",
      "std: 0.40253210062701306\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5503647534204594\n",
      "std: 0.2029314754699005\n",
      "min: 0.020643658787159916\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.029737858491211758\n",
      "min: 0.11782966247484129\n",
      "max: 0.2663896262434558\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.400662514224427\n",
      "std: 0.012766203825804172\n",
      "min: 1.3732635842493492\n",
      "max: 1.4139876647995064\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4029913998255386\n",
      "std: 0.012665614325420732\n",
      "min: 1.3734429700939237\n",
      "max: 1.4139876647995064\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.21988625003059634\n",
      "min: 0.24397891302068386\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2980954794817185\n",
      "std: 0.3052895659703333\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359749\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6371962894023421\n",
      "std: 0.18661705678331314\n",
      "min: 0.1786407334882694\n",
      "max: 0.9345062847359749\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03264758104280544\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8443061490327828\n",
      "std: 0.5061438207953619\n",
      "min: -0.2941077066191617\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9511161467790437\n",
      "std: 0.5095685451728392\n",
      "min: -0.2941077066191617\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.2653662493820915\n",
      "min: 0.07293152928685523\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3131149274192291\n",
      "std: 0.37437819796105215\n",
      "min: -1.0461975431230803\n",
      "max: 0.8674392152848591\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5000552547278199\n",
      "std: 0.2068371222797709\n",
      "min: 0.00534087003993411\n",
      "max: 0.8674392152848591\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.031081586933738088\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3932646622503677\n",
      "std: 0.02208983298425191\n",
      "min: 1.3400049256626838\n",
      "max: 1.4140088846156442\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.396991466346412\n",
      "std: 0.021707946965485652\n",
      "min: 1.3400049256626838\n",
      "max: 1.4140088846156442\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.21996053344335792\n",
      "min: 0.2380460985458565\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31662973914083664\n",
      "std: 0.30526743654214566\n",
      "min: -0.7898164726898776\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6327722687696327\n",
      "std: 0.19336709070724478\n",
      "min: 0.1683971104032064\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999998\n",
      "std: 0.03310180068990521\n",
      "min: 0.1307286395969958\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9316990458457172\n",
      "std: 0.4011981105887229\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0231731356213796\n",
      "std: 0.40751534668343553\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.24611845255094672\n",
      "min: 0.09769427941573716\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2698041357458696\n",
      "std: 0.37113800490911203\n",
      "min: -1.040564191267659\n",
      "max: 0.8851708429522361\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5469650478559724\n",
      "std: 0.18882859983513114\n",
      "min: 0.027431687648286643\n",
      "max: 0.8851708429522361\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.029597811564652805\n",
      "min: 0.11804781246265543\n",
      "max: 0.26604853368266546\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4043437357286672\n",
      "std: 0.007727014981954311\n",
      "min: 1.389151928673519\n",
      "max: 1.4139876647995064\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4059018659399138\n",
      "std: 0.008067196182484096\n",
      "min: 1.389151928673519\n",
      "max: 1.4139876647995064\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.21985991686309436\n",
      "min: 0.24709126705615692\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30435703850541135\n",
      "std: 0.3037470354806062\n",
      "min: -0.7852794356729705\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6325072704686617\n",
      "std: 0.18643222090526212\n",
      "min: 0.17837449106347592\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03292003846939976\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8260905881567766\n",
      "std: 0.5046954390791859\n",
      "min: 0.023304721427690054\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9388720455074676\n",
      "std: 0.5085985137814171\n",
      "min: 0.023304721427690054\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.25916164003208836\n",
      "min: 0.09835117451514451\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3112803510105613\n",
      "std: 0.3583256286754413\n",
      "min: -1.0418624388317728\n",
      "max: 0.8674392152848591\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49848227545502155\n",
      "std: 0.19863282524503387\n",
      "min: 0.009653828235930322\n",
      "max: 0.8674392152848591\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03065232456742846\n",
      "min: 0.11730985224476699\n",
      "max: 0.2670528328723887\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3969749379950172\n",
      "std: 0.01795772535060027\n",
      "min: 1.359563993068071\n",
      "max: 1.4139876647995064\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.400084116111243\n",
      "std: 0.0174761773605919\n",
      "min: 1.3608048072234429\n",
      "max: 1.4139876647995064\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.21989237074387016\n",
      "min: 0.2413012764962137\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3160331954564589\n",
      "std: 0.30524117587266514\n",
      "min: -0.787348876746184\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6309384414033227\n",
      "std: 0.19058795121014083\n",
      "min: 0.15480168777656353\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03313987126389387\n",
      "min: 0.13056046422770326\n",
      "max: 0.26678531638937797\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1822303510492187\n",
      "std: 0.170414813819749\n",
      "min: 0.8055519524013274\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2159428865332884\n",
      "std: 0.18092053697155946\n",
      "min: 0.8544662153487502\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333333\n",
      "std: 0.2104321660495947\n",
      "min: 0.14732430296998564\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34745745440138226\n",
      "std: 0.37689580975379633\n",
      "min: -1.0393282332938176\n",
      "max: 0.8674392152848591\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5008926827670033\n",
      "std: 0.20260404481309174\n",
      "min: 0.0003616977723124115\n",
      "max: 0.8674392152848591\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03295034687923483\n",
      "min: 0.11878810475429609\n",
      "max: 0.26565002122661713\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4088334168961132\n",
      "std: 0.0038053528820251726\n",
      "min: 1.397405269697209\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4094685205996258\n",
      "std: 0.004267657612519102\n",
      "min: 1.397405269697209\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.33333333333333326\n",
      "std: 0.20276290444062617\n",
      "min: 0.19867323978268908\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31703371780441125\n",
      "std: 0.30353689492811375\n",
      "min: -0.7917247096695829\n",
      "max: 0.9118540924163263\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6185188677805431\n",
      "std: 0.18767930884306025\n",
      "min: 0.1590496034630183\n",
      "max: 0.9118540924163263\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03328480379306692\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668559274200261\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.938532950715296\n",
      "std: 0.41779785903733235\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.012797618697749\n",
      "std: 0.42375298488144797\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333334\n",
      "std: 0.23391045961741766\n",
      "min: 0.0828389111440554\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2686398153734176\n",
      "std: 0.399708350237169\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.528799143456666\n",
      "std: 0.20850931976922615\n",
      "min: 0.020643658787159916\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.030616812862182277\n",
      "min: 0.11782966247484129\n",
      "max: 0.2663896262434558\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4020729658758102\n",
      "std: 0.011903123631271903\n",
      "min: 1.3732635842493495\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4038483696947452\n",
      "std: 0.011791448716066598\n",
      "min: 1.373442970093924\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.33333333333333337\n",
      "std: 0.20278897760377085\n",
      "min: 0.19550151689304526\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.301463331750543\n",
      "std: 0.3049959616617697\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359749\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.631671641911489\n",
      "std: 0.18677989184318475\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359749\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999996\n",
      "std: 0.03276237210135639\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9724614645415912\n",
      "std: 0.37545323528005364\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0418796229379248\n",
      "std: 0.3803765951882272\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.33333333333333326\n",
      "std: 0.22414953339507948\n",
      "min: 0.08930966514056929\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2818361736851954\n",
      "std: 0.373700703825486\n",
      "min: -1.040564191267659\n",
      "max: 0.8851708429522361\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5269603311654815\n",
      "std: 0.19687145811637963\n",
      "min: 0.027431687648286643\n",
      "max: 0.8851708429522361\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.030512629369002873\n",
      "min: 0.11804781246265543\n",
      "max: 0.26604853368266546\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4052225513671046\n",
      "std: 0.007189242820663617\n",
      "min: 1.389151928673519\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406460156975403\n",
      "std: 0.007391464486907807\n",
      "min: 1.389151928673519\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333333\n",
      "std: 0.20276803001945234\n",
      "min: 0.19794557920053174\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30651328020432794\n",
      "std: 0.30390375421144156\n",
      "min: -0.7852794356729706\n",
      "max: 0.9125577534895606\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6282558922944433\n",
      "std: 0.1865442000375483\n",
      "min: 0.16771075385624493\n",
      "max: 0.9125577534895606\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999993\n",
      "std: 0.032992183929795804\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.884367729663889\n",
      "std: 0.4980022952919234\n",
      "min: -0.3220562513263309\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9667922364951866\n",
      "std: 0.4990224105295292\n",
      "min: -0.3220562513263309\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333333\n",
      "std: 0.23962375552540674\n",
      "min: 0.05101998228411438\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32084469348984923\n",
      "std: 0.37495644159332153\n",
      "min: -1.0461975431230803\n",
      "max: 0.8674392152848591\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4866199243094577\n",
      "std: 0.20869606106834326\n",
      "min: 0.00534087003993411\n",
      "max: 0.8674392152848591\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.031741306429207646\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3955515861130172\n",
      "std: 0.021265294210316713\n",
      "min: 1.3400049256626834\n",
      "max: 1.4140088846156442\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3982926216244447\n",
      "std: 0.02090385389535829\n",
      "min: 1.3400049256626834\n",
      "max: 1.4140088846156442\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333333\n",
      "std: 0.20285095967039146\n",
      "min: 0.19007844965459514\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31828116172334\n",
      "std: 0.30471028445808485\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6271501778601561\n",
      "std: 0.19280819446059969\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.0331886591093971\n",
      "min: 0.1307286395969958\n",
      "max: 0.2666052098290663\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8724777761781999\n",
      "std: 0.49525838915873754\n",
      "min: -0.00792896706212934\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9586048108882365\n",
      "std: 0.49500418363272713\n",
      "min: 0.0020790043109757375\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.33333333333333337\n",
      "std: 0.235068526431446\n",
      "min: 0.06733662482752614\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31758271488598105\n",
      "std: 0.3616615091150251\n",
      "min: -1.0418624388317728\n",
      "max: 0.8674392152848591\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4858951250967246\n",
      "std: 0.20217498162362102\n",
      "min: 0.009653828235930322\n",
      "max: 0.8674392152848591\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03141743002627002\n",
      "min: 0.11730985224476699\n",
      "max: 0.2670528328723887\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3988064220353729\n",
      "std: 0.017088013815019936\n",
      "min: 1.3595639930680712\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.401121855572899\n",
      "std: 0.01658990199609135\n",
      "min: 1.3608048072234427\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333333\n",
      "std: 0.20279700497523298\n",
      "min: 0.19275695147838381\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3177734766415897\n",
      "std: 0.3048634334366476\n",
      "min: -0.7873488767461841\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6260699833901189\n",
      "std: 0.19045933504621196\n",
      "min: 0.1548016877765636\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999996\n",
      "std: 0.03322784266836038\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1775929551477997\n",
      "std: 0.1675137080631079\n",
      "min: 0.7740393198270334\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2089957707392895\n",
      "std: 0.17770670871182323\n",
      "min: 0.8154559782521462\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.19362650070920634\n",
      "min: 0.1143876940702646\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3326921446270279\n",
      "std: 0.3777676597968451\n",
      "min: -1.0393282332938176\n",
      "max: 0.8674392152848591\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4942151510477392\n",
      "std: 0.20227871933886798\n",
      "min: 0.0003616977723124115\n",
      "max: 0.8674392152848591\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03249851505653308\n",
      "min: 0.11878810475429609\n",
      "max: 0.26565002122661713\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408451890151304\n",
      "std: 0.004202858778937641\n",
      "min: 1.3930501023055841\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4091010874917098\n",
      "std: 0.004616084511634272\n",
      "min: 1.3930501023055841\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.18717743224127903\n",
      "min: 0.1645197302063212\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3160695720436405\n",
      "std: 0.30310507229585293\n",
      "min: -0.7917247096695829\n",
      "max: 0.9118540924163263\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6156611753837065\n",
      "std: 0.1868853502501375\n",
      "min: 0.1590496034630183\n",
      "max: 0.9118540924163263\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033268009885178015\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668559274200261\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9672918345730364\n",
      "std: 0.38950443963982023\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0282432084662023\n",
      "std: 0.3965029523289134\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.21285884755912013\n",
      "min: 0.06927779248720833\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.26622816379172615\n",
      "std: 0.39742664344300616\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5202738699776728\n",
      "std: 0.20764225309002823\n",
      "min: 0.020643658787159916\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03050250012407627\n",
      "min: 0.11782966247484129\n",
      "max: 0.2663896262434558\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4024967983649173\n",
      "std: 0.011296871368146024\n",
      "min: 1.3732635842493495\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4040111063760363\n",
      "std: 0.01125770825410809\n",
      "min: 1.373442970093924\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.1871989120622437\n",
      "min: 0.16267084008275867\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30238179355407324\n",
      "std: 0.304351709533953\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359749\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6273888965474586\n",
      "std: 0.18609930694012772\n",
      "min: 0.1684927514814485\n",
      "max: 0.9345062847359749\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03279578782219569\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9947071922746292\n",
      "std: 0.3574912189779483\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0522512647622226\n",
      "std: 0.3626660803825417\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.2051958611764854\n",
      "min: 0.06515184149231606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.276360354094297\n",
      "std: 0.375496205418387\n",
      "min: -1.040564191267659\n",
      "max: 0.8851708429522361\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5189219828920252\n",
      "std: 0.19770608271083134\n",
      "min: 0.027431687648286643\n",
      "max: 0.8851708429522361\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.030405272271722784\n",
      "min: 0.11804781246265543\n",
      "max: 0.26604853368266546\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4052489288748184\n",
      "std: 0.007176605249362907\n",
      "min: 1.3864517515454817\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4063670645671398\n",
      "std: 0.007329294947154264\n",
      "min: 1.3887761213835204\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.28571428571428575\n",
      "std: 0.18718184254468362\n",
      "min: 0.1644339410678294\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3066755185822605\n",
      "std: 0.30357599275455577\n",
      "min: -0.7852794356729706\n",
      "max: 0.9125577534895606\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6247429426166315\n",
      "std: 0.1858680193700313\n",
      "min: 0.1677107538562449\n",
      "max: 0.9125577534895606\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032999011722312226\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9109373901171417\n",
      "std: 0.47964602217052527\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9791344387046328\n",
      "std: 0.48144574185331346\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.28571428571428575\n",
      "std: 0.2178997417336621\n",
      "min: 0.03912628490824474\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31234568757423914\n",
      "std: 0.37637831036660396\n",
      "min: -1.0461975431230803\n",
      "max: 0.8731582008431125\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48338436601895024\n",
      "std: 0.206828249794807\n",
      "min: 0.00534087003993411\n",
      "max: 0.8731582008431125\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03150954356167138\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3966726736181638\n",
      "std: 0.020407889323325205\n",
      "min: 1.3400049256626834\n",
      "max: 1.4140088846156442\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3988852792247606\n",
      "std: 0.020165195944625784\n",
      "min: 1.3400049256626834\n",
      "max: 1.4140088846156442\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.18725149859905077\n",
      "min: 0.15842891937309717\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3177924883650805\n",
      "std: 0.3039593962292857\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6228521507069379\n",
      "std: 0.1915505985873477\n",
      "min: 0.1601745286014399\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033195742594861584\n",
      "min: 0.1307286395969958\n",
      "max: 0.2666052098290663\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9007852446012551\n",
      "std: 0.48298647262889555\n",
      "min: -0.0357030236597033\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9716875329346853\n",
      "std: 0.48241659218476446\n",
      "min: -0.027522218170909225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.28571428571428564\n",
      "std: 0.21451371591766555\n",
      "min: 0.0546908058039119\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30812075936335\n",
      "std: 0.36493575113681564\n",
      "min: -1.0418624388317728\n",
      "max: 0.8681034969459459\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48269960302382764\n",
      "std: 0.20151205898328037\n",
      "min: 0.009653828235930322\n",
      "max: 0.8681034969459459\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.031229501398017775\n",
      "min: 0.11730985224476699\n",
      "max: 0.2670528328723887\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3994974862624059\n",
      "std: 0.016682709220258087\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4014146875152222\n",
      "std: 0.016257450317063635\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.18720787710361755\n",
      "min: 0.15988389339029072\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3174245874998463\n",
      "std: 0.3042375327804864\n",
      "min: -0.7873488767461841\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6221900870915366\n",
      "std: 0.18954157603466884\n",
      "min: 0.1548016877765636\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033239728040725745\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1857691004514663\n",
      "std: 0.15726815873594216\n",
      "min: 0.7740393198270334\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.211563814571216\n",
      "std: 0.167366920288674\n",
      "min: 0.8154559782521462\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.24999999999999997\n",
      "std: 0.17895142736543732\n",
      "min: 0.10568892954053766\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33100422931966084\n",
      "std: 0.374904152250761\n",
      "min: -1.0393282332938176\n",
      "max: 0.8674392152848591\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4896178323759296\n",
      "std: 0.19965698717898542\n",
      "min: 0.0003616977723124115\n",
      "max: 0.8674392152848591\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03229734612497016\n",
      "min: 0.11878810475429609\n",
      "max: 0.26565002122661713\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083354296545385\n",
      "std: 0.00418935419952434\n",
      "min: 1.3904455376842182\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408774682094082\n",
      "std: 0.004668650291396653\n",
      "min: 1.3904455376842182\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.1735026349744413\n",
      "min: 0.14088341420250747\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3172497486772877\n",
      "std: 0.30296263061182493\n",
      "min: -0.7917247096695829\n",
      "max: 0.9118540924163263\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6129798822846957\n",
      "std: 0.18644768422885494\n",
      "min: 0.1590496034630183\n",
      "max: 0.9118540924163263\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033336545570958075\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668559274200261\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9998140831592611\n",
      "std: 0.371022206197589\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.048257394480739\n",
      "std: 0.3765243218405848\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.19520345275767548\n",
      "min: 0.06139433050355361\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2734910710313076\n",
      "std: 0.3933513637646464\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5137143921622672\n",
      "std: 0.2045148631089975\n",
      "min: 0.020643658787159916\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.030555910410520252\n",
      "min: 0.11782966247484129\n",
      "max: 0.2663896262434558\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4029694358865914\n",
      "std: 0.010955865709375921\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4040908956177485\n",
      "std: 0.010950457245078574\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.17352105974765872\n",
      "min: 0.13885646627955844\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3050764632483789\n",
      "std: 0.3041014054068375\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359749\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6235351027564074\n",
      "std: 0.18578104481554042\n",
      "min: 0.1684927514814485\n",
      "max: 0.9345062847359749\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03290879691874777\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0237946927910373\n",
      "std: 0.3382417485226483\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0695985230342904\n",
      "std: 0.3423140723771682\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.18882259930793827\n",
      "min: 0.05753863614276312\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.28133394253993826\n",
      "std: 0.37401253777225335\n",
      "min: -1.040564191267659\n",
      "max: 0.8851708429522361\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5130077448428332\n",
      "std: 0.1957190674443233\n",
      "min: 0.027431687648286643\n",
      "max: 0.8851708429522361\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.030461834900110125\n",
      "min: 0.11804781246265543\n",
      "max: 0.26604853368266546\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4054179313923685\n",
      "std: 0.006980345475063624\n",
      "min: 1.3864517515454817\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4062358779262187\n",
      "std: 0.007148914845424616\n",
      "min: 1.3887761213835204\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.17350647574211384\n",
      "min: 0.140742538976685\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30877045935368497\n",
      "std: 0.30351976751025345\n",
      "min: -0.7852794356729706\n",
      "max: 0.9125577534895606\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6214846651322198\n",
      "std: 0.18555130655829521\n",
      "min: 0.1677107538562449\n",
      "max: 0.9125577534895606\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03308887537622504\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9454575061747871\n",
      "std: 0.46399200092280934\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.999880026684365\n",
      "std: 0.46464953834584066\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.19963942586551692\n",
      "min: 0.036934374599274934\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3149093051506106\n",
      "std: 0.374345750619775\n",
      "min: -1.0461975431230803\n",
      "max: 0.8731582008431125\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4810165134736664\n",
      "std: 0.20327797995849717\n",
      "min: 0.00534087003993411\n",
      "max: 0.8731582008431125\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03147112961083324\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3976839194146646\n",
      "std: 0.019955124381492394\n",
      "min: 1.3326428470785963\n",
      "max: 1.4140088846156442\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.399331117815674\n",
      "std: 0.019773236726413422\n",
      "min: 1.3326428470785963\n",
      "max: 1.4140088846156442\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.173566917894983\n",
      "min: 0.13432864506477782\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31926523663050527\n",
      "std: 0.3035751952803883\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6191542084614838\n",
      "std: 0.19073669154115178\n",
      "min: 0.1601745286014399\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03328276907522921\n",
      "min: 0.1307286395969958\n",
      "max: 0.2666052098290663\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9379671262907466\n",
      "std: 0.4645795219915195\n",
      "min: -0.0357030236597033\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.994385308835178\n",
      "std: 0.4627617916926691\n",
      "min: -0.027522218170909225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.19685114181697944\n",
      "min: 0.04789520522627234\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3101986868156364\n",
      "std: 0.3641535596609334\n",
      "min: -1.0418624388317728\n",
      "max: 0.8681034969459459\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4805450629308855\n",
      "std: 0.1986585073352146\n",
      "min: 0.009653828235930322\n",
      "max: 0.8681034969459459\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.031226173631214552\n",
      "min: 0.11730985224476699\n",
      "max: 0.2670528328723887\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4002423611667347\n",
      "std: 0.016141267915972063\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4016686920308192\n",
      "std: 0.015777104783746974\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25000000000000006\n",
      "std: 0.17352973875871774\n",
      "min: 0.13698723819325026\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31897512778789966\n",
      "std: 0.30393714772727426\n",
      "min: -0.7873488767461841\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6187872946333423\n",
      "std: 0.18899411407935715\n",
      "min: 0.1548016877765636\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03332724300987108\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1904032120524954\n",
      "std: 0.1493078517904957\n",
      "min: 0.7740393198270334\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.212460989600017\n",
      "std: 0.15971583933784203\n",
      "min: 0.8154559782521462\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.16630548608070012\n",
      "min: 0.09027777403900655\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32964347436733943\n",
      "std: 0.3766444862219585\n",
      "min: -1.0393282332938176\n",
      "max: 0.8674392152848591\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48890301987629436\n",
      "std: 0.19981149869858028\n",
      "min: 0.0003616977723124115\n",
      "max: 0.8674392152848591\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032358177138017245\n",
      "min: 0.11878810475429609\n",
      "max: 0.26565002122661713\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084727881562353\n",
      "std: 0.003941315646668537\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408867336795584\n",
      "std: 0.004405064488467015\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.16159895771143906\n",
      "min: 0.1235640371807299\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31643743596097273\n",
      "std: 0.30305704554967855\n",
      "min: -0.7917247096695829\n",
      "max: 0.9118540924163263\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6123701380653659\n",
      "std: 0.18600371202868815\n",
      "min: 0.15904960346301825\n",
      "max: 0.9118540924163263\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033306704099243765\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668559274200261\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0206970173688812\n",
      "std: 0.3614403810697916\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0610213001680557\n",
      "std: 0.36595060293906373\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.180400955350615\n",
      "min: 0.04622834601720121\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2789892547870468\n",
      "std: 0.39370440430554904\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.511219198279598\n",
      "std: 0.2040178505021327\n",
      "min: 0.020643658787159916\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.030822744199595794\n",
      "min: 0.11782966247484129\n",
      "max: 0.2663896262434558\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4035347737496484\n",
      "std: 0.010625415741881769\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4044917963266361\n",
      "std: 0.010605278777047462\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.1616150966265713\n",
      "min: 0.12153656379914062\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30540765038945433\n",
      "std: 0.30403431363716704\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359749\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6220172524496995\n",
      "std: 0.1853517445404821\n",
      "min: 0.16849275148144835\n",
      "max: 0.9345062847359749\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03291133508227409\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0420540891617087\n",
      "std: 0.32690840671236776\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0802328733853956\n",
      "std: 0.3303916701750517\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.17493835491310208\n",
      "min: 0.04492634349452921\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.28520895022046616\n",
      "std: 0.3767139540598624\n",
      "min: -1.040564191267659\n",
      "max: 0.8851708429522361\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.510956223941118\n",
      "std: 0.19627899728492973\n",
      "min: 0.027431687648286643\n",
      "max: 0.8851708429522361\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03074442865786618\n",
      "min: 0.11804781246265543\n",
      "max: 0.26604853368266546\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4057428939551926\n",
      "std: 0.006806547577270838\n",
      "min: 1.3864517515454817\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406461065857168\n",
      "std: 0.0069140833848025975\n",
      "min: 1.3887761213835206\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.16160242121204646\n",
      "min: 0.12315570575068714\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3086840561741953\n",
      "std: 0.30362014373558255\n",
      "min: -0.7852794356729706\n",
      "max: 0.9125577534895606\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6203696613794796\n",
      "std: 0.18516717006872588\n",
      "min: 0.1677107538562449\n",
      "max: 0.9125577534895606\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033075160529811055\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9732177791670495\n",
      "std: 0.44939514187407614\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0181000495196548\n",
      "std: 0.4495575540685571\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.18425166240813853\n",
      "min: 0.03076942045461365\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3164167343126353\n",
      "std: 0.37647514744635113\n",
      "min: -1.04619754312308\n",
      "max: 0.8731582008431125\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4820555113347808\n",
      "std: 0.20281471280546715\n",
      "min: 0.005340870039934089\n",
      "max: 0.8731582008431125\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03164242196433318\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.398773812703344\n",
      "std: 0.019378196124619967\n",
      "min: 1.332642847078597\n",
      "max: 1.4140088846156442\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.400125380111797\n",
      "std: 0.0192266818753244\n",
      "min: 1.332642847078597\n",
      "max: 1.4140088846156442\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.16165541240752548\n",
      "min: 0.118118684462011\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31855478483172045\n",
      "std: 0.3034993350993934\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6178523828082598\n",
      "std: 0.1899159523079592\n",
      "min: 0.16017452860143988\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326366703486707\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9678439032060884\n",
      "std: 0.44487763389254975\n",
      "min: -0.0357030236597033\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0141856817593298\n",
      "std: 0.4428546595668859\n",
      "min: -0.027522218170909225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.1818666562800394\n",
      "min: 0.04543935923532854\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31159160933135743\n",
      "std: 0.3674788342474839\n",
      "min: -1.0418624388317728\n",
      "max: 0.868103496945946\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48179083888388874\n",
      "std: 0.19884649572111696\n",
      "min: 0.009653828235930322\n",
      "max: 0.868103496945946\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.031434945902128024\n",
      "min: 0.11730985224476699\n",
      "max: 0.2670528328723887\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4010992954730124\n",
      "std: 0.015690935427636936\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.402283475265785\n",
      "std: 0.015339777225835575\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.16162331636639077\n",
      "min: 0.11969661993213916\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.318359695167488\n",
      "std: 0.3039007052906985\n",
      "min: -0.7873488767461841\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6176653458197\n",
      "std: 0.18839170593186474\n",
      "min: 0.1548016877765636\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03330852224941868\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1977718055010287\n",
      "std: 0.14013648985366703\n",
      "min: 0.7740393198270334\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2177496409257516\n",
      "std: 0.15017248666358232\n",
      "min: 0.8154559782521462\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.15532053838156537\n",
      "min: 0.08313808348406977\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33779647781391403\n",
      "std: 0.37817327626398317\n",
      "min: -1.0393282332938176\n",
      "max: 0.9069400431186838\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4955853912426581\n",
      "std: 0.20134555946921437\n",
      "min: 0.0003616977723124115\n",
      "max: 0.9069400431186838\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03258229373967304\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087778712888332\n",
      "std: 0.003691426194589568\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090898780577097\n",
      "std: 0.004116925784582684\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.15121739353451305\n",
      "min: 0.11029400943225186\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3169846279799651\n",
      "std: 0.3031908517953235\n",
      "min: -0.7917247096695829\n",
      "max: 0.9118540924163263\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6129558047654493\n",
      "std: 0.18572488862397243\n",
      "min: 0.15904960346301825\n",
      "max: 0.9118540924163263\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03333053812935511\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668559274200261\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.043203733430588\n",
      "std: 0.34937877494876113\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0779680136437\n",
      "std: 0.3532737274687107\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.16770384843306657\n",
      "min: 0.041203480605189045\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2925526941044308\n",
      "std: 0.3949462070114943\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5164090617967105\n",
      "std: 0.20455918035290394\n",
      "min: 0.020643658787159916\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03121387388489588\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4043297624802598\n",
      "std: 0.010185452330655402\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4051027284328097\n",
      "std: 0.010140461938270917\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.1512315842038746\n",
      "min: 0.1083457175403827\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.306901071623925\n",
      "std: 0.3040783034123824\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359749\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6218481932342631\n",
      "std: 0.18504994850273293\n",
      "min: 0.16849275148144835\n",
      "max: 0.9345062847359749\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032963490363081854\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0624549937038035\n",
      "std: 0.31531670209048257\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0954389242414926\n",
      "std: 0.31817572589583193\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.16295359305994658\n",
      "min: 0.03969392280289475\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.29768078362688055\n",
      "std: 0.3797198859031491\n",
      "min: -1.040564191267659\n",
      "max: 0.9222806257991402\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5165949473910068\n",
      "std: 0.19780628575722967\n",
      "min: 0.027431687648286643\n",
      "max: 0.9222806257991402\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.031146272388672062\n",
      "min: 0.11804781246265543\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4063304173096614\n",
      "std: 0.006462527888754906\n",
      "min: 1.3864517515454817\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406910595419668\n",
      "std: 0.006524154960718274\n",
      "min: 1.3887761213835206\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.15122044183541344\n",
      "min: 0.10975660849651256\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30985366572305445\n",
      "std: 0.3037712377007176\n",
      "min: -0.7852794356729706\n",
      "max: 0.9125577534895606\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6204957650550702\n",
      "std: 0.1849188259253572\n",
      "min: 0.1677107538562449\n",
      "max: 0.9125577534895606\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03311417567554259\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0012609260388132\n",
      "std: 0.4322528294927507\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0395767942570076\n",
      "std: 0.43236562111042975\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.1710918061682626\n",
      "min: 0.028446366338657006\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32694642263959806\n",
      "std: 0.37861955520535234\n",
      "min: -1.04619754312308\n",
      "max: 0.9144740589268884\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4899877889260245\n",
      "std: 0.20419681841349002\n",
      "min: 0.005340870039934089\n",
      "max: 0.9144740589268884\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03196838891172769\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3999777075662057\n",
      "std: 0.0187192211544266\n",
      "min: 1.332642847078597\n",
      "max: 1.4140088846156442\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4010573320477735\n",
      "std: 0.018583686765728927\n",
      "min: 1.332642847078597\n",
      "max: 1.4140088846156442\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.15126738747058818\n",
      "min: 0.10473540631466333\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31918000311097705\n",
      "std: 0.30351781214131107\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6179097630118622\n",
      "std: 0.1892967634391069\n",
      "min: 0.16017452860143988\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03329684477615333\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9968507272274052\n",
      "std: 0.4272008664883326\n",
      "min: -0.0357030236597033\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0363226203795362\n",
      "std: 0.42508713045340396\n",
      "min: -0.027522218170909225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.1690333188515714\n",
      "min: 0.034210920908895145\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32213326545675225\n",
      "std: 0.37075751689768366\n",
      "min: -1.0418624388317728\n",
      "max: 0.9166961082268397\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4899454734442124\n",
      "std: 0.20088842902300608\n",
      "min: 0.009653828235930322\n",
      "max: 0.9166961082268397\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03179407131480474\n",
      "min: 0.11730985224476699\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4021227856130727\n",
      "std: 0.014987847026458771\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4030705880710166\n",
      "std: 0.014657912773543207\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999996\n",
      "std: 0.1512391060053337\n",
      "min: 0.10688409883374836\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3190662304339417\n",
      "std: 0.30394961427315526\n",
      "min: -0.7873488767461841\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6178290097194504\n",
      "std: 0.18796086170948464\n",
      "min: 0.1548016877765636\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999996\n",
      "std: 0.03334224040969327\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.195861948758639\n",
      "std: 0.13714127305968538\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2132991211929303\n",
      "std: 0.1474409815550569\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.14578356822785954\n",
      "min: 0.06362103680521326\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3462415063901082\n",
      "std: 0.37347103383141883\n",
      "min: -1.0393282332938176\n",
      "max: 0.9069400431186838\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48378015433332533\n",
      "std: 0.20895940129280036\n",
      "min: -0.11744174501600657\n",
      "max: 0.9069400431186838\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03279919212329714\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4086617412628522\n",
      "std: 0.003691415601396463\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090080465137118\n",
      "std: 0.00406951727545579\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.14211524874487355\n",
      "min: 0.09853439920964972\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31874409107281526\n",
      "std: 0.3028305017724373\n",
      "min: -0.7917247096695829\n",
      "max: 0.9118540924163263\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6116474103632583\n",
      "std: 0.1860351939182554\n",
      "min: 0.15904960346301825\n",
      "max: 0.9118540924163263\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03339242387924867\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668559274200261\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0542488052190893\n",
      "std: 0.33909639900548655\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.083929455561233\n",
      "std: 0.34301031165521345\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.15680504233879938\n",
      "min: 0.033930323552858785\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3056073444964285\n",
      "std: 0.39033786053833397\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5031683303810054\n",
      "std: 0.21269233350427694\n",
      "min: -0.11415131062850674\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.031572408444541684\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4044839482038327\n",
      "std: 0.01002499784614893\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4052283636549006\n",
      "std: 0.00997694560507763\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.14212801819948231\n",
      "min: 0.09696983944955939\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30946525587806206\n",
      "std: 0.3036657086342766\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359749\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6198969106431231\n",
      "std: 0.18541947781021836\n",
      "min: 0.16849275148144835\n",
      "max: 0.9345062847359749\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03305013917066241\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0717435551213887\n",
      "std: 0.3040260478274845\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.099927789499865\n",
      "std: 0.3070978200959853\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.15260821368111557\n",
      "min: 0.03969392280289474\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3098118465671326\n",
      "std: 0.37618976410075766\n",
      "min: -1.040564191267659\n",
      "max: 0.9222806257991404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5035643443777613\n",
      "std: 0.20665347524774708\n",
      "min: -0.10883049623165533\n",
      "max: 0.9222806257991404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03151012204665781\n",
      "min: 0.11804781246265543\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4063596015563429\n",
      "std: 0.006357591906562901\n",
      "min: 1.3862543041541702\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069407687029054\n",
      "std: 0.00638822664565894\n",
      "min: 1.3887761213835206\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.14211801053283069\n",
      "min: 0.09841477336680969\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3121628590567698\n",
      "std: 0.3034378351840105\n",
      "min: -0.7852794356729706\n",
      "max: 0.9125577534895606\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6187720032926418\n",
      "std: 0.18530767415678145\n",
      "min: 0.1677107538562449\n",
      "max: 0.9125577534895606\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0331900651409132\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0168053395076109\n",
      "std: 0.41662118172918977\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0492905175101166\n",
      "std: 0.4172022502141292\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.1598239176917562\n",
      "min: 0.028340512297233274\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.337268435523411\n",
      "std: 0.37460964289674875\n",
      "min: -1.04619754312308\n",
      "max: 0.9144740589268884\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4789862905331324\n",
      "std: 0.21111857564945757\n",
      "min: -0.1201296195363326\n",
      "max: 0.9144740589268884\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03226698206541457\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4005282768645946\n",
      "std: 0.018186687007398887\n",
      "min: 1.332642847078597\n",
      "max: 1.4140088846156442\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.401508128543752\n",
      "std: 0.01809444115554213\n",
      "min: 1.332642847078597\n",
      "max: 1.4140088846156442\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.14216014880349379\n",
      "min: 0.0941420313037324\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32097676755692023\n",
      "std: 0.30306789024582725\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6161359086046608\n",
      "std: 0.18937272758879958\n",
      "min: 0.16017452860143988\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033365817481380074\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0135616307399056\n",
      "std: 0.40976219898335847\n",
      "min: -0.0357030236597033\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.046972391474926\n",
      "std: 0.40821845047079625\n",
      "min: -0.027522218170909225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.15800308433435786\n",
      "min: 0.0339128703611933\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33248118514728625\n",
      "std: 0.3674036158270657\n",
      "min: -1.0418624388317728\n",
      "max: 0.9166961082268398\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47911484886912886\n",
      "std: 0.20813772961019186\n",
      "min: -0.11614260933525505\n",
      "max: 0.9166961082268398\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03211365612368538\n",
      "min: 0.11730985224476699\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4025343034839712\n",
      "std: 0.014490060000944596\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4034081597069723\n",
      "std: 0.01419975469345503\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.14213489985312214\n",
      "min: 0.09593691836892267\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32093111058754115\n",
      "std: 0.3035281468729316\n",
      "min: -0.7873488767461841\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.616145810616752\n",
      "std: 0.18817836701570906\n",
      "min: 0.1548016877765636\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03341144472921876\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1973324341058826\n",
      "std: 0.13027951681792846\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2134321774315346\n",
      "std: 0.14042983500275633\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.1373727640104741\n",
      "min: 0.06362103680521326\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3444385071585356\n",
      "std: 0.37220658315280186\n",
      "min: -1.0393282332938176\n",
      "max: 0.9069400431186838\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48186641137668224\n",
      "std: 0.2089542336305598\n",
      "min: -0.11744174501600657\n",
      "max: 0.9069400431186838\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03286483764816773\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408584105695216\n",
      "std: 0.0036712395627684327\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408881204442853\n",
      "std: 0.004068848845658814\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.13408385302537337\n",
      "min: 0.08961098771165457\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3184477981193198\n",
      "std: 0.30244263290650897\n",
      "min: -0.7917247096695829\n",
      "max: 0.9118540924163263\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6109877675347292\n",
      "std: 0.18573608543138853\n",
      "min: 0.15904960346301825\n",
      "max: 0.9118540924163263\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03338531675648594\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668559274200261\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0684464871580779\n",
      "std: 0.3233331884268305\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.094668329219953\n",
      "std: 0.3274177449021428\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.14725537939787184\n",
      "min: 0.033930323552858785\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3072647824925051\n",
      "std: 0.3880091843265737\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.500203235964589\n",
      "std: 0.21245519247914502\n",
      "min: -0.11415131062850674\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.031740721443287614\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4047349469553405\n",
      "std: 0.009673609029106186\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4053706033289497\n",
      "std: 0.009658947743810395\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.13409534972647427\n",
      "min: 0.08861851073237464\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30979999950268783\n",
      "std: 0.30318684608757707\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359749\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6187015061772612\n",
      "std: 0.18513897155088924\n",
      "min: 0.16849275148144835\n",
      "max: 0.9345062847359749\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0330622455959016\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0841598208421552\n",
      "std: 0.29095666318679564\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.109130473916918\n",
      "std: 0.2940554754118304\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.1435173657520412\n",
      "min: 0.03969392280289474\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3107456815285531\n",
      "std: 0.3750305888534528\n",
      "min: -1.040564191267659\n",
      "max: 0.9222806257991404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5006991253833197\n",
      "std: 0.20691524573279482\n",
      "min: -0.10883049623165533\n",
      "max: 0.9222806257991404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.031683040472814034\n",
      "min: 0.11804781246265543\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064576072908204\n",
      "std: 0.006159795054744912\n",
      "min: 1.3862543041541702\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406957112473008\n",
      "std: 0.006216887725744407\n",
      "min: 1.3887761213835206\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.1340863478469862\n",
      "min: 0.08972690986137727\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31229396590232644\n",
      "std: 0.3030369582936069\n",
      "min: -0.7852794356729706\n",
      "max: 0.9125577534895606\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6177577631141022\n",
      "std: 0.18505450481650743\n",
      "min: 0.1677107538562449\n",
      "max: 0.9125577534895606\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033193454290591444\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0321125730641103\n",
      "std: 0.4025862452958594\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0608108503544147\n",
      "std: 0.40345045860754286\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.15000618095516027\n",
      "min: 0.024747470962023538\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33678083142958104\n",
      "std: 0.37344784960605115\n",
      "min: -1.04619754312308\n",
      "max: 0.9144740589268884\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47775001426911334\n",
      "std: 0.2108436285203871\n",
      "min: -0.1201296195363326\n",
      "max: 0.9144740589268884\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03238926421239537\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4009929685249125\n",
      "std: 0.01781806479279181\n",
      "min: 1.3319112038791698\n",
      "max: 1.4140088846156442\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4018224523208505\n",
      "std: 0.01776233216543424\n",
      "min: 1.3319112038791698\n",
      "max: 1.4140088846156442\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.13412464341751448\n",
      "min: 0.08503945118673592\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3206517561340709\n",
      "std: 0.3026025812075334\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6150881681058369\n",
      "std: 0.1888551112294988\n",
      "min: 0.16017452860143988\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033362884741633986\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0292456229310905\n",
      "std: 0.39709051856800026\n",
      "min: -0.0357030236597033\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0587286333035955\n",
      "std: 0.3957294528732306\n",
      "min: -0.027522218170909225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.14839351082035768\n",
      "min: 0.028693717860794388\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33200286786306527\n",
      "std: 0.3667760856955539\n",
      "min: -1.0418624388317728\n",
      "max: 0.9166961082268398\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4779344037088559\n",
      "std: 0.20813357993077974\n",
      "min: -0.11614260933525505\n",
      "max: 0.9166961082268398\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999996\n",
      "std: 0.03225046832255948\n",
      "min: 0.11730985224476699\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4028473707174551\n",
      "std: 0.014200746981357943\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4035920687200725\n",
      "std: 0.013947232977714392\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.13410189095981953\n",
      "min: 0.08684080466621484\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32067094614712643\n",
      "std: 0.30307966529241775\n",
      "min: -0.7873488767461841\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6151716164827633\n",
      "std: 0.18778025622262928\n",
      "min: 0.1548016877765636\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999996\n",
      "std: 0.033408785490673464\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1999715101906454\n",
      "std: 0.12714295241342474\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2140432009987183\n",
      "std: 0.1371258863747304\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.12993926563171831\n",
      "min: 0.05473353682697026\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34061039879457483\n",
      "std: 0.3704965549661467\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813369\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48549508448219414\n",
      "std: 0.21154592940895578\n",
      "min: -0.11744174501600659\n",
      "max: 0.9594521654813369\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032729173943335674\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4085632099127914\n",
      "std: 0.0035538008845970334\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408795908688171\n",
      "std: 0.003944524670740777\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.12695109472306162\n",
      "min: 0.08228994926458046\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31759409585047094\n",
      "std: 0.3022229053316648\n",
      "min: -0.7917247096695829\n",
      "max: 0.9118540924163263\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6116495484557066\n",
      "std: 0.18524658115294435\n",
      "min: 0.15904960346301825\n",
      "max: 0.9118540924163263\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033342540861638764\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668559274200261\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.080897271076852\n",
      "std: 0.3133900829817476\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.103555280674754\n",
      "std: 0.3173085836350668\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.13889218441496348\n",
      "min: 0.03393032355285879\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30632336319568926\n",
      "std: 0.3851370288975022\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5028734349498681\n",
      "std: 0.21452365828936942\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03168103699036634\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4049894559032472\n",
      "std: 0.009415683469711071\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4055135000225845\n",
      "std: 0.009395174914151538\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.12696157051141518\n",
      "min: 0.08079348619147428\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.309495347109287\n",
      "std: 0.3028797935506384\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359749\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6189000800055499\n",
      "std: 0.1846396984547565\n",
      "min: 0.16849275148144835\n",
      "max: 0.9345062847359749\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03303632995275861\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0953792184272748\n",
      "std: 0.2814619218958998\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1169457049617888\n",
      "std: 0.28446106677182154\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.1355200429650201\n",
      "min: 0.03298208696718896\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3092323077795126\n",
      "std: 0.37315425527415774\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5034692672751909\n",
      "std: 0.20949527239414065\n",
      "min: -0.10883049623165533\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.031627961151737986\n",
      "min: 0.11804781246265543\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065723747950782\n",
      "std: 0.006042609313790365\n",
      "min: 1.38625430415417\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069820975826774\n",
      "std: 0.006075714423294819\n",
      "min: 1.3887761213835206\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.12695339521683865\n",
      "min: 0.08196378210635258\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31182007900104597\n",
      "std: 0.30278875988715737\n",
      "min: -0.7852794356729706\n",
      "max: 0.9125577534895606\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6180971811704848\n",
      "std: 0.1845815272350558\n",
      "min: 0.1677107538562449\n",
      "max: 0.9125577534895606\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033160086305517825\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0449327958255572\n",
      "std: 0.38350772870709854\n",
      "min: -0.0357030236597033\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.07032073324439\n",
      "std: 0.3823429517003999\n",
      "min: -0.027522218170909225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.13994428943300163\n",
      "min: 0.02811672908356682\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32927725666502383\n",
      "std: 0.3655385656421302\n",
      "min: -1.0418624388317728\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.482287040169304\n",
      "std: 0.21091468261536045\n",
      "min: -0.11614260933525505\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032167601275370473\n",
      "min: 0.11730985224476699\n",
      "max: 0.267109449683781\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4031633103455003\n",
      "std: 0.013975957061222144\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4037797813214372\n",
      "std: 0.013730977781661982\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.12696779255034335\n",
      "min: 0.07941945707613973\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31982882649634514\n",
      "std: 0.30280851131000164\n",
      "min: -0.7873488767461841\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6155905683411826\n",
      "std: 0.18717557908655227\n",
      "min: 0.1548016877765636\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03336914351544457\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0473925987137664\n",
      "std: 0.38917507941306645\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0721087617838119\n",
      "std: 0.39017995244868325\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.1413947619017349\n",
      "min: 0.023115433230658088\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3339729352516815\n",
      "std: 0.37172370240990155\n",
      "min: -1.04619754312308\n",
      "max: 0.9667459598634704\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4820529386481872\n",
      "std: 0.2133144145156785\n",
      "min: -0.12012961953633255\n",
      "max: 0.9667459598634704\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032292658701218134\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4014458046864122\n",
      "std: 0.01747052240322784\n",
      "min: 1.3319112038791698\n",
      "max: 1.4140088846156442\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.402129522652524\n",
      "std: 0.017427953394934404\n",
      "min: 1.3319112038791698\n",
      "max: 1.4140088846156442\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.1269884438536726\n",
      "min: 0.07782492066620578\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3197522730216679\n",
      "std: 0.30232581144726844\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.61546433295938\n",
      "std: 0.1881520411995206\n",
      "min: 0.16017452860143988\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03332319925058651\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1056221976763916\n",
      "std: 0.2747788494505487\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1246336027388548\n",
      "std: 0.277579112955338\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.1284190164667233\n",
      "min: 0.026478447798692538\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31006015401709036\n",
      "std: 0.3717873933115133\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49876261914035236\n",
      "std: 0.21088269987100933\n",
      "min: -0.10883049623165533\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.031703718546335\n",
      "min: 0.11804781246265543\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4067517045242646\n",
      "std: 0.005940579182864847\n",
      "min: 1.38625430415417\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071182997399234\n",
      "std: 0.00596816506900093\n",
      "min: 1.3887761213835206\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.120578950447399\n",
      "min: 0.07562934278444772\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3117955027819195\n",
      "std: 0.3027030407441299\n",
      "min: -0.7852794356729706\n",
      "max: 0.9125577534895606\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6171878855130646\n",
      "std: 0.18450093804302053\n",
      "min: 0.1677107538562449\n",
      "max: 0.9125577534895606\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03316600696708859\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.092227326991291\n",
      "std: 0.3057918759596843\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1122022278129127\n",
      "std: 0.3094872171983005\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.13148417257233316\n",
      "min: 0.027419760266060942\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30758691443326747\n",
      "std: 0.382947723570299\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4981133670639948\n",
      "std: 0.2155254545481207\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.031752262116394675\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4052871898316492\n",
      "std: 0.00919206348109622\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4057511249740575\n",
      "std: 0.009180663082821942\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12058643078130311\n",
      "min: 0.07462167728371973\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30960724777495946\n",
      "std: 0.30274490524637115\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359749\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6178742660157999\n",
      "std: 0.18453971974545694\n",
      "min: 0.16849275148144835\n",
      "max: 0.9345062847359749\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03304844131347305\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2036019684170436\n",
      "std: 0.12194006283195523\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2161585681844094\n",
      "std: 0.13191118491567025\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12330161709519544\n",
      "min: 0.05473353682697026\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33934998226266355\n",
      "std: 0.3690637004381231\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813369\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48165591374660316\n",
      "std: 0.21263302713599852\n",
      "min: -0.11744174501600659\n",
      "max: 0.9594521654813369\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03272581031002423\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4086293719282983\n",
      "std: 0.0034468103844331613\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088375478829773\n",
      "std: 0.0038346046864416476\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12057681611995211\n",
      "min: 0.07607160147429945\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31722916272595725\n",
      "std: 0.3021525350540772\n",
      "min: -0.7917247096695829\n",
      "max: 0.9118540924163263\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6110350805712753\n",
      "std: 0.1851224026745716\n",
      "min: 0.15904960346301825\n",
      "max: 0.9118540924163263\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033339520951899036\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668559274200261\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0586427657222734\n",
      "std: 0.3740177871754744\n",
      "min: -0.0357030236597033\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.08095044400313\n",
      "std: 0.37291083619341503\n",
      "min: -0.027522218170909225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.1324665182495595\n",
      "min: 0.024744639944925553\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3289804484185513\n",
      "std: 0.3646134383285366\n",
      "min: -1.0418624388317728\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4788844934638658\n",
      "std: 0.21190601766573028\n",
      "min: -0.11614260933525505\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.03221485249514061\n",
      "min: 0.11730985224476699\n",
      "max: 0.267109449683781\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.403538996614234\n",
      "std: 0.013745528017115002\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4040796698854507\n",
      "std: 0.013516981547764059\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12059232672868306\n",
      "min: 0.07332825031783861\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3194652047237369\n",
      "std: 0.3026952524799255\n",
      "min: -0.7873488767461841\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6147432416167263\n",
      "std: 0.18697558200683212\n",
      "min: 0.1548016877765636\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0333687729865397\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.060752334788989\n",
      "std: 0.37999278317991564\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.082491078713544\n",
      "std: 0.38100300238459844\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.13378056398255883\n",
      "min: 0.017954246835429514\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3336036568816496\n",
      "std: 0.3703863138799598\n",
      "min: -1.04619754312308\n",
      "max: 0.9667459598634704\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4786637815013397\n",
      "std: 0.21406983973151028\n",
      "min: -0.12012961953633255\n",
      "max: 0.9667459598634704\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03232929298801555\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4019342749833228\n",
      "std: 0.017130311295628475\n",
      "min: 1.3319112038791698\n",
      "max: 1.4140088846156442\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4025295722405964\n",
      "std: 0.017105611670032786\n",
      "min: 1.3319112038791698\n",
      "max: 1.4140088846156442\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12061121042838384\n",
      "min: 0.0719904919119912\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3193373054485255\n",
      "std: 0.3022062993636697\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6145843664705126\n",
      "std: 0.1878639927585184\n",
      "min: 0.16017452860143988\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033322684164513075\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1152079841775198\n",
      "std: 0.26737838824009624\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1323003534152447\n",
      "std: 0.27004325970178006\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.12206577385010225\n",
      "min: 0.026227873314977022\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3088873746643536\n",
      "std: 0.3734740171064181\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4975346472896565\n",
      "std: 0.2105528931822106\n",
      "min: -0.10883049623165533\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.031700403357892856\n",
      "min: 0.11804781246265543\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406878866174357\n",
      "std: 0.005790518918101729\n",
      "min: 1.38625430415417\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072214946529984\n",
      "std: 0.005820953672624282\n",
      "min: 1.3887761213835206\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.11484900600362642\n",
      "min: 0.07046670729207984\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31146513467372106\n",
      "std: 0.3027545204409903\n",
      "min: -0.7852794356729706\n",
      "max: 0.9125577534895606\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6164455304568504\n",
      "std: 0.18450424183137468\n",
      "min: 0.1677107538562449\n",
      "max: 0.9125577534895606\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999998\n",
      "std: 0.03315820871997109\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1027282183298774\n",
      "std: 0.29670703178131175\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1206768690694429\n",
      "std: 0.3002999255677482\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.12487047515439215\n",
      "min: 0.02741976026606093\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3067340701958336\n",
      "std: 0.3837728805940854\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49680935901042955\n",
      "std: 0.21489326275623702\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03174603969987492\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4055054065358104\n",
      "std: 0.00893227159704427\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405933046161171\n",
      "std: 0.008928099173115368\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1333333333333333\n",
      "std: 0.11485588670488596\n",
      "min: 0.06945314805048051\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30939529486899137\n",
      "std: 0.30275612935710894\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359749\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6170390498906985\n",
      "std: 0.18452523958238262\n",
      "min: 0.16849275148144835\n",
      "max: 0.9345062847359749\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0330461518752002\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2063605038307645\n",
      "std: 0.11897493199435479\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2179154743874465\n",
      "std: 0.12847261734113635\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.11735329742864557\n",
      "min: 0.04964114403860137\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3364085972189285\n",
      "std: 0.37081007911631775\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813369\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48114770487609043\n",
      "std: 0.2121720717248209\n",
      "min: -0.11744174501600659\n",
      "max: 0.9594521654813369\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03265793645723344\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408638645519723\n",
      "std: 0.0034155796121189083\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088393780348\n",
      "std: 0.0037919627579544204\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.1148470362749884\n",
      "min: 0.07043146033793783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.316601780798301\n",
      "std: 0.3022240037933561\n",
      "min: -0.7917247096695829\n",
      "max: 0.9118540924163263\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6105556875592815\n",
      "std: 0.18508885529099997\n",
      "min: 0.15904960346301825\n",
      "max: 0.9118540924163263\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03332387366127868\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668559274200261\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0700824541524414\n",
      "std: 0.3669443019011649\n",
      "min: -0.05194513118713192\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.090129934696593\n",
      "std: 0.3658553876213964\n",
      "min: -0.05194513118713192\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.12580263548454468\n",
      "min: 0.020469383746327372\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32681858218424426\n",
      "std: 0.36673677804637944\n",
      "min: -1.0418624388317728\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4787854373375467\n",
      "std: 0.2114958871040815\n",
      "min: -0.11614260933525505\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032187476577456714\n",
      "min: 0.11730985224476699\n",
      "max: 0.267109449683781\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.403852960176898\n",
      "std: 0.013403601944616638\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4043431994145559\n",
      "std: 0.01320204686706352\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1333333333333333\n",
      "std: 0.11486143817894695\n",
      "min: 0.06819427721113339\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31882578377444515\n",
      "std: 0.30273236895080213\n",
      "min: -0.7873488767461841\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6140627618864087\n",
      "std: 0.1868673847733288\n",
      "min: 0.1548016877765636\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03335500101827417\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0719392263524368\n",
      "std: 0.3725719552797353\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0914924966616801\n",
      "std: 0.3735511461682475\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.12700013474911007\n",
      "min: 0.015757041134209386\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.331286839255581\n",
      "std: 0.3720918054374936\n",
      "min: -1.04619754312308\n",
      "max: 0.9667459598634704\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4785243837639939\n",
      "std: 0.21346763241062455\n",
      "min: -0.12012961953633255\n",
      "max: 0.9667459598634704\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032292595374163284\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4023470149193695\n",
      "std: 0.016683054482673217\n",
      "min: 1.3319112038791698\n",
      "max: 1.4140088846156442\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.402881918653204\n",
      "std: 0.016683088235674253\n",
      "min: 1.3319112038791698\n",
      "max: 1.4140088846156442\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.11487879733148643\n",
      "min: 0.06730169420819844\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31865245705609324\n",
      "std: 0.3022419277832293\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6138796603376833\n",
      "std: 0.1876782341231521\n",
      "min: 0.16017452860143988\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03330885214938581\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.124836866588275\n",
      "std: 0.2607258193888906\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1402854082370841\n",
      "std: 0.2632202368324842\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.1163471071670282\n",
      "min: 0.023171579463964566\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3108254284081413\n",
      "std: 0.37122650782439975\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49712479262976594\n",
      "std: 0.21064793212019256\n",
      "min: -0.10883049623165533\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0316955674326146\n",
      "min: 0.11804781246265543\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070965709499639\n",
      "std: 0.005640443690149967\n",
      "min: 1.38625430415417\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074072731298861\n",
      "std: 0.00565801924953257\n",
      "min: 1.3887761213835206\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.10967054025493321\n",
      "min: 0.06559506334744371\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3119592484966299\n",
      "std: 0.30269733498512086\n",
      "min: -0.7852794356729706\n",
      "max: 0.9125577534895606\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6162834162421136\n",
      "std: 0.18444586969822033\n",
      "min: 0.1677107538562449\n",
      "max: 0.9125577534895606\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03316854884172823\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1130019420602433\n",
      "std: 0.2899977982655302\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.129222879074529\n",
      "std: 0.2933963880739951\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.11893582680332188\n",
      "min: 0.023517495753197924\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3089893004130823\n",
      "std: 0.38093780368402214\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49634278565542445\n",
      "std: 0.21470877011488812\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03173882252169513\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4058010715110636\n",
      "std: 0.008706487401181818\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061866688858766\n",
      "std: 0.008699468539309519\n",
      "min: 1.3710038210551025\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.10967691102412654\n",
      "min: 0.06475277013235024\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30999759239228275\n",
      "std: 0.30266605774313027\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359749\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6167910947383204\n",
      "std: 0.18444924389076914\n",
      "min: 0.16849275148144835\n",
      "max: 0.9345062847359749\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03306143772047011\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2106234234851423\n",
      "std: 0.11603035629403743\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2212325006504832\n",
      "std: 0.1250406226079052\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.11198475095012063\n",
      "min: 0.04759232420676906\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3367506236712831\n",
      "std: 0.3684600407114397\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813369\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4814083213273881\n",
      "std: 0.2121490730998887\n",
      "min: -0.11744174501600659\n",
      "max: 0.9594521654813369\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03259593273462745\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408764056449205\n",
      "std: 0.0033065756399323068\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4089464700603265\n",
      "std: 0.003661617372483801\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.1096687085403495\n",
      "min: 0.06600937395017814\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3168222868492645\n",
      "std: 0.30217025606736314\n",
      "min: -0.7917247096695829\n",
      "max: 0.9118540924163263\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.610629394366013\n",
      "std: 0.1850082353183671\n",
      "min: 0.15904960346301825\n",
      "max: 0.9118540924163263\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03332676297426643\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668559274200261\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0823707402708278\n",
      "std: 0.3574611792847839\n",
      "min: -0.05194513118713192\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1004200347567328\n",
      "std: 0.3564473314376173\n",
      "min: -0.05194513118713192\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.11980757189489565\n",
      "min: 0.020469383746327372\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3278729914752984\n",
      "std: 0.3647377384141262\n",
      "min: -1.0418624388317728\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4793588724167817\n",
      "std: 0.21154388624477757\n",
      "min: -0.11614260933525505\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032160530849475434\n",
      "min: 0.11730985224476699\n",
      "max: 0.267109449683781\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.404273062734841\n",
      "std: 0.013021760868293254\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4047069011182032\n",
      "std: 0.012835140107225687\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139876647995067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.10968210854576028\n",
      "min: 0.06365700763862941\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3190414686882659\n",
      "std: 0.3026509025609829\n",
      "min: -0.7873488767461841\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6139608537006794\n",
      "std: 0.18671249878150328\n",
      "min: 0.1548016877765636\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03335969453088529\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0838460030121724\n",
      "std: 0.36432049737454575\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1014631239778574\n",
      "std: 0.36530844038657884\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.12091235984661657\n",
      "min: 0.015219574377605705\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3322596812625339\n",
      "std: 0.36979597238014605\n",
      "min: -1.04619754312308\n",
      "max: 0.9667459598634704\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4790950047108345\n",
      "std: 0.21335528000276685\n",
      "min: -0.12012961953633255\n",
      "max: 0.9667459598634704\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03225851704086111\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4028542990134862\n",
      "std: 0.016241382366296922\n",
      "min: 1.3319112038791698\n",
      "max: 1.4140088846156442\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4033247883091289\n",
      "std: 0.016257027001422137\n",
      "min: 1.3319112038791698\n",
      "max: 1.4140088846156442\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.10969816709557022\n",
      "min: 0.06239208167550042\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31883596055985225\n",
      "std: 0.30215649376809567\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6137575709986939\n",
      "std: 0.18745652444884803\n",
      "min: 0.16017452860143988\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03331378862801954\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1305373326431396\n",
      "std: 0.2564752120170327\n",
      "min: 0.057924141187968514\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.144386643854974\n",
      "std: 0.2588743155167232\n",
      "min: 0.057924141187968514\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.11118543081604296\n",
      "min: 0.020081627700605197\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31446834565844595\n",
      "std: 0.37088543457080914\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49450888618697497\n",
      "std: 0.21126261173057664\n",
      "min: -0.10883049623165536\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03187727086293285\n",
      "min: 0.11804781246265543\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072299653753513\n",
      "std: 0.005572056432710128\n",
      "min: 1.3862543041541702\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075196749373813\n",
      "std: 0.005585557945472767\n",
      "min: 1.3887761213835206\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.10496721130787096\n",
      "min: 0.06139972150298415\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3122340856148105\n",
      "std: 0.30263205593990855\n",
      "min: -0.7852794356729706\n",
      "max: 0.9125577534895606\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6162574674090886\n",
      "std: 0.18438623762219455\n",
      "min: 0.1677107538562449\n",
      "max: 0.9125577534895606\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03317645504228957\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.119551180245686\n",
      "std: 0.2841725657805883\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.134093568683933\n",
      "std: 0.2875015800531937\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.11358201735446864\n",
      "min: 0.02281705614202005\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31287873434493874\n",
      "std: 0.3800507125719371\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49369414936342026\n",
      "std: 0.21505548776992775\n",
      "min: -0.11415131062850693\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03191571728058815\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406000487841967\n",
      "std: 0.008607071922300707\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4063568271907518\n",
      "std: 0.008600429659172772\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.1049731569536983\n",
      "min: 0.06024897949350899\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31036226531989525\n",
      "std: 0.30257162294086354\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359749\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.616696470451841\n",
      "std: 0.18437126708888518\n",
      "min: 0.16849275148144835\n",
      "max: 0.9345062847359749\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033073599981374824\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2122237860506726\n",
      "std: 0.11357319680373577\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2217727128305405\n",
      "std: 0.12242934956205948\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1176470588235294\n",
      "std: 0.10711969797875424\n",
      "min: 0.041892149035940525\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3389349647361\n",
      "std: 0.36793477022301174\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4794053765568963\n",
      "std: 0.2125823428598678\n",
      "min: -0.11744174501600654\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03271983043912396\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4088429408708238\n",
      "std: 0.0032406386346600703\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139907789377222\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.409014066805755\n",
      "std: 0.0035890061468438197\n",
      "min: 1.3904455376842184\n",
      "max: 1.4139907789377222\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.10496549012355597\n",
      "min: 0.061678612542695785\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3168524013301546\n",
      "std: 0.30211365576118154\n",
      "min: -0.7917247096695829\n",
      "max: 0.9118540924163263\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6108155292308155\n",
      "std: 0.18493055909452907\n",
      "min: 0.15904960346301825\n",
      "max: 0.9118540924163263\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033328007306576625\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668559274200261\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0919192955638217\n",
      "std: 0.34708994715220537\n",
      "min: -0.05194513118713192\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1079976983491333\n",
      "std: 0.3462873792351606\n",
      "min: -0.05194513118713192\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.11439300190923081\n",
      "min: 0.020469383746327372\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3307205203291181\n",
      "std: 0.36462147803689327\n",
      "min: -1.0418624388317728\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47767456994857393\n",
      "std: 0.21196108520839893\n",
      "min: -0.11614260933525505\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032320271300043626\n",
      "min: 0.11730985224476699\n",
      "max: 0.267109449683781\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4045880823267805\n",
      "std: 0.012712511653985369\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139917536538014\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4049809441123517\n",
      "std: 0.01254334317620396\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139917536538014\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.10497802455474722\n",
      "min: 0.05965274885432707\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3190583669981837\n",
      "std: 0.3025716861106449\n",
      "min: -0.7873488767461841\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6139955172237732\n",
      "std: 0.18656718532417896\n",
      "min: 0.1548016877765636\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03336236264969179\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0933123904634945\n",
      "std: 0.3534957340981665\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1090047014973625\n",
      "std: 0.35467418213754076\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.11541355265212909\n",
      "min: 0.01521957437760571\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3349994247077597\n",
      "std: 0.3693776743612716\n",
      "min: -1.04619754312308\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47738197998076864\n",
      "std: 0.2136330966582296\n",
      "min: -0.12012961953633265\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0324095855239164\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4032434224310761\n",
      "std: 0.015901494580874177\n",
      "min: 1.3319112038791698\n",
      "max: 1.4140088846156442\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.403666973260475\n",
      "std: 0.015931613110136852\n",
      "min: 1.3319112038791698\n",
      "max: 1.4140088846156442\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.10499297277381735\n",
      "min: 0.05845801101782972\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3188214111099327\n",
      "std: 0.3020771555799232\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6137784028577894\n",
      "std: 0.18725161104027757\n",
      "min: 0.16017452860143988\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033316776961077856\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1341856520638218\n",
      "std: 0.2489986801304884\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1473630594593875\n",
      "std: 0.251613357159496\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10648330732519647\n",
      "min: 0.020081627700605197\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31666090360040716\n",
      "std: 0.3701475310156516\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48926988673638905\n",
      "std: 0.2141450591979132\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032040079879201086\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407293036071379\n",
      "std: 0.00541578123837575\n",
      "min: 1.38625430415417\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075539608064986\n",
      "std: 0.005434947754718603\n",
      "min: 1.3887761213835208\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.100675884331604\n",
      "min: 0.058178333569259236\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3123388606700695\n",
      "std: 0.302561988506562\n",
      "min: -0.7852794356729709\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6156284976997639\n",
      "std: 0.18419977576331856\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033164972479208625\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1237769512033906\n",
      "std: 0.2760986329940047\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1375824599893531\n",
      "std: 0.27963001832189804\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10871550712864182\n",
      "min: 0.022817056142020065\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31531754772602066\n",
      "std: 0.3788267095629056\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4884153777131562\n",
      "std: 0.21770397165351715\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032075915377704524\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40613447933477\n",
      "std: 0.008357972358540485\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4064546505351803\n",
      "std: 0.008359997616902428\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10068143164333823\n",
      "min: 0.057337075163933535\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.310549398226352\n",
      "std: 0.30247870710492814\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6160082646480606\n",
      "std: 0.18417359794957794\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999996\n",
      "std: 0.03306608271386943\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2109750542469322\n",
      "std: 0.11217969129862335\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2203856425721715\n",
      "std: 0.12073138148280763\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10268842014649807\n",
      "min: 0.039340330023840624\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33992851026902415\n",
      "std: 0.3671263315274591\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47471866068692725\n",
      "std: 0.21520718873282355\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03283723220325094\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087982613687426\n",
      "std: 0.003235819940326448\n",
      "min: 1.3904455376842184\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408952306868343\n",
      "std: 0.0035696852524537684\n",
      "min: 1.3904455376842184\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10067428083615133\n",
      "min: 0.058121118039192725\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31674634476021246\n",
      "std: 0.3020573147157124\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6103873991490958\n",
      "std: 0.18471897245239532\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03331104729716723\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0968419211089848\n",
      "std: 0.339414213632121\n",
      "min: -0.05194513118713196\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1120480501184271\n",
      "std: 0.33892696002936645\n",
      "min: -0.05194513118713196\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.1094855365481315\n",
      "min: 0.01925220490730743\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3322582373509959\n",
      "std: 0.3641003075040223\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4731962011600177\n",
      "std: 0.21453942425382397\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032465291845014926\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.404749557758594\n",
      "std: 0.012451163878004844\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4051003442068517\n",
      "std: 0.012296356801160483\n",
      "min: 1.3552488404298222\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.1006860576059561\n",
      "min: 0.05613900804797291\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3189326068829447\n",
      "std: 0.3024884911477483\n",
      "min: -0.787348876746184\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6134223319645427\n",
      "std: 0.18629689807692093\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0333462201607912\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.097975554879491\n",
      "std: 0.34665573158257745\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1128386361691742\n",
      "std: 0.34807281322765676\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.11043537351216054\n",
      "min: 0.012930616370502825\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3364659588572666\n",
      "std: 0.3686119252739966\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4728735870589329\n",
      "std: 0.21609019599331158\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03254726294008627\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4034675544157253\n",
      "std: 0.015631751076577338\n",
      "min: 1.3294247359252644\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4038442588749156\n",
      "std: 0.015674323015651248\n",
      "min: 1.3294247359252644\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10070004603768194\n",
      "min: 0.054777637131186864\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3186662237727561\n",
      "std: 0.3019955512656537\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6131897819807105\n",
      "std: 0.1869298007624714\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033300836292718856\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1394329393823623\n",
      "std: 0.2450910617927797\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.151906034105091\n",
      "std: 0.24766302223989042\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.10219331363843935\n",
      "min: 0.01812938846249621\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31821112075050256\n",
      "std: 0.3713406748284538\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48784329238874147\n",
      "std: 0.21593230511624215\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03218767219080288\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073479489847731\n",
      "std: 0.005404006255879267\n",
      "min: 1.378989263365626\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076380275102758\n",
      "std: 0.005391473459932548\n",
      "min: 1.3832335649133196\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.09674409393446948\n",
      "min: 0.054318611080230846\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3125693931983759\n",
      "std: 0.3026853356466119\n",
      "min: -0.7852794356729709\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6153481290421181\n",
      "std: 0.18424531128085112\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033177879065593385\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1296734791131855\n",
      "std: 0.27105196100122964\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1427158015342327\n",
      "std: 0.27457183206516295\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.10427839000880576\n",
      "min: 0.019485629443467257\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3170510598237933\n",
      "std: 0.37955746642551597\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48699709947036274\n",
      "std: 0.21927048381244663\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032221354780403576\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406248543373014\n",
      "std: 0.008228559614897792\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406591705692052\n",
      "std: 0.008219745989192275\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.09674929409521882\n",
      "min: 0.05390410394026622\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3108505867969648\n",
      "std: 0.3025825828179616\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6156816648614971\n",
      "std: 0.1842077526952606\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03308246543535933\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.212714589856319\n",
      "std: 0.10898141249985056\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2218340738569669\n",
      "std: 0.11734025144553174\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.09862854640645044\n",
      "min: 0.039340330023840624\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3403462329211678\n",
      "std: 0.36829462366162674\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4738433183200998\n",
      "std: 0.2168974766561643\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0329422445897793\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087922418364978\n",
      "std: 0.003225990549783684\n",
      "min: 1.3904455376842184\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408983177698183\n",
      "std: 0.003507227651875284\n",
      "min: 1.3904455376842184\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.09674257548938027\n",
      "min: 0.05493607213010697\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3167809163789059\n",
      "std: 0.3021918562395996\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.610291431802772\n",
      "std: 0.18474542841345126\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03331849682493589\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1047577166698463\n",
      "std: 0.3316052551269069\n",
      "min: -0.05194513118713196\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.119011250821633\n",
      "std: 0.3313269861356261\n",
      "min: -0.05194513118713196\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.1050031380620614\n",
      "min: 0.019022738616465786\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3331406685025524\n",
      "std: 0.36555050492303715\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4725274955054054\n",
      "std: 0.21624589349295453\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03259400046470354\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4049403170100403\n",
      "std: 0.012250933978394789\n",
      "min: 1.3486282808158256\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4053067686998013\n",
      "std: 0.012101316952018666\n",
      "min: 1.349125596167667\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.0967536884569288\n",
      "min: 0.05259635656989417\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3189423019563224\n",
      "std: 0.3026046316384506\n",
      "min: -0.787348876746184\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6132052414975037\n",
      "std: 0.18626589852836867\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03335438115697971\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.105814754601201\n",
      "std: 0.33841671929375533\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1197559618368311\n",
      "std: 0.34003368394579236\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.10588867965644956\n",
      "min: 0.012930616370502822\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33725543447552137\n",
      "std: 0.36983491653735673\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4722165060184065\n",
      "std: 0.21767925561160734\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032671109111525896\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.403725243659069\n",
      "std: 0.015308544001722884\n",
      "min: 1.3294247359252647\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4041128362950266\n",
      "std: 0.015360141509957374\n",
      "min: 1.3294247359252647\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.09676678240113688\n",
      "min: 0.051884990162350396\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.318652341131216\n",
      "std: 0.3021139298524266\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.612968224298833\n",
      "std: 0.18685267778566103\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0333093471514779\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1422379450773068\n",
      "std: 0.2402399357649445\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1541732855912894\n",
      "std: 0.24283191153976796\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09825752208301565\n",
      "min: 0.01812938846249621\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31716640049584893\n",
      "std: 0.3714926433883021\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48612843141190304\n",
      "std: 0.21526124138643743\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03210952663506798\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407370733378049\n",
      "std: 0.005404718130038255\n",
      "min: 1.378989263365626\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076410885386919\n",
      "std: 0.005426932153455633\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09312782283311953\n",
      "min: 0.051520637097026804\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31232640208918705\n",
      "std: 0.3026205877335141\n",
      "min: -0.7852794356729709\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6149426559800157\n",
      "std: 0.1841189162173362\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033171040095641154\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1330672247097153\n",
      "std: 0.2651429145088307\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1455152172257346\n",
      "std: 0.26871192567498875\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.10021210652177409\n",
      "min: 0.018672845905404505\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31616850252088163\n",
      "std: 0.37930373168245396\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48527972968955335\n",
      "std: 0.21843819541271342\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03214219944832059\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4063292992629433\n",
      "std: 0.00811530277609448\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066473272067699\n",
      "std: 0.008135890110477552\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09313271350344074\n",
      "min: 0.05100767192011593\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3106724301240968\n",
      "std: 0.3025010895115966\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6152318619003762\n",
      "std: 0.1840728328516877\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033078822788393566\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2121575168054353\n",
      "std: 0.10670275539996893\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2210925121783627\n",
      "std: 0.11481357437251218\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09490068299975439\n",
      "min: 0.03864356974827985\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3383252656374418\n",
      "std: 0.36858241104947986\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4726547834424848\n",
      "std: 0.21609079392486147\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032831839436909094\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408757104172006\n",
      "std: 0.0032500539224768906\n",
      "min: 1.3881332718040698\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4089353533669386\n",
      "std: 0.003574132056451945\n",
      "min: 1.3881332718040698\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09312638154565536\n",
      "min: 0.051837648202533636\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3163614394553896\n",
      "std: 0.30214388624957117\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6100581332365662\n",
      "std: 0.18459577333009636\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03330669522510311\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1090766532419694\n",
      "std: 0.3257176974074217\n",
      "min: -0.11120208507519015\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.122623562066659\n",
      "std: 0.32560041826402825\n",
      "min: -0.11120208507519015\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.10090175999810239\n",
      "min: 0.014548738283141667\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3315235953317179\n",
      "std: 0.36600447984446777\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4714762356735355\n",
      "std: 0.215490130076241\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03250250103026594\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405069633186567\n",
      "std: 0.01208779567221016\n",
      "min: 1.348124373903737\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405406506409316\n",
      "std: 0.011967881791882374\n",
      "min: 1.348124373903737\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09313690469194753\n",
      "min: 0.04994826857578079\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31849174356263027\n",
      "std: 0.30254062002388804\n",
      "min: -0.787348876746184\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.612855859542907\n",
      "std: 0.18607428574200824\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03334297658184096\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1101068134073115\n",
      "std: 0.3314849015679245\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1233593285208132\n",
      "std: 0.3332845433953961\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.1017302200747945\n",
      "min: 0.012930616370502822\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33554822755175495\n",
      "std: 0.37009797895089647\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47116387753361705\n",
      "std: 0.21685163679946018\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03257585539356689\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4039168584876618\n",
      "std: 0.015044727380428521\n",
      "min: 1.3294247359252647\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4042708805737292\n",
      "std: 0.01512205537207702\n",
      "min: 1.3294247359252647\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09314921104454037\n",
      "min: 0.049139951035699424\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31818134417060817\n",
      "std: 0.30205230823622814\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6126146553817087\n",
      "std: 0.18662079086751018\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.03329822888833257\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1468054846571816\n",
      "std: 0.23480438553223512\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1575071441788016\n",
      "std: 0.2373327577048103\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.09463063036400975\n",
      "min: 0.01812938846249621\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.316966493077138\n",
      "std: 0.3697658896012171\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48377285559617106\n",
      "std: 0.21664860728383317\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03202723308059992\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074287901641305\n",
      "std: 0.005292148549048363\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076887052972276\n",
      "std: 0.005312950860779273\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.08978994412628893\n",
      "min: 0.04925619305915875\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3117526777737141\n",
      "std: 0.30219588029177247\n",
      "min: -0.7852794356729709\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6145418960239263\n",
      "std: 0.18399681362463272\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033150302313335316\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1380938033808383\n",
      "std: 0.25891128912981887\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1492655497125346\n",
      "std: 0.26240884772492495\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.0964702229146673\n",
      "min: 0.01867284590540451\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3161147489031112\n",
      "std: 0.37723058151460886\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48290296155716633\n",
      "std: 0.2196642607894242\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03205860942008976\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064320466280031\n",
      "std: 0.007952280197500685\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067352346627642\n",
      "std: 0.00797517333579292\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.08979456070016727\n",
      "min: 0.048489290075362214\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3101579539756759\n",
      "std: 0.3020592173711975\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6147898694700572\n",
      "std: 0.18394426185921423\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03306102837490209\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.213297432480516\n",
      "std: 0.10500779011451673\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2213043070694278\n",
      "std: 0.11291197162140194\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.09146344124859143\n",
      "min: 0.03251878823968577\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3372294180961626\n",
      "std: 0.3669146887609935\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4707096294519664\n",
      "std: 0.21732204423511475\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032719058978638596\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087535876467916\n",
      "std: 0.003201725223410541\n",
      "min: 1.3881332718040702\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4089279719130132\n",
      "std: 0.0035127285931978772\n",
      "min: 1.3881332718040702\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.08978858168136059\n",
      "min: 0.04932971508375973\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31563147340094116\n",
      "std: 0.3017387756038911\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6098109417108312\n",
      "std: 0.18445454638809783\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03328163486275053\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1148099095166206\n",
      "std: 0.3198640590487329\n",
      "min: -0.11120208507519017\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1269957138436233\n",
      "std: 0.31973762638639325\n",
      "min: -0.11120208507519017\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.09712802736736682\n",
      "min: 0.014188233301488481\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3308094223666679\n",
      "std: 0.3644783654316661\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4696959022228006\n",
      "std: 0.21675456079193403\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03240812791563668\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4052133974204788\n",
      "std: 0.011891893656536884\n",
      "min: 1.3481243739037365\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405531321335492\n",
      "std: 0.011781070184977524\n",
      "min: 1.3481243739037365\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.08979856399600339\n",
      "min: 0.04753390799669559\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3177305957668099\n",
      "std: 0.30211777257345995\n",
      "min: -0.787348876746184\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6125062895009324\n",
      "std: 0.18588732867348187\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033318184041894724\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1158138985226966\n",
      "std: 0.3253701236130728\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1277192177277187\n",
      "std: 0.3271331587150967\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.09790617131969744\n",
      "min: 0.010317216955760999\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33474469392927153\n",
      "std: 0.36840547039838323\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46937134034847633\n",
      "std: 0.21803424981376393\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03247742993893378\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4041086900181647\n",
      "std: 0.014804074364998941\n",
      "min: 1.3294247359252644\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.404440735998019\n",
      "std: 0.014890122461230672\n",
      "min: 1.3294247359252644\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.08981018270265105\n",
      "min: 0.0465299249306243\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31740006358610356\n",
      "std: 0.30163218118604795\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6122581415198204\n",
      "std: 0.18639880081924814\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327368466798204\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1482959783861464\n",
      "std: 0.22981324911421552\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1578363696813898\n",
      "std: 0.23244264459667674\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.09128113334821047\n",
      "min: 0.016328565126136847\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3197451224144278\n",
      "std: 0.36875160623562886\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48107959752488755\n",
      "std: 0.2173969331297061\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.0321325855004095\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074239264446637\n",
      "std: 0.005201085856894532\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407616193079955\n",
      "std: 0.0052408973325544055\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.08669896092928657\n",
      "min: 0.04689130122313532\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31234948854601685\n",
      "std: 0.3023284035305633\n",
      "min: -0.7852794356729709\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6143072800991145\n",
      "std: 0.18397123740941623\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03317998631306858\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1399264752772207\n",
      "std: 0.2537823339208216\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1499063430189855\n",
      "std: 0.25732843841541064\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.09301959280408288\n",
      "min: 0.016619238648458257\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31901983834975683\n",
      "std: 0.37589329416653006\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48018208335983625\n",
      "std: 0.22026744922883437\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032161847648554086\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064694917475573\n",
      "std: 0.007797485922238184\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067014184560775\n",
      "std: 0.007834145425727248\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.08670332979366224\n",
      "min: 0.046210538134218104\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31081172197552875\n",
      "std: 0.3021811445128001\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6145187707572128\n",
      "std: 0.1839108760544362\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033093655643353544\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2117936442122883\n",
      "std: 0.10391463612872892\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2188974708387619\n",
      "std: 0.11187037298994473\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.08828482308915656\n",
      "min: 0.03187752219177068\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3391660677358535\n",
      "std: 0.3658078991188551\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46840263317419123\n",
      "std: 0.21795354393081268\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03279222142819376\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4086954286817996\n",
      "std: 0.0031836171383072646\n",
      "min: 1.3881332718040702\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088082678256322\n",
      "std: 0.0035160438977543153\n",
      "min: 1.3881332718040702\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.08669766921516067\n",
      "min: 0.046849310391537675\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3160777404816771\n",
      "std: 0.3018736522911545\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6097168073145268\n",
      "std: 0.18441417618279884\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033306887047680325\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1176954742636052\n",
      "std: 0.31273970461303197\n",
      "min: -0.11120208507519017\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1285913066524473\n",
      "std: 0.3127966793827893\n",
      "min: -0.11120208507519017\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.0936448051881607\n",
      "min: 0.014188233301488481\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3331204375281947\n",
      "std: 0.36357683796843954\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4675212027143273\n",
      "std: 0.2173931808349082\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032501290880589805\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405304614165133\n",
      "std: 0.01164199469495193\n",
      "min: 1.3481243739037365\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4055469818576884\n",
      "std: 0.011546152469350087\n",
      "min: 1.3481243739037365\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.08670714296365853\n",
      "min: 0.045382455712560624\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31815564364970367\n",
      "std: 0.3022368996067013\n",
      "min: -0.787348876746184\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6123150714190144\n",
      "std: 0.18580151978569878\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03334396723693955\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1185269311439952\n",
      "std: 0.3191554215260823\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1291630660523841\n",
      "std: 0.32104592684629185\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.09438026594593599\n",
      "min: 0.010317216955760999\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3369771598827343\n",
      "std: 0.3673223061972413\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.467187056104394\n",
      "std: 0.2185960836931339\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03256584719775358\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4042410755381056\n",
      "std: 0.01451512061816448\n",
      "min: 1.3294247359252644\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.404495635457478\n",
      "std: 0.014612681097327258\n",
      "min: 1.3294247359252644\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.08671813966378081\n",
      "min: 0.044397762677550474\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3178107400103875\n",
      "std: 0.301754473593356\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6120633194464635\n",
      "std: 0.18627879476750117\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03329996018615659\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1514099551067811\n",
      "std: 0.22598340783584805\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1602544549993137\n",
      "std: 0.22864735895372906\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08817844722402741\n",
      "min: 0.016328565126136844\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32558562380922007\n",
      "std: 0.36926732883308616\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4774398125233076\n",
      "std: 0.22077200998476784\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03240866624425189\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075180069691344\n",
      "std: 0.0051423622067431896\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077148327847369\n",
      "std: 0.00516975894250059\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08382795063177183\n",
      "min: 0.04459724204272511\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3128555087593002\n",
      "std: 0.30247553341328204\n",
      "min: -0.7852794356729709\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6141513881627988\n",
      "std: 0.1840390393650025\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033194459771443384\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.143368891974862\n",
      "std: 0.2502645246169652\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1526228865022294\n",
      "std: 0.25380312998897425\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.0898256769653966\n",
      "min: 0.015691326148363275\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32497007548128737\n",
      "std: 0.3761193827137874\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47653689780257197\n",
      "std: 0.22347905544063434\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03243552440462703\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406600202214952\n",
      "std: 0.007709495666109561\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4068336414545837\n",
      "std: 0.007739916925306075\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08383210153553139\n",
      "min: 0.043956039462618425\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3113667834035566\n",
      "std: 0.3023189009127405\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6143342768894903\n",
      "std: 0.1839712495340584\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033110696485161434\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2124055266015503\n",
      "std: 0.10298400298092704\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2190339139602375\n",
      "std: 0.11081084400389159\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08533445083134386\n",
      "min: 0.028452937912743996\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.344188710234209\n",
      "std: 0.36611561214514227\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4651618374378538\n",
      "std: 0.22115554909280785\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033034150645075935\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087487291644425\n",
      "std: 0.003147320507824947\n",
      "min: 1.3881332718040702\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088709055111106\n",
      "std: 0.0034567064595592955\n",
      "min: 1.3881332718040702\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08382671984568428\n",
      "min: 0.04485025432342875\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3164406859406882\n",
      "std: 0.3020263089365485\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6096983787281867\n",
      "std: 0.18446914075940044\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03331724969718155\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.122566790267017\n",
      "std: 0.30599567195712224\n",
      "min: -0.11120208507519017\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1326304793265456\n",
      "std: 0.30622242542646977\n",
      "min: -0.11120208507519017\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.09041854223904079\n",
      "min: 0.014188233301488481\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33847817677715347\n",
      "std: 0.36414308730871225\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4644018027790781\n",
      "std: 0.2205966945431277\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032762017173852694\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4054904541770576\n",
      "std: 0.011450905569858111\n",
      "min: 1.3481243739037365\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4057301494544268\n",
      "std: 0.011359884319714174\n",
      "min: 1.3481243739037365\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08383573982421176\n",
      "min: 0.043038594308313666\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3184935966919803\n",
      "std: 0.3023774164667515\n",
      "min: -0.787348876746184\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6122085442153817\n",
      "std: 0.18581303750659595\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03335457341919383\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1232220726529973\n",
      "std: 0.3132745386124027\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1330457719429445\n",
      "std: 0.31528564753405164\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.09111582932757985\n",
      "min: 0.010317216955760999\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3422503773811\n",
      "std: 0.36770446292504677\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4640582561397624\n",
      "std: 0.22172943729026182\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03282195665014947\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.404465771655965\n",
      "std: 0.01430318737317039\n",
      "min: 1.329302628401904\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4047157603351463\n",
      "std: 0.014404491616956804\n",
      "min: 1.329302628401904\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08384618150353548\n",
      "min: 0.04216070043271431\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31813386336081967\n",
      "std: 0.3018990747066216\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6119551773898869\n",
      "std: 0.18625942494109513\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033310997101916116\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1515026389564034\n",
      "std: 0.22235509820301258\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1600122352181905\n",
      "std: 0.22513408176610572\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08529355296013909\n",
      "min: 0.016328565126136844\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3274699177413562\n",
      "std: 0.36845084258974226\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47375223127609006\n",
      "std: 0.22216239626900325\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0324922786223317\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075869361232554\n",
      "std: 0.005048805756807644\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077754865136825\n",
      "std: 0.005082639665393395\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08115377968427143\n",
      "min: 0.04271366640544008\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31307590350384096\n",
      "std: 0.3023851706820311\n",
      "min: -0.7852794356729709\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6136329404709282\n",
      "std: 0.18399133659548914\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033200507293497064\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.143933813608003\n",
      "std: 0.2452786718918229\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1528181860666888\n",
      "std: 0.24895974024117712\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08685540387412556\n",
      "min: 0.015691326148363275\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3269549738695361\n",
      "std: 0.37503285807332903\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47287115312157185\n",
      "std: 0.22473888751309246\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032518309816807284\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4067121132427307\n",
      "std: 0.007539364642171346\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406934169264119\n",
      "std: 0.007579236840225827\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08115772236975498\n",
      "min: 0.04218005042418324\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.311631849662687\n",
      "std: 0.30222076821620864\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6137904203785535\n",
      "std: 0.18391778977729795\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03311905846736617\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2101131387557849\n",
      "std: 0.10148580649760916\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2166021437138976\n",
      "std: 0.10933254036945683\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08258699695789651\n",
      "min: 0.028452937912743996\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3453836366311237\n",
      "std: 0.3652960982958856\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46189123085929784\n",
      "std: 0.22239945807121367\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03309294331466323\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408754942874921\n",
      "std: 0.0030921948700541025\n",
      "min: 1.3881332718040702\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088742314822695\n",
      "std: 0.0034037095516536104\n",
      "min: 1.3881332718040702\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08115260701106325\n",
      "min: 0.04294271996079276\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31653214246549516\n",
      "std: 0.3019455746189528\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6093152043559272\n",
      "std: 0.18440316430927553\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03331958441380254\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1234410108772803\n",
      "std: 0.30266632308722696\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1330858216966424\n",
      "std: 0.303033221494581\n",
      "min: -0.18769022866504992\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08742525156746685\n",
      "min: 0.011068364309978722\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.339931289811654\n",
      "std: 0.3634442434566677\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.461179473965865\n",
      "std: 0.22183916238982843\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03283438517745707\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405611920839293\n",
      "std: 0.011336481397844949\n",
      "min: 1.3481243739037365\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4058388229881857\n",
      "std: 0.011253829209239848\n",
      "min: 1.3481243739037365\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08116123033478238\n",
      "min: 0.04117049061845899\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3185568796336416\n",
      "std: 0.30228060323834605\n",
      "min: -0.787348876746184\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6117376393189642\n",
      "std: 0.18571154211302318\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03335694558404558\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1240970244366697\n",
      "std: 0.3089556565278314\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1335135147781585\n",
      "std: 0.3111109398635553\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08808543165642585\n",
      "min: 0.008725245544753972\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34363547806824885\n",
      "std: 0.3668530723439094\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46084861059924354\n",
      "std: 0.22290636976341266\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032891713194506886\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4046309466390847\n",
      "std: 0.014109076258250003\n",
      "min: 1.3281260373548938\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4048660593084823\n",
      "std: 0.01421927013715934\n",
      "min: 1.3281260373548938\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08117115499194616\n",
      "min: 0.040316535429580934\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3181850515645767\n",
      "std: 0.30180591700336096\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6114813746139528\n",
      "std: 0.18612989646712363\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03331374653781136\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1528225850991962\n",
      "std: 0.2183395719853991\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1608410602081987\n",
      "std: 0.22116870560613144\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.08260364834648468\n",
      "min: 0.016328565126136844\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32150249471315767\n",
      "std: 0.3721792064235404\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47549910139999807\n",
      "std: 0.22214776903326464\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032400735022272066\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076702493197786\n",
      "std: 0.004991867935804916\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078429011028877\n",
      "std: 0.005027945285906659\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.07865647402314545\n",
      "min: 0.0408257110028939\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31255838138301695\n",
      "std: 0.30262296262691857\n",
      "min: -0.7852794356729709\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6137263699904641\n",
      "std: 0.18395171155865062\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033186961698297865\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1455709838254988\n",
      "std: 0.2408433657556408\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1539362232398176\n",
      "std: 0.2445618891934316\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.08408948544995866\n",
      "min: 0.01569132614836328\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32107854505275824\n",
      "std: 0.3783975987318984\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4746298868741536\n",
      "std: 0.22462186950143567\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03242619366803385\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068318793928252\n",
      "std: 0.007412416281105223\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070356487471376\n",
      "std: 0.0074568938216355\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.07866022896248266\n",
      "min: 0.04042133502034423\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31115461617042156\n",
      "std: 0.3024480827227012\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6138624823402028\n",
      "std: 0.18387076711120118\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03310758663480856\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.208998343136975\n",
      "std: 0.10130205670105107\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2151757071253435\n",
      "std: 0.10893166852206827\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.08002464751370875\n",
      "min: 0.025832038177094833\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3388256652271246\n",
      "std: 0.3692979866009896\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4639711026455551\n",
      "std: 0.2224383379647961\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03298200981989555\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087931630481103\n",
      "std: 0.0030632759809747483\n",
      "min: 1.38813327180407\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408900965939255\n",
      "std: 0.0033724187814549913\n",
      "min: 1.38813327180407\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.07865535310321227\n",
      "min: 0.04100978039024602\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3158976943131237\n",
      "std: 0.30219750878459883\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6095306077407521\n",
      "std: 0.18435511898544105\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033302614675792264\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1256902586905113\n",
      "std: 0.2976743210832008\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1347608512458958\n",
      "std: 0.2981609013100513\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.08463587793157473\n",
      "min: 0.011068364309978724\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3335909149754327\n",
      "std: 0.36751483650928696\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46335858400666036\n",
      "std: 0.22192894037235958\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03273375765287769\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4057637497754707\n",
      "std: 0.011182446681909926\n",
      "min: 1.3481243739037365\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4059700255879675\n",
      "std: 0.011107222696404384\n",
      "min: 1.3481243739037365\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.07866360000778617\n",
      "min: 0.039430006423521555\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31789097723704823\n",
      "std: 0.3025245524288936\n",
      "min: -0.787348876746184\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6118779360092585\n",
      "std: 0.1856257837960778\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033339931975652035\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.126275769363519\n",
      "std: 0.3041186210161017\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.135128820189108\n",
      "std: 0.30636022708107546\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.08526355011936756\n",
      "min: 0.008725245544753972\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3372096151175221\n",
      "std: 0.37079855287894564\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4630346595897131\n",
      "std: 0.22293747671880124\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03278860000011949\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.404822241218688\n",
      "std: 0.013886089122460319\n",
      "min: 1.328126037354894\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4050350733869736\n",
      "std: 0.01400389631496947\n",
      "min: 1.328126037354894\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.07867305189574783\n",
      "min: 0.03876999555011502\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31750627649979746\n",
      "std: 0.3020546255193682\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6116217019653403\n",
      "std: 0.18601798392741623\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03329705554502578\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1544581590074072\n",
      "std: 0.214299833323294\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1619480636354893\n",
      "std: 0.21723064928593894\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.08008830612712703\n",
      "min: 0.01496309527221537\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3215574688242116\n",
      "std: 0.37039330949228666\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4766476344570372\n",
      "std: 0.2211959170020727\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032298610731351304\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076741475107661\n",
      "std: 0.0049108146576777355\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077936648036296\n",
      "std: 0.0049609837006304724\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07631868166301589\n",
      "min: 0.03940785738828199\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3125429340405646\n",
      "std: 0.30237732143687823\n",
      "min: -0.7852794356729709\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.613663001917689\n",
      "std: 0.18380089228987467\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033177553095590784\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1474375067775886\n",
      "std: 0.2368205086449866\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.155252702376493\n",
      "std: 0.24060087106470793\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.08150558365090572\n",
      "min: 0.014998497372787259\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32121886881994555\n",
      "std: 0.3764054677977122\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47575870014727717\n",
      "std: 0.2235861413491993\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032323625712841995\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068634555555302\n",
      "std: 0.007309560509541014\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070119791695386\n",
      "std: 0.007361345149931134\n",
      "min: 1.370081783950066\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07632227022170407\n",
      "min: 0.03868705865181371\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3111790359626958\n",
      "std: 0.30219480735637183\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6137748084844404\n",
      "std: 0.1837147964666628\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03310023449638764\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1282976858880132\n",
      "std: 0.2923888651620846\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1367618924288487\n",
      "std: 0.29303197254061947\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.08202897405241029\n",
      "min: 0.011068364309978724\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3332967077985392\n",
      "std: 0.36587266838239213\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4648829010671359\n",
      "std: 0.22104400311586786\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03262366412512006\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405832585007866\n",
      "std: 0.01100160439061986\n",
      "min: 1.348021896137743\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4059812640935971\n",
      "std: 0.010938692925980814\n",
      "min: 1.348021896137743\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07632550530720504\n",
      "min: 0.03787120461101194\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3177397435509512\n",
      "std: 0.3022772342982209\n",
      "min: -0.787348876746184\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6118527851166766\n",
      "std: 0.18543179164608417\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03332730504550218\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2084088856305428\n",
      "std: 0.1003601295710616\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2142138719717885\n",
      "std: 0.10800551617686956\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07762637775664788\n",
      "min: 0.025832038177094833\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3382918543855991\n",
      "std: 0.3675645979133829\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46539643365575456\n",
      "std: 0.22152973129417045\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03286089050079424\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087625334245721\n",
      "std: 0.0030403003129258793\n",
      "min: 1.38813327180407\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088207465398155\n",
      "std: 0.0033625162933514\n",
      "min: 1.38813327180407\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07631761005399916\n",
      "min: 0.039429100818063785\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31577217277881126\n",
      "std: 0.30196059385852353\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6095748615715256\n",
      "std: 0.1841946811613463\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03328999579238822\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.128785538969472\n",
      "std: 0.29916466891749427\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.137043086580984\n",
      "std: 0.3015196796313535\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.08262773871144748\n",
      "min: 0.008725245544753972\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3368457456007129\n",
      "std: 0.3690573976720853\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4645506828662523\n",
      "std: 0.22200890382718597\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032676282021402034\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.404919395332476\n",
      "std: 0.0137116300385657\n",
      "min: 1.3219962782655488\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405073580397354\n",
      "std: 0.013836235363006695\n",
      "min: 1.3219962782655488\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.0763345414427771\n",
      "min: 0.036930928585723395\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31734412689086283\n",
      "std: 0.3018102037412075\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6115958729959827\n",
      "std: 0.18580028864405432\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03328470960411152\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1565635573310584\n",
      "std: 0.21084297124979362\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1635395969494864\n",
      "std: 0.2137693839485271\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.077731779269\n",
      "min: 0.012953919620569458\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32574181385449985\n",
      "std: 0.37069485027323673\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4753975698288813\n",
      "std: 0.22130812125160707\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03235346114613571\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407661147560174\n",
      "std: 0.0048765501268386744\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077295113415333\n",
      "std: 0.004944300538594787\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.07412526987250778\n",
      "min: 0.037693493416227866\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.313175509759198\n",
      "std: 0.30249053287483163\n",
      "min: -0.7871924589197588\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6134497806723134\n",
      "std: 0.1838808193020162\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319295085832108\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1498256999510301\n",
      "std: 0.23258857381223028\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1571063069009042\n",
      "std: 0.2363731633238916\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.07908499908047198\n",
      "min: 0.01409781528698875\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3254520988234882\n",
      "std: 0.37648003101450284\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.474493805594597\n",
      "std: 0.223610449891691\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032376679772993806\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068814873037807\n",
      "std: 0.007247320909549414\n",
      "min: 1.3677479395215844\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069768703068066\n",
      "std: 0.007307744353166789\n",
      "min: 1.3681908654463255\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.07412870622707816\n",
      "min: 0.03700087468183117\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31184634905738445\n",
      "std: 0.302303689608917\n",
      "min: -0.7867949373052625\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6135401392281055\n",
      "std: 0.18378995275571808\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03311750444179161\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1314074173905968\n",
      "std: 0.2872686427262857\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1392845747858567\n",
      "std: 0.2879958955622586\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.0795879146172558\n",
      "min: 0.011068364309978724\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33712672142269307\n",
      "std: 0.36620758967181205\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4639922930349397\n",
      "std: 0.22112607110747648\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03266880057340291\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4058871966255055\n",
      "std: 0.010846044616189274\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4059808189271756\n",
      "std: 0.010797499490588738\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.07413181312720703\n",
      "min: 0.03628309929596255\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3182418724949937\n",
      "std: 0.3023815056918679\n",
      "min: -0.7876075524056428\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6116755846003584\n",
      "std: 0.18546928805682664\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033339524683505706\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2085415991742836\n",
      "std: 0.09893750413337861\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2139679586878507\n",
      "std: 0.10648910905424047\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.0753768000335011\n",
      "min: 0.025832038177094833\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3418902122788778\n",
      "std: 0.36774477995791505\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4644286224272986\n",
      "std: 0.2215869942814235\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032894425586992425\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087196714802517\n",
      "std: 0.0030501708913690797\n",
      "min: 1.38813327180407\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4087299207629325\n",
      "std: 0.0033948847994132096\n",
      "min: 1.38813327180407\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.07412424195634201\n",
      "min: 0.03787799584237517\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31629701998421683\n",
      "std: 0.30207511493478517\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6094652230391269\n",
      "std: 0.18426198484046205\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03330220106384064\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1319218430677593\n",
      "std: 0.2935440209235757\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1396000386308112\n",
      "std: 0.29597046101729846\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.08015875516479014\n",
      "min: 0.008725245544753972\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34060380943375024\n",
      "std: 0.36924990375804645\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4636434668025823\n",
      "std: 0.2220456293299621\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032718444400665285\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4050072454332543\n",
      "std: 0.013543421767033319\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4051053078681386\n",
      "std: 0.013676021037696119\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.07414046358307229\n",
      "min: 0.035514030830163204\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3178360584132256\n",
      "std: 0.3019179605705349\n",
      "min: -0.7898164726898779\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6114180664140229\n",
      "std: 0.18581526301386028\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033297188312081366\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1596624058087734\n",
      "std: 0.20777262796063076\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.166704778785736\n",
      "std: 0.21068216047370908\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07551893946747394\n",
      "min: 0.012953919620569458\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32668840115604486\n",
      "std: 0.37087816927333556\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47434609030420904\n",
      "std: 0.22086270774811395\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03234881996788042\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077448660990846\n",
      "std: 0.004796664916864063\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407803417732121\n",
      "std: 0.004859362525734991\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07206296770666784\n",
      "min: 0.03641705765880073\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31362604298623936\n",
      "std: 0.3026507103767667\n",
      "min: -0.7913196044999236\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6132554080715946\n",
      "std: 0.18395823706920292\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319985268092045\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1531055603658726\n",
      "std: 0.2297749435250652\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1604343655291638\n",
      "std: 0.23353599115793966\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.0768145590219702\n",
      "min: 0.012277480605241307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3264647892275941\n",
      "std: 0.37645218399734054\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4734480289375144\n",
      "std: 0.22308572785481798\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03237136104982856\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069915877571137\n",
      "std: 0.007138799128395823\n",
      "min: 1.3677479395215844\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070753858845437\n",
      "std: 0.007196084541984149\n",
      "min: 1.3681908654463255\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07206626114129386\n",
      "min: 0.035781078668454175\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3123310177692093\n",
      "std: 0.3024594085172959\n",
      "min: -0.7903948481249875\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6133283210969269\n",
      "std: 0.18386274501182104\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03312621127950989\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2099341868967088\n",
      "std: 0.09781297241237366\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2155538652122142\n",
      "std: 0.1050772853299988\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.073262409785151\n",
      "min: 0.02477128742990695\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34231394082218397\n",
      "std: 0.3679322085182908\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46366235251817856\n",
      "std: 0.2211025864679676\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03287151164943763\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087699023005587\n",
      "std: 0.00300485235348705\n",
      "min: 1.38813327180407\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4087731258830412\n",
      "std: 0.003336154567240604\n",
      "min: 1.38813327180407\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07206198182007867\n",
      "min: 0.03666484369601149\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3166481483331014\n",
      "std: 0.3022380462050504\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6093703082033178\n",
      "std: 0.1843280015222079\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033306135360307534\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1354866265801307\n",
      "std: 0.28262880119781486\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1433604092335186\n",
      "std: 0.28344563373960113\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07729697715126352\n",
      "min: 0.011068364309978724\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3377580626024013\n",
      "std: 0.36650100659617973\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4632875926536724\n",
      "std: 0.22066442848536533\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03265545010619159\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4060416902349118\n",
      "std: 0.010630660515568404\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40612115904794\n",
      "std: 0.010587119951660433\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07206924201074927\n",
      "min: 0.03536053342928208\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3185714115018049\n",
      "std: 0.30253717541093506\n",
      "min: -0.7919169564135115\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6115160875726963\n",
      "std: 0.18550727914154916\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03334348581959739\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1359413318446028\n",
      "std: 0.2894693039530021\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1436252093184869\n",
      "std: 0.2919618780971457\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07784336400620516\n",
      "min: 0.007525264474855244\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34117541026073794\n",
      "std: 0.36943347016396927\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4629499543873584\n",
      "std: 0.22154247563096532\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0327032851143209\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4051887665227702\n",
      "std: 0.013299686056196925\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4052717927012697\n",
      "std: 0.01343566390041029\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07207753029660684\n",
      "min: 0.034729545943131705\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3181580365000564\n",
      "std: 0.302077330879768\n",
      "min: -0.7907729109645121\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6112605903317299\n",
      "std: 0.18583233844843827\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03330153322291937\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1634110417449117\n",
      "std: 0.2050169071917968\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.170461964058004\n",
      "std: 0.20793380436115305\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07343643621865699\n",
      "min: 0.012243285406212305\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32670518590410974\n",
      "std: 0.3710737480106084\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4748205435214687\n",
      "std: 0.22016302214377212\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03237922179310199\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078165802992266\n",
      "std: 0.004731912100235167\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078846158094185\n",
      "std: 0.004786645401406194\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07012010427470691\n",
      "min: 0.03509341644170703\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31349024292695515\n",
      "std: 0.3026724483284111\n",
      "min: -0.7913196044999237\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6131343276473021\n",
      "std: 0.18393479585821573\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319473684426393\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1571170968526703\n",
      "std: 0.22635575088804794\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1644370851871362\n",
      "std: 0.23013408578280703\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07467775669338882\n",
      "min: 0.012277480605241307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3265344348041795\n",
      "std: 0.37645478156129525\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4739266717780823\n",
      "std: 0.22231722339069618\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03240087624686047\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070854725514363\n",
      "std: 0.007056339846678562\n",
      "min: 1.3677479395215841\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071772504864128\n",
      "std: 0.007109209767758784\n",
      "min: 1.3681908654463255\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07012326727161136\n",
      "min: 0.034563493790772185\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31222637024260935\n",
      "std: 0.30247595268320543\n",
      "min: -0.7903948481249876\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6131914577403074\n",
      "std: 0.18383496283412326\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03312275627220319\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2120827631757418\n",
      "std: 0.09607097009199113\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2178267551364617\n",
      "std: 0.10320416152162208\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07127031986107514\n",
      "min: 0.024771287429906946\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3418435215031175\n",
      "std: 0.36817776543453334\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46439500985076776\n",
      "std: 0.22042203217029935\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032884846078669656\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4088158299361915\n",
      "std: 0.0029671671401859225\n",
      "min: 1.38813327180407\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088310938776467\n",
      "std: 0.003280813993104499\n",
      "min: 1.38813327180407\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07011915674223958\n",
      "min: 0.035320778930038585\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31641932877938483\n",
      "std: 0.30226933563220254\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6093435808276351\n",
      "std: 0.18429483278306033\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033298218192652385\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1402024168850025\n",
      "std: 0.2783865318059033\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.148024551345983\n",
      "std: 0.27929774573479516\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07514203775594155\n",
      "min: 0.010814142092913278\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3374726491202629\n",
      "std: 0.3668267451525335\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4640832530746808\n",
      "std: 0.22000657247598843\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03267792731977415\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4061795810942337\n",
      "std: 0.010439504983255502\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4062652398846132\n",
      "std: 0.010400135185508976\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.0701261308816666\n",
      "min: 0.03406486002153758\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3183179187974375\n",
      "std: 0.3025621498671769\n",
      "min: -0.7919169564135113\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6114309769421562\n",
      "std: 0.18544704871398493\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03333550475354589\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1406974809866481\n",
      "std: 0.2846942354385943\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1483372069799707\n",
      "std: 0.2872644462052873\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07566483780388689\n",
      "min: 0.007525264474855244\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3408261845056259\n",
      "std: 0.3696628810330632\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46374774533054036\n",
      "std: 0.22084975074831287\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03272360702629141\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405352085652232\n",
      "std: 0.013091997606538099\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405440454362692\n",
      "std: 0.01323085206317115\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07013408735143875\n",
      "min: 0.033341686664384966\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3178973732735062\n",
      "std: 0.3021065587652904\n",
      "min: -0.7907729109645121\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6111773420818493\n",
      "std: 0.1857529656756281\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03329388887775319\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1651666980007107\n",
      "std: 0.2013204643321795\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1719338844621765\n",
      "std: 0.2042574154012622\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.0714730727502398\n",
      "min: 0.012243285406212305\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32503718481549193\n",
      "std: 0.3694462496413556\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47320796819800653\n",
      "std: 0.2192399187152795\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032285457588552446\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407842286904037\n",
      "std: 0.0046726492931128735\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078933511454552\n",
      "std: 0.004736357581754407\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.06828636343885139\n",
      "min: 0.0339153799616789\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3132003844327693\n",
      "std: 0.30257484632658305\n",
      "min: -0.7913196044999237\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6127766225169393\n",
      "std: 0.18381524419772718\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03317444348778133\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.159087885081485\n",
      "std: 0.22219335256546704\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1661070232206756\n",
      "std: 0.22599463466263547\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.07266456328913375\n",
      "min: 0.012277480605241307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32491728414725396\n",
      "std: 0.3746684314834286\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47231625233868024\n",
      "std: 0.22133430844331425\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03230638498656541\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071353614656341\n",
      "std: 0.0069578714761572335\n",
      "min: 1.3677479395215841\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072086867740945\n",
      "std: 0.0070182027186253704\n",
      "min: 1.3681908654463255\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.06828940334599672\n",
      "min: 0.03339797779179514\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31196570067642926\n",
      "std: 0.3023731721682553\n",
      "min: -0.7903948481249876\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6128180006644478\n",
      "std: 0.18371242735208482\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03310401907545649\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2120921741944064\n",
      "std: 0.09484559352882398\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2176532502568582\n",
      "std: 0.10189624547524433\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.06939213619957917\n",
      "min: 0.02427694678421792\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33972763155642416\n",
      "std: 0.3666539898178746\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4630274742172077\n",
      "std: 0.21944802027596974\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032777200820092625\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4088144062758345\n",
      "std: 0.0029483410141086454\n",
      "min: 1.38813327180407\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088152157759344\n",
      "std: 0.0032671487123166255\n",
      "min: 1.38813327180407\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.06828545186772189\n",
      "min: 0.03390258366933751\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31604451351918894\n",
      "std: 0.3021817987802151\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6090735139693713\n",
      "std: 0.18416271117604818\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033275452179586426\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.142579541678443\n",
      "std: 0.2740384865586363\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1500712281408465\n",
      "std: 0.2750155530014948\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666668\n",
      "std: 0.07311268259649104\n",
      "min: 0.010814142092913278\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33551626754479524\n",
      "std: 0.3653374359209904\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4627601641902931\n",
      "std: 0.21903132445756987\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032576985755538565\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406258260770562\n",
      "std: 0.01029542633292764\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4063241844671996\n",
      "std: 0.01026374461252167\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.06829216635737109\n",
      "min: 0.0327884775633616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31791615808217466\n",
      "std: 0.3024670723824971\n",
      "min: -0.7919169564135113\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.611105401084383\n",
      "std: 0.18529157066080112\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033312489328334687\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1430668772615553\n",
      "std: 0.2800858482323788\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1503813966159713\n",
      "std: 0.2827085906937287\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.07361413921440073\n",
      "min: 0.007525264474855244\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3388118311129924\n",
      "std: 0.3681141579077261\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4624247185888143\n",
      "std: 0.21984994829880522\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032621123737631055\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4054598384863912\n",
      "std: 0.012902418801408834\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4055275582268365\n",
      "std: 0.01304779440383061\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.06829981105703371\n",
      "min: 0.03216443914618057\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3174884407924115\n",
      "std: 0.302015440853344\n",
      "min: -0.7907729109645121\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6108517683418827\n",
      "std: 0.18558039600200069\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327117500497\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1660093184576692\n",
      "std: 0.19784924720139188\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1724721288403828\n",
      "std: 0.2008637839077574\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06961935940681127\n",
      "min: 0.012243285406212305\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32504928637590663\n",
      "std: 0.37027547546445666\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4717058149540304\n",
      "std: 0.2190284683729012\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03229468741562435\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079312327467781\n",
      "std: 0.004607309384941595\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407981516821988\n",
      "std: 0.004670436134210492\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06655259119114693\n",
      "min: 0.03275467139848352\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31300821581298066\n",
      "std: 0.30261193506357625\n",
      "min: -0.7913196044999237\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6124090859524309\n",
      "std: 0.1837575037479382\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03316715081077039\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1601240983036027\n",
      "std: 0.21848996470387322\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1668257088534872\n",
      "std: 0.2223535187016317\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.07076484907455269\n",
      "min: 0.012277480605241307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32497433760076155\n",
      "std: 0.3753117942512086\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4708126710223914\n",
      "std: 0.221054089958538\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032314786408330465\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072473581365805\n",
      "std: 0.006860337228108768\n",
      "min: 1.3677479395215841\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073185592010415\n",
      "std: 0.006922131293702325\n",
      "min: 1.3681908654463255\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06655551664206215\n",
      "min: 0.03235674670407188\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3118009074329097\n",
      "std: 0.30240571345193645\n",
      "min: -0.7903948481249876\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6124375983839507\n",
      "std: 0.1836516422271996\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03309818573993639\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.211319504368197\n",
      "std: 0.09407490375711496\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2166714140479755\n",
      "std: 0.10109060836168923\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06761745211456427\n",
      "min: 0.022280841443085894\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3393195677438167\n",
      "std: 0.36751225011955246\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46174741151923665\n",
      "std: 0.21919422293741392\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03277129218474301\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408872810780547\n",
      "std: 0.0029151580956880557\n",
      "min: 1.38813327180407\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088752309470225\n",
      "std: 0.0032262000576731274\n",
      "min: 1.38813327180407\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06655171350483892\n",
      "min: 0.032888013290618454\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3157727317704187\n",
      "std: 0.30222750444458596\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6087907020799214\n",
      "std: 0.18409260775511183\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326574481506979\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1442856218379247\n",
      "std: 0.26901750422406295\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1514235205740508\n",
      "std: 0.2701159942086971\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.0711966177603683\n",
      "min: 0.010814142092913278\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33527799929109614\n",
      "std: 0.3662843797515993\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46154486458845556\n",
      "std: 0.21877578578238668\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03257974412345026\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406401838953251\n",
      "std: 0.01012514477036136\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4064644143825487\n",
      "std: 0.010099093134225861\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06655818028569126\n",
      "min: 0.031776580125113744\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.317619445438985\n",
      "std: 0.30250713033662047\n",
      "min: -0.7919169564135113\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6107711066748922\n",
      "std: 0.18519961401451676\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033302587671877916\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1447548148644233\n",
      "std: 0.2751081386253739\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1517219100142333\n",
      "std: 0.27782780469101787\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.07167851306700457\n",
      "min: 0.007525264474855244\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3385052835137534\n",
      "std: 0.368969286834032\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46120166585822886\n",
      "std: 0.21955878869293838\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0326216638923279\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405629372096305\n",
      "std: 0.01270169151063074\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4056929299989274\n",
      "std: 0.012850974224733904\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06656553620578527\n",
      "min: 0.031170932134886486\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3171851920786404\n",
      "std: 0.30205992780715113\n",
      "min: -0.7907729109645121\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6105186374889155\n",
      "std: 0.18547224574226054\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326161141838532\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1667219038093712\n",
      "std: 0.19543605916756498\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1728486273171959\n",
      "std: 0.19846312938132146\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.0678663780364848\n",
      "min: 0.01065291048590247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32622839620654953\n",
      "std: 0.3697590843863848\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4688932517378663\n",
      "std: 0.21915096698708939\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03228088648598306\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079561388432993\n",
      "std: 0.004549075717478776\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079846582295104\n",
      "std: 0.004618068063328182\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06491064390189868\n",
      "min: 0.03177544080966923\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31306320893004447\n",
      "std: 0.30271294780057956\n",
      "min: -0.7913196044999237\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6120723341086195\n",
      "std: 0.18382960069202212\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03317191106934166\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1610304387775914\n",
      "std: 0.215731735435333\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.167383640790088\n",
      "std: 0.21959278812155855\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.0689688893704885\n",
      "min: 0.011473070600501548\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3261979255554601\n",
      "std: 0.37465096642135776\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4680026612130964\n",
      "std: 0.22111762026228046\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03230072586154693\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072932425234272\n",
      "std: 0.006773309432286593\n",
      "min: 1.3677479395215841\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073414517422\n",
      "std: 0.006839161652394042\n",
      "min: 1.3681908654463255\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06491346331533918\n",
      "min: 0.031229736640275042\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3118827205157474\n",
      "std: 0.302504230679006\n",
      "min: -0.7903948481249876\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6120878437182646\n",
      "std: 0.18372148259900573\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033104409892738725\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2106612686777831\n",
      "std: 0.09314985731181781\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2157562428633526\n",
      "std: 0.10011788725691813\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06593725396035433\n",
      "min: 0.022280841443085894\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34009871032940314\n",
      "std: 0.3670004828170298\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4591756536314597\n",
      "std: 0.21922186584190462\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03274369327579126\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4088655515559299\n",
      "std: 0.002901092850108336\n",
      "min: 1.38813327180407\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088485963552109\n",
      "std: 0.0032147489812309866\n",
      "min: 1.38813327180407\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06490979794801358\n",
      "min: 0.031891974504068665\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3157502095410054\n",
      "std: 0.3023344302156422\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6085358726985572\n",
      "std: 0.1841528067174578\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326810501051417\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1455258663131345\n",
      "std: 0.26607020850417\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1522873013407935\n",
      "std: 0.2672175922578983\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06938647868002276\n",
      "min: 0.008514510010926828\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3362089295927902\n",
      "std: 0.36583387362316616\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4589895245606941\n",
      "std: 0.21881598465599247\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03255932235606622\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064660032523766\n",
      "std: 0.009998236824611005\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406504869386467\n",
      "std: 0.009978801858478421\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06491603922593417\n",
      "min: 0.030674489808144478\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3175732500410861\n",
      "std: 0.302606676853399\n",
      "min: -0.7919169564135113\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6104638774876066\n",
      "std: 0.18523826558246678\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03330472600071595\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.145963554019295\n",
      "std: 0.2720914858314582\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1525590281601514\n",
      "std: 0.2748426317138535\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06985005560575314\n",
      "min: 0.006186380336109203\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3393843861339854\n",
      "std: 0.3684395064717371\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45864622993054344\n",
      "std: 0.21957293046339413\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03260000807010586\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4057153933383857\n",
      "std: 0.012561644635220385\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4057546341090719\n",
      "std: 0.012715034488771933\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06492313070707158\n",
      "min: 0.02985128583666252\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3171340689941669\n",
      "std: 0.302163441905274\n",
      "min: -0.7907729109645121\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6102123322250137\n",
      "std: 0.18549574993089996\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326408126635262\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.168915812570452\n",
      "std: 0.1938382198884879\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1747949632169299\n",
      "std: 0.19681455050222826\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06620561651138787\n",
      "min: 0.010119371837119922\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.327183115094709\n",
      "std: 0.3702967664009787\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4663813965780351\n",
      "std: 0.2205225370280238\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03229859583380998\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407938865513572\n",
      "std: 0.004554599261789079\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079688654575515\n",
      "std: 0.004630258143558788\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.0633532502570982\n",
      "min: 0.030531685841817237\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31336906545203697\n",
      "std: 0.30281073131266095\n",
      "min: -0.7913196044999237\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6115667499843911\n",
      "std: 0.18395681587215293\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318228699683215\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.16340937557553\n",
      "std: 0.21412048855141863\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1695041467004479\n",
      "std: 0.21791539151913397\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06726817019599714\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32718772601524404\n",
      "std: 0.375034712037305\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46549909894844665\n",
      "std: 0.22241683252169256\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03231761280769392\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407293783939319\n",
      "std: 0.006774728345258352\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073425177113605\n",
      "std: 0.006846051273392382\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.063355975013707\n",
      "min: 0.029926627462536673\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31221185289202713\n",
      "std: 0.30259921326499367\n",
      "min: -0.7903948481249876\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6115707423117481\n",
      "std: 0.1838466065431528\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03311606731598366\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.211787201045519\n",
      "std: 0.09193615190639365\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2167023147493492\n",
      "std: 0.09879837560561405\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06434365086653013\n",
      "min: 0.0222808414430859\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3406552544224425\n",
      "std: 0.3675491178352997\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45690610696599754\n",
      "std: 0.22049999986750807\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03274743327392707\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4088354570605097\n",
      "std: 0.002908964611561073\n",
      "min: 1.3871969056270168\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088217121041868\n",
      "std: 0.003227524802965391\n",
      "min: 1.3871969056270168\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06335243092681071\n",
      "min: 0.0306956429137788\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31597877751041414\n",
      "std: 0.3024352637903333\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6081093130059548\n",
      "std: 0.18426618034674105\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327603991320526\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1486219910624174\n",
      "std: 0.26257845754554615\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1550915944928128\n",
      "std: 0.2637529634753649\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06767098751082085\n",
      "min: 0.008514510010926828\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33691139722013175\n",
      "std: 0.3664555072886758\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4567497217170202\n",
      "std: 0.22010522904939742\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03256981700065681\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064969716915412\n",
      "std: 0.00989932345930685\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065353714168687\n",
      "std: 0.009888867219243903\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06335846347410214\n",
      "min: 0.029550563797232848\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3177806193915716\n",
      "std: 0.3027015192093256\n",
      "min: -0.7919169564135113\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.609987723816908\n",
      "std: 0.18533046060759928\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033312504635916666\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1490136582869406\n",
      "std: 0.2688901848123671\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1553250003197033\n",
      "std: 0.271633987674884\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06811769468393278\n",
      "min: 0.006166630372460981\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3400247176520422\n",
      "std: 0.36898042364631817\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45640447236082177\n",
      "std: 0.2208328074468388\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0326088686579272\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405766509194025\n",
      "std: 0.01245674066120755\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4058048482200518\n",
      "std: 0.012616748273766503\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06336531026196597\n",
      "min: 0.02880851284671316\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3173355888498095\n",
      "std: 0.30226191420247606\n",
      "min: -0.790772910964512\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6097368818420971\n",
      "std: 0.1855737801567053\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033272163056150224\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.171091526919481\n",
      "std: 0.19146190529573084\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1769468997790897\n",
      "std: 0.19438877265230017\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06462870655505434\n",
      "min: 0.010119371837119922\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.327625506924458\n",
      "std: 0.37046381258597383\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4676303002100893\n",
      "std: 0.2197723743820456\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032318661833465975\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079709671304457\n",
      "std: 0.004510956958573654\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079761506182558\n",
      "std: 0.0045967069267568265\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06187388353446466\n",
      "min: 0.029804765893857853\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31336378108876634\n",
      "std: 0.3028675156570746\n",
      "min: -0.7913196044999237\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6114481607924981\n",
      "std: 0.1839471967631944\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033181461163949606\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.165770022551329\n",
      "std: 0.21109452508062762\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1718299467312454\n",
      "std: 0.21484833504810652\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06565365634808731\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3276599507884374\n",
      "std: 0.37506006031878475\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4667545230714106\n",
      "std: 0.22161661247037248\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032337145465394665\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073453459762826\n",
      "std: 0.006677274831694205\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073682348032548\n",
      "std: 0.006755986672184608\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06187651334043096\n",
      "min: 0.029520759628656454\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3122289725052134\n",
      "std: 0.3026535488380599\n",
      "min: -0.7903948481249876\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6114428287996576\n",
      "std: 0.1838339144376081\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03311647648010406\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2127157057283837\n",
      "std: 0.0909631877241077\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2176778977145364\n",
      "std: 0.09759190391253098\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06283048989788019\n",
      "min: 0.021532927098359758\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3407404514935946\n",
      "std: 0.36774548835287446\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4583501622389925\n",
      "std: 0.2197955049794566\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03275490264132433\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4088422092826385\n",
      "std: 0.0029050862719988122\n",
      "min: 1.3871969056270168\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088055494766258\n",
      "std: 0.003231727414228023\n",
      "min: 1.3871969056270168\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06187309175228593\n",
      "min: 0.029825986768160534\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.315904772863704\n",
      "std: 0.3024981997748386\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6080636420590206\n",
      "std: 0.18424912796111845\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033273083451678315\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1512464024642959\n",
      "std: 0.2597772702453389\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.15766098617941\n",
      "std: 0.26096404456333433\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06604423313491391\n",
      "min: 0.0077758466438723915\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33712849759583463\n",
      "std: 0.36670719400186463\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45822594476323536\n",
      "std: 0.21942034027328092\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032583907235794476\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065753754102583\n",
      "std: 0.00975784410561461\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065870639663696\n",
      "std: 0.009755749954484225\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06187892217119856\n",
      "min: 0.028822447727763056\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31768432998802815\n",
      "std: 0.30275923317083275\n",
      "min: -0.7919169564135113\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6098959584701126\n",
      "std: 0.18529272911262284\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033309388916276154\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1516532674205808\n",
      "std: 0.2656292293797735\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.157915316681855\n",
      "std: 0.26837087591437725\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06647477434593503\n",
      "min: 0.006166630372460981\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3401913182638557\n",
      "std: 0.36915746950509837\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4578853439195832\n",
      "std: 0.22012253006347307\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03262162900666732\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4058681356411524\n",
      "std: 0.012259109833299434\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4058792338858583\n",
      "std: 0.012424812652300696\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.061885529693412794\n",
      "min: 0.028404777817241975\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31723482378028517\n",
      "std: 0.30232354846928033\n",
      "min: -0.790772910964512\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6096474238249274\n",
      "std: 0.1855224114668367\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326933883696967\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1721928683342804\n",
      "std: 0.18881196127060942\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1776020523649096\n",
      "std: 0.1917610689019523\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06313003076147403\n",
      "min: 0.010119371837119922\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32843311838271183\n",
      "std: 0.3706167874575822\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4673740914911098\n",
      "std: 0.21908590613639084\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03231719475960262\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407996855842317\n",
      "std: 0.00445555497276863\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407993351985208\n",
      "std: 0.004539273190876409\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06046668818048593\n",
      "min: 0.028946990055064462\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3133020823526305\n",
      "std: 0.30297588618652926\n",
      "min: -0.7913196044999237\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6114623284345655\n",
      "std: 0.18387277684536785\n",
      "min: 0.16771075385624476\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03317770908706508\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1670129707100976\n",
      "std: 0.2081468920677371\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.172618155429508\n",
      "std: 0.21190384644677276\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06412014390536155\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3284984308920222\n",
      "std: 0.3750809172981705\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46649646100304926\n",
      "std: 0.22088506289592227\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032335079702602174\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073873316835506\n",
      "std: 0.006596421260202982\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074006474790055\n",
      "std: 0.00667424289446965\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.060469230970336706\n",
      "min: 0.028468489237100006\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3121897498521234\n",
      "std: 0.30275993620242597\n",
      "min: -0.7903948481249876\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6114473046927777\n",
      "std: 0.18375709219942524\n",
      "min: 0.16849275148144816\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03311396813695671\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1528362351876837\n",
      "std: 0.2563242119586473\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.15877505230531\n",
      "std: 0.2575539608490199\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06449865282954703\n",
      "min: 0.0077758466438723915\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33772532020866464\n",
      "std: 0.36693292971345853\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45819188378977793\n",
      "std: 0.218742864308965\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032576848849437845\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066319131392602\n",
      "std: 0.009648964050282345\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066336048444164\n",
      "std: 0.009648761034453914\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.060471567152811635\n",
      "min: 0.02779422608202544\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3175371240610627\n",
      "std: 0.30286837254183285\n",
      "min: -0.7919169564135113\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.60993682354292\n",
      "std: 0.18519214472763965\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033303526845457496\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2126000147774323\n",
      "std: 0.09037101247786003\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.217173187962128\n",
      "std: 0.09699983928292402\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06139204248077031\n",
      "min: 0.019740216752738418\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3412108367560687\n",
      "std: 0.367920791031849\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4582796361888368\n",
      "std: 0.21910989324357028\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03274199678194335\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4088431333456946\n",
      "std: 0.0028836097888216158\n",
      "min: 1.3871969056270168\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408799487944313\n",
      "std: 0.003202768822881713\n",
      "min: 1.3871969056270168\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06046592249921451\n",
      "min: 0.028977484157109733\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31577941585491504\n",
      "std: 0.30261375435551174\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6081458095152458\n",
      "std: 0.18416958896523164\n",
      "min: 0.15904960346301836\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033267447060890604\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1532156303344248\n",
      "std: 0.2622243276354653\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1590075812748764\n",
      "std: 0.2649829043119522\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06491444545559857\n",
      "min: 0.006166630372460981\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34073560652641954\n",
      "std: 0.36931434882543535\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4578480969000855\n",
      "std: 0.21942527193297945\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032613150532522436\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4059409731058272\n",
      "std: 0.012144785679535091\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405941794056452\n",
      "std: 0.012310545769315345\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06047795897326105\n",
      "min: 0.027079480017597055\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3170836422351539\n",
      "std: 0.302437104567984\n",
      "min: -0.790772910964512\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6096900332412298\n",
      "std: 0.18540967446840964\n",
      "min: 0.16017452860144005\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326379109885118\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1718696418998795\n",
      "std: 0.18606933836203432\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1772592196910254\n",
      "std: 0.18903858599288156\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.061703745133410065\n",
      "min: 0.010119371837119922\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33026950960483237\n",
      "std: 0.37045868929376835\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46460643942507496\n",
      "std: 0.2198571125580005\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032414844399377606\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408002815723278\n",
      "std: 0.004414764687149112\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079742348419044\n",
      "std: 0.004519383329815863\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.05912638525064515\n",
      "min: 0.028081536705495\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31359755230781505\n",
      "std: 0.3030562037377436\n",
      "min: -0.7914138288123347\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6110478550507861\n",
      "std: 0.1838619638899868\n",
      "min: 0.16029776572535132\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318699579878974\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1668252821629572\n",
      "std: 0.2054858796178428\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1724025369492677\n",
      "std: 0.2092528860395025\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.06266135901447199\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3303718010933968\n",
      "std: 0.3748022585773873\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4637341525561114\n",
      "std: 0.2215974765250449\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032432030096397405\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074088953107182\n",
      "std: 0.006529889306046921\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407396421995553\n",
      "std: 0.006622246802019701\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.05912884665183065\n",
      "min: 0.02762931248325462\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31250713508932526\n",
      "std: 0.30283901846518185\n",
      "min: -0.7906479859950234\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6110234576807043\n",
      "std: 0.18374443956154846\n",
      "min: 0.16090021273511781\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033124451916834816\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1531888529177945\n",
      "std: 0.2522096881874049\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1590745061418282\n",
      "std: 0.25351797379067326\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.06302769066712227\n",
      "min: 0.0077758466438723915\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3393636210776159\n",
      "std: 0.3668209527242437\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4556370066263205\n",
      "std: 0.21943592934018596\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032668159274868463\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406674401177637\n",
      "std: 0.009529125228887667\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406649617933507\n",
      "std: 0.009540891380298977\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.05913111136835937\n",
      "min: 0.02722358511130042\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3177503754641334\n",
      "std: 0.3029459679490673\n",
      "min: -0.7919169564135113\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.609547416266628\n",
      "std: 0.18515332323855302\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033310678591680784\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.211162944866511\n",
      "std: 0.08940570098067045\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2157749787821899\n",
      "std: 0.09592489324465335\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.06002200812367253\n",
      "min: 0.019740216752738418\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3427217914371946\n",
      "std: 0.36774382062306876\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4557048255838313\n",
      "std: 0.21980345952374242\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03282708070213086\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40882709806308\n",
      "std: 0.002891009651776912\n",
      "min: 1.3859137186055552\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408760058975092\n",
      "std: 0.0032314112792425193\n",
      "min: 1.3859137186055552\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.05912564434402196\n",
      "min: 0.028066040888940543\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3160122232174908\n",
      "std: 0.30269787378102675\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6077994716054896\n",
      "std: 0.18414885787006485\n",
      "min: 0.15903830581947997\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327480991210708\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.153515556824762\n",
      "std: 0.2585467114033872\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1592613255291218\n",
      "std: 0.26135766708761643\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.0634298855542131\n",
      "min: 0.006166630372460981\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34233227112828785\n",
      "std: 0.36913602622964176\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4552950753932663\n",
      "std: 0.22009513583517817\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03270311509390271\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4060003432835335\n",
      "std: 0.01201442116199253\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405974504414625\n",
      "std: 0.012188155277371389\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.05913729948723686\n",
      "min: 0.026475954992020687\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3172944565600622\n",
      "std: 0.3025189636327705\n",
      "min: -0.7909092834075816\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6093011569825673\n",
      "std: 0.18535900183381537\n",
      "min: 0.160099877223954\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033271313043884386\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1720967243234948\n",
      "std: 0.18446705558713014\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1775616832438514\n",
      "std: 0.18736002551928116\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.060345412552073416\n",
      "min: 0.009317739624232905\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33124993284055404\n",
      "std: 0.37086935796018217\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4654189564680975\n",
      "std: 0.21987756153993274\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03242009591422211\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080389866087721\n",
      "std: 0.004377984892071898\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080190649142819\n",
      "std: 0.004477355792400956\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.057848203086161336\n",
      "min: 0.02716928936725893\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3136532172171355\n",
      "std: 0.3030448627130557\n",
      "min: -0.7914138288123347\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6110784453053019\n",
      "std: 0.18377545985542115\n",
      "min: 0.16029776572535143\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033182602307880185\n",
      "min: 0.1308270098194005\n",
      "max: 0.26659446165166767\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1672261474239969\n",
      "std: 0.20329731180645655\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.172868752105229\n",
      "std: 0.20701245902468596\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.06127198089949303\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33138152654690645\n",
      "std: 0.37509207888674295\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4645599257080617\n",
      "std: 0.2215724457752941\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03243712216426407\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074608063145702\n",
      "std: 0.006464262376404379\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074562645201512\n",
      "std: 0.006555268309703677\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.057850587522779114\n",
      "min: 0.026782197799776922\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3125823594624131\n",
      "std: 0.3028261123345877\n",
      "min: -0.7906479859950236\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6110469911439321\n",
      "std: 0.1836558304959841\n",
      "min: 0.16090021273511773\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03312111720492027\n",
      "min: 0.13098150831459748\n",
      "max: 0.2663970505834289\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1541256954394443\n",
      "std: 0.24883071407752874\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1600539830404217\n",
      "std: 0.25016387145953334\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.061627088637595584\n",
      "min: 0.0077758466438723915\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34014659849458717\n",
      "std: 0.36729350521169407\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45666517311391236\n",
      "std: 0.21949970475940025\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03266815415441559\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4067480320447987\n",
      "std: 0.009415372820231502\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067306275281424\n",
      "std: 0.009429260182371743\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.05785278505592373\n",
      "min: 0.026402762915261706\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3177258377051757\n",
      "std: 0.3029351969684929\n",
      "min: -0.7919169564135113\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6096052827790365\n",
      "std: 0.1850424638260505\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033304200337657894\n",
      "min: 0.13056046422770326\n",
      "max: 0.266785316389378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2103994112634346\n",
      "std: 0.08940739210304599\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2151401204473065\n",
      "std: 0.09559611137681341\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.05871625800223185\n",
      "min: 0.018961525349030825\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3434046833189815\n",
      "std: 0.36816783635060857\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45670055541400034\n",
      "std: 0.21985392020909378\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03282206458737919\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4088428592431843\n",
      "std: 0.002862510301383722\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4087860060347919\n",
      "std: 0.003191828456629833\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.05784748429631397\n",
      "min: 0.02743170672883431\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3160093978331664\n",
      "std: 0.30269206353513134\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.607894494886057\n",
      "std: 0.18405828094249155\n",
      "min: 0.15903830581948003\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326861174198309\n",
      "min: 0.13097219002032653\n",
      "max: 0.26685592742002606\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.154475693991284\n",
      "std: 0.25468850053994646\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.160266790933832\n",
      "std: 0.25751952400036554\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.062016007271664904\n",
      "min: 0.006166630372460981\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3430696682740922\n",
      "std: 0.36953906112724993\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45632797798409086\n",
      "std: 0.22013410591168978\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032702146378261875\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406092879589241\n",
      "std: 0.011863443107788885\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406074022396878\n",
      "std: 0.012039136937272\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.057858777551026926\n",
      "min: 0.025845376289576154\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31726687138788373\n",
      "std: 0.3025114877850436\n",
      "min: -0.7909092834075816\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6093615780584497\n",
      "std: 0.18523715763322912\n",
      "min: 0.1600998772239539\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326511288671534\n",
      "min: 0.13072863959699577\n",
      "max: 0.2666052098290664\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1739888519841233\n",
      "std: 0.18250914576274518\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.179221682006701\n",
      "std: 0.18535838988322237\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05904893116680001\n",
      "min: 0.009304979576478311\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33140421398666736\n",
      "std: 0.3708274571200377\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4660981170186815\n",
      "std: 0.2207629346448281\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032465360027240854\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080112275511585\n",
      "std: 0.004359243847142587\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079820195327084\n",
      "std: 0.004470049673274706\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05662781914242768\n",
      "min: 0.026497450588970673\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3138681356068638\n",
      "std: 0.3030731763480589\n",
      "min: -0.7914138288123347\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6108573375797933\n",
      "std: 0.18393551630037736\n",
      "min: 0.16029776572535143\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03320278041466373\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1692362710177036\n",
      "std: 0.2012351797639728\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1746396112188686\n",
      "std: 0.20489497263144196\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05994656143111053\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33155482775571593\n",
      "std: 0.37494465813711086\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46524844205937754\n",
      "std: 0.22241158238740985\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03248206498332855\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074459242049429\n",
      "std: 0.00643127513593122\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074315088892952\n",
      "std: 0.0065306221171334625\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05663013260900479\n",
      "min: 0.025943862216276325\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.312815931434616\n",
      "std: 0.3028535833580157\n",
      "min: -0.7906479859950236\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6108190018389598\n",
      "std: 0.18381489051307723\n",
      "min: 0.16090021273511773\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033142391495048454\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1564121958664966\n",
      "std: 0.24635881743687593\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1620858503065299\n",
      "std: 0.2476894136955867\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.06029156943624969\n",
      "min: 0.0075396074965068585\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3401037261504494\n",
      "std: 0.36733118853422325\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45753497773055796\n",
      "std: 0.22042381821808466\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03270772858016062\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406756154024476\n",
      "std: 0.00931337187762529\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067283787970684\n",
      "std: 0.009336408690866112\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05663226534446287\n",
      "min: 0.025613331416671256\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31786389724643305\n",
      "std: 0.30296252974388954\n",
      "min: -0.7919169564135113\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.609406514911881\n",
      "std: 0.1851768372781232\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033322338986746206\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.211295472097498\n",
      "std: 0.08851621059388293\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.215850492330234\n",
      "std: 0.09460208688081696\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.057469493016496835\n",
      "min: 0.01833100890741517\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34326134373795464\n",
      "std: 0.3681643615615145\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4575570424436155\n",
      "std: 0.22075811402459058\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032856433604971494\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408800588364262\n",
      "std: 0.0028727398872900106\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4087357579733326\n",
      "std: 0.003210346463666299\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05662712145398614\n",
      "min: 0.026539519194015832\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31616688798001286\n",
      "std: 0.3027243274867129\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6077346505815725\n",
      "std: 0.1842097062069191\n",
      "min: 0.15903830581948003\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03328690974731555\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1567499852449405\n",
      "std: 0.2521870769345427\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1622914650934715\n",
      "std: 0.254992520686534\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.06066817947417005\n",
      "min: 0.005570598384979188\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34297952549796484\n",
      "std: 0.36952593159173036\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4572055753287618\n",
      "std: 0.22103586200341477\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03274088910142775\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406115857469162\n",
      "std: 0.011745840295633924\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4060864835950992\n",
      "std: 0.011927609131247966\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05663807678891235\n",
      "min: 0.025035021051056667\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31740195156994927\n",
      "std: 0.3025420935366161\n",
      "min: -0.7909092834075816\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6091657491006993\n",
      "std: 0.18536133887099343\n",
      "min: 0.1600998772239539\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03328356827848565\n",
      "min: 0.13072863959699577\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1765729941411154\n",
      "std: 0.18025693167781254\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1814238027241384\n",
      "std: 0.18300086951055025\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.057810043134269115\n",
      "min: 0.009287357660340029\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33234389908893414\n",
      "std: 0.371002027787682\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4672625554964447\n",
      "std: 0.22046510549937123\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03246495086363721\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080752834633334\n",
      "std: 0.004318613278471921\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080580037830692\n",
      "std: 0.004427594684479964\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05546130398416167\n",
      "min: 0.025843926265662544\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31380902216893664\n",
      "std: 0.3031088842960297\n",
      "min: -0.7914138288123347\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6107998529756165\n",
      "std: 0.18385531092023213\n",
      "min: 0.16029776572535143\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319584666792653\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1719386045788835\n",
      "std: 0.1985422121358312\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1769541115608275\n",
      "std: 0.20209976186532316\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05868026380919208\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33250840153236927\n",
      "std: 0.37500640524962514\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46641588825010266\n",
      "std: 0.2220735920373622\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032480995459958285\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075258190260473\n",
      "std: 0.006365940847044617\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075227392368972\n",
      "std: 0.0064646471436535695\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05546354877327876\n",
      "min: 0.025422883533611246\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31277366522519173\n",
      "std: 0.30288789602729843\n",
      "min: -0.7906479859950236\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.610755874867754\n",
      "std: 0.18373288436686933\n",
      "min: 0.16090021273511773\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03313642166046115\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1592663672152848\n",
      "std: 0.24387708504306496\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1645410602716815\n",
      "std: 0.2451405001836666\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05901614936253186\n",
      "min: 0.0075396074965068585\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3408667812605339\n",
      "std: 0.3675645778506383\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45887657258307946\n",
      "std: 0.2201798730619052\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03270269789040098\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068493307432934\n",
      "std: 0.009219513043175117\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4068325089918226\n",
      "std: 0.009245128261593322\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05546562285796169\n",
      "min: 0.024948855127560787\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.317731264341899\n",
      "std: 0.30299995638470567\n",
      "min: -0.7919169564135113\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6093715884944259\n",
      "std: 0.18507380722173813\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0333135106279828\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.212834551007623\n",
      "std: 0.08758232748769636\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.217051219865862\n",
      "std: 0.09347847530281106\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05627791277400411\n",
      "min: 0.018331008907415167\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3439255498005649\n",
      "std: 0.3683541546249545\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4588673232536562\n",
      "std: 0.22049803458065478\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032846865603794934\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4088476970573924\n",
      "std: 0.00284934974455459\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4087959949152828\n",
      "std: 0.003180377855785237\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.0554606265365011\n",
      "min: 0.025900945560721356\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31605438036236905\n",
      "std: 0.3027661737687396\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6077348718112794\n",
      "std: 0.18412426098021537\n",
      "min: 0.15903830581948003\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327834047465414\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1596082664266307\n",
      "std: 0.24950883221929285\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1647558699349558\n",
      "std: 0.25223199480413233\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05938099020050422\n",
      "min: 0.005402427103959512\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3436941172739375\n",
      "std: 0.36969514994675134\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45854541355924305\n",
      "std: 0.220768973909841\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032734552491356414\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4062269356238\n",
      "std: 0.011624201494308076\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4062083214152388\n",
      "std: 0.011807054247971552\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05547126144040501\n",
      "min: 0.02453182761791997\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.317265939967177\n",
      "std: 0.3025830667575294\n",
      "min: -0.7909092834075816\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6091332368021111\n",
      "std: 0.18524861780519655\n",
      "min: 0.1600998772239539\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327498910177313\n",
      "min: 0.13072863959699577\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1765630325907366\n",
      "std: 0.17760056595562015\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1810553857849029\n",
      "std: 0.180364804757051\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.056625685770372865\n",
      "min: 0.009287357660340029\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33081264371390945\n",
      "std: 0.3695840903069879\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4665725562835882\n",
      "std: 0.21955079609481024\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03234802874705762\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408127237250983\n",
      "std: 0.0042575782314295835\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081190358838556\n",
      "std: 0.004365630275546075\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.0543450834509705\n",
      "min: 0.025246808863236398\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3135455401478808\n",
      "std: 0.30300824620467504\n",
      "min: -0.7914138288123347\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6106553695164737\n",
      "std: 0.18376286724283297\n",
      "min: 0.16029776572535143\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033183633051877645\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1720188825045323\n",
      "std: 0.19583509642697852\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1766700145400395\n",
      "std: 0.19939777535162634\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.0574702844416835\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33099644287128904\n",
      "std: 0.37349867630951067\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46572771135514923\n",
      "std: 0.22112558706436497\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03236389032492866\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075911879670344\n",
      "std: 0.006275792875220067\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075965520848401\n",
      "std: 0.006375303562200519\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05434726252224797\n",
      "min: 0.024904973621200723\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31252755668032606\n",
      "std: 0.30278620718416505\n",
      "min: -0.7906479859950236\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6106047911273004\n",
      "std: 0.1836392437768314\n",
      "min: 0.16090021273511773\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033125175935517684\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1595703636518637\n",
      "std: 0.24070500345332735\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1644671646830673\n",
      "std: 0.24200331245316362\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05779711278649262\n",
      "min: 0.0075396074965068585\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33917301497837493\n",
      "std: 0.3662298107364728\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4583514262774368\n",
      "std: 0.2192562648171546\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03258216530652373\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069289382342156\n",
      "std: 0.009105945766415578\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069202470283226\n",
      "std: 0.00913412522413262\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05434928053477005\n",
      "min: 0.024470903435489685\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.317397663782892\n",
      "std: 0.30290228914563366\n",
      "min: -0.7919169564135113\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.609248421885198\n",
      "std: 0.18495984574526111\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03329948109804373\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2117662328853656\n",
      "std: 0.08718525638528067\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2156642864649478\n",
      "std: 0.09307130760369146\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05513861126248383\n",
      "min: 0.018331008907415167\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3421433940006998\n",
      "std: 0.3670100466157769\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45832505998579687\n",
      "std: 0.2195636690784341\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03272276520466911\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408877247621377\n",
      "std: 0.0028103067918020023\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088359185161732\n",
      "std: 0.003135440227106997\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.054344425672537396\n",
      "min: 0.025335896595780866\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31574093979992485\n",
      "std: 0.30267311404552655\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6076459461667653\n",
      "std: 0.18402551063156167\n",
      "min: 0.15903830581948003\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326459441838608\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1598957508668528\n",
      "std: 0.2464362766693032\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1646684855539124\n",
      "std: 0.24918052630692988\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05815105961415135\n",
      "min: 0.005402427103959512\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3419589483439323\n",
      "std: 0.36832354864616923\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4580260878529089\n",
      "std: 0.21983031059959032\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032613314878723404\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4063209521275468\n",
      "std: 0.011480737122683533\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406310197599734\n",
      "std: 0.011665188622050945\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05435475486284312\n",
      "min: 0.02396494850744841\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3169300185226684\n",
      "std: 0.3024890132612176\n",
      "min: -0.7909092834075816\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6090118110557439\n",
      "std: 0.18512563448705419\n",
      "min: 0.1600998772239539\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326122195475361\n",
      "min: 0.13072863959699577\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1769416969407975\n",
      "std: 0.1762503452720106\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1815698114753348\n",
      "std: 0.17900838627675117\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05549253554092786\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32941203652884443\n",
      "std: 0.37079992972743225\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46646654936429516\n",
      "std: 0.21904179933710544\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03233553876697833\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081479033346331\n",
      "std: 0.004221252334413487\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081613277431366\n",
      "std: 0.00432791557564525\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05327589782015852\n",
      "min: 0.024545593818392133\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3132020202651438\n",
      "std: 0.30319455723477357\n",
      "min: -0.7914138288123347\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6105787256188724\n",
      "std: 0.18366771603164414\n",
      "min: 0.16029776572535123\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318054815246227\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1725320327744615\n",
      "std: 0.19392811135982535\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1773128881005908\n",
      "std: 0.19749197233055998\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05631261322375504\n",
      "min: 0.008105277866865783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32961264035621635\n",
      "std: 0.37460190557735085\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46562526623108497\n",
      "std: 0.2205808696411206\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03235076299922052\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076240793992962\n",
      "std: 0.006211846896485878\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076505206009449\n",
      "std: 0.006312268903518214\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05327801532524599\n",
      "min: 0.024198935944906755\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3121999715520175\n",
      "std: 0.3029712519579357\n",
      "min: -0.7906479859950236\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6105227411233678\n",
      "std: 0.18354247167699803\n",
      "min: 0.16090021273511773\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03312300033589016\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.160477610225098\n",
      "std: 0.23806031816079007\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1654881953343719\n",
      "std: 0.23941174483999647\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05663051170945601\n",
      "min: 0.007401284169367215\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33760826360253654\n",
      "std: 0.3675408936587264\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45841741214443515\n",
      "std: 0.21875364895350663\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032565005874987896\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069782116658258\n",
      "std: 0.009013227979211625\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40699032861767\n",
      "std: 0.009044540436902991\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05327998008126601\n",
      "min: 0.023750550386302794\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3169856749934517\n",
      "std: 0.30309265951962217\n",
      "min: -0.7919169564135113\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6091939105654312\n",
      "std: 0.18484325893881004\n",
      "min: 0.1548016877765637\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033294611675656276\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.211385636260251\n",
      "std: 0.08632074672320827\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2154575460542372\n",
      "std: 0.09210387311473947\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05404717888868345\n",
      "min: 0.018331008907415163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34049857723630333\n",
      "std: 0.36830115193613244\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45836917056643045\n",
      "std: 0.21905785816644188\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03270182270037059\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4088822111194508\n",
      "std: 0.0027925402008216523\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088635254467519\n",
      "std: 0.003109653984538723\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05327525809971437\n",
      "min: 0.02454160054519814\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3153493601183118\n",
      "std: 0.30286687051147937\n",
      "min: -0.7917247096695827\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6076224438599499\n",
      "std: 0.18392580531356686\n",
      "min: 0.15903830581948003\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03325998550282769\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1608020019583902\n",
      "std: 0.24363418482064095\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.165693293712616\n",
      "std: 0.24641550398475218\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.056974002961303866\n",
      "min: 0.005036729970517471\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3403512582053043\n",
      "std: 0.369587631709125\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4580906599476724\n",
      "std: 0.2193119994314652\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03259511509210646\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4063845831371493\n",
      "std: 0.011356431575513398\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4063944470784724\n",
      "std: 0.0115432034066569\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05328529904982725\n",
      "min: 0.02324567609311003\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3165157738463262\n",
      "std: 0.30268381062362115\n",
      "min: -0.7909092834075819\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6089593907199471\n",
      "std: 0.18500026111177975\n",
      "min: 0.1600998772239539\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033256641550649044\n",
      "min: 0.13072863959699577\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1766938238088294\n",
      "std: 0.17502178763405057\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1813523491401787\n",
      "std: 0.17770409032837137\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05440700931554552\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33037830664416584\n",
      "std: 0.3712540263547663\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4639913256068255\n",
      "std: 0.22015585292178666\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03240224036269578\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408138459397656\n",
      "std: 0.004189465930973622\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081421951664328\n",
      "std: 0.004300287326440728\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05225076349722983\n",
      "min: 0.023998593497720842\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3135019019963493\n",
      "std: 0.3033097038092606\n",
      "min: -0.798819610586693\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6100734245620061\n",
      "std: 0.18376160902677594\n",
      "min: 0.14911475972492547\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319043575300132\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1723903742645676\n",
      "std: 0.1926414420981804\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.177194557203235\n",
      "std: 0.1961323158000797\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05520412953513183\n",
      "min: 0.008105277866865783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33059604586559277\n",
      "std: 0.3749604528189863\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46315382506917635\n",
      "std: 0.2216492779369116\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03241692485898971\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076262958705927\n",
      "std: 0.006166188092867616\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076425725693635\n",
      "std: 0.006269580805406367\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.052252823603758915\n",
      "min: 0.02352725242903209\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3125159567417072\n",
      "std: 0.3030863245850887\n",
      "min: -0.7981271851124029\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.610011810153216\n",
      "std: 0.18363556832825778\n",
      "min: 0.1496665648513587\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03313380064220845\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2103860042068464\n",
      "std: 0.08643127854678935\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.21452296467087\n",
      "std: 0.09193743922136875\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05300133010381332\n",
      "min: 0.01656583730500829\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3412215568017901\n",
      "std: 0.3687609953029638\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45604869767870926\n",
      "std: 0.2201056324238179\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03275922065496206\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4088593195066608\n",
      "std: 0.0027946600572181838\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088319200655648\n",
      "std: 0.003111467813664993\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05225014124540441\n",
      "min: 0.024007794355794046\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31560130163509004\n",
      "std: 0.3029845150772781\n",
      "min: -0.7986681568822113\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071702560262625\n",
      "std: 0.1840096167305555\n",
      "min: 0.14810924774025563\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033268330654011316\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1607731352397435\n",
      "std: 0.23540230848252874\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1657929828411535\n",
      "std: 0.23675024577811557\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05551317050959289\n",
      "min: 0.007401284169367215\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33841470836970605\n",
      "std: 0.36804164410496804\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4561103396342477\n",
      "std: 0.21979830811557186\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032626527154895855\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070000945033558\n",
      "std: 0.008912642181696311\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407001664652355\n",
      "std: 0.008947408452601608\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.052254735674863204\n",
      "min: 0.02312387476062789\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3172197699302463\n",
      "std: 0.3032055428772526\n",
      "min: -0.79914626272397\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6087096003776925\n",
      "std: 0.18491357783826334\n",
      "min: 0.14810818784157045\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033302711129716576\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.161058612196397\n",
      "std: 0.24113495946988006\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1659609445865302\n",
      "std: 0.24389879536695436\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.0558471162262531\n",
      "min: 0.005036729970517471\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3411116967373032\n",
      "std: 0.3700361690286203\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45578089674493777\n",
      "std: 0.2203383528962041\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03265559859186276\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064199494405316\n",
      "std: 0.011242527448762297\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4064190812503445\n",
      "std: 0.01143142308700275\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05225990922395\n",
      "min: 0.022684153323206925\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31674848539452594\n",
      "std: 0.3028003375578859\n",
      "min: -0.7982867040747369\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6084767349221238\n",
      "std: 0.1850619417326646\n",
      "min: 0.14902012471818252\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326506436258789\n",
      "min: 0.13072863959699577\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1793738001171032\n",
      "std: 0.17399983610105338\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1838159148388405\n",
      "std: 0.1765799723792145\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.053365459248199416\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33097670030916543\n",
      "std: 0.37164743601498046\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46479520531847074\n",
      "std: 0.22018377869044123\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03243274422197884\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081993541160587\n",
      "std: 0.00415997730802224\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082144259097327\n",
      "std: 0.004270329916198635\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05126694772296947\n",
      "min: 0.02334852214400489\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3135545247344856\n",
      "std: 0.3033003256528517\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6100930220350422\n",
      "std: 0.18374194143335962\n",
      "min: 0.14911475972492558\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033190144046149415\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1751840559993354\n",
      "std: 0.19126313453709087\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.179766450538659\n",
      "std: 0.1946535817755504\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05414063954561685\n",
      "min: 0.008105277866865783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33120971784048453\n",
      "std: 0.3752656879792249\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4639676076125763\n",
      "std: 0.22164354196716524\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03244717715580257\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407699212930487\n",
      "std: 0.00611326316705373\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077263470268575\n",
      "std: 0.006217838067673155\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.051268952553039156\n",
      "min: 0.022978049631715586\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31258316117444285\n",
      "std: 0.30307622585477484\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6100272301687862\n",
      "std: 0.18361445565569415\n",
      "min: 0.14966656485135868\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03313433526120851\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2123756118207136\n",
      "std: 0.08602262817688983\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.21632510824597\n",
      "std: 0.09133311664764164\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05199735020562879\n",
      "min: 0.015962127648045187\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3415894294884279\n",
      "std: 0.3691760408791641\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4569968074289305\n",
      "std: 0.22016113076377147\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03278148149573085\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4089065893084165\n",
      "std: 0.002773303143141175\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088914220664737\n",
      "std: 0.0030858831283712817\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.051266341560075375\n",
      "min: 0.023466090602103886\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3156090782766579\n",
      "std: 0.3029794542257104\n",
      "min: -0.7986681568822113\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6072400932600881\n",
      "std: 0.1839864736236718\n",
      "min: 0.14810924774025572\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033266613807969046\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1638061456803888\n",
      "std: 0.23380074729484976\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1685935479954312\n",
      "std: 0.23508829941389658\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05444181550153724\n",
      "min: 0.0064209258800005916\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3388583102528118\n",
      "std: 0.3684874423404359\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4570712614664868\n",
      "std: 0.21986305943644213\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03265254072274177\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070869554724494\n",
      "std: 0.00883226166969451\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070991650129352\n",
      "std: 0.008869757472374807\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.051270816381432806\n",
      "min: 0.022569098765343902\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31720930835001243\n",
      "std: 0.3031968866863649\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6087500988904166\n",
      "std: 0.1848748225874655\n",
      "min: 0.14810818784157043\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033300747910497634\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1640854078459149\n",
      "std: 0.23935342739957313\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1687584522469543\n",
      "std: 0.2420490480231712\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05476648735394323\n",
      "min: 0.005036729970517471\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34151528175537926\n",
      "std: 0.3704354696016192\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45674643098204026\n",
      "std: 0.22038688033244602\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032680892201406464\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065209152613356\n",
      "std: 0.011134632888808029\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065305313639058\n",
      "std: 0.011325217069669885\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.051275850408576386\n",
      "min: 0.02213225463585766\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3167363304319177\n",
      "std: 0.30279477274762656\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6085198174684396\n",
      "std: 0.1850153873667604\n",
      "min: 0.1490201247181824\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033263370430754606\n",
      "min: 0.13072863959699577\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.180609997006428\n",
      "std: 0.1716852578768217\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.184887217769129\n",
      "std: 0.1742688165575916\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05236496546793809\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3317560844252039\n",
      "std: 0.3710884821539746\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46531210230513204\n",
      "std: 0.22018422463103496\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03240089344503044\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082574666465686\n",
      "std: 0.004121569219420344\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408264838820488\n",
      "std: 0.004226382000437094\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05032194201685621\n",
      "min: 0.022817530462093276\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3135691129218994\n",
      "std: 0.3032684647695744\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6101846903308231\n",
      "std: 0.18369299367993797\n",
      "min: 0.14911475972492558\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319156011850245\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1765018198282946\n",
      "std: 0.18885818312726235\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1809142126663765\n",
      "std: 0.19225104577750404\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.053119425898490884\n",
      "min: 0.008105277866865783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3320019673128008\n",
      "std: 0.37463163452740544\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4644878536373584\n",
      "std: 0.22161129705049548\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03241511245248416\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077686595470449\n",
      "std: 0.006052817006094896\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077876951113015\n",
      "std: 0.006153928480049983\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05032389415651447\n",
      "min: 0.02250101343904747\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3126120695525527\n",
      "std: 0.3030442300270751\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6101151183894229\n",
      "std: 0.18356470721995455\n",
      "min: 0.14966656485135868\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033136580905375704\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2127679827274327\n",
      "std: 0.08512954297177887\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2165832667615888\n",
      "std: 0.09040855838307299\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05103315128263795\n",
      "min: 0.015962127648045187\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34215119950088\n",
      "std: 0.36863418116398794\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45764022891739775\n",
      "std: 0.2201715076188325\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032742982199573584\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4089479698757201\n",
      "std: 0.002743893701715167\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4089262244866851\n",
      "std: 0.003048575432518957\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05032135138332546\n",
      "min: 0.0229125156952373\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3155805134790673\n",
      "std: 0.3029521097156269\n",
      "min: -0.7986681568822113\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6073791672434795\n",
      "std: 0.18393475616673344\n",
      "min: 0.14810924774025572\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326663344145929\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.165381628110309\n",
      "std: 0.23082765463602972\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1699868757120964\n",
      "std: 0.23214943715124384\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05341302647813845\n",
      "min: 0.0064209258800005916\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33950016585245774\n",
      "std: 0.36798006872575223\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45773343042898257\n",
      "std: 0.2198897893816901\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03261764854111968\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071669387055994\n",
      "std: 0.008749179828256825\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071709936988521\n",
      "std: 0.008785628404659617\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05032571224124041\n",
      "min: 0.022071994911176777\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3171632715440704\n",
      "std: 0.3031660938163609\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6088619752758165\n",
      "std: 0.1848079159254689\n",
      "min: 0.14810818784157043\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033300542595182836\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1656572385058346\n",
      "std: 0.2362782908161177\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1701508654147403\n",
      "std: 0.23899881437729223\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.053728932565740316\n",
      "min: 0.005036729970517471\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3421174049311585\n",
      "std: 0.3698845907809893\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45740848821364094\n",
      "std: 0.22039683996059237\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03264514559757192\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066135973186995\n",
      "std: 0.011025408953155577\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066149177842149\n",
      "std: 0.01121444047220617\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05033061364362844\n",
      "min: 0.02160837066338567\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3166889132330769\n",
      "std: 0.3027671603086331\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6086346732639257\n",
      "std: 0.18494150799560416\n",
      "min: 0.1490201247181824\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033263434444851386\n",
      "min: 0.13072863959699577\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1805192098430863\n",
      "std: 0.1698971542060297\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.184675385698884\n",
      "std: 0.17250433363046028\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.05140424371635753\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3321133568375267\n",
      "std: 0.37041155699135\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46372614073106366\n",
      "std: 0.22144117731811805\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03241841690924562\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082715720146157\n",
      "std: 0.004086944878580028\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082963126508983\n",
      "std: 0.004180211155999879\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.04941343951562194\n",
      "min: 0.022279491457200398\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3134989738351686\n",
      "std: 0.3031982712178043\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6100303033707067\n",
      "std: 0.1835997430619244\n",
      "min: 0.14911475972492552\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318869338013321\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1765049824186076\n",
      "std: 0.18685606327640808\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1807922197824274\n",
      "std: 0.1902648099553863\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.05213893880148369\n",
      "min: 0.008105277866865783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3323751158470198\n",
      "std: 0.37388020229085744\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4629070129394576\n",
      "std: 0.2228291493961567\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0324322637225309\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077925959081488\n",
      "std: 0.005991496354011153\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078286022764706\n",
      "std: 0.00608586721312102\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.049415341358364506\n",
      "min: 0.021999099425631614\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31255586991414774\n",
      "std: 0.30297371852167443\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6099571435394063\n",
      "std: 0.18347088534206255\n",
      "min: 0.14966656485135882\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033134494076472204\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1656751668424215\n",
      "std: 0.22815452460557342\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1701440839349035\n",
      "std: 0.2295205238470736\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.05242524735209419\n",
      "min: 0.0064209258800005916\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33972560441609573\n",
      "std: 0.36734940320857695\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4562933716974349\n",
      "std: 0.22111140933098752\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03263161928834539\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407202473613215\n",
      "std: 0.008671029311759127\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407223285329265\n",
      "std: 0.008704585892123043\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.049417116169964144\n",
      "min: 0.02149175860945218\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3170352506130377\n",
      "std: 0.3030970938544219\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6087271412605685\n",
      "std: 0.184695610506076\n",
      "min: 0.14810818784157054\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0332961476647522\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2119575770921778\n",
      "std: 0.08453475134319013\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.21568015606471\n",
      "std: 0.0897940496726094\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.05010667850334672\n",
      "min: 0.015720911602309328\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3423037952518925\n",
      "std: 0.36797868459495087\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4561833453016745\n",
      "std: 0.22138785344414993\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03275341284158278\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408947683715817\n",
      "std: 0.00272631833495081\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408944167185199\n",
      "std: 0.0030109966617100315\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.049412863714293404\n",
      "min: 0.022412085527026088\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31546917283949627\n",
      "std: 0.302886871582454\n",
      "min: -0.7986681568822113\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6072706775616394\n",
      "std: 0.18383618556686163\n",
      "min: 0.14810924774025575\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0332624425677275\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.165933759744005\n",
      "std: 0.23367595728903512\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1702945665289464\n",
      "std: 0.23642550464262793\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.05273279545638075\n",
      "min: 0.004900611357952902\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3423090789185787\n",
      "std: 0.3692142824178634\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45596877169670136\n",
      "std: 0.22160190491388554\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032658280487758706\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066599441080425\n",
      "std: 0.010917401527938535\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066778969540301\n",
      "std: 0.011103929721903452\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.04942189106850408\n",
      "min: 0.021060436971331264\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31656003089221446\n",
      "std: 0.3027015451465156\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6085018679036676\n",
      "std: 0.18482259301797282\n",
      "min: 0.14902012471818235\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03325930510854898\n",
      "min: 0.13072863959699577\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1811351403408477\n",
      "std: 0.16825329601951497\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1851085827722072\n",
      "std: 0.17082055629659346\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.05048025432904138\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33215846417574635\n",
      "std: 0.36997114020838984\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4628116824441412\n",
      "std: 0.22116558562981994\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03239742033977868\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082600473345452\n",
      "std: 0.004060792352261408\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082636421720025\n",
      "std: 0.00416194113533273\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.04853931480247912\n",
      "min: 0.021859295325444773\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31353694592077164\n",
      "std: 0.3031913957863886\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6098000115500892\n",
      "std: 0.18360688302621575\n",
      "min: 0.14911475972492552\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319178416163613\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1772054897125084\n",
      "std: 0.18491622282826467\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.181306146196155\n",
      "std: 0.18827597855652053\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.05119615864500564\n",
      "min: 0.007471783927356017\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33243476401395616\n",
      "std: 0.3733686149984853\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4619995745852656\n",
      "std: 0.22252574682781012\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0324113232230844\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077906197315375\n",
      "std: 0.005930693209479994\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078050556864943\n",
      "std: 0.006030676541973311\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.04854116836792799\n",
      "min: 0.021587161797563224\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31260769133657224\n",
      "std: 0.3029665518953368\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6097227283230626\n",
      "std: 0.18347715013947696\n",
      "min: 0.14966656485135882\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03313835490421958\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1665563609745226\n",
      "std: 0.22600938727955275\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1708302800452348\n",
      "std: 0.22736740597487115\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.051475705103149236\n",
      "min: 0.0058776530762690935\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33964157622439095\n",
      "std: 0.3669576868135403\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45550972418155916\n",
      "std: 0.2208244406046734\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032607297366364994\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072115142220663\n",
      "std: 0.008592686620941366\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072107037881192\n",
      "std: 0.008630834085454146\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.04854290169889782\n",
      "min: 0.021105484074998376\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31701829957253164\n",
      "std: 0.303090370565629\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6085138182911767\n",
      "std: 0.1846849593979696\n",
      "min: 0.14810818784157054\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03329776874822243\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2118562412770693\n",
      "std: 0.08396583984366361\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2154213369252953\n",
      "std: 0.08912357161540821\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.049215384252141024\n",
      "min: 0.015354345068632645\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34215755362265576\n",
      "std: 0.3675667427132076\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4553926267115122\n",
      "std: 0.22109334688472917\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03272608858415695\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4089194981160638\n",
      "std: 0.002731906571376727\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088956783270496\n",
      "std: 0.0030234376908916233\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.04853875333384246\n",
      "min: 0.021852242891971085\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3154692979933833\n",
      "std: 0.30288354094183745\n",
      "min: -0.7986681568822113\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.607083549450905\n",
      "std: 0.183836919121199\n",
      "min: 0.14810924774025575\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326428201222945\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.166806509648464\n",
      "std: 0.23142025237441652\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.17097566103319\n",
      "std: 0.23414391026512588\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.051775342106333305\n",
      "min: 0.004900611357952902\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34219478545070625\n",
      "std: 0.3687890730360865\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4551907208299019\n",
      "std: 0.22130280864771384\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03263372718473102\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066792083592587\n",
      "std: 0.01080708111569827\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066754427705521\n",
      "std: 0.010996209433522324\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.04854755578041291\n",
      "min: 0.020660809567622902\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3165426103156638\n",
      "std: 0.30269792026012166\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6082903988185058\n",
      "std: 0.18480505031658015\n",
      "min: 0.14902012471818235\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326118030908017\n",
      "min: 0.13072863959699577\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1823281896208975\n",
      "std: 0.16688909391087303\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.186225592277248\n",
      "std: 0.16947152345731623\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.049591039727646676\n",
      "min: 0.007137886790462734\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33285603114211065\n",
      "std: 0.37080211720883527\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46392761502557317\n",
      "std: 0.22127258793090665\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03243032622615203\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082905720572916\n",
      "std: 0.004026561313386603\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082965400663527\n",
      "std: 0.004123092098738736\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.04769760598172634\n",
      "min: 0.021337727778924762\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31366278240899387\n",
      "std: 0.3032835222071164\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6099153702307003\n",
      "std: 0.18359544147468898\n",
      "min: 0.14911475972492552\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033194289213634105\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1784831142219403\n",
      "std: 0.1834262583352426\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.18250397543275\n",
      "std: 0.18679145874831019\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.050289058776002545\n",
      "min: 0.007471783927356017\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3331440613868921\n",
      "std: 0.3741234287455512\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4631247084342392\n",
      "std: 0.22260581301129212\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032443903930670086\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078310046680476\n",
      "std: 0.00586948502074158\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078474601714157\n",
      "std: 0.0059673523929410595\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.047699413677407466\n",
      "min: 0.021077928152522366\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31274631804243885\n",
      "std: 0.30305898687811983\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6098351327621161\n",
      "std: 0.18346485715481578\n",
      "min: 0.14966656485135882\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03314160207508457\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1681046517023954\n",
      "std: 0.2238908435944921\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.172289024873281\n",
      "std: 0.22528697656497546\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.05056190136846549\n",
      "min: 0.0058776530762690935\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34021002689796986\n",
      "std: 0.3678440745469797\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4567642910229092\n",
      "std: 0.22097467402440543\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0326366141676855\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072629775964711\n",
      "std: 0.008516085418928641\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407264140898862\n",
      "std: 0.0085534858871693\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.047701107336027046\n",
      "min: 0.020675024358167888\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31708989120866743\n",
      "std: 0.3031829759002551\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6086481456527515\n",
      "std: 0.18465760962963104\n",
      "min: 0.14810818784157054\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033298821422482194\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.212445654540894\n",
      "std: 0.08317509517991796\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2159569709392406\n",
      "std: 0.08834510618307463\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.048357129168932665\n",
      "min: 0.015354345068632648\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34266464744262454\n",
      "std: 0.36842155614311056\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45663269125843825\n",
      "std: 0.2212339431228885\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0327524444847021\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4089360535002693\n",
      "std: 0.002701419268538211\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4089154393014156\n",
      "std: 0.002986087222338807\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.0476970577853081\n",
      "min: 0.02148353724519435\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3155570063318929\n",
      "std: 0.3029793600852926\n",
      "min: -0.7986681568822113\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.607241206764102\n",
      "std: 0.18382335444932132\n",
      "min: 0.14810924774025575\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326556526420691\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1683396977794978\n",
      "std: 0.2292783853617092\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1724230102277382\n",
      "std: 0.23202180132358088\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.05085402894289532\n",
      "min: 0.004900611357952902\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.342726981169674\n",
      "std: 0.3696337275454867\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45644922095217877\n",
      "std: 0.22144037945638476\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032662276419204814\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4067422130939975\n",
      "std: 0.010693457779140778\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067403238099019\n",
      "std: 0.010881500779871814\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.04770564558011283\n",
      "min: 0.020352537060689284\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3166134746565358\n",
      "std: 0.3027938881593913\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6084274587638352\n",
      "std: 0.18477154302729404\n",
      "min: 0.14902012471818235\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033262505527008324\n",
      "min: 0.13072863959699577\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1834968844976108\n",
      "std: 0.16559206866213558\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1870300307204185\n",
      "std: 0.16812309213831966\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04873467739599222\n",
      "min: 0.006749489675278262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33394529367580966\n",
      "std: 0.3698444276037703\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46336168446933174\n",
      "std: 0.2213662304665712\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03249661415186767\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083078792222716\n",
      "std: 0.003987690816475235\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083146000231124\n",
      "std: 0.004083745068124075\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04688649942502209\n",
      "min: 0.020944344011193803\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3138502676401858\n",
      "std: 0.3032588705772743\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.609803961146697\n",
      "std: 0.18361159932259977\n",
      "min: 0.14911475972492552\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03320751696702398\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1797377550226034\n",
      "std: 0.18189410876048034\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1833907858053745\n",
      "std: 0.18520065361425248\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04941561327657629\n",
      "min: 0.0074304841430578895\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33424354521155586\n",
      "std: 0.373108265705302\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4625658919655585\n",
      "std: 0.2226705277366226\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03250979417106719\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078584747217495\n",
      "std: 0.00580660992968445\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078752836901687\n",
      "std: 0.005904855296816755\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04688826338917483\n",
      "min: 0.020665060591255786\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3129462623334897\n",
      "std: 0.3030346215277696\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6097200364844623\n",
      "std: 0.1834804674909307\n",
      "min: 0.14966656485135882\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03315557079787431\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.169534731861243\n",
      "std: 0.22217749267435127\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1733442525763955\n",
      "std: 0.22353689558478393\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.049682234363860475\n",
      "min: 0.0058776530762690935\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3411730124175502\n",
      "std: 0.366919156431142\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45632347325504113\n",
      "std: 0.22106260557375\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032699207001888546\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073006688719691\n",
      "std: 0.008439054263441655\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073021379259358\n",
      "std: 0.008476920274368324\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04688991907184843\n",
      "min: 0.02018305263259573\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3172252778657758\n",
      "std: 0.303157332678589\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6085538698948944\n",
      "std: 0.1846569237706713\n",
      "min: 0.14810818784157054\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03331063587855848\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.213020741796593\n",
      "std: 0.08254264074044255\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2161858410457804\n",
      "std: 0.08766245311903126\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04753036124055223\n",
      "min: 0.014964023336498619\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3435643974173864\n",
      "std: 0.36747000788003553\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4561821772430049\n",
      "std: 0.2213165706286448\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03281156690892737\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4089400280980824\n",
      "std: 0.00267894664427762\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4089208532176376\n",
      "std: 0.0029601591987997674\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04688596424235074\n",
      "min: 0.020996050687120876\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3157079878471622\n",
      "std: 0.30295761930343984\n",
      "min: -0.7986681568822113\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071704608669695\n",
      "std: 0.18383509653790822\n",
      "min: 0.14810924774025575\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327759119481584\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.169753203277316\n",
      "std: 0.22752157608932913\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1734645412073141\n",
      "std: 0.2302175793761013\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04996718811257991\n",
      "min: 0.004622232797715273\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34365722224313106\n",
      "std: 0.368676777161301\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4560123368524379\n",
      "std: 0.22151659541429158\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03272415591374671\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4067912503013404\n",
      "std: 0.010586362408896393\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067895606425074\n",
      "std: 0.010774362112246595\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04689434722211485\n",
      "min: 0.019895829900204266\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3167484973201264\n",
      "std: 0.3027712932415414\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6083347154702307\n",
      "std: 0.18476494648182396\n",
      "min: 0.14902012471818235\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327460744404185\n",
      "min: 0.13072863959699577\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1847986611626504\n",
      "std: 0.1640980282618453\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1881333531897287\n",
      "std: 0.1666003807653965\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.047909043749169246\n",
      "min: 0.006749489675278261\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33288144997941915\n",
      "std: 0.3700896486683101\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46351770251223134\n",
      "std: 0.22207816353090962\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03246613694671063\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083280823421118\n",
      "std: 0.003956468753362447\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083409805493121\n",
      "std: 0.004049605439264637\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.046104316140096864\n",
      "min: 0.02052252487182424\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.313550420664446\n",
      "std: 0.30329822227727465\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6099642782767187\n",
      "std: 0.18353128294252258\n",
      "min: 0.1491147597249256\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319701574412187\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1811158327435758\n",
      "std: 0.18019127519414838\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.184567133478058\n",
      "std: 0.18346215848902067\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.048573681064362696\n",
      "min: 0.007430484143057889\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.333190553203466\n",
      "std: 0.3732808294230612\n",
      "min: -1.0440863089215333\n",
      "max: 1.0031226127594253\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46272875782886647\n",
      "std: 0.22335369426830828\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594253\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03247905081392524\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078887719174684\n",
      "std: 0.005748722145449375\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079114571699336\n",
      "std: 0.005845451332552211\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.04610603820421947\n",
      "min: 0.02021218389000635\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3126581300656609\n",
      "std: 0.3030735524972427\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6098776825615466\n",
      "std: 0.1833992898919351\n",
      "min: 0.14966656485135882\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03314573129347016\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1710838232794591\n",
      "std: 0.2201962813044473\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1746845627708333\n",
      "std: 0.22154638541381635\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.04883436018138063\n",
      "min: 0.005877653076269093\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3399951736750957\n",
      "std: 0.3672283543407342\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4566030185445541\n",
      "std: 0.22178883526945026\n",
      "min: -0.11614260933525512\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03266582416464131\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073366500477411\n",
      "std: 0.008369488076589751\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073440290914039\n",
      "std: 0.008407171756024966\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.046107657738702484\n",
      "min: 0.01979466979614856\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3168750141149372\n",
      "std: 0.3031998231483494\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6087315528995035\n",
      "std: 0.18456188790572997\n",
      "min: 0.14810818784157054\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03329880156909777\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2137110356813707\n",
      "std: 0.08199176436468139\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2166975873450163\n",
      "std: 0.08703900505690605\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.04673314483929775\n",
      "min: 0.014489802841169812\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3423347267610109\n",
      "std: 0.3677671222493028\n",
      "min: -1.0393282332938176\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4564492059867484\n",
      "std: 0.22203715565451318\n",
      "min: -0.11744174501600634\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032775736905466084\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4089456500652169\n",
      "std: 0.0026681098955129144\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4089334236787054\n",
      "std: 0.002941226319839899\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.04610379347451108\n",
      "min: 0.020535589090223835\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3153743537608865\n",
      "std: 0.30300237359118337\n",
      "min: -0.7986681568822114\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6073701032709871\n",
      "std: 0.18375343563876062\n",
      "min: 0.1481092477402557\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033266014648642095\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1712909898868789\n",
      "std: 0.22552568051569907\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1747961418213015\n",
      "std: 0.22819998264810307\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.0491124447727528\n",
      "min: 0.004622232797715271\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34244731303731474\n",
      "std: 0.3689539117104704\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4562943320542632\n",
      "std: 0.22222887560463894\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03269011412151801\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068377895958757\n",
      "std: 0.010491683221490168\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4068419720506604\n",
      "std: 0.010678715468443588\n",
      "min: 1.3207873374723202\n",
      "max: 1.414008884615644\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.046111981152517106\n",
      "min: 0.01943626041473\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3163975429903846\n",
      "std: 0.3028169204264566\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6085144100655396\n",
      "std: 0.1846643101918762\n",
      "min: 0.14902012471818235\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033263007933059106\n",
      "min: 0.13072863959699577\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1856381426781566\n",
      "std: 0.16237687890933664\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1887882975237587\n",
      "std: 0.16486691905162223\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04711260887922426\n",
      "min: 0.006749489675278261\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33326110356561195\n",
      "std: 0.3696409933090752\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4622962959494548\n",
      "std: 0.22286228813224232\n",
      "min: -0.10883049623165547\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03247623930735445\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083434251408664\n",
      "std: 0.00391981856304602\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408350814984695\n",
      "std: 0.004005215461354441\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.045349499479031524\n",
      "min: 0.020044527827363354\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3137007488392157\n",
      "std: 0.3032410986149342\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6097332629656298\n",
      "std: 0.18357193621479073\n",
      "min: 0.14911475972492552\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03320346467311165\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1820200447955886\n",
      "std: 0.17841979107091185\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1852837591080492\n",
      "std: 0.18166628085751685\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.047761706782293946\n",
      "min: 0.007430484143057889\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3335785156828109\n",
      "std: 0.37277429554206315\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4615133722865884\n",
      "std: 0.22410831276442147\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03248888788564693\n",
      "min: 0.11782966247484129\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407912284831355\n",
      "std: 0.0056957342443204285\n",
      "min: 1.3631779066326057\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079291904782425\n",
      "std: 0.005787002180877418\n",
      "min: 1.3631779066326057\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04535118186294092\n",
      "min: 0.019731156086744615\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3128200585203112\n",
      "std: 0.30301680657228425\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6096437530860996\n",
      "std: 0.18343975743214647\n",
      "min: 0.14966656485135874\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03315284706206239\n",
      "min: 0.1309815083145975\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1721645615008347\n",
      "std: 0.2180704255435753\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.175571068980456\n",
      "std: 0.21942549911681591\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.048016644264828406\n",
      "min: 0.005877653076269093\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3402593704016293\n",
      "std: 0.3668238433628245\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45549725558282406\n",
      "std: 0.22255154115178175\n",
      "min: -0.11614260933525508\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03267284717156235\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073746951491477\n",
      "std: 0.0082818410028641\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073761393380408\n",
      "std: 0.008316940368711138\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04000000000000001\n",
      "std: 0.04535276516026296\n",
      "min: 0.019415000337047735\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3169759421526594\n",
      "std: 0.30314241784056073\n",
      "min: -0.7991462627239704\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6085166299280638\n",
      "std: 0.1845861359308863\n",
      "min: 0.14810818784157048\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03330389358122951\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.213941191130323\n",
      "std: 0.0812270257057268\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2167623523991355\n",
      "std: 0.0862397971980865\n",
      "min: 0.7199851205004337\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04596391863728755\n",
      "min: 0.014489802841169812\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34254405645553015\n",
      "std: 0.3673376343794921\n",
      "min: -1.0393282332938174\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4553381059296608\n",
      "std: 0.2227941117393216\n",
      "min: -0.11744174501600639\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03278000848669217\n",
      "min: 0.11878810475429608\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408950738282615\n",
      "std: 0.002645121554546263\n",
      "min: 1.385913718605555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408933681415798\n",
      "std: 0.002906453351214622\n",
      "min: 1.385913718605555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04534898868541501\n",
      "min: 0.020162587591408855\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31548986450697214\n",
      "std: 0.302947987807971\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071775667823726\n",
      "std: 0.18378808539113023\n",
      "min: 0.14810924774025563\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033271294971887536\n",
      "min: 0.13097219002032653\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1723608887578016\n",
      "std: 0.22343149840400778\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1756744068774176\n",
      "std: 0.22609189390125617\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04828818729478291\n",
      "min: 0.004622232797715271\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34268115694606743\n",
      "std: 0.3685185870874525\n",
      "min: -1.0461975431230799\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45519062475303146\n",
      "std: 0.2229777924719869\n",
      "min: -0.12012961953633236\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032696537323487214\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068851515804703\n",
      "std: 0.0103841671242488\n",
      "min: 1.3207873374723207\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40688333756428\n",
      "std: 0.01056837940361505\n",
      "min: 1.3207873374723207\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.045356988489313306\n",
      "min: 0.018974306393514013\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.316498519577644\n",
      "std: 0.30276235936403945\n",
      "min: -0.7982867040747369\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6083013426402845\n",
      "std: 0.18468322478332577\n",
      "min: 0.14902012471818246\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326835047418137\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1868903929317247\n",
      "std: 0.16131284554613448\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1899595820223838\n",
      "std: 0.16380483642094415\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04634411817580324\n",
      "min: 0.006710811012526809\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3332177235456888\n",
      "std: 0.3703082608511838\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4622112017611739\n",
      "std: 0.2224997852487645\n",
      "min: -0.10883049623165546\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03248081483746057\n",
      "min: 0.11804781246265542\n",
      "max: 0.2666644669328233\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083645114027432\n",
      "std: 0.0039032464036971555\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408381275489669\n",
      "std: 0.00398109077493837\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04462060398222881\n",
      "min: 0.01960494918645951\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.313638441143649\n",
      "std: 0.30334206641910316\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6097383707291041\n",
      "std: 0.1835343809080839\n",
      "min: 0.1491147597249255\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999998\n",
      "std: 0.03319644203278537\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.183361479531304\n",
      "std: 0.17700352748877066\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1865413020099198\n",
      "std: 0.18024863077615774\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04697820681433993\n",
      "min: 0.00668439443831623\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33354220569538273\n",
      "std: 0.3733757706784394\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4614366227687914\n",
      "std: 0.22372228878341166\n",
      "min: -0.11415131062850678\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03249305753838056\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407942191569229\n",
      "std: 0.005657512282930985\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079681625503808\n",
      "std: 0.005744046504531868\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04462224837920396\n",
      "min: 0.019353704460264538\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31276837909761174\n",
      "std: 0.30311784843265166\n",
      "min: -0.7981271851124029\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6096468585989807\n",
      "std: 0.18340139478997083\n",
      "min: 0.14966656485135868\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033146428357878774\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1736649530488188\n",
      "std: 0.2165833506583272\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1769808476336427\n",
      "std: 0.21795453118232766\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.047227732323334645\n",
      "min: 0.005710200884191564\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34010424218753027\n",
      "std: 0.3675451934575594\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4555269925016033\n",
      "std: 0.2221965429088906\n",
      "min: -0.11614260933525507\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999998\n",
      "std: 0.03267432135114161\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407415483452871\n",
      "std: 0.008219202410925929\n",
      "min: 1.3429135180663998\n",
      "max: 1.4139917536538014\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074259641135558\n",
      "std: 0.008252464335957513\n",
      "min: 1.3429135180663998\n",
      "max: 1.4139917536538014\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.044623797797959344\n",
      "min: 0.018953751233084223\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31686570293068794\n",
      "std: 0.3032449502802427\n",
      "min: -0.7991462627239702\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6085377313642202\n",
      "std: 0.18453431904148712\n",
      "min: 0.14810818784157048\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033295586922556346\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2146979681007342\n",
      "std: 0.08065808195005038\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2174549373602648\n",
      "std: 0.08566240465523446\n",
      "min: 0.7199851205004337\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04522123795839489\n",
      "min: 0.013311520165241128\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34233824679392916\n",
      "std: 0.36803701720158705\n",
      "min: -1.0393282332938178\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4553590189528327\n",
      "std: 0.22243360709484253\n",
      "min: -0.11744174501600647\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032779143869009195\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4089631077690619\n",
      "std: 0.002632197004399465\n",
      "min: 1.3859137186055552\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4089559786399128\n",
      "std: 0.002882251682971493\n",
      "min: 1.3859137186055552\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.044620104165886895\n",
      "min: 0.019672677100788155\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31539469053479047\n",
      "std: 0.30305261006330914\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6072195851980091\n",
      "std: 0.18374744684201852\n",
      "min: 0.14810924774025575\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033263215387731374\n",
      "min: 0.13097219002032656\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1738689282279946\n",
      "std: 0.22172044836155058\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1770951180585836\n",
      "std: 0.22438489387634783\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.047492904721139144\n",
      "min: 0.004181555809506524\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34249555390920133\n",
      "std: 0.36920715609366705\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4552219867357441\n",
      "std: 0.22261172422977826\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032697341010610906\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069360739723324\n",
      "std: 0.010296292747133862\n",
      "min: 1.3207873374723205\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069432181508528\n",
      "std: 0.010478171914947668\n",
      "min: 1.3207873374723205\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04462792514647948\n",
      "min: 0.018657666141716614\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3163880371496273\n",
      "std: 0.3028680760746076\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6083247326791724\n",
      "std: 0.18462620767886503\n",
      "min: 0.14902012471818238\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326027243278508\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1870234798279626\n",
      "std: 0.16000976431560046\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1900389324231742\n",
      "std: 0.16247658717598273\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03846153846153846\n",
      "std: 0.045601986469845916\n",
      "min: 0.006710811012526809\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33148826394811026\n",
      "std: 0.3710522792084016\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46139843281629134\n",
      "std: 0.22202776343696\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03241272260031583\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083676486914487\n",
      "std: 0.003866619597360816\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083956729625489\n",
      "std: 0.0039427030361728335\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.04391628396986061\n",
      "min: 0.019353158544366568\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3133956409323146\n",
      "std: 0.3034051906921291\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6096124171317964\n",
      "std: 0.1834826744321716\n",
      "min: 0.14911475972492552\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318665859254994\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1835582072988857\n",
      "std: 0.17565702854934193\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1866804311920813\n",
      "std: 0.17887189221565472\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.046221867141682145\n",
      "min: 0.00668439443831623\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33182402990773174\n",
      "std: 0.3740565869937245\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4606284495401199\n",
      "std: 0.22323089490987602\n",
      "min: -0.1141513106285068\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032424989016678105\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407953555946851\n",
      "std: 0.005604998526140405\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079904826978062\n",
      "std: 0.005690599044295714\n",
      "min: 1.3631779066326055\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.04391789193485385\n",
      "min: 0.019050309954048408\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31253634665830926\n",
      "std: 0.30318074930074246\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6095181449540414\n",
      "std: 0.1833492224122551\n",
      "min: 0.1496665648513588\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033137253654081836\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1740339416650738\n",
      "std: 0.21487107740209854\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1772863998250154\n",
      "std: 0.21623900249913194\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.04646604479325793\n",
      "min: 0.005354687199620961\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3382710666034792\n",
      "std: 0.368365457980998\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043075\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45482210981480875\n",
      "std: 0.22171233750942013\n",
      "min: -0.11614260933525501\n",
      "max: 0.9680281682043075\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03260360972030318\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407436772131229\n",
      "std: 0.008130843169898979\n",
      "min: 1.3429135180664\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074581654578406\n",
      "std: 0.00816529741416375\n",
      "min: 1.3429135180664\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.04391940775333942\n",
      "min: 0.018733489563796276\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31657740555704544\n",
      "std: 0.3033116317169062\n",
      "min: -0.7991462627239704\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6084272667678884\n",
      "std: 0.18446843702323815\n",
      "min: 0.14810818784157043\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03328459065316014\n",
      "min: 0.1305604642277033\n",
      "max: 0.26691480912471316\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2143034494199965\n",
      "std: 0.08063600069749075\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2170226504336819\n",
      "std: 0.08552563080167652\n",
      "min: 0.7199851205004337\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.044504027257254886\n",
      "min: 0.012434515686955576\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3404582518423605\n",
      "std: 0.36884511254574887\n",
      "min: -1.0393282332938178\n",
      "max: 0.9594521654813369\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.454647055791013\n",
      "std: 0.22194613479727174\n",
      "min: -0.11744174501600652\n",
      "max: 0.9594521654813369\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03270639098111376\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4089547057304197\n",
      "std: 0.002621627205322465\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4089593276366337\n",
      "std: 0.002864185647437039\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.04391579531190649\n",
      "min: 0.019346414568569694\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3151216636223951\n",
      "std: 0.30312073137059004\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071298387685191\n",
      "std: 0.18369183822977025\n",
      "min: 0.14810924774025572\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033252452457422824\n",
      "min: 0.13097219002032656\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1742214434981921\n",
      "std: 0.2200720447849135\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1773854126898022\n",
      "std: 0.22272326739752576\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.04672528442452626\n",
      "min: 0.004181555809506524\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3406337491381561\n",
      "std: 0.3700069403913283\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634704\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45451858102117915\n",
      "std: 0.22212100398924473\n",
      "min: -0.12012961953633253\n",
      "max: 0.9667459598634704\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03262639177948548\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069658945578527\n",
      "std: 0.010201957470907628\n",
      "min: 1.3207873374723207\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069838877401448\n",
      "std: 0.010383879673863916\n",
      "min: 1.3207873374723207\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.04392344425025178\n",
      "min: 0.018264614281770963\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3160993489760318\n",
      "std: 0.3029377409162985\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6082161093443796\n",
      "std: 0.18455530701458084\n",
      "min: 0.14902012471818238\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324950061416548\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1874366689225022\n",
      "std: 0.15872855515688875\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1904394204902655\n",
      "std: 0.16119145906153348\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04488451941583117\n",
      "min: 0.006140696417090343\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3322118541175353\n",
      "std: 0.3711946601040685\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46154887897347824\n",
      "std: 0.22216460379999847\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032421102939035475\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083907120006027\n",
      "std: 0.0038415962239279297\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084221086304949\n",
      "std: 0.003909586679557385\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04323528855808116\n",
      "min: 0.018870817586805422\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3133980349828755\n",
      "std: 0.3033598568223338\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6096787246962676\n",
      "std: 0.18339175314982897\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318258101381371\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.184033475198632\n",
      "std: 0.17427444834617428\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.187140469206794\n",
      "std: 0.1774798043915325\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.0454907790233211\n",
      "min: 0.006684394438316229\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33255651557469657\n",
      "std: 0.37414090531916083\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4607831061789315\n",
      "std: 0.22334409345967643\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032433071165003394\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079842227818717\n",
      "std: 0.005564562108436437\n",
      "min: 1.3631779066326057\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080242970993577\n",
      "std: 0.005644710590066215\n",
      "min: 1.3631779066326057\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04323686170521928\n",
      "min: 0.018599014513333494\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3125491860204117\n",
      "std: 0.3031354694681964\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6095820296136221\n",
      "std: 0.18325780491338078\n",
      "min: 0.1496665648513587\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03313376803210448\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1747626442444916\n",
      "std: 0.21269120531467473\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1779925208704807\n",
      "std: 0.2140833788490417\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.045729670832016525\n",
      "min: 0.005354687199620961\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3388954877771812\n",
      "std: 0.368541490022371\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4550803158101811\n",
      "std: 0.22186036002171072\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03260920059511117\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407477016614662\n",
      "std: 0.008062327601291509\n",
      "min: 1.3429135180663998\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407501492686083\n",
      "std: 0.008094285421568552\n",
      "min: 1.3429135180663998\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04323834587931967\n",
      "min: 0.01829455415613431\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.316535908523684\n",
      "std: 0.3032674385783802\n",
      "min: -0.7991462627239704\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6085094183712778\n",
      "std: 0.18436450327395826\n",
      "min: 0.1481081878415704\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327932590298534\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.214217471339358\n",
      "std: 0.08005889221529625\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2169408419061234\n",
      "std: 0.08489321113091673\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04381040484071032\n",
      "min: 0.012434515686955574\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34103342549370774\n",
      "std: 0.3689990671312212\n",
      "min: -1.0393282332938178\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4548903182155345\n",
      "std: 0.22209096388804345\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032709730684016884\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4089679443227143\n",
      "std: 0.002601989622939309\n",
      "min: 1.385913718605555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4089764859106644\n",
      "std: 0.0028325874234674674\n",
      "min: 1.385913718605555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.043234810164184054\n",
      "min: 0.019037022488193823\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31509424650934836\n",
      "std: 0.30307895592498696\n",
      "min: -0.7986681568822113\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6072308325391379\n",
      "std: 0.18359917538082615\n",
      "min: 0.14810924774025575\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324741189346242\n",
      "min: 0.13097219002032656\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.174937585073549\n",
      "std: 0.21793647279497513\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1780814543429088\n",
      "std: 0.22059733856043293\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04598321603469702\n",
      "min: 0.004181555809506525\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3412292576276249\n",
      "std: 0.37014899527185396\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4547762981477121\n",
      "std: 0.22225769903194695\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03263131669547398\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070147469972423\n",
      "std: 0.010116272418713804\n",
      "min: 1.3207873374723205\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070358140364798\n",
      "std: 0.010295372771215769\n",
      "min: 1.3207873374723205\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04324229462033385\n",
      "min: 0.01790703980853506\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31605784974741963\n",
      "std: 0.3028962117093347\n",
      "min: -0.7982867040747369\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6083002019095499\n",
      "std: 0.18444671347172242\n",
      "min: 0.14902012471818246\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324446787574209\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.187453292706497\n",
      "std: 0.1574954819333942\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.190299910324214\n",
      "std: 0.1599491152719567\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.044190824255633525\n",
      "min: 0.006140696417090343\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33156506813095926\n",
      "std: 0.3705176301160694\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4600421262258041\n",
      "std: 0.22279106959624773\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03242845233099039\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408389684517711\n",
      "std: 0.003813037567422836\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955162\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084135201155008\n",
      "std: 0.0038810305292130104\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955162\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04257645023769167\n",
      "min: 0.018486033164615\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31339184045965146\n",
      "std: 0.30330578671781744\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6095352682702061\n",
      "std: 0.18337070550165582\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033181672821773776\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1841045414248639\n",
      "std: 0.17307698058718263\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1870524840693684\n",
      "std: 0.17626207729798757\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04478404934730151\n",
      "min: 0.006475206007519072\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33191612147405813\n",
      "std: 0.3734147729790246\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45928132032901275\n",
      "std: 0.22394411765859978\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03244001882905782\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079908899906297\n",
      "std: 0.005529019302199253\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080231789056359\n",
      "std: 0.005608856712644073\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04257799030222629\n",
      "min: 0.01814010280311442\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31255299427856514\n",
      "std: 0.3030813800471316\n",
      "min: -0.7981271851124029\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6094358237300991\n",
      "std: 0.1832365783522513\n",
      "min: 0.14966656485135876\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033133434265004626\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1750247509214164\n",
      "std: 0.21087019717354225\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1780900820469964\n",
      "std: 0.21226696345405247\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04501793790663879\n",
      "min: 0.005354687199620961\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3381467973683144\n",
      "std: 0.36791116478548275\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45367359563381965\n",
      "std: 0.2224571033549094\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032613478166530215\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074943014422907\n",
      "std: 0.007986811089373734\n",
      "min: 1.3429135180663998\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075109051199157\n",
      "std: 0.008019611678525988\n",
      "min: 1.3429135180663998\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04257944336183166\n",
      "min: 0.017934613688297078\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31648641780375725\n",
      "std: 0.3032145547163455\n",
      "min: -0.7991462627239704\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6083800330153757\n",
      "std: 0.1843296365498349\n",
      "min: 0.14810818784157048\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327723884190876\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2137554287020562\n",
      "std: 0.0797911599129889\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.216336126498826\n",
      "std: 0.0845844088728\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04313960889127231\n",
      "min: 0.012434515686955574\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3402395043829088\n",
      "std: 0.3683570759334208\n",
      "min: -1.0393282332938178\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45347934431633835\n",
      "std: 0.2226824530124396\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032711888482263654\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4089591142192008\n",
      "std: 0.002583167522856782\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4089605978379318\n",
      "std: 0.0028124014641536955\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04257598176293025\n",
      "min: 0.018557966542018287\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31505882725277484\n",
      "std: 0.3030280452665264\n",
      "min: -0.7986681568822113\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071210857951334\n",
      "std: 0.18357388702196473\n",
      "min: 0.14810924774025572\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033245542053693566\n",
      "min: 0.13097219002032656\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.175178875589161\n",
      "std: 0.21629617102893192\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1781597834738846\n",
      "std: 0.21895016965667813\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.045266053885944346\n",
      "min: 0.004181555809506525\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3404526998521416\n",
      "std: 0.36949819274918677\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.453371678347392\n",
      "std: 0.22284462162812316\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032635012805404894\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070406355966671\n",
      "std: 0.010033073188404042\n",
      "min: 1.3207873374723205\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070538287556493\n",
      "std: 0.010211959677781442\n",
      "min: 1.3207873374723205\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04258330848634607\n",
      "min: 0.01746524774916029\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3160084265112528\n",
      "std: 0.3028457678092765\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6081723995461741\n",
      "std: 0.1844074233266015\n",
      "min: 0.14902012471818246\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324260758101479\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1885795729657773\n",
      "std: 0.15631605763942558\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1915610088238189\n",
      "std: 0.15880271412613214\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04351941550602679\n",
      "min: 0.006140696417090343\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33203175054130596\n",
      "std: 0.3703848665438881\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4593519390725132\n",
      "std: 0.22345648372837584\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032475817080463584\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084259249993718\n",
      "std: 0.0037875607170551424\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084616155090979\n",
      "std: 0.0038494483551652944\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04193867875945635\n",
      "min: 0.018213454123761675\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3133619472547631\n",
      "std: 0.3033006803023448\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6094795887748121\n",
      "std: 0.1833566845038069\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318389112372046\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.185298656727597\n",
      "std: 0.17164848403684052\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1883782284764355\n",
      "std: 0.17486468621514237\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04410002015723345\n",
      "min: 0.006475206007519074\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3323905175786097\n",
      "std: 0.3732312906021006\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4585986048315515\n",
      "std: 0.22458344204192682\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032487141588440925\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080342957470477\n",
      "std: 0.00548091975999178\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080782040293833\n",
      "std: 0.005557298237012379\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.041940186355406556\n",
      "min: 0.017988909776826708\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31253280052969695\n",
      "std: 0.3030767836551665\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6093784187697788\n",
      "std: 0.18322235312430324\n",
      "min: 0.14966656485135862\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03313622490989711\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.176362178800161\n",
      "std: 0.20931467610771196\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1795541725761307\n",
      "std: 0.21075810692622643\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04432924560195533\n",
      "min: 0.005125629112121128\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3385188871781769\n",
      "std: 0.36781145632486373\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45308095869888215\n",
      "std: 0.22311530310052594\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032658034432438574\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407544694982393\n",
      "std: 0.007929034977447545\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407572920040768\n",
      "std: 0.007960231919041137\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.041941610946822555\n",
      "min: 0.017561150595222674\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31641508424752585\n",
      "std: 0.3032105325382431\n",
      "min: -0.7991462627239702\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6083388691012092\n",
      "std: 0.18430245614224344\n",
      "min: 0.1481081878415704\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327832932684409\n",
      "min: 0.1305604642277033\n",
      "max: 0.26691480912471316\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2144156132249109\n",
      "std: 0.07929459284045888\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2171469286847258\n",
      "std: 0.08407670831752027\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04249015979534089\n",
      "min: 0.012308134224543887\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3405669530622759\n",
      "std: 0.3682412797185373\n",
      "min: -1.0393282332938178\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45288174723848734\n",
      "std: 0.22333531164344092\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03275419616764415\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4089839835496833\n",
      "std: 0.002570453908165582\n",
      "min: 1.385913718605555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4089978744686233\n",
      "std: 0.0027882002057237052\n",
      "min: 1.385913718605555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.041938219951990194\n",
      "min: 0.018267857702340882\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31500098609536076\n",
      "std: 0.3030264204293982\n",
      "min: -0.7986681568822113\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6070981767624238\n",
      "std: 0.18355680436500993\n",
      "min: 0.1481092477402558\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324682688392356\n",
      "min: 0.13097219002032656\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1765217858552497\n",
      "std: 0.2146055059764856\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1796308110485167\n",
      "std: 0.21729762270328662\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.0445720249323198\n",
      "min: 0.004048918960777755\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3407999908248662\n",
      "std: 0.36937076616298997\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45278179068245117\n",
      "std: 0.2234904155019897\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032679079042319065\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070992787629866\n",
      "std: 0.009949365002198054\n",
      "min: 1.3207873374723205\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071240493556132\n",
      "std: 0.01012690918688409\n",
      "min: 1.3207873374723205\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.041945394601006276\n",
      "min: 0.017220309289710654\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31593743349351006\n",
      "std: 0.3028448144787875\n",
      "min: -0.7982867040747369\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6081332587340708\n",
      "std: 0.1843760950816072\n",
      "min: 0.1490201247181824\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324394573266595\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1888314089034666\n",
      "std: 0.15498566009682538\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1917608625016494\n",
      "std: 0.1574891036690799\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.042869362242986715\n",
      "min: 0.006140696417090343\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3321942978686612\n",
      "std: 0.36991076323196825\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4591579920759327\n",
      "std: 0.2236963269470821\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03246505211086521\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084534009149157\n",
      "std: 0.0037608941091033083\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084952147535605\n",
      "std: 0.0038204292035778154\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04132095602337238\n",
      "min: 0.017804186229490433\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31341067097298975\n",
      "std: 0.30325567432481343\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6093705751049396\n",
      "std: 0.18336093548848892\n",
      "min: 0.14911475972492555\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318609648767854\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1856197084933369\n",
      "std: 0.170014124123151\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1886440837566818\n",
      "std: 0.17324495925772848\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04343779722370652\n",
      "min: 0.006475206007519074\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33255788905995176\n",
      "std: 0.37271311603205753\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4584130031883411\n",
      "std: 0.2248039557637071\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032476316469587194\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408068720161338\n",
      "std: 0.005430233213685468\n",
      "min: 1.3631779066326053\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081185521771742\n",
      "std: 0.005505780173398037\n",
      "min: 1.3631779066326053\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04132243231842783\n",
      "min: 0.01759816339973041\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31259105586922387\n",
      "std: 0.30303249452349096\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6092678695222036\n",
      "std: 0.18322652672402562\n",
      "min: 0.1496665648513588\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03313898825612238\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1768035820216853\n",
      "std: 0.20758007947796805\n",
      "min: -0.20406795652609228\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1799357267059207\n",
      "std: 0.20905836011474918\n",
      "min: -0.1876902286650499\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04366261247414981\n",
      "min: 0.005125629112121128\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33858752935196684\n",
      "std: 0.36737414686820985\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45298114485552715\n",
      "std: 0.22335842528208089\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03264497461388478\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075876561070257\n",
      "std: 0.007868722421272636\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407621825919961\n",
      "std: 0.007900070306092388\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.0413238294109844\n",
      "min: 0.017239300795853986\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3164229528106858\n",
      "std: 0.3031660085058568\n",
      "min: -0.7991462627239704\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6082442935855281\n",
      "std: 0.18429414842174616\n",
      "min: 0.14810818784157045\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327940762075423\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2141678039229817\n",
      "std: 0.07891787903554061\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2168609322784658\n",
      "std: 0.08369024990455114\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.0418612982553656\n",
      "min: 0.012308134224543887\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3405946078307788\n",
      "std: 0.3677881274418334\n",
      "min: -1.0393282332938178\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4527780741883451\n",
      "std: 0.223569642390805\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0327391801559905\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090005960939749\n",
      "std: 0.002549941043836346\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090211554505208\n",
      "std: 0.0027631670188160576\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04132050640816704\n",
      "min: 0.017948256200217255\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31502214092525593\n",
      "std: 0.3029846044951061\n",
      "min: -0.7986681568822113\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6070214609246664\n",
      "std: 0.1835570977888833\n",
      "min: 0.14810924774025575\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324811822785398\n",
      "min: 0.13097219002032656\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1769746243100403\n",
      "std: 0.2125714143968738\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1800246166160298\n",
      "std: 0.21529029442458697\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04390022251348277\n",
      "min: 0.004048918960777755\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34084336213458216\n",
      "std: 0.36891060155922145\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45268576051791937\n",
      "std: 0.22372496149712878\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03266569645678692\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407150431295201\n",
      "std: 0.009857043055599958\n",
      "min: 1.3207873374723207\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071811028423253\n",
      "std: 0.010034572174385876\n",
      "min: 1.3207873374723207\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04132753420546201\n",
      "min: 0.016941501540760982\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.315945939826137\n",
      "std: 0.30280298175660986\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6080407280906047\n",
      "std: 0.18436377497242767\n",
      "min: 0.1490201247181825\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324525756062458\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1894471880731892\n",
      "std: 0.1537702754984167\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1922552631074175\n",
      "std: 0.15628319040742794\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04223965751642871\n",
      "min: 0.006140696417090344\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33228351663745515\n",
      "std: 0.36985759556565717\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45991289860907114\n",
      "std: 0.2241677609587844\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032477062538602684\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084727944323463\n",
      "std: 0.003749671223215562\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4085195095583865\n",
      "std: 0.0038104457753484903\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04072232908435248\n",
      "min: 0.017431356784563205\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31327776847065236\n",
      "std: 0.3032114190374018\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6093713473019337\n",
      "std: 0.18327333323054462\n",
      "min: 0.14911475972492558\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318009012228685\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.186280618409345\n",
      "std: 0.16887786855275755\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.18918158345565\n",
      "std: 0.1721035960599215\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.042796533834094236\n",
      "min: 0.005991365314890132\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3326534091676661\n",
      "std: 0.372610896405572\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4591721103034851\n",
      "std: 0.22525533459879368\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032488158315344115\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080943862397248\n",
      "std: 0.005405899356226746\n",
      "min: 1.3631779066326057\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081489632821056\n",
      "std: 0.005482506285735637\n",
      "min: 1.3631779066326057\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.0407237758590329\n",
      "min: 0.017203163368358837\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31246741616811113\n",
      "std: 0.3029884699219804\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.609267252009373\n",
      "std: 0.18313885043057807\n",
      "min: 0.14966656485135868\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03313351817486247\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1776029085018371\n",
      "std: 0.20598781273172084\n",
      "min: -0.20406795652609225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1806071692858715\n",
      "std: 0.2074812467407474\n",
      "min: -0.18769022866504972\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.043016961331392344\n",
      "min: 0.005125629112121126\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3385866148216363\n",
      "std: 0.36735784127889326\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4538274588391028\n",
      "std: 0.22385462204340897\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03265453142589816\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076204870667728\n",
      "std: 0.007826062458151772\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407659417010332\n",
      "std: 0.007859482239014146\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04072514637931146\n",
      "min: 0.0167734433157312\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3162504043555635\n",
      "std: 0.30312365331559415\n",
      "min: -0.7991462627239702\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6082587756257792\n",
      "std: 0.1841945324240707\n",
      "min: 0.14810818784157054\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327232414663124\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2143174594517472\n",
      "std: 0.07871224856818508\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2169014365922037\n",
      "std: 0.08347068567713573\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04125197490097112\n",
      "min: 0.011660689369961615\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34055295826470866\n",
      "std: 0.3677584377265356\n",
      "min: -1.0393282332938178\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4536146161473035\n",
      "std: 0.22405957961139675\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032746836349356545\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090126453469292\n",
      "std: 0.0025463843524465082\n",
      "min: 1.3859137186055552\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090385938774757\n",
      "std: 0.002759255496641676\n",
      "min: 1.3859137186055552\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04072188821552204\n",
      "min: 0.017500676936433472\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3148629620214674\n",
      "std: 0.30294417733987705\n",
      "min: -0.7986681568822113\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6070531364716132\n",
      "std: 0.1834671610280312\n",
      "min: 0.14810924774025572\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324125436026034\n",
      "min: 0.13097219002032656\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.177750565812012\n",
      "std: 0.2111965641837511\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.180675050277988\n",
      "std: 0.213912997199566\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04324974894009373\n",
      "min: 0.003580235298510747\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34081574466494213\n",
      "std: 0.36886893583364755\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4535333883883238\n",
      "std: 0.2242128477666287\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03267476501582798\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071900817641865\n",
      "std: 0.009802153942090979\n",
      "min: 1.3207873374723205\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072255323946739\n",
      "std: 0.0099804048732636\n",
      "min: 1.3207873374723205\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04072877688861106\n",
      "min: 0.016441234207156066\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3157737209143336\n",
      "std: 0.3027632977435632\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6080573370498947\n",
      "std: 0.184260435365937\n",
      "min: 0.1490201247181824\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03323840020307677\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1897720426502116\n",
      "std: 0.15269259460564902\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1924425994211834\n",
      "std: 0.15520097501128152\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.0416293634341582\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3327883113865287\n",
      "std: 0.36955371406185034\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45983832153739235\n",
      "std: 0.22415937594937677\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032470183786462554\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084842993972049\n",
      "std: 0.0037261268502682154\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4085125279539932\n",
      "std: 0.0037880986157969487\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.040141904332297106\n",
      "min: 0.01723838063653537\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31335359467526636\n",
      "std: 0.303208777064653\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6092772407060204\n",
      "std: 0.18321946562878447\n",
      "min: 0.14911475972492552\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318208798337772\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1866683752558482\n",
      "std: 0.16749698113658254\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.189429647574505\n",
      "std: 0.17071183738327494\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.042175031941662854\n",
      "min: 0.005991365314890132\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33316211532671236\n",
      "std: 0.37225834621559617\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4591001541553227\n",
      "std: 0.22522966339709655\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032481126152531674\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081129442264784\n",
      "std: 0.005361097916398486\n",
      "min: 1.3631779066326057\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081488243118958\n",
      "std: 0.005438140924901319\n",
      "min: 1.3631779066326057\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.04014332223936253\n",
      "min: 0.016983924188007267\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3125524446238803\n",
      "std: 0.30298646522112815\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6091710984920459\n",
      "std: 0.183084804062441\n",
      "min: 0.14966656485135874\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03313604042361296\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1781209432486888\n",
      "std: 0.20439366784577848\n",
      "min: -0.20406795652609225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1809813445719264\n",
      "std: 0.2058954056733333\n",
      "min: -0.18769022866504972\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.042391290582853486\n",
      "min: 0.005125629112121126\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3390061635252559\n",
      "std: 0.3670748340599557\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45383762611254974\n",
      "std: 0.22385166631873268\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032645477913972175\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076436532281558\n",
      "std: 0.007776496031869677\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076639930808028\n",
      "std: 0.0078105638170818245\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.04014466749248825\n",
      "min: 0.016532479953334667\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3162886252460524\n",
      "std: 0.30312088185837166\n",
      "min: -0.7991462627239702\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6081780040195729\n",
      "std: 0.18412858706120197\n",
      "min: 0.14810818784157045\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327327176238994\n",
      "min: 0.1305604642277033\n",
      "max: 0.26691480912471316\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.21420641976878\n",
      "std: 0.07829922892599636\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.216664309966002\n",
      "std: 0.0830376654703447\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.04066126178378382\n",
      "min: 0.01148856370921786\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34093249616034027\n",
      "std: 0.36746227218582955\n",
      "min: -1.0393282332938178\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45361520515990755\n",
      "std: 0.2240547688612926\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03273584287254964\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.409013080124681\n",
      "std: 0.002539703822320024\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.409021059971851\n",
      "std: 0.002753619079047284\n",
      "min: 1.3859137186055555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.04014147212485706\n",
      "min: 0.017267356911957802\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3149138113223177\n",
      "std: 0.3029439905553974\n",
      "min: -0.798668156882211\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6069889839624464\n",
      "std: 0.18341040404651218\n",
      "min: 0.1481092477402557\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324241006350249\n",
      "min: 0.13097219002032656\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1782670031866895\n",
      "std: 0.2094859751876419\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1810490356038108\n",
      "std: 0.21219971268643625\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03448275862068966\n",
      "std: 0.04261936317554902\n",
      "min: 0.003580235298510747\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3412100548431965\n",
      "std: 0.368558217844429\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4535432075996908\n",
      "std: 0.2242028261468635\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032665266558113734\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072207411984539\n",
      "std: 0.009735346992149833\n",
      "min: 1.3206317473286184\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072375786844737\n",
      "std: 0.009913046361992053\n",
      "min: 1.3206317473286184\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.040148226012696894\n",
      "min: 0.016138028616546472\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31581264862271313\n",
      "std: 0.30276324500238705\n",
      "min: -0.7982867040747369\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6079779842858568\n",
      "std: 0.18419062968876793\n",
      "min: 0.14902012471818235\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03323956877959247\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1901622971998487\n",
      "std: 0.15183316497598956\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.192845007878766\n",
      "std: 0.15431700336357804\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.04103762633441271\n",
      "min: 0.0052508147561464\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3325752998747045\n",
      "std: 0.3698621577372811\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.458837761981144\n",
      "std: 0.2244620880116236\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03251440890633197\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084715684941016\n",
      "std: 0.003721989804140036\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084949142068688\n",
      "std: 0.0037856537943255345\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.03957884509718257\n",
      "min: 0.0168858396045213\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.313474450755239\n",
      "std: 0.3032657152279049\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6092706507272645\n",
      "std: 0.18325823915787798\n",
      "min: 0.1491147597249256\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318743995761054\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1871128214368676\n",
      "std: 0.1665357079502117\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1898836829488968\n",
      "std: 0.16972268766193552\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.04157254783304485\n",
      "min: 0.005886533691104929\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33295430237192236\n",
      "std: 0.3725176840539766\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45810369535375656\n",
      "std: 0.22551185237795718\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032524949420257784\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081057707740412\n",
      "std: 0.00534734159023852\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081365924479914\n",
      "std: 0.005425306031317282\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.03958023584797892\n",
      "min: 0.01656806733955684\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3126820921445857\n",
      "std: 0.3030440084758437\n",
      "min: -0.7981271851124029\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.609162677403289\n",
      "std: 0.18312340484020367\n",
      "min: 0.14966656485135882\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03314190724132783\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1787334919309582\n",
      "std: 0.2029528967394805\n",
      "min: -0.20406795652609225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1815990748903689\n",
      "std: 0.2044540756391284\n",
      "min: -0.18769022866504972\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.04178467890467245\n",
      "min: 0.005125629112121126\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33870857033647567\n",
      "std: 0.3674204064651786\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45292508577985763\n",
      "std: 0.2241380863024762\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032686952299047195\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076451291241734\n",
      "std: 0.007727637643603639\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076604218354003\n",
      "std: 0.007763502351340901\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.039581555606047564\n",
      "min: 0.016268153637335653\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3163725879446239\n",
      "std: 0.3031777440265641\n",
      "min: -0.7991462627239702\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6081841038200646\n",
      "std: 0.18415585144069643\n",
      "min: 0.14810818784157048\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033277610272423104\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2142281378743514\n",
      "std: 0.07801454963703817\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2167093073749806\n",
      "std: 0.08266365985110524\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.04008829684584135\n",
      "min: 0.011488563709217862\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34059596583361373\n",
      "std: 0.36779447524811626\n",
      "min: -1.0393282332938178\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45269638121277994\n",
      "std: 0.2243374019234988\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03277523539127625\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4089942290069082\n",
      "std: 0.002549720385485531\n",
      "min: 1.385913718605555\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4089977145234847\n",
      "std: 0.0027633052799720726\n",
      "min: 1.385913718605555\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.03957842101711564\n",
      "min: 0.01694683196714037\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3150098982409922\n",
      "std: 0.30300302680629804\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6070110126030415\n",
      "std: 0.18344669973174438\n",
      "min: 0.14810924774025572\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324693266171546\n",
      "min: 0.13097219002032656\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1788682812366282\n",
      "std: 0.2081095875830514\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.181656528827898\n",
      "std: 0.2108138570285094\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.04200825421814026\n",
      "min: 0.0035359243345667365\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.340887421055021\n",
      "std: 0.36888056144326026\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4526306188626575\n",
      "std: 0.22448151152620469\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03270617062845215\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072280469446719\n",
      "std: 0.009683739228637982\n",
      "min: 1.317576505944788\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072398646858904\n",
      "std: 0.00986162467397649\n",
      "min: 1.317576505944788\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.03958504573129789\n",
      "min: 0.015819875727532937\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31589713701423977\n",
      "std: 0.30282276783108825\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.607985713993146\n",
      "std: 0.18421427718488756\n",
      "min: 0.1490201247181825\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324413813428182\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1899541825824695\n",
      "std: 0.15086459511684625\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.192763380674907\n",
      "std: 0.1533204176442962\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.040463444077170535\n",
      "min: 0.0052508147561464\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33271948833366444\n",
      "std: 0.3692971821441506\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45897527524555043\n",
      "std: 0.22396923012704928\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03252400496938535\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084674120905927\n",
      "std: 0.003702669470667894\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084828214490717\n",
      "std: 0.0037751764434484953\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.039032364638936334\n",
      "min: 0.016628682406707857\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31362690338487076\n",
      "std: 0.3032437567365057\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6091963835542239\n",
      "std: 0.183269091588136\n",
      "min: 0.14911475972492558\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319161234809326\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.186967491029898\n",
      "std: 0.16528930735177108\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1898619837065136\n",
      "std: 0.16845053257101217\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.04098794835816976\n",
      "min: 0.005886533691104929\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33310305891239866\n",
      "std: 0.37191438748820416\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.458249508953017\n",
      "std: 0.2250049763720258\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032534359841454356\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081074694462068\n",
      "std: 0.005311843194590586\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408130171797054\n",
      "std: 0.005395859887398987\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.03903372879627952\n",
      "min: 0.01641774933260356\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3128429206629714\n",
      "std: 0.3030227542047053\n",
      "min: -0.7981271851124029\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6090867516427066\n",
      "std: 0.1831341134582191\n",
      "min: 0.14966656485135868\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03314657032573652\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1786892438355803\n",
      "std: 0.20169780559490688\n",
      "min: -0.20406795652609225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1816754915344572\n",
      "std: 0.203197172216775\n",
      "min: -0.18769022866504972\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.041196243771970543\n",
      "min: 0.004671325359064498\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33876996088714423\n",
      "std: 0.36688687924006563\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45314446507401424\n",
      "std: 0.2236561855086983\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03269424766986225\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076522858261522\n",
      "std: 0.007681304713445358\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076595216557461\n",
      "std: 0.0077221699526262635\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.0390350248265749\n",
      "min: 0.01599866188833317\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31648928064443604\n",
      "std: 0.3031554019781786\n",
      "min: -0.7991462627239702\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6081216737993124\n",
      "std: 0.18415554587765748\n",
      "min: 0.14810818784157054\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033280802129602216\n",
      "min: 0.1305604642277033\n",
      "max: 0.26691480912471316\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2136310347642625\n",
      "std: 0.07781139540608734\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2162501528448355\n",
      "std: 0.08234263806185958\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.03953223393174502\n",
      "min: 0.011488563709217862\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34062077092674925\n",
      "std: 0.3672498924212547\n",
      "min: -1.0393282332938178\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45291272368039664\n",
      "std: 0.22385065923023703\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03278079263053508\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4089822908884782\n",
      "std: 0.002548053185946925\n",
      "min: 1.3859090680685242\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4089782228923913\n",
      "std: 0.002771172983486454\n",
      "min: 1.3859090680685242\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.039031948574499806\n",
      "min: 0.01662334680394657\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3151382301116498\n",
      "std: 0.30298309629336106\n",
      "min: -0.7986681568822113\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6069650312079872\n",
      "std: 0.1834545766889526\n",
      "min: 0.14810924774025575\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033250312928991645\n",
      "min: 0.13097219002032656\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1788288410540002\n",
      "std: 0.2066574857113128\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1817389484931478\n",
      "std: 0.20935171506586714\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.04141542665349876\n",
      "min: 0.0035359243345667365\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34092720555877887\n",
      "std: 0.36832771813832665\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.452854625253564\n",
      "std: 0.22399523240510857\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03271314951936892\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072414547701257\n",
      "std: 0.009627949422606237\n",
      "min: 1.317576505944788\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072452324432476\n",
      "std: 0.009808891615006097\n",
      "min: 1.317576505944788\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.03903844861842845\n",
      "min: 0.015585505111007467\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3160145339038682\n",
      "std: 0.3028028302071311\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6079246282084503\n",
      "std: 0.18421044623036406\n",
      "min: 0.14902012471818238\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324754114037904\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.191120828295267\n",
      "std: 0.1496876849643549\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1939767431539972\n",
      "std: 0.15214862675592392\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.03990592597157447\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33331944315381595\n",
      "std: 0.3698993210893142\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4600697395639176\n",
      "std: 0.2238732359720515\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03254614859137946\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084938786335088\n",
      "std: 0.003679341590192543\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4085120658808612\n",
      "std: 0.003750141698225349\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.038501724069073866\n",
      "min: 0.016370422668787212\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3136821294071864\n",
      "std: 0.3033340570236711\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6092836102221235\n",
      "std: 0.1832555138980784\n",
      "min: 0.1491147597249255\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319301506160309\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1881759991251497\n",
      "std: 0.16406092798504657\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1911147209845465\n",
      "std: 0.16722604043722428\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.040420458229562056\n",
      "min: 0.0058865336911049304\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3337070652139207\n",
      "std: 0.37246944258873427\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4593485047338424\n",
      "std: 0.22489449318326402\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0325564132050312\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081395995626913\n",
      "std: 0.00527629947980872\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081649357937729\n",
      "std: 0.005358995531989111\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.03850306261525581\n",
      "min: 0.01615207593581854\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3129065246387749\n",
      "std: 0.3031139018280194\n",
      "min: -0.7981271851124029\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6091728051649749\n",
      "std: 0.18312037325025782\n",
      "min: 0.1496665648513588\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03314847036172937\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1800546993276448\n",
      "std: 0.20002551483123582\n",
      "min: -0.20406795652609225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.183081098651202\n",
      "std: 0.20154773682140298\n",
      "min: -0.18769022866504972\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.04062492420022787\n",
      "min: 0.004671325359064498\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3392898594926349\n",
      "std: 0.36751635708694147\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45431931414850224\n",
      "std: 0.22359054711871768\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03271412328705767\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076915166533344\n",
      "std: 0.007627102263261779\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077014104884358\n",
      "std: 0.0076681964939446816\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.038504335263463106\n",
      "min: 0.015735564292362125\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3165094998950064\n",
      "std: 0.3032461246624601\n",
      "min: -0.7991462627239702\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6082214014967641\n",
      "std: 0.1841317887340272\n",
      "min: 0.1481081878415705\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033281243987214326\n",
      "min: 0.1305604642277033\n",
      "max: 0.26691480912471316\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.214388902533023\n",
      "std: 0.07745638010541114\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2170649860843787\n",
      "std: 0.08195609841934505\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.038992299490917065\n",
      "min: 0.011488563709217864\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3411067317198464\n",
      "std: 0.36786442066404684\n",
      "min: -1.0393282332938178\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45407941076233366\n",
      "std: 0.22378186949514944\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03279901356459614\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090002976499365\n",
      "std: 0.0025356790968379885\n",
      "min: 1.3859090680685242\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4089994351415014\n",
      "std: 0.002755020726174327\n",
      "min: 1.3859090680685242\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.03850131573907187\n",
      "min: 0.016408520340916843\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31517041661490325\n",
      "std: 0.30307588604778873\n",
      "min: -0.7986681568822113\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6070796275851716\n",
      "std: 0.1834399379526882\n",
      "min: 0.1481092477402557\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03325096671906742\n",
      "min: 0.13097219002032656\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1801946126981073\n",
      "std: 0.20491698734110267\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1831459716832224\n",
      "std: 0.2076262175690681\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.040839916123982516\n",
      "min: 0.003535924334566736\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34142323447060485\n",
      "std: 0.36892988030915175\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4540315402042742\n",
      "std: 0.2239233380473563\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03273268295888995\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407287179496434\n",
      "std: 0.00956072972243215\n",
      "min: 1.3175765059447877\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407293634815474\n",
      "std: 0.009741109256798103\n",
      "min: 1.3175765059447877\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.038507694716180624\n",
      "min: 0.015409680150428382\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.316035487332786\n",
      "std: 0.3028962456399048\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6080265279575454\n",
      "std: 0.18418326378484\n",
      "min: 0.1490201247181824\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324820438786482\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1917331965804627\n",
      "std: 0.148368616736242\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.194528937064756\n",
      "std: 0.15082525255258986\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.039364466799707364\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33319701808889896\n",
      "std: 0.3699914795933915\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4599048015639016\n",
      "std: 0.22332798733477974\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03253033291861657\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4085117552257962\n",
      "std: 0.0036644163185242827\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4085151990454463\n",
      "std: 0.003737723142640326\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.03798622864547148\n",
      "min: 0.016068320595335573\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3137151390362904\n",
      "std: 0.30334387028119064\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6091774494759021\n",
      "std: 0.183217894995214\n",
      "min: 0.1491147597249257\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033193578242478865\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.188824551439843\n",
      "std: 0.16269004200832404\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.191700956238744\n",
      "std: 0.16584535812237855\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.03986940145097745\n",
      "min: 0.0058865336911049304\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3335877928428097\n",
      "std: 0.37252039844989426\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45918758192066805\n",
      "std: 0.22433545467214644\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03254047379224233\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081627456416241\n",
      "std: 0.00525059725996601\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081731977134049\n",
      "std: 0.0053346989859508285\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.03798754261913822\n",
      "min: 0.015799020226059314\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31294760404465616\n",
      "std: 0.3031243650368324\n",
      "min: -0.7981271851124029\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6090653350627502\n",
      "std: 0.18308274712386474\n",
      "min: 0.14966656485135882\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03314951087381155\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1808312894849202\n",
      "std: 0.19830136093223258\n",
      "min: -0.20406795652609225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1837921081934737\n",
      "std: 0.19982947241939994\n",
      "min: -0.18769022866504972\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.04007019421597489\n",
      "min: 0.004671325359064498\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3390887619585305\n",
      "std: 0.36764264356572596\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45423205973767833\n",
      "std: 0.22304710113759277\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032696248573268444\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077224237415822\n",
      "std: 0.007576416866825879\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077174427818304\n",
      "std: 0.007619017954557391\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.03798879244490173\n",
      "min: 0.015480416351568231\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3165084495759685\n",
      "std: 0.30325666497849546\n",
      "min: -0.7991462627239702\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6081271251719327\n",
      "std: 0.1840834478591962\n",
      "min: 0.14810818784157048\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03328087032774327\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2145944220561817\n",
      "std: 0.07706339283111384\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2172194478638922\n",
      "std: 0.08152809822127854\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.038467862728211726\n",
      "min: 0.010583128182429364\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34087080414696685\n",
      "std: 0.3679775974891926\n",
      "min: -1.0393282332938178\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4539850155079963\n",
      "std: 0.22323695319331785\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03277950844121576\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090117904025947\n",
      "std: 0.0025325725987239214\n",
      "min: 1.3859090680685242\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408996574117747\n",
      "std: 0.002754076624652839\n",
      "min: 1.3859090680685242\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612904\n",
      "std: 0.03798582772115578\n",
      "min: 0.01609161891046265\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3151807966284285\n",
      "std: 0.30308832476160114\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6070001723407197\n",
      "std: 0.183399362800814\n",
      "min: 0.1481092477402556\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0332507801811112\n",
      "min: 0.13097219002032656\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1809633972241422\n",
      "std: 0.20321611539686257\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1838503631481365\n",
      "std: 0.20592330670495163\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.04028116366209304\n",
      "min: 0.003535924334566737\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34119803000095766\n",
      "std: 0.36903608764986623\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45394608406858633\n",
      "std: 0.22337394838227975\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032714441592128\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073238774652999\n",
      "std: 0.009502057521992895\n",
      "min: 1.317576505944788\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073154825045204\n",
      "std: 0.009682582990550321\n",
      "min: 1.317576505944788\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.037992090121478285\n",
      "min: 0.015092499910277035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3160350886712078\n",
      "std: 0.3029092734647621\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6079340467900654\n",
      "std: 0.18413164340655302\n",
      "min: 0.14902012471818246\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033248043635546676\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1931678203976637\n",
      "std: 0.1471733521523382\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1960207003191967\n",
      "std: 0.1496386590967127\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.03883833368548015\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33401638235455233\n",
      "std: 0.37028469867510055\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45972402521926814\n",
      "std: 0.22354977913475801\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0325441503460571\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408531759482501\n",
      "std: 0.003636453387040371\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4085290015970005\n",
      "std: 0.003708892941680696\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.03748522355597752\n",
      "min: 0.01586011468779345\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3136539280667253\n",
      "std: 0.30330371576873505\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6090977484490638\n",
      "std: 0.18316991883561567\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318744593779\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.190304018691259\n",
      "std: 0.16134014386540663\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1932358466119568\n",
      "std: 0.16449912443410233\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.03933395386590098\n",
      "min: 0.0058865336911049304\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33440880909205695\n",
      "std: 0.3727705192028594\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45901102671015226\n",
      "std: 0.2245395451113408\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03255405255615574\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408188498607357\n",
      "std: 0.005216273877381096\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081926206955901\n",
      "std: 0.005299159704470736\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.0374865137892407\n",
      "min: 0.015603715001727643\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31289405754819494\n",
      "std: 0.30308464883115965\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6089848392365349\n",
      "std: 0.1830346232557121\n",
      "min: 0.14966656485135887\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03314382038828206\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1823942121948956\n",
      "std: 0.19690613880323043\n",
      "min: -0.20406795652609225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1854070816694675\n",
      "std: 0.1984532943322241\n",
      "min: -0.18769022866504972\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.03953129869416642\n",
      "min: 0.004671325359064498\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3398327657989096\n",
      "std: 0.3679595333365309\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45412398233786627\n",
      "std: 0.22327253994869142\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03270799889524867\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407754888331459\n",
      "std: 0.007516537480951065\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077435976739618\n",
      "std: 0.007559330668894231\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.03748774140938481\n",
      "min: 0.015258136549307086\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3164143013378202\n",
      "std: 0.30321799561487134\n",
      "min: -0.7991462627239704\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.608058708119428\n",
      "std: 0.18402515045105985\n",
      "min: 0.14810818784157034\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033273842180853816\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2156195162916725\n",
      "std: 0.0766987412812046\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2183125071103562\n",
      "std: 0.08112827211988279\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.037958128910553474\n",
      "min: 0.01058312818242936\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3415794693096313\n",
      "std: 0.36827671794008693\n",
      "min: -1.0393282332938178\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4538721089976292\n",
      "std: 0.22345852543318948\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03278952434080851\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090255488644596\n",
      "std: 0.0025170990831992106\n",
      "min: 1.3859090680685242\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090044907316763\n",
      "std: 0.0027357601659548088\n",
      "min: 1.3859090680685242\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.037484829888564594\n",
      "min: 0.015854807909637253\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3150979846362886\n",
      "std: 0.3030512957743581\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6069467427455485\n",
      "std: 0.18334876037063227\n",
      "min: 0.14810924774025577\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324394146126837\n",
      "min: 0.13097219002032656\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1825321992283402\n",
      "std: 0.2017222103073855\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1854728590675911\n",
      "std: 0.20443910185113176\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03174603174603175\n",
      "std: 0.039738331012480185\n",
      "min: 0.003535924334566737\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3419189132970418\n",
      "std: 0.36932708629762645\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4538387267641306\n",
      "std: 0.2235908282325898\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03272571866410618\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073626762981508\n",
      "std: 0.009438864299694476\n",
      "min: 1.317576505944788\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407348018336424\n",
      "std: 0.009618338792616537\n",
      "min: 1.317576505944788\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.037490979594202736\n",
      "min: 0.014889000190966457\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3159415669511988\n",
      "std: 0.3028729424710644\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6078675039148616\n",
      "std: 0.18407014859321966\n",
      "min: 0.1490201247181824\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033241207155010166\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1940342909477746\n",
      "std: 0.14631116174318334\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1968146899454986\n",
      "std: 0.14873938374685552\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03832710214809469\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3343634902518328\n",
      "std: 0.3699338673354365\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45871817072542215\n",
      "std: 0.22322382732359108\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032540920062672216\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4085537465676263\n",
      "std: 0.0036150374960242488\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4085639911987458\n",
      "std: 0.0036852556830514883\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03699809211923526\n",
      "min: 0.015574078740154726\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.313789429924894\n",
      "std: 0.3033233555259769\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6088483149627999\n",
      "std: 0.18319375863221\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319254599316429\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1912131929042657\n",
      "std: 0.16040520828470906\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1940706545421245\n",
      "std: 0.1635250501117807\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03881375250226981\n",
      "min: 0.00537788043977454\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33476020168850046\n",
      "std: 0.3723848795983701\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45801142263267447\n",
      "std: 0.2241988287752623\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03255078615511527\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408215816349582\n",
      "std: 0.005185273917010361\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082328006337084\n",
      "std: 0.00526712548167289\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03699935938063747\n",
      "min: 0.015330162284821269\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31303709467068547\n",
      "std: 0.30310496441540513\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6087342049613627\n",
      "std: 0.1830584800534242\n",
      "min: 0.14966656485135887\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033149359425553145\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.183424962919049\n",
      "std: 0.19568554737273364\n",
      "min: -0.20406795652609225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1863601166908144\n",
      "std: 0.19721365264765944\n",
      "min: -0.18769022866504972\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.039007669041578916\n",
      "min: 0.004430835159487861\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34010475542473606\n",
      "std: 0.36763158652193384\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45319090152509006\n",
      "std: 0.2229319108170737\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03270272931572106\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407790255369397\n",
      "std: 0.007460103041895851\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077917991730717\n",
      "std: 0.007503494468243889\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03700056551900876\n",
      "min: 0.015053454789559021\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31651743032111407\n",
      "std: 0.30323752342913946\n",
      "min: -0.7991462627239704\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6078198655311421\n",
      "std: 0.18403815470117305\n",
      "min: 0.14810818784157034\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327802317386843\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2161654097974595\n",
      "std: 0.07634437151011327\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2187937281667809\n",
      "std: 0.08069696462187048\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.0374626289240835\n",
      "min: 0.01058312818242936\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3418194884256355\n",
      "std: 0.3679374432225653\n",
      "min: -1.0393282332938178\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4529378680542215\n",
      "std: 0.22311506670811249\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03278268095012186\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090412309341895\n",
      "std: 0.0025024613162032945\n",
      "min: 1.3859090680685242\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090334819341763\n",
      "std: 0.002716123001796299\n",
      "min: 1.3859090680685242\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.0369977053411067\n",
      "min: 0.015671749602430066\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3152119323269463\n",
      "std: 0.30307286475348383\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6067227563313256\n",
      "std: 0.18336822208817344\n",
      "min: 0.14810924774025577\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033248300253910616\n",
      "min: 0.13097219002032656\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.183556757290942\n",
      "std: 0.2005045752834095\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1864207470840058\n",
      "std: 0.20319706715168132\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03921094211492515\n",
      "min: 0.003400302191169203\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34217194840567655\n",
      "std: 0.36898115578699175\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4529095583046026\n",
      "std: 0.22324461123121264\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03272027399028816\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407404246244899\n",
      "std: 0.009370711682512384\n",
      "min: 1.3175765059447877\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074024253668704\n",
      "std: 0.009550441205526455\n",
      "min: 1.3175765059447877\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.037003745771231486\n",
      "min: 0.014708983300722322\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3160454429679442\n",
      "std: 0.3028946531233371\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.607630216842734\n",
      "std: 0.18407993997833108\n",
      "min: 0.1490201247181824\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033245582249441956\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1937236374052533\n",
      "std: 0.1453410697324657\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1965990584806527\n",
      "std: 0.14777543862006165\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.0378299811087451\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33384434442302213\n",
      "std: 0.37056227592672253\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4592961879535379\n",
      "std: 0.2227660457209405\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03256266457104323\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4085410060009158\n",
      "std: 0.0036114621257921473\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4085617738855414\n",
      "std: 0.0036786684335036774\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.03652425265563489\n",
      "min: 0.015327910165093038\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31376149811632176\n",
      "std: 0.30341752662075644\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.608830229494333\n",
      "std: 0.18320581404665526\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319610554718665\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.190943491593333\n",
      "std: 0.15933181050398734\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1938944011476964\n",
      "std: 0.1624530529627842\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.038307955313561355\n",
      "min: 0.005377880439774539\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33424417654574806\n",
      "std: 0.37297224772657045\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4585960336160495\n",
      "std: 0.22372904063332882\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03257238248073071\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082076933226806\n",
      "std: 0.005166027457242174\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408235087164704\n",
      "std: 0.00524617938454579\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030769230769230767\n",
      "std: 0.036525497686118014\n",
      "min: 0.015057308425036445\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3130164009579357\n",
      "std: 0.3031996006411523\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6087153469938694\n",
      "std: 0.18307033839832962\n",
      "min: 0.14966656485135887\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03315335231586891\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1832948519678799\n",
      "std: 0.19420490746199023\n",
      "min: -0.20406795652609225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1863196414632673\n",
      "std: 0.19575624871522623\n",
      "min: -0.18769022866504972\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.03849853427420412\n",
      "min: 0.004430835159487861\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3395154055849304\n",
      "std: 0.3683003390555064\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4538404271374379\n",
      "std: 0.22249288334778508\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032722475154764175\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40778969781414\n",
      "std: 0.0074136486361287245\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078016411839207\n",
      "std: 0.00745712181579541\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.03652668311763783\n",
      "min: 0.01476898389652246\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31645805052537374\n",
      "std: 0.30333307177566715\n",
      "min: -0.7991462627239704\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6078121986410855\n",
      "std: 0.18404068431966356\n",
      "min: 0.14810818784157034\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033280707728109885\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2155150750415864\n",
      "std: 0.07606766833680595\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2182475149920933\n",
      "std: 0.08037325760453948\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.03698074106632064\n",
      "min: 0.01058312818242936\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.341199198670221\n",
      "std: 0.3685955276156788\n",
      "min: -1.0393282332938178\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4535813335565422\n",
      "std: 0.2226720651642965\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03280089065788033\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.409022203990271\n",
      "std: 0.0025131794775666285\n",
      "min: 1.3859090680685244\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090252992712482\n",
      "std: 0.0027192343880470707\n",
      "min: 1.3859090680685244\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030769230769230767\n",
      "std: 0.0365238725275973\n",
      "min: 0.015334376310774701\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.315163625371027\n",
      "std: 0.30316942218359966\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6067288876368531\n",
      "std: 0.18337829991581667\n",
      "min: 0.14810924774025577\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03325115992749194\n",
      "min: 0.13097219002032656\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1834248040632456\n",
      "std: 0.19900678002480113\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.186380272380878\n",
      "std: 0.20171122161733152\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.038698159373637867\n",
      "min: 0.003400302191169203\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3415623035042367\n",
      "std: 0.369631677324667\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45356351855321664\n",
      "std: 0.22280133731865148\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03273973839631289\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074089413378663\n",
      "std: 0.00930809353927288\n",
      "min: 1.317576505944788\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074175671437845\n",
      "std: 0.00948737687481578\n",
      "min: 1.317576505944788\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.0365298072574971\n",
      "min: 0.014480264800806872\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3159867233647926\n",
      "std: 0.30299249524047395\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6076245202144509\n",
      "std: 0.184079370482572\n",
      "min: 0.1490201247181824\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033248466229303844\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1941995966075316\n",
      "std: 0.1443213338498276\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.196905283049398\n",
      "std: 0.14673346279964444\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.037346330485315646\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33389034195378303\n",
      "std: 0.37022844729180476\n",
      "min: -1.040564191267659\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4592445007384175\n",
      "std: 0.22230835537060994\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03254990912642168\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4085650431792207\n",
      "std: 0.0035840687442881777\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4085768860495278\n",
      "std: 0.003650852301930219\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.036063155195039144\n",
      "min: 0.015169860457732515\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3137907441552851\n",
      "std: 0.3034342539028965\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6087418697396131\n",
      "std: 0.18318428352746907\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033195130269758004\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1914627741277453\n",
      "std: 0.15814456891718054\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1942419595442402\n",
      "std: 0.16123994322357676\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.0378159024097777\n",
      "min: 0.005377880439774539\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3342929431169548\n",
      "std: 0.37260613913426194\n",
      "min: -1.044086308921533\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4585498702716101\n",
      "std: 0.22325969075670254\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03255953754568476\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082368434880972\n",
      "std: 0.005125694070601981\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082551866623911\n",
      "std: 0.005205348880017624\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.036064378550214576\n",
      "min: 0.014910135331735092\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3130527243789639\n",
      "std: 0.30321707541829274\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6086260409928108\n",
      "std: 0.18304879549336764\n",
      "min: 0.14966656485135887\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033152798740323015\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.183857884784277\n",
      "std: 0.19320464625474382\n",
      "min: -0.20406795652609225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1867097300844704\n",
      "std: 0.19473448659037482\n",
      "min: -0.18769022866504972\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.03800338462482527\n",
      "min: 0.004194415530429109\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33949024637094966\n",
      "std: 0.367992819058833\n",
      "min: -1.0418624388317725\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45385748729007114\n",
      "std: 0.22203954993573696\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032707803497242734\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078238798135425\n",
      "std: 0.0073605657772227474\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078268221702677\n",
      "std: 0.007403900616194046\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.03606554423529887\n",
      "min: 0.01464468370077068\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31645635015553725\n",
      "std: 0.3033503086508956\n",
      "min: -0.7991462627239704\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6077345565926086\n",
      "std: 0.1840095086901654\n",
      "min: 0.14810818784157034\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327886375780647\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.215654066865227\n",
      "std: 0.0757017660146007\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2182226861112317\n",
      "std: 0.0799785610900046\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.03651185586812918\n",
      "min: 0.010055160744903945\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34114557074793195\n",
      "std: 0.368281629337561\n",
      "min: -1.0393282332938178\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4535960727329544\n",
      "std: 0.22221803549971808\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032784984375776094\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.409038740620509\n",
      "std: 0.0024976199172506855\n",
      "min: 1.3859090680685242\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090332409188775\n",
      "std: 0.0027021341254083345\n",
      "min: 1.3859090680685242\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03030303030303031\n",
      "std: 0.03606278165882601\n",
      "min: 0.01517202296082041\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3151727585539845\n",
      "std: 0.3031886074172643\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6066647843073321\n",
      "std: 0.1833541413332662\n",
      "min: 0.14810924774025577\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324951747181524\n",
      "min: 0.13097219002032656\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.183982878541526\n",
      "std: 0.19790389160655644\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.186766149513744\n",
      "std: 0.20058189301634635\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.038199482058855275\n",
      "min: 0.003103809363328191\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34151635602288\n",
      "std: 0.36930880422664997\n",
      "min: -1.0461975431230803\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4535830387361501\n",
      "std: 0.22234370485954355\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032724812831842344\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074489568619435\n",
      "std: 0.009243554104787702\n",
      "min: 1.317576505944788\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074485962213552\n",
      "std: 0.009421973349005354\n",
      "min: 1.317576505944788\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.03606861420400206\n",
      "min: 0.01427263818373694\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3159856587647743\n",
      "std: 0.30301198564736026\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6075483687528372\n",
      "std: 0.1840453172759884\n",
      "min: 0.1490201247181824\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324680949084517\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1951201601327974\n",
      "std: 0.1434628656605842\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1978573732043367\n",
      "std: 0.1458644355850612\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03687561983294247\n",
      "min: 0.004997925647148765\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3342698745769479\n",
      "std: 0.37116804629910743\n",
      "min: -1.0772735203280668\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45997979491379065\n",
      "std: 0.22226824846153428\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03258186146136132\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40859031667623\n",
      "std: 0.0035667505825460123\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4086035006895794\n",
      "std: 0.003635706368317688\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.035614281002467676\n",
      "min: 0.014856277019525126\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31384168290530257\n",
      "std: 0.3035545482779967\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6087546624149854\n",
      "std: 0.18321334076195442\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319979799936398\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1924268269582725\n",
      "std: 0.15713086422666647\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1952360271831977\n",
      "std: 0.1602126208587662\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03733706429426692\n",
      "min: 0.005377880439774539\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3346730468818857\n",
      "std: 0.3735026612047076\n",
      "min: -1.077281606680121\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4592909505124434\n",
      "std: 0.22320576095758632\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03259122073965433\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082673777761103\n",
      "std: 0.005091502346381504\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082869656373418\n",
      "std: 0.005172986628390905\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03561548334683098\n",
      "min: 0.014707512944118213\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3131103313342656\n",
      "std: 0.3033381625989666\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.608638342752657\n",
      "std: 0.18307762709033656\n",
      "min: 0.14966656485135887\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03315787155955301\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1849117738437425\n",
      "std: 0.1920809923720666\n",
      "min: -0.20406795652609225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.187790702758866\n",
      "std: 0.1936127224983865\n",
      "min: -0.18769022866504972\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03752148527259074\n",
      "min: 0.004194415530429108\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3398002009320314\n",
      "std: 0.3689580224677723\n",
      "min: -1.076894375351741\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45466182862412957\n",
      "std: 0.22201988099833606\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0327376502668186\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407858586668118\n",
      "std: 0.007321328494034455\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407862844437601\n",
      "std: 0.007366304591563657\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03561663027678673\n",
      "min: 0.01429843842162717\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31647697691593324\n",
      "std: 0.303470813136103\n",
      "min: -0.7991462627239704\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6077579805283028\n",
      "std: 0.18402931452834748\n",
      "min: 0.14810818784157034\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033282669214364416\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2162587506341045\n",
      "std: 0.07531467159451402\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2188664784630878\n",
      "std: 0.07954793406944063\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03605539109693043\n",
      "min: 0.010055160744903946\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34142772969275975\n",
      "std: 0.36923559314087345\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45439666702461706\n",
      "std: 0.22219602368457908\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03281341096506048\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090563416734267\n",
      "std: 0.002488599080516476\n",
      "min: 1.3859090680685242\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090525334309423\n",
      "std: 0.0026944477010553344\n",
      "min: 1.3859090680685242\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.035613913741990355\n",
      "min: 0.014899007312107993\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.315203813464357\n",
      "std: 0.30331109467069806\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6067011339882105\n",
      "std: 0.18338143377499302\n",
      "min: 0.14810924774025577\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03325350775501074\n",
      "min: 0.13097219002032656\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1850335765340012\n",
      "std: 0.19675398434537236\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1878455587705685\n",
      "std: 0.19942594565414845\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.037714162524753826\n",
      "min: 0.0029581084628523247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3418045861331932\n",
      "std: 0.3702504838644161\n",
      "min: -1.0771801916339687\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4543899563675742\n",
      "std: 0.22231790848642877\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03275424979035916\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074894890173026\n",
      "std: 0.009186214216185781\n",
      "min: 1.317576505944788\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074904925909937\n",
      "std: 0.009365232136130056\n",
      "min: 1.317576505944788\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03561964758441701\n",
      "min: 0.014053163204101757\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.316006976276083\n",
      "std: 0.3031349376567154\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6075734267858992\n",
      "std: 0.1840622272841953\n",
      "min: 0.1490201247181824\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03325080876950014\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1958360250473428\n",
      "std: 0.14261762379684179\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1986521767593545\n",
      "std: 0.14498593372980434\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03641733886265108\n",
      "min: 0.004997925647148765\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33460481375408785\n",
      "std: 0.3714494637368268\n",
      "min: -1.0772735203280668\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4595591314629726\n",
      "std: 0.22187628044836585\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03257801093184241\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4086117663405642\n",
      "std: 0.0035436779364633885\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4086224901581208\n",
      "std: 0.003611297321930694\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03517713891789545\n",
      "min: 0.014651496430295952\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3138391038712464\n",
      "std: 0.3035832876266452\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6085873820286269\n",
      "std: 0.18322261299105064\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03320137285579541\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1931834658358098\n",
      "std: 0.15618796854532094\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1960697588481568\n",
      "std: 0.15924009239889056\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.0368709308318623\n",
      "min: 0.005377880439774539\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3350101164129189\n",
      "std: 0.37374818445501473\n",
      "min: -1.077281606680121\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45887434784900494\n",
      "std: 0.22280173406891138\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03258728191449438\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082933364726644\n",
      "std: 0.005057554139142476\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083103544667006\n",
      "std: 0.005137997746652645\n",
      "min: 1.3631779066326055\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03517832102967022\n",
      "min: 0.014433157878948284\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31311466307952196\n",
      "std: 0.30336760597921614\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6084702904957494\n",
      "std: 0.18308696005308217\n",
      "min: 0.14966656485135887\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03315985002719744\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1857730913648785\n",
      "std: 0.19090140152534546\n",
      "min: -0.20406795652609225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1887260031247522\n",
      "std: 0.19242559546176058\n",
      "min: -0.18769022866504972\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03705235050201839\n",
      "min: 0.004194415530429108\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3400686007543995\n",
      "std: 0.3692637959855366\n",
      "min: -1.076894375351741\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45430772420543736\n",
      "std: 0.2216244411660625\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03273199738774032\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407891415720308\n",
      "std: 0.007268686170294182\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078931367241128\n",
      "std: 0.007313629588925414\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03517944919497588\n",
      "min: 0.014149782820169016\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31644484955381186\n",
      "std: 0.3035004174631467\n",
      "min: -0.7991462627239704\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6076008620876081\n",
      "std: 0.184029057864862\n",
      "min: 0.14810818784157034\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03328340579488801\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2166758675401808\n",
      "std: 0.0749801467084059\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2193706535396434\n",
      "std: 0.07911484688101353\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03561089733971122\n",
      "min: 0.010055160744903946\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34166773473227535\n",
      "std: 0.3695307443351762\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4540405597610893\n",
      "std: 0.22179756923137633\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03280637222805718\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090718988649262\n",
      "std: 0.0024741345752937035\n",
      "min: 1.3859090680685242\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090659134802608\n",
      "std: 0.0026768556892113\n",
      "min: 1.3859090680685242\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03517677777014884\n",
      "min: 0.014694080051032387\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31518214026033287\n",
      "std: 0.3033423415379723\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6065570468440735\n",
      "std: 0.18338729112280328\n",
      "min: 0.14810924774025577\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033254422691354694\n",
      "min: 0.13097219002032656\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1858906389167043\n",
      "std: 0.19554380420198922\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1887770824368982\n",
      "std: 0.1982055983138292\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.037241736366824596\n",
      "min: 0.0029581084628523247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34205291196548704\n",
      "std: 0.37053634317948914\n",
      "min: -1.0771801916339687\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45403651073117846\n",
      "std: 0.22191823616440168\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03274832911496772\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075275038427024\n",
      "std: 0.00912090447928295\n",
      "min: 1.317576505944788\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075259845387622\n",
      "std: 0.009299200848308672\n",
      "min: 1.317576505944788\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03518241565711643\n",
      "min: 0.013832026906518472\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3159757825526309\n",
      "std: 0.30316677601684106\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6074178125252441\n",
      "std: 0.1840592909336127\n",
      "min: 0.1490201247181824\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033251733498423766\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1960215750999377\n",
      "std: 0.1418169689437415\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1989092176489125\n",
      "std: 0.14416192788675103\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03597107175757497\n",
      "min: 0.004997925647148765\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3352743214964996\n",
      "std: 0.37147042014851933\n",
      "min: -1.077273520328067\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4576845638368154\n",
      "std: 0.22245307353149593\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03259516389334651\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408594547472568\n",
      "std: 0.003544791082164436\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408596907859047\n",
      "std: 0.003613842327910723\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03475126463800404\n",
      "min: 0.014359228532757813\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3139085787366858\n",
      "std: 0.3035673063393159\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6083207705990941\n",
      "std: 0.18322392709035162\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03320400358033038\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1934152307081576\n",
      "std: 0.15526014872638086\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1963711505785424\n",
      "std: 0.15829094468837673\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03641703647459984\n",
      "min: 0.005080353818882393\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3356823960949429\n",
      "std: 0.37373671161807664\n",
      "min: -1.0772816066801212\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4570048530155204\n",
      "std: 0.22336034288235185\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03260427009595369\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082803261240522\n",
      "std: 0.005048582584587028\n",
      "min: 1.3612026776250012\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40828887440729\n",
      "std: 0.005129884130322819\n",
      "min: 1.3612026776250012\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.034752427400432884\n",
      "min: 0.014073212892965571\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31319099522782684\n",
      "std: 0.3033524210876758\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6082028551281808\n",
      "std: 0.1830884848828923\n",
      "min: 0.14966656485135887\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033162876503865034\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1861241469857766\n",
      "std: 0.18967938483171343\n",
      "min: -0.20406795652609225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.189143795171841\n",
      "std: 0.1912025743926152\n",
      "min: -0.18769022866504972\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.036595533317727975\n",
      "min: 0.004194415530429108\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3406716367021093\n",
      "std: 0.36930410370284644\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4524982334691855\n",
      "std: 0.22216874514966284\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03274719311757417\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078857781395946\n",
      "std: 0.0072351689353425605\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078791008807028\n",
      "std: 0.007281134563560493\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03475353744844131\n",
      "min: 0.013839822039689842\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3164854138360366\n",
      "std: 0.3034847436634918\n",
      "min: -0.7991462627239704\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6073439578140997\n",
      "std: 0.18402056656091406\n",
      "min: 0.14810818784157034\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03328521803282811\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2165838490541854\n",
      "std: 0.07472539939595534\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2193574437131258\n",
      "std: 0.07877769965296555\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03517796365195428\n",
      "min: 0.009392358214265827\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3422420692957787\n",
      "std: 0.3695594387717058\n",
      "min: -1.0765562360804253\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4522324085779027\n",
      "std: 0.22233885953776425\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03282023434179046\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090512398896609\n",
      "std: 0.002484118520427952\n",
      "min: 1.3848106090316328\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.409037216599955\n",
      "std: 0.002687022952689857\n",
      "min: 1.3848106090316328\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03475090926297486\n",
      "min: 0.014399181315566934\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31523267886526224\n",
      "std: 0.30332848066144946\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6063133326396204\n",
      "std: 0.18338460237780257\n",
      "min: 0.14810924774025577\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03325640398128177\n",
      "min: 0.13097219002032656\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1862426285212522\n",
      "std: 0.19423461660779287\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1891964121505212\n",
      "std: 0.1968898047571223\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03678171632485782\n",
      "min: 0.002958108462852325\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3426375434787283\n",
      "std: 0.37055757250972615\n",
      "min: -1.077180191633969\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4522276791753302\n",
      "std: 0.22245656106857048\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032763235121586\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075270481272473\n",
      "std: 0.0090784214688338\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075171446723695\n",
      "std: 0.009256692608457658\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03475645503824783\n",
      "min: 0.013455213110372701\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3160175015313379\n",
      "std: 0.3031533478929121\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071622435963384\n",
      "std: 0.18404829672989742\n",
      "min: 0.1490201247181824\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03325373750953972\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1960074521216575\n",
      "std: 0.14116101585431703\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1987862470482498\n",
      "std: 0.14355074046522218\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.03553628490706359\n",
      "min: 0.004580657668410551\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33425646239740714\n",
      "std: 0.3710887887139079\n",
      "min: -1.0772735203280668\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45777671271818154\n",
      "std: 0.22193564970178573\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03254960874775052\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408588074394856\n",
      "std: 0.0035364987435272206\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4085860097519853\n",
      "std: 0.0036092721701010276\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.0343362174312294\n",
      "min: 0.014203194508149638\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31386884921392283\n",
      "std: 0.30358089796822796\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6083311380746732\n",
      "std: 0.18315940603113906\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319972578319256\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1934407960572644\n",
      "std: 0.15445906571809068\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1962866228925169\n",
      "std: 0.15752282587874314\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.03597488907933987\n",
      "min: 0.005080353818882393\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3346673822983838\n",
      "std: 0.3733256974222693\n",
      "min: -1.0772816066801212\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4571030936920112\n",
      "std: 0.22283299061666165\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03255869425077203\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082780178001806\n",
      "std: 0.0050275903730537756\n",
      "min: 1.3612026776250012\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082820461435888\n",
      "std: 0.005111464476368206\n",
      "min: 1.3612026776250012\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028571428571428567\n",
      "std: 0.03433736127769147\n",
      "min: 0.013986526782781825\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31315778237225916\n",
      "std: 0.3033664311089108\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6082127559278919\n",
      "std: 0.18302388439974393\n",
      "min: 0.14966656485135887\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03315897148147337\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1862381790415677\n",
      "std: 0.1887108392480295\n",
      "min: -0.20406795652609225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1891453796284124\n",
      "std: 0.19027535486147126\n",
      "min: -0.18769022866504972\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.03615056905084288\n",
      "min: 0.004080705027846568\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3395902296330371\n",
      "std: 0.368958517754186\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4526528347893388\n",
      "std: 0.22165817050583617\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03270002894557521\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078903402184348\n",
      "std: 0.007190499094139096\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407879176767135\n",
      "std: 0.0072387682417029454\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.034338453610450646\n",
      "min: 0.013749650648035178\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3164176218247426\n",
      "std: 0.3034994062987209\n",
      "min: -0.7991462627239704\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6073638719693765\n",
      "std: 0.1839478032169388\n",
      "min: 0.14810818784157034\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03328015285057264\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2162970091660992\n",
      "std: 0.074673610218756\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2189673882918324\n",
      "std: 0.07879905520297564\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.034756108797453486\n",
      "min: 0.009392358214265827\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34113620121499605\n",
      "std: 0.36921159714438667\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4523840035863202\n",
      "std: 0.22182672563208605\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03277207904824132\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090403314416977\n",
      "std: 0.002485573871609514\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090221383209123\n",
      "std: 0.002691737869804911\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.034335867715820305\n",
      "min: 0.01419835002303471\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31517514022285653\n",
      "std: 0.30334445927764897\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6063455430328734\n",
      "std: 0.18331870308215029\n",
      "min: 0.14810924774025577\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03325152761081905\n",
      "min: 0.13097219002032656\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1863502314002012\n",
      "std: 0.19327155743049673\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1891928780487668\n",
      "std: 0.19595526998537016\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.036333674468751465\n",
      "min: 0.002958108462852325\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34153808889768406\n",
      "std: 0.37020215815449786\n",
      "min: -1.0771801916339685\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4523852447656944\n",
      "std: 0.22194255656845638\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03271595190358594\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075366843268302\n",
      "std: 0.009020405625096853\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407522333618034\n",
      "std: 0.009199613406359506\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.03434132348874218\n",
      "min: 0.013455213110372698\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31595065423814933\n",
      "std: 0.3031700000614256\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071837960016578\n",
      "std: 0.1839730528560736\n",
      "min: 0.1490201247181824\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324884837050742\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.195817029516808\n",
      "std: 0.14015767135141408\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.198462111819546\n",
      "std: 0.14256445963175554\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03511241202277192\n",
      "min: 0.004580657668410551\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33390548978177026\n",
      "std: 0.37109325592021475\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4588135427295386\n",
      "std: 0.22208172850017907\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032536492737186846\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4085896949015113\n",
      "std: 0.0035196605246277613\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408598401797039\n",
      "std: 0.0035852634041219755\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03393157988057674\n",
      "min: 0.01404612802065653\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31375413596456936\n",
      "std: 0.3035896684534254\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6084281885583168\n",
      "std: 0.18311371009912575\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319568183442067\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.193273147145208\n",
      "std: 0.15351351167791888\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.195984132833084\n",
      "std: 0.15658374200921146\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03554392925460039\n",
      "min: 0.004951541197071224\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33431932493562755\n",
      "std: 0.37329833242583477\n",
      "min: -1.0772816066801212\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4581427042396163\n",
      "std: 0.22296769125868524\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03254551708731512\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082835945519494\n",
      "std: 0.005001503063864815\n",
      "min: 1.3612026776250017\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082982976291138\n",
      "std: 0.005080611805555771\n",
      "min: 1.3612026776250017\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.0339327054014143\n",
      "min: 0.013820629712879503\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31304950347897215\n",
      "std: 0.30337565362866536\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6083091435620529\n",
      "std: 0.182978301804356\n",
      "min: 0.14966656485135887\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03315530347049131\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1861677846992509\n",
      "std: 0.1873905330514878\n",
      "min: -0.20406795652609225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1889373830459196\n",
      "std: 0.18897465800604968\n",
      "min: -0.18769022866504972\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.035716838637043856\n",
      "min: 0.004080705027846568\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33918162696373716\n",
      "std: 0.36899367389167664\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4537500726961222\n",
      "std: 0.22183059201628286\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03268546068592142\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078996395796444\n",
      "std: 0.007146576289773111\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078992071924317\n",
      "std: 0.00719221560967649\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03393378068871976\n",
      "min: 0.01354141315312205\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3162759526371529\n",
      "std: 0.3035097440812748\n",
      "min: -0.7991462627239704\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6074702920603121\n",
      "std: 0.18389436880778215\n",
      "min: 0.14810818784157034\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033275363794978606\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2157947021245312\n",
      "std: 0.07446892951885375\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2183364427140226\n",
      "std: 0.07861948864199285\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03434485647784458\n",
      "min: 0.009392358214265827\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3407036035597301\n",
      "std: 0.36924031976569244\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45347315866581\n",
      "std: 0.2219942707314624\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03275635387034284\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090354865403907\n",
      "std: 0.002481267752893409\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090283204679026\n",
      "std: 0.002675439100178699\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03393123576302295\n",
      "min: 0.014107593208379947\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3150436445339992\n",
      "std: 0.3033560044595643\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6064633459438428\n",
      "std: 0.18327235953205734\n",
      "min: 0.14810924774025577\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033246924157641744\n",
      "min: 0.13097219002032656\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1862648831864953\n",
      "std: 0.19206970578033408\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1889712696674846\n",
      "std: 0.1947622995037352\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03589700254113138\n",
      "min: 0.002958108462852325\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34111109833954967\n",
      "std: 0.37022154365001075\n",
      "min: -1.0771801916339685\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45348473907512343\n",
      "std: 0.22211002063740207\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03270112352595945\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075498564190432\n",
      "std: 0.008972460634479566\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075462734273867\n",
      "std: 0.009148912755758899\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03393660476943364\n",
      "min: 0.013200086203106762\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3158097269820076\n",
      "std: 0.3031822602123163\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6072918242658696\n",
      "std: 0.18391731590054594\n",
      "min: 0.1490201247181824\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033244225914580594\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1961192743135434\n",
      "std: 0.13932430371644425\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.198533678885761\n",
      "std: 0.14170298683742938\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03469914568831481\n",
      "min: 0.00455777770589654\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33429585335329254\n",
      "std: 0.3706500279944458\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4592708577651899\n",
      "std: 0.22190406861651424\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032547266962661574\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4086020905213514\n",
      "std: 0.0034934491494554042\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4086141103414422\n",
      "std: 0.003557892071015986\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777783\n",
      "std: 0.03353695631759437\n",
      "min: 0.01387672875941982\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31380943304730397\n",
      "std: 0.30355146329194066\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6083269770426454\n",
      "std: 0.18313149684200947\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0332010198498695\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.193616795889403\n",
      "std: 0.15244512697736756\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1960958384077687\n",
      "std: 0.15548352437191898\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03512370942517325\n",
      "min: 0.004951541197071224\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33470987090582616\n",
      "std: 0.3728275884705293\n",
      "min: -1.0772816066801212\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4586051800753177\n",
      "std: 0.222780138373515\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03255619318816857\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083004233216045\n",
      "std: 0.00495907519600064\n",
      "min: 1.3612026776250012\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408318314145861\n",
      "std: 0.005037724533418002\n",
      "min: 1.3612026776250012\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03353806378123924\n",
      "min: 0.013705673734295864\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31311094223656794\n",
      "std: 0.30333833062607757\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6082072864718787\n",
      "std: 0.1829962138235137\n",
      "min: 0.14966656485135887\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03316101547032846\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1865598799187347\n",
      "std: 0.1864407262254987\n",
      "min: -0.20406795652609225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.189095716264085\n",
      "std: 0.18800247409625137\n",
      "min: -0.18769022866504972\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03529404371019781\n",
      "min: 0.0038960231319341157\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33951069085901875\n",
      "std: 0.3685680585800563\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45426477986773134\n",
      "std: 0.22166595888851434\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03269455565797781\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079198654586276\n",
      "std: 0.0071027728098080915\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079227098178944\n",
      "std: 0.007148217863336975\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03353912294398434\n",
      "min: 0.013341769956533822\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3163048671128145\n",
      "std: 0.30347172461819166\n",
      "min: -0.7991462627239704\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6073781667611717\n",
      "std: 0.1839036897407653\n",
      "min: 0.14810818784157034\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327995717663018\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2158073435717107\n",
      "std: 0.0741262333659157\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.218122153450356\n",
      "std: 0.07825682350122609\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.033943777890743106\n",
      "min: 0.009392358214265829\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3410091815934992\n",
      "std: 0.36880795426101515\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4539858910766699\n",
      "std: 0.22182825072212808\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03276417406300515\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090406228583339\n",
      "std: 0.002466814136126945\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090370135201913\n",
      "std: 0.0026578826060236218\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03353661767343825\n",
      "min: 0.013939714818457382\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31508203749461206\n",
      "std: 0.3033199841777836\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.606382779839439\n",
      "std: 0.18328772064656532\n",
      "min: 0.14810924774025577\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033251685832156395\n",
      "min: 0.13097219002032656\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1866595874540153\n",
      "std: 0.19092902023250247\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.189133234711454\n",
      "std: 0.19359448249860717\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03547127933085239\n",
      "min: 0.002958108462852325\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34142219726123385\n",
      "std: 0.3697805581423568\n",
      "min: -1.0771801916339685\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45400283977088823\n",
      "std: 0.22194197432128945\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03271002529960446\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075751133327477\n",
      "std: 0.008907978502822936\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075748175037945\n",
      "std: 0.00908390271772221\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.0335419017761558\n",
      "min: 0.01315484955411445\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31583955718580325\n",
      "std: 0.30314627041828907\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6072010225555371\n",
      "std: 0.18392430934610127\n",
      "min: 0.1490201247181824\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033248994062626776\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1969337086730705\n",
      "std: 0.13844553765464734\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.19938376068817\n",
      "std: 0.14081242041422853\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03429603605662164\n",
      "min: 0.004557777705896541\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33380965045722133\n",
      "std: 0.3712269937585561\n",
      "min: -1.077273520328067\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45933289099666946\n",
      "std: 0.2220349985085377\n",
      "min: -0.10883049623165526\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0325427615525916\n",
      "min: 0.11804781246265542\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4086219299955158\n",
      "std: 0.0034779766451238188\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4086295714326365\n",
      "std: 0.003544343867475573\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.0331519711949421\n",
      "min: 0.013635291105236065\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31375040885079936\n",
      "std: 0.30358487878797713\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6082935589401223\n",
      "std: 0.18313268960281254\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319995939919618\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1944634725872745\n",
      "std: 0.1515097581975116\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1969770174299124\n",
      "std: 0.15453186270408853\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.034713892496544003\n",
      "min: 0.0049515411970712225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3342251738127144\n",
      "std: 0.37337051523186565\n",
      "min: -1.0772816066801212\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4586725737522629\n",
      "std: 0.22289865573853915\n",
      "min: -0.11415131062850671\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03255157367351756\n",
      "min: 0.1178296624748413\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083249386541867\n",
      "std: 0.0049301303875974745\n",
      "min: 1.3612026776250017\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083383865823278\n",
      "std: 0.005009872599324062\n",
      "min: 1.3612026776250017\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03315306126826996\n",
      "min: 0.013491417591421088\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3130578173844618\n",
      "std: 0.3033723403237267\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6081736985308583\n",
      "std: 0.18299745868958556\n",
      "min: 0.14966656485135887\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033160302704122256\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1874898915403869\n",
      "std: 0.1853149987903646\n",
      "min: -0.20406795652609225\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1900579938405345\n",
      "std: 0.18687673218055406\n",
      "min: -0.18769022866504972\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.034881656142776746\n",
      "min: 0.003896023131934116\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3389664666616787\n",
      "std: 0.3691767274539464\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45438619838419275\n",
      "std: 0.22180204350606525\n",
      "min: -0.11614260933525503\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032688431282426676\n",
      "min: 0.117309852244767\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407948637755156\n",
      "std: 0.007062898496989636\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079471401632162\n",
      "std: 0.007109507052600048\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.0331541045303284\n",
      "min: 0.013187078739373324\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3162195545381832\n",
      "std: 0.3035063446440131\n",
      "min: -0.7991462627239704\n",
      "max: 0.919219519501969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6073540713288695\n",
      "std: 0.18389689672474907\n",
      "min: 0.14810818784157034\n",
      "max: 0.919219519501969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327814763880484\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2163350907399249\n",
      "std: 0.07385663369568542\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2186914117251457\n",
      "std: 0.0779345629036471\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03355250991822466\n",
      "min: 0.009392358214265829\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3404427334640159\n",
      "std: 0.3694095867107508\n",
      "min: -1.0765562360804253\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45410542908047263\n",
      "std: 0.2219615225000725\n",
      "min: -0.11744174501600678\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03275700839001929\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.409054360222888\n",
      "std: 0.0024601545337299734\n",
      "min: 1.3848106090316332\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.409046693786131\n",
      "std: 0.002652854082579695\n",
      "min: 1.3848106090316332\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03315163778255354\n",
      "min: 0.013663991682523443\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3150063705802237\n",
      "std: 0.3033558341023587\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6063699561734435\n",
      "std: 0.18328694528505557\n",
      "min: 0.14810924774025577\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03325005430110237\n",
      "min: 0.13097219002032656\n",
      "max: 0.266898773424504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1875868465010138\n",
      "std: 0.1898088156194753\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1900941289589226\n",
      "std: 0.19246376829980844\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03505607784093914\n",
      "min: 0.002958108462852325\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3408592930875113\n",
      "std: 0.37037339291704025\n",
      "min: -1.0771801916339687\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4541258353567508\n",
      "std: 0.22207214145851834\n",
      "min: -0.1201296195363325\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032703630448958035\n",
      "min: 0.11712467665367407\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076093188944814\n",
      "std: 0.008852013665965486\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407604719502792\n",
      "std: 0.009027885998864367\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.033156839664900004\n",
      "min: 0.012976460978026952\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3157550730488374\n",
      "std: 0.3031829314650621\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071784805167907\n",
      "std: 0.18391531552104115\n",
      "min: 0.1490201247181824\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033247354553144946\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1972081261920626\n",
      "std: 0.13785564540242617\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1996528188637128\n",
      "std: 0.14021097266322674\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.0339027952995726\n",
      "min: 0.003956627346677075\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3331240205855247\n",
      "std: 0.3707700888208707\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45921023275608697\n",
      "std: 0.22194947913388002\n",
      "min: -0.10883049623165542\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03250881570496532\n",
      "min: 0.11804781246265544\n",
      "max: 0.2666644669328233\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4086289832785421\n",
      "std: 0.003468053934625983\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4086318541559066\n",
      "std: 0.0035319411858898185\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.032776267435136876\n",
      "min: 0.01340363127582672\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31366784003529513\n",
      "std: 0.3035332380466261\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6082768025744739\n",
      "std: 0.18310025874586636\n",
      "min: 0.14911475972492572\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319641440354457\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.194775167567141\n",
      "std: 0.15073776108704418\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1972822077926997\n",
      "std: 0.15374480578257882\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03431412360109364\n",
      "min: 0.004636582542056037\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33354014312725844\n",
      "std: 0.3728884077575249\n",
      "min: -1.0772816066801212\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.458556173556446\n",
      "std: 0.22280235467239326\n",
      "min: -0.11415131062850681\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03251754867645912\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40833576126381\n",
      "std: 0.0049072351388613515\n",
      "min: 1.3612026776250015\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083443582714934\n",
      "std: 0.004985188980300758\n",
      "min: 1.3612026776250015\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.032777340689265994\n",
      "min: 0.013207948058294311\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31298101358864844\n",
      "std: 0.3033212972784062\n",
      "min: -0.7981271851124029\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6081566005869461\n",
      "std: 0.18296522347978547\n",
      "min: 0.14966656485135882\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03315709833246306\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.187889403661885\n",
      "std: 0.18433603930722886\n",
      "min: -0.20406795652609244\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1904489795548612\n",
      "std: 0.18589828928397567\n",
      "min: -0.18769022866504978\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03447938997776439\n",
      "min: 0.003896023131934116\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33822281308632574\n",
      "std: 0.36874892185278585\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4543212455048501\n",
      "std: 0.22171799969585723\n",
      "min: -0.11614260933525498\n",
      "max: 0.9680281682043078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03265299306894227\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407964149879676\n",
      "std: 0.007031568763999294\n",
      "min: 1.3429135180663998\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079578717047982\n",
      "std: 0.007077241954476873\n",
      "min: 1.3429135180663998\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03277836865167085\n",
      "min: 0.012899921634052739\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3161111913418699\n",
      "std: 0.30345588512525995\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6073462969660149\n",
      "std: 0.18385675159493708\n",
      "min: 0.1481081878415705\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327386685129966\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2163554793481897\n",
      "std: 0.07366287273808042\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2187118017189518\n",
      "std: 0.0776978129255705\n",
      "min: 0.7199851205004337\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03317071825119197\n",
      "min: 0.009392358214265829\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3396772201112414\n",
      "std: 0.36897921526529487\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4540404419199293\n",
      "std: 0.22187590810926874\n",
      "min: -0.11744174501600643\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03272063228498354\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090559629598298\n",
      "std: 0.0024553959209396925\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.409043821317871\n",
      "std: 0.002644033906534169\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03277593902614389\n",
      "min: 0.01345839571805948\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3149073480010793\n",
      "std: 0.30330663748284076\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6063732503237169\n",
      "std: 0.1832527622682344\n",
      "min: 0.1481092477402556\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324594578129937\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1879869099295137\n",
      "std: 0.18874327543302535\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1904865809856424\n",
      "std: 0.19139027802488745\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03465106464064914\n",
      "min: 0.00281082950672774\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34009826607926547\n",
      "std: 0.36993483747719447\n",
      "min: -1.0771801916339685\n",
      "max: 0.9667459598634701\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4540638416409021\n",
      "std: 0.22198318564623568\n",
      "min: -0.1201296195363326\n",
      "max: 0.9667459598634701\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032668008849453\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076293388994319\n",
      "std: 0.008805440930146772\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076199760492956\n",
      "std: 0.008979860994281058\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.032781061476005124\n",
      "min: 0.01262665185933286\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31564759709474083\n",
      "std: 0.3031343519316405\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071721825981302\n",
      "std: 0.1838731729848316\n",
      "min: 0.14902012471818255\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324323885835483\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1976137335127865\n",
      "std: 0.13716960701950437\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.199986323044619\n",
      "std: 0.13952771179304405\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.033518994607201875\n",
      "min: 0.0037371563448466163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33323935294347357\n",
      "std: 0.3706671373469308\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45868808607881867\n",
      "std: 0.22201268937236351\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03250743340287975\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4086302608519916\n",
      "std: 0.00345613076495038\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4086381834495696\n",
      "std: 0.0035179610535255312\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.03240950562557349\n",
      "min: 0.0132141086430704\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3136662165537154\n",
      "std: 0.3035592978379794\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6082192327844637\n",
      "std: 0.18306394094405756\n",
      "min: 0.14911475972492558\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033195747373709054\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1952118886255723\n",
      "std: 0.1499195974378414\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1976459775834853\n",
      "std: 0.152922474347783\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.033924007606714865\n",
      "min: 0.004510304502820164\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3336548370155378\n",
      "std: 0.37275709092777787\n",
      "min: -1.077281606680121\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4580363791268154\n",
      "std: 0.22285318454552114\n",
      "min: -0.11415131062850675\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032515930162969185\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083414530515608\n",
      "std: 0.004887738207921128\n",
      "min: 1.3612026776250012\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408354999579566\n",
      "std: 0.0049642998063187\n",
      "min: 1.3612026776250012\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.03241056266591528\n",
      "min: 0.01300918986234696\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31298514659414095\n",
      "std: 0.3033480410783378\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.608098423132438\n",
      "std: 0.18292903127953794\n",
      "min: 0.1496665648513588\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033156772146688385\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1884486289277376\n",
      "std: 0.18307738370572665\n",
      "min: -0.20406795652609244\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1909324997482582\n",
      "std: 0.1846521864870984\n",
      "min: -0.18769022866504992\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.03408678986946726\n",
      "min: 0.0038960231319341153\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3382812875732278\n",
      "std: 0.36866790876715955\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043074\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45385491343286466\n",
      "std: 0.22177557021943553\n",
      "min: -0.11614260933525519\n",
      "max: 0.9680281682043074\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03265002217087118\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079747863775192\n",
      "std: 0.00699330710004707\n",
      "min: 1.3429135180663998\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079735334282366\n",
      "std: 0.007038449421870647\n",
      "min: 1.3429135180663998\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.03241157539463827\n",
      "min: 0.012775299190763555\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3160845366634725\n",
      "std: 0.3034824983895393\n",
      "min: -0.7991462627239704\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6072973052464025\n",
      "std: 0.1838126928856774\n",
      "min: 0.14810818784157048\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03327249254685126\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2165152259071983\n",
      "std: 0.07334252544827095\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.218804012815865\n",
      "std: 0.07737803894047834\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.032798059018792965\n",
      "min: 0.009343892882096238\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3397121356564351\n",
      "std: 0.3688896023861551\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813369\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45357132030935593\n",
      "std: 0.22193148989214354\n",
      "min: -0.11744174501600653\n",
      "max: 0.9594521654813369\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03271658281202675\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.409053817220978\n",
      "std: 0.0024468783632550324\n",
      "min: 1.384810609031633\n",
      "max: 1.4139907789377222\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.409046941391983\n",
      "std: 0.00263200778299837\n",
      "min: 1.384810609031633\n",
      "max: 1.4139907789377222\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.03240918205832478\n",
      "min: 0.01323184609696075\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3148898070266145\n",
      "std: 0.30333467999394326\n",
      "min: -0.7986681568822113\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6063348613371734\n",
      "std: 0.183214540716565\n",
      "min: 0.1481092477402557\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324474266305589\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.188541947777195\n",
      "std: 0.18747904387763528\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1909672560161884\n",
      "std: 0.1901288433025459\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.03425582202642439\n",
      "min: 0.002810829506727741\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3401383715037409\n",
      "std: 0.3698384722453288\n",
      "min: -1.0771801916339683\n",
      "max: 0.9667459598634701\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4535971729792804\n",
      "std: 0.22203565226394884\n",
      "min: -0.12012961953633251\n",
      "max: 0.9667459598634701\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03266469687241636\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076451263504624\n",
      "std: 0.008758994589170527\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076408150406585\n",
      "std: 0.008932288526127694\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.03241422736614534\n",
      "min: 0.012467934635107406\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31562191205520074\n",
      "std: 0.3031630332403474\n",
      "min: -0.7982867040747369\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.607124573578326\n",
      "std: 0.18382708859197033\n",
      "min: 0.1490201247181824\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324203554028179\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1972407773340854\n",
      "std: 0.13664403679367812\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1996057363523969\n",
      "std: 0.13897770636722653\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03314435786037688\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3328249284108218\n",
      "std: 0.3704873315037951\n",
      "min: -1.0772735203280668\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45904145131590257\n",
      "std: 0.22202367522080269\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03250509389343485\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4086336615796\n",
      "std: 0.003433819720470867\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955167\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4086507933753767\n",
      "std: 0.0034939281146581275\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955167\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.0320513626952471\n",
      "min: 0.013114603873405763\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3135647865541468\n",
      "std: 0.3035946161317203\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6082634988557315\n",
      "std: 0.1830533261409933\n",
      "min: 0.14911475972492552\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319072117316043\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1948720315068002\n",
      "std: 0.14928980042190895\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1972973452089266\n",
      "std: 0.15226619931889387\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.033543229647245966\n",
      "min: 0.004074749627124123\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.333241330115046\n",
      "std: 0.37255097984235463\n",
      "min: -1.0772816066801212\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45839480913536484\n",
      "std: 0.22285335198221384\n",
      "min: -0.11415131062850675\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03251344195060799\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083489424744664\n",
      "std: 0.00485493748413261\n",
      "min: 1.3612026776250017\n",
      "max: 1.4139911658253617\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083716000149518\n",
      "std: 0.004930537736166067\n",
      "min: 1.3612026776250017\n",
      "max: 1.4139911658253617\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03205240382503786\n",
      "min: 0.012891761794206156\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3128891611716979\n",
      "std: 0.30338388819298845\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6081425937122674\n",
      "std: 0.18291843264271523\n",
      "min: 0.14966656485135887\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033152061808660725\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1882331547938096\n",
      "std: 0.18196864931948686\n",
      "min: -0.20406795652609244\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1907059838703848\n",
      "std: 0.18353604420289996\n",
      "min: -0.18769022866504978\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.033703590822646894\n",
      "min: 0.003896023131934116\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3378121453917782\n",
      "std: 0.36851435490981255\n",
      "min: -1.0768943753517413\n",
      "max: 0.9680281682043074\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4542638725075127\n",
      "std: 0.22179745413632945\n",
      "min: -0.11614260933525519\n",
      "max: 0.9680281682043074\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03264615981426669\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079881398866962\n",
      "std: 0.006942187856023757\n",
      "min: 1.3429135180663998\n",
      "max: 1.4139917536538014\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079960232032547\n",
      "std: 0.006987393076517509\n",
      "min: 1.3429135180663998\n",
      "max: 1.4139917536538014\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.032053401607675565\n",
      "min: 0.012718251365335536\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31595863882891473\n",
      "std: 0.30351924192403124\n",
      "min: -0.7991462627239704\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6073504277768468\n",
      "std: 0.18379495596243586\n",
      "min: 0.1481081878415705\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326677918529666\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2159279349350074\n",
      "std: 0.07321510937433336\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.218213324717104\n",
      "std: 0.07719057383447905\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03243420415360979\n",
      "min: 0.008628906921418267\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33922084100545463\n",
      "std: 0.368730679898307\n",
      "min: -1.0765562360804253\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4539757533694448\n",
      "std: 0.22195099245403568\n",
      "min: -0.11744174501600653\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03271164053751198\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090527864004048\n",
      "std: 0.00243229710165979\n",
      "min: 1.384810609031633\n",
      "max: 1.4139907789377222\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090553164331063\n",
      "std: 0.002613389753977233\n",
      "min: 1.384810609031633\n",
      "max: 1.4139907789377222\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03205104393787101\n",
      "min: 0.013178919508780177\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31477291490615095\n",
      "std: 0.30337239863588183\n",
      "min: -0.7986681568822116\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6063980564931216\n",
      "std: 0.18320277928081857\n",
      "min: 0.1481092477402557\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03323918877880072\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1883186028577455\n",
      "std: 0.18639242970400116\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.190733857084258\n",
      "std: 0.18902992854110087\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03387005786586816\n",
      "min: 0.002810829506727741\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3396520922022177\n",
      "std: 0.3696728360779689\n",
      "min: -1.077180191633969\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4540085710270398\n",
      "std: 0.22205309729517747\n",
      "min: -0.12012961953633251\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032660574635887486\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076633176781708\n",
      "std: 0.008693742924356871\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076681544693186\n",
      "std: 0.008866515391651992\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03205601350691715\n",
      "min: 0.012467934635107404\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3154969333409487\n",
      "std: 0.3032017224288869\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071792916452787\n",
      "std: 0.18380736774402093\n",
      "min: 0.14902012471818257\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033236484566206134\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1974322332343923\n",
      "std: 0.13600715181601558\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1997900426102726\n",
      "std: 0.13833980970328247\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.03277844030689746\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33247139934308323\n",
      "std: 0.3701230704182279\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4590231298336562\n",
      "std: 0.22166361129449277\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03248876463745406\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4086453416508147\n",
      "std: 0.0034101035334293856\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4086578678007395\n",
      "std: 0.003470093745549309\n",
      "min: 1.3808413703716924\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.03170153159647625\n",
      "min: 0.012902904263800457\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3135127785149117\n",
      "std: 0.3035579210180713\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6082731283165647\n",
      "std: 0.1830530701862103\n",
      "min: 0.1491147597249257\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319007966813709\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1951006822335464\n",
      "std: 0.14846254465026149\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1975179446564514\n",
      "std: 0.1514328128518941\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.033171323435622416\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3328889774147717\n",
      "std: 0.37216146727394034\n",
      "min: -1.0772816066801212\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4583823277956122\n",
      "std: 0.22248425461439794\n",
      "min: -0.11415131062850675\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03249706557370623\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083638827795086\n",
      "std: 0.004819955788574087\n",
      "min: 1.3612026776250015\n",
      "max: 1.4139911658253619\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083818505414736\n",
      "std: 0.004895417076225115\n",
      "min: 1.3612026776250015\n",
      "max: 1.4139911658253619\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.03170255722212563\n",
      "min: 0.01274468914899848\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3128426911869512\n",
      "std: 0.3033478029290736\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6081520152231897\n",
      "std: 0.18291832018218496\n",
      "min: 0.1496665648513588\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033151741711632016\n",
      "min: 0.13098150831459748\n",
      "max: 0.26684508789154937\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1885109362012505\n",
      "std: 0.18126071137219638\n",
      "min: -0.21786463479911827\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1909740617096671\n",
      "std: 0.18283216741829986\n",
      "min: -0.2133591058344205\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.03332942569759334\n",
      "min: 0.0032079484930234202\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3374078367931177\n",
      "std: 0.3681732448434172\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043074\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4542984326587571\n",
      "std: 0.22144159464623034\n",
      "min: -0.11614260933525519\n",
      "max: 0.9680281682043074\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032628555310576596\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080070888196634\n",
      "std: 0.006898824614165855\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080103933134067\n",
      "std: 0.006944191147346645\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.031703540782068294\n",
      "min: 0.012456423713468433\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31588308353759953\n",
      "std: 0.3034833826949583\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.607368416831826\n",
      "std: 0.18378762120818865\n",
      "min: 0.1481081878415705\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326546937454687\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2158884325836996\n",
      "std: 0.07298052169187648\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2181713707600084\n",
      "std: 0.0769370041370423\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.03207878080496278\n",
      "min: 0.008628906921418262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3387957516400607\n",
      "std: 0.36838708840792395\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4540103140393069\n",
      "std: 0.2215923223831927\n",
      "min: -0.11744174501600653\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03269305055811869\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090585379501903\n",
      "std: 0.002416566008492017\n",
      "min: 1.3848106090316328\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090566910485005\n",
      "std: 0.002596500905231111\n",
      "min: 1.3848106090316328\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.0317012175384965\n",
      "min: 0.012981072654507838\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3147062907128114\n",
      "std: 0.3033377689946483\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6064261276349211\n",
      "std: 0.18320109704536391\n",
      "min: 0.14810924774025577\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03323803667627315\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1886007885638459\n",
      "std: 0.18555232040089267\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1910073974672766\n",
      "std: 0.18818516238875596\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.033493372564695235\n",
      "min: 0.0025321524639696897\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3392317862875692\n",
      "std: 0.3693191917235502\n",
      "min: -1.0771801916339685\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4540457920794518\n",
      "std: 0.22169378161134135\n",
      "min: -0.12012961953633251\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03264280671512325\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407685605470868\n",
      "std: 0.008638964273309634\n",
      "min: 1.3156862828233125\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076859008343845\n",
      "std: 0.00881104808877852\n",
      "min: 1.3156862828233125\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.03170611390177216\n",
      "min: 0.01221585166865075\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31542243175961376\n",
      "std: 0.3031676481172047\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071987377482808\n",
      "std: 0.1837981855538447\n",
      "min: 0.14902012471818246\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03323533279450566\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1979561312418276\n",
      "std: 0.13522271647040024\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.200342053610426\n",
      "std: 0.13754372989396216\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.032420941294565804\n",
      "min: 0.0037371563448466163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33215558347351487\n",
      "std: 0.3698749298887431\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4576839218502345\n",
      "std: 0.2219467382089071\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032480600048652775\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4086506594017605\n",
      "std: 0.003393425465737885\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408662046229729\n",
      "std: 0.003454512945470986\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.03135971975280872\n",
      "min: 0.012750476981182176\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3135203511586524\n",
      "std: 0.3035535082063761\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6081180735762718\n",
      "std: 0.18304911313608524\n",
      "min: 0.1491147597249255\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318910081770204\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1956538205041254\n",
      "std: 0.14760001236789036\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.198097981479453\n",
      "std: 0.15055684436551964\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.032808033107500564\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33257499400469487\n",
      "std: 0.3718896190796709\n",
      "min: -1.0772816066801212\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4570478996457676\n",
      "std: 0.22275471995237403\n",
      "min: -0.11415131062850675\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032488786348362865\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083723446422867\n",
      "std: 0.004795020302236382\n",
      "min: 1.3612026776250017\n",
      "max: 1.4139911658253619\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083890934238343\n",
      "std: 0.004871309485591078\n",
      "min: 1.3612026776250017\n",
      "max: 1.4139911658253619\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.031360730427213164\n",
      "min: 0.012538256031860135\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3128556724410506\n",
      "std: 0.3033439252091025\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6079964649070014\n",
      "std: 0.1829145620621514\n",
      "min: 0.14966656485135874\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033151079872114096\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1891334842520012\n",
      "std: 0.18026639793026275\n",
      "min: -0.21786463479911833\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1916220541006155\n",
      "std: 0.18183562969105413\n",
      "min: -0.21335910583442058\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.03296389868805222\n",
      "min: 0.0032079484930234194\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3370404391663533\n",
      "std: 0.3679465046456918\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043074\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4530099939335471\n",
      "std: 0.22170411599964024\n",
      "min: -0.11614260933525519\n",
      "max: 0.9680281682043074\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03261884570332451\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080204560624765\n",
      "std: 0.0068612848438761925\n",
      "min: 1.3429135180663998\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080226047661146\n",
      "std: 0.006907438031552765\n",
      "min: 1.3429135180663998\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.031361700079301384\n",
      "min: 0.012322807565442705\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3158674801076064\n",
      "std: 0.30347950234107596\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6072214068519804\n",
      "std: 0.18377599980271556\n",
      "min: 0.14810818784157048\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03326382532078379\n",
      "min: 0.13056046422770326\n",
      "max: 0.26691480912471316\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2161717617259513\n",
      "std: 0.07268445658641819\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.218487439651347\n",
      "std: 0.07659784979606789\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.031731520337350896\n",
      "min: 0.008628906921418262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3384083161123458\n",
      "std: 0.36815605932272155\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4527228415063399\n",
      "std: 0.22185153800483762\n",
      "min: -0.11744174501600653\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03268250785183698\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.409059614651501\n",
      "std: 0.002407136643610731\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.409056845639165\n",
      "std: 0.002587473794883587\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.031359410223768085\n",
      "min: 0.012746471823200907\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3146992716893279\n",
      "std: 0.3033350889893067\n",
      "min: -0.7986681568822113\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6062892070336511\n",
      "std: 0.18319446157651006\n",
      "min: 0.14810924774025577\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03323655882974937\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1892189711699297\n",
      "std: 0.1845752999310395\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1916518112951142\n",
      "std: 0.18720013585918177\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.03312542345229125\n",
      "min: 0.0025321524639696897\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33884915568940005\n",
      "std: 0.36908279435930036\n",
      "min: -1.0771801916339685\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4527590559132337\n",
      "std: 0.2219524795314654\n",
      "min: -0.12012961953633251\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03263290902330219\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077028756633725\n",
      "std: 0.00859119052554774\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407702033915\n",
      "std: 0.008763331199448977\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.031364235590706585\n",
      "min: 0.012032814074803088\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3154078097763403\n",
      "std: 0.3031655315760918\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6070528474424064\n",
      "std: 0.18378473657914085\n",
      "min: 0.14902012471818246\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03323384934279393\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.19847704747723\n",
      "std: 0.1345211460081383\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2008585428294256\n",
      "std: 0.1368231596084633\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.03207163157550212\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33229960505310097\n",
      "std: 0.3699794348075496\n",
      "min: -1.0772735203280668\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4575972825907073\n",
      "std: 0.22223548297019238\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032475443814808776\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408665018205518\n",
      "std: 0.003380089819756202\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4086823610150772\n",
      "std: 0.0034398152973755037\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.03102564815616112\n",
      "min: 0.012557196360567811\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31345301336320636\n",
      "std: 0.30349283878982547\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6081169228132368\n",
      "std: 0.18296588944789957\n",
      "min: 0.1491147597249257\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318501698957832\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1962070062840051\n",
      "std: 0.1467566961279903\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1986456715020943\n",
      "std: 0.14969281616680064\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.03245307369072965\n",
      "min: 0.004074749627124123\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33271958595837675\n",
      "std: 0.37196862711710355\n",
      "min: -1.0772816066801212\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4569652526559296\n",
      "std: 0.22303196929773006\n",
      "min: -0.11415131062850675\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03248347375062855\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408390358550801\n",
      "std: 0.004769216072430069\n",
      "min: 1.3612026776250012\n",
      "max: 1.4139911658253619\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084129749991585\n",
      "std: 0.0048448230848394235\n",
      "min: 1.3612026776250012\n",
      "max: 1.4139911658253619\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.031026644194286964\n",
      "min: 0.012384362345774683\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31279357152133774\n",
      "std: 0.3032838551301769\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6079950415524862\n",
      "std: 0.1828315809359138\n",
      "min: 0.1496665648513588\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03314730234286361\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1897854114784423\n",
      "std: 0.17914080147591385\n",
      "min: -0.21786463479911833\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1922667164297167\n",
      "std: 0.18070291533044994\n",
      "min: -0.21335910583442058\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.03260674057564843\n",
      "min: 0.0032079484930234194\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33713409486291546\n",
      "std: 0.3680707251273137\n",
      "min: -1.0768943753517406\n",
      "max: 0.9680281682043074\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45297409520918985\n",
      "std: 0.22199454586561232\n",
      "min: -0.11614260933525519\n",
      "max: 0.9680281682043074\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03261226875327248\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080414095875058\n",
      "std: 0.006831169887776954\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080495119109884\n",
      "std: 0.006877124045644636\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.031027600563166547\n",
      "min: 0.01209554968478791\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31577755407249164\n",
      "std: 0.303419904787927\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6072285171505638\n",
      "std: 0.18368589907641045\n",
      "min: 0.1481081878415705\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033259107664840325\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2164638175802986\n",
      "std: 0.07235833003428396\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2187793057939431\n",
      "std: 0.07622408907144418\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.03139215479241688\n",
      "min: 0.008628906921418267\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33848231785532984\n",
      "std: 0.3682734207086643\n",
      "min: -1.0765562360804253\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45268495501913025\n",
      "std: 0.22214038668152172\n",
      "min: -0.11744174501600653\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032675046600311904\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090689017854867\n",
      "std: 0.0023996442809602805\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090723122780193\n",
      "std: 0.0025768619343841926\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.03102534301461577\n",
      "min: 0.012567293176850208\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3146179531938441\n",
      "std: 0.3032766971064839\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6063056512537562\n",
      "std: 0.18311007875642402\n",
      "min: 0.1481092477402558\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033232003176701524\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1898719177830457\n",
      "std: 0.18337635097056162\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1922982000218536\n",
      "std: 0.18598971405295037\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.03276589193104593\n",
      "min: 0.00253215246396969\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33892716132314027\n",
      "std: 0.369193549845376\n",
      "min: -1.0771801916339687\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45272474441885097\n",
      "std: 0.22223827510736247\n",
      "min: -0.12012961953633251\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.03262609222980827\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077280491835473\n",
      "std: 0.00854641949472434\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077331748882822\n",
      "std: 0.00871790905408002\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.031030099346332846\n",
      "min: 0.011839659620614838\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31531891999787637\n",
      "std: 0.30310775057264233\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.60706132929412\n",
      "std: 0.18369299997139452\n",
      "min: 0.1490201247181825\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03322929014121149\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1995433683060304\n",
      "std: 0.1340221246448674\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.201730805245427\n",
      "std: 0.13623054876867505\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.031730197821696005\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3331571115515359\n",
      "std: 0.36979848243157365\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4571593957163857\n",
      "std: 0.22266815042040133\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03249394351108813\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4086883608249274\n",
      "std: 0.003364541869626664\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4086984840446608\n",
      "std: 0.0034232706689658454\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.030699050796459796\n",
      "min: 0.0124192742767116\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3134405683219219\n",
      "std: 0.30347826090316055\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6081108256042729\n",
      "std: 0.18298309041191846\n",
      "min: 0.14911475972492574\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318646967609765\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1973007017723585\n",
      "std: 0.146194874207465\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1995443810833128\n",
      "std: 0.14903726441800544\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.03210616120159646\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3335776208573983\n",
      "std: 0.3717645320579687\n",
      "min: -1.0772816066801212\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45653213120740516\n",
      "std: 0.223452912821063\n",
      "min: -0.11415131062850675\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03250188073398565\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084171435646196\n",
      "std: 0.004741643686948516\n",
      "min: 1.3612026776250015\n",
      "max: 1.4139911658253619\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084324649656872\n",
      "std: 0.004816517421100837\n",
      "min: 1.3612026776250015\n",
      "max: 1.4139911658253619\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.03070003258114949\n",
      "min: 0.012260556366718328\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31278629954141907\n",
      "std: 0.3032700129663887\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6079887486160672\n",
      "std: 0.18284904516135522\n",
      "min: 0.1496665648513588\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03314906399604728\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1909587397518058\n",
      "std: 0.17831895291304428\n",
      "min: -0.21786463479911827\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.193243351128746\n",
      "std: 0.17981126282793597\n",
      "min: -0.2133591058344205\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.0322576933423662\n",
      "min: 0.0032079484930234202\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3379412996128039\n",
      "std: 0.367901197879676\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043074\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45258578930312104\n",
      "std: 0.2224236195583392\n",
      "min: -0.11614260933525519\n",
      "max: 0.9680281682043074\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03262935814767836\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080714513373556\n",
      "std: 0.006798830315813019\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080723467181298\n",
      "std: 0.006844225887158891\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.030700975968453642\n",
      "min: 0.01198640992224551\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3157427024868081\n",
      "std: 0.3034059987779363\n",
      "min: -0.7991462627239704\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6072304435379211\n",
      "std: 0.1836963956604088\n",
      "min: 0.14810818784157054\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03325991916636722\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2173231854611315\n",
      "std: 0.07221996010053058\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2194471706758108\n",
      "std: 0.07593740737407086\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.031060386557215183\n",
      "min: 0.008628906921418262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3392694970377432\n",
      "std: 0.36809555713520703\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45229845752438513\n",
      "std: 0.22256561415303883\n",
      "min: -0.11744174501600653\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032691152226471516\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090860003373318\n",
      "std: 0.0023878198217997235\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090824175014929\n",
      "std: 0.0025637315593096373\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.03069874992403122\n",
      "min: 0.012459652959941862\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3145916601471502\n",
      "std: 0.3032641418568012\n",
      "min: -0.7986681568822116\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.606317186998046\n",
      "std: 0.18312572427834742\n",
      "min: 0.1481092477402557\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03323297956364532\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1910414476420847\n",
      "std: 0.18254459032022394\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1932715765066066\n",
      "std: 0.18508383225456665\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.032414555407207654\n",
      "min: 0.0025321524639696897\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33971910020189955\n",
      "std: 0.36900896498539637\n",
      "min: -1.0771801916339685\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4523386534503366\n",
      "std: 0.22266265744337704\n",
      "min: -0.12012961953633251\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032642982234473254\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077619322994093\n",
      "std: 0.008498829765667074\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077598787430539\n",
      "std: 0.008669339824199257\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.030703438961015964\n",
      "min: 0.011742015779081577\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31528514392247675\n",
      "std: 0.30309567551502564\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6070646735872621\n",
      "std: 0.18370190787493404\n",
      "min: 0.14902012471818246\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03323026364533042\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.19970470432893\n",
      "std: 0.1334906881448321\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2018692049434048\n",
      "std: 0.1356778472683246\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.03139641667227419\n",
      "min: 0.0037371563448466163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3335346487604021\n",
      "std: 0.36999736679198847\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4563086890946302\n",
      "std: 0.2231752220613641\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03252409030520028\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087139062689902\n",
      "std: 0.003349420969560524\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4087278078807723\n",
      "std: 0.003408095709247252\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.030379673895552853\n",
      "min: 0.012267514399870488\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3134021026821718\n",
      "std: 0.30348215988029237\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6080458749482698\n",
      "std: 0.18297314031527837\n",
      "min: 0.1491147597249256\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318689862532115\n",
      "min: 0.1308270098194005\n",
      "max: 0.26687682950816566\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1974880592365102\n",
      "std: 0.14564514174799867\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1997080045363027\n",
      "std: 0.14845970910855505\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.03176705552450157\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3339555098677774\n",
      "std: 0.3719379012982297\n",
      "min: -1.077281606680121\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45568500999075157\n",
      "std: 0.2239473607472303\n",
      "min: -0.11415131062850675\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032531875981159336\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408446307932625\n",
      "std: 0.004718072998709809\n",
      "min: 1.3612026776250017\n",
      "max: 1.4139911658253619\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408465330691805\n",
      "std: 0.004792983403104653\n",
      "min: 1.3612026776250017\n",
      "max: 1.4139911658253619\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.030380641878223286\n",
      "min: 0.012083410792639564\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3127529324247022\n",
      "std: 0.3032745743114475\n",
      "min: -0.7981271851124029\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6079236219212827\n",
      "std: 0.18283934421098882\n",
      "min: 0.14966656485135868\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03314979531616726\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.191246365254305\n",
      "std: 0.1773612584370464\n",
      "min: -0.21786463479911833\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1935052010165448\n",
      "std: 0.17884641161358478\n",
      "min: -0.21335910583442058\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.03191647762466843\n",
      "min: 0.0032079484930234194\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3382705834096672\n",
      "std: 0.3681183130020136\n",
      "min: -1.076894375351741\n",
      "max: 0.9680281682043074\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4517848821722355\n",
      "std: 0.22291952463765485\n",
      "min: -0.11614260933525519\n",
      "max: 0.9680281682043074\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03265810968126756\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081036391038373\n",
      "std: 0.0067658221115924465\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081083229266302\n",
      "std: 0.0068115888944628705\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.03038157249881958\n",
      "min: 0.011827917892721017\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3156823947107452\n",
      "std: 0.30341072043184336\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071733690607843\n",
      "std: 0.1836795291597795\n",
      "min: 0.1481081878415705\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03325972815012882\n",
      "min: 0.13056046422770326\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2172895450076582\n",
      "std: 0.07205229695067525\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2193942476962356\n",
      "std: 0.07571532904430907\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691353\n",
      "std: 0.030735999452836064\n",
      "min: 0.008628906921418262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3395782236414938\n",
      "std: 0.3683041119754347\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4514968416842159\n",
      "std: 0.22305885750929902\n",
      "min: -0.11744174501600653\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03271880309384614\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4091066648059885\n",
      "std: 0.002377676076323453\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4091070613979293\n",
      "std: 0.002552436328483449\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.03037937719276914\n",
      "min: 0.012289601294646589\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31453964854983485\n",
      "std: 0.3032700970862255\n",
      "min: -0.7986681568822114\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6062692613963465\n",
      "std: 0.183113963839928\n",
      "min: 0.1481092477402557\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03323294209032435\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1913199439552624\n",
      "std: 0.1816825002534558\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1935253073124557\n",
      "std: 0.18420459036168538\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.032071120803361025\n",
      "min: 0.0025321524639696897\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3400322493463214\n",
      "std: 0.36921099665197876\n",
      "min: -1.0771801916339685\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45153841867929223\n",
      "std: 0.22315377663838962\n",
      "min: -0.12012961953633251\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032671431628548755\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077980526003901\n",
      "std: 0.008455783188300434\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077998198914636\n",
      "std: 0.008626030000710074\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.03038400083614383\n",
      "min: 0.011556718469370748\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3152258914279614\n",
      "std: 0.30310223363619465\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6070089238376977\n",
      "std: 0.18368345838723202\n",
      "min: 0.14902012471818235\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0332302333692786\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2001141919689935\n",
      "std: 0.1327775710844073\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2020571621317646\n",
      "std: 0.13493030790474922\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.031069953238093504\n",
      "min: 0.0037371563448466154\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33345732134115064\n",
      "std: 0.3694295254665466\n",
      "min: -1.0772735203280668\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4562093797303812\n",
      "std: 0.2232615384865518\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03252766477605998\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408725051476692\n",
      "std: 0.0033311267639899193\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4087379948120098\n",
      "std: 0.003387504749452466\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.030067275217700046\n",
      "min: 0.012086816338433748\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3134442317632966\n",
      "std: 0.3034810115669922\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6080006010687821\n",
      "std: 0.18296199031483787\n",
      "min: 0.1491147597249257\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319072083742932\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1979237493441526\n",
      "std: 0.144826683748352\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1999214686338535\n",
      "std: 0.14760096364135278\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.03143540040927718\n",
      "min: 0.004074749627124124\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33387946266989355\n",
      "std: 0.3713492474195158\n",
      "min: -1.0772816066801212\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45558991992795056\n",
      "std: 0.2240246439914156\n",
      "min: -0.11415131062850675\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03253542619369642\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084602123908965\n",
      "std: 0.004688777630405335\n",
      "min: 1.3612026776250017\n",
      "max: 1.4139911658253619\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084782153010027\n",
      "std: 0.004762092133718925\n",
      "min: 1.3612026776250017\n",
      "max: 1.4139911658253619\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.0300682296950017\n",
      "min: 0.011915876475167975\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31280023382124805\n",
      "std: 0.30327425860017004\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6078782165835886\n",
      "std: 0.18282845461720038\n",
      "min: 0.14966656485135874\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03315392264981277\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1917346196143477\n",
      "std: 0.17647336873299915\n",
      "min: -0.21786463479911833\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1937698692289265\n",
      "std: 0.17793042562233438\n",
      "min: -0.21335910583442058\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.03158282575969883\n",
      "min: 0.0032079484930234194\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3381473742794525\n",
      "std: 0.3675683127285408\n",
      "min: -1.076894375351741\n",
      "max: 0.9680281682043074\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4517308609150013\n",
      "std: 0.22300892474483683\n",
      "min: -0.11614260933525519\n",
      "max: 0.9680281682043074\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032660498674024874\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081218218349087\n",
      "std: 0.006729668640664788\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081255502411059\n",
      "std: 0.006774481415812942\n",
      "min: 1.3429135180663996\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.030069147902323665\n",
      "min: 0.011666351829304858\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31570345749716433\n",
      "std: 0.303409815216976\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071356418376131\n",
      "std: 0.183661666122116\n",
      "min: 0.14810818784157054\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0332629430672924\n",
      "min: 0.13056046422770326\n",
      "max: 0.26691480912471316\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2174738511849814\n",
      "std: 0.07181170371240991\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2193597206320603\n",
      "std: 0.07542975069624475\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.030418720873809552\n",
      "min: 0.008137892369931255\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3394361975848904\n",
      "std: 0.36774966602663994\n",
      "min: -1.0765562360804253\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.451441329425774\n",
      "std: 0.22314587708538866\n",
      "min: -0.11744174501600653\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032720250294617025\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4091128623401377\n",
      "std: 0.0023652108158001427\n",
      "min: 1.3848106090316328\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4091125149755905\n",
      "std: 0.0025362498839683416\n",
      "min: 1.3848106090316328\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.03006698258728397\n",
      "min: 0.012136400456163085\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31456866183885274\n",
      "std: 0.3032705581676169\n",
      "min: -0.7986681568822116\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.606240517855537\n",
      "std: 0.1831011852136717\n",
      "min: 0.14810924774025572\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033236300316670984\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1918028143766477\n",
      "std: 0.18080016619218983\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1937852879538153\n",
      "std: 0.1832872503220659\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.031735300322529\n",
      "min: 0.00253215246396969\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33989518303984634\n",
      "std: 0.36865078416268915\n",
      "min: -1.0771801916339687\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4514868757900927\n",
      "std: 0.22323987525981892\n",
      "min: -0.12012961953633251\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032673674200337864\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078193566041033\n",
      "std: 0.008405427440013076\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078201949099143\n",
      "std: 0.008574559072739034\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.03007154231977903\n",
      "min: 0.01142032427361668\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3152482213017333\n",
      "std: 0.3031032301202024\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.606972400762725\n",
      "std: 0.18366406188367868\n",
      "min: 0.14902012471818246\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033233612735137565\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2001039978378116\n",
      "std: 0.1322202031621501\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2019064046281471\n",
      "std: 0.1343605002773059\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.03075067619731378\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33324967163687497\n",
      "std: 0.36910178377562713\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4564529624701395\n",
      "std: 0.22336953403194634\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03251469146306494\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408717315299793\n",
      "std: 0.0033274828859397995\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4087357537585954\n",
      "std: 0.003383381156010594\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.029761623402996436\n",
      "min: 0.011917328918543298\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3134321665036514\n",
      "std: 0.30345594560673067\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6080415555113999\n",
      "std: 0.1829195515506307\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318868619276201\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1979470118148803\n",
      "std: 0.14408027413015198\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1998031993418738\n",
      "std: 0.1468389489733883\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.031111044270008666\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3336724060831046\n",
      "std: 0.37100072362299197\n",
      "min: -1.077281606680121\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45583950733980144\n",
      "std: 0.2241239476603488\n",
      "min: -0.11415131062850675\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03252237444409087\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084554091856818\n",
      "std: 0.004667858511116173\n",
      "min: 1.3612026776250017\n",
      "max: 1.4139911658253619\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084788410939784\n",
      "std: 0.004741232950561683\n",
      "min: 1.3612026776250017\n",
      "max: 1.4139911658253619\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.029762564681719957\n",
      "min: 0.01180521248520942\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.312792958467038\n",
      "std: 0.30324989061476204\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6079191029374958\n",
      "std: 0.1827861859690362\n",
      "min: 0.14966656485135885\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033152171057630374\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.191806560564518\n",
      "std: 0.17573975316675677\n",
      "min: -0.21786463479911827\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1936990507785807\n",
      "std: 0.17718795573818638\n",
      "min: -0.2133591058344205\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.03125653817202022\n",
      "min: 0.0032079484930234202\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3378937110962203\n",
      "std: 0.3672601527107034\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043074\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4520198584386245\n",
      "std: 0.22312439020738162\n",
      "min: -0.11614260933525519\n",
      "max: 0.9680281682043074\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03264632259958879\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408119229438412\n",
      "std: 0.006711136359417729\n",
      "min: 1.3379747655965302\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081284768865578\n",
      "std: 0.0067561482676484095\n",
      "min: 1.3379747655965302\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.029763471134415083\n",
      "min: 0.011403959170801144\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3156706719469556\n",
      "std: 0.30338525178070225\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.607183982242335\n",
      "std: 0.1836131924174682\n",
      "min: 0.14810818784157048\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033260321873227236\n",
      "min: 0.13056046422770326\n",
      "max: 0.26691480912471316\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2172602850021494\n",
      "std: 0.07168765254529534\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2190075138504692\n",
      "std: 0.0752956589723486\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.030108363280017335\n",
      "min: 0.008137892369931258\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3391659959435814\n",
      "std: 0.36743903882471174\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4517300451161468\n",
      "std: 0.22326040779576303\n",
      "min: -0.11744174501600653\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032705326956331215\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4091000921534904\n",
      "std: 0.002370858853326876\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4091054287461413\n",
      "std: 0.002539251532566197\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.029761334706324995\n",
      "min: 0.011974234051207488\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31454393175934897\n",
      "std: 0.3032471141319419\n",
      "min: -0.7986681568822116\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6062973495834554\n",
      "std: 0.18305792378148972\n",
      "min: 0.1481092477402556\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03323383309137805\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1918780518338286\n",
      "std: 0.17992811423718902\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1937185704101068\n",
      "std: 0.18240069052477048\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.031406880110274135\n",
      "min: 0.0025321524639696897\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3396281808437968\n",
      "std: 0.36833246862437713\n",
      "min: -1.0771801916339683\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45177927230444676\n",
      "std: 0.223351853917731\n",
      "min: -0.12012961953633251\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03265936203384482\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078198299181488\n",
      "std: 0.008369693086399056\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078262201354694\n",
      "std: 0.008538519512479673\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.02976583252132665\n",
      "min: 0.011208210438439\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31521656532041903\n",
      "std: 0.3030803747267231\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6070220655249425\n",
      "std: 0.18361407488893025\n",
      "min: 0.1490201247181825\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033231140290471715\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2003542535777598\n",
      "std: 0.1315822497685386\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2020894980430883\n",
      "std: 0.13368943047654608\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.030438224342957454\n",
      "min: 0.0037371563448466163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3338959923005764\n",
      "std: 0.3692404257285829\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45636787747988744\n",
      "std: 0.22353309524939932\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03253382939203151\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408718325080648\n",
      "std: 0.0033091569615301885\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4087266707880595\n",
      "std: 0.003368901717976573\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.029462497060147273\n",
      "min: 0.011872135953775146\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31356108351709927\n",
      "std: 0.3034530039723547\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.607970383865875\n",
      "std: 0.18291507823271497\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033191027925181\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1982254085483186\n",
      "std: 0.1433394310083796\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2000135038843518\n",
      "std: 0.14606267231320522\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.03079365741011463\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3343183059410567\n",
      "std: 0.37111562354740385\n",
      "min: -1.077281606680121\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45575856712404456\n",
      "std: 0.22427768056648215\n",
      "min: -0.11415131062850675\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032541363098086924\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084598649619087\n",
      "std: 0.004639438706647497\n",
      "min: 1.3612026776250012\n",
      "max: 1.4139911658253619\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084731454910562\n",
      "std: 0.00471520140708364\n",
      "min: 1.3612026776250012\n",
      "max: 1.4139911658253619\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.029463425530894614\n",
      "min: 0.011705301850030436\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3129265715302239\n",
      "std: 0.30324780599897627\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6078477342900463\n",
      "std: 0.18278187215558322\n",
      "min: 0.14966656485135885\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0331547943083471\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1921341072474645\n",
      "std: 0.17495033929026763\n",
      "min: -0.21786463479911833\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1939575188609213\n",
      "std: 0.17637573363163042\n",
      "min: -0.21335910583442058\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.030937260334987074\n",
      "min: 0.0032079484930234194\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33849485057627937\n",
      "std: 0.3674107813358956\n",
      "min: -1.076894375351741\n",
      "max: 0.9680281682043074\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45197937571576535\n",
      "std: 0.2232900581065748\n",
      "min: -0.11614260933525519\n",
      "max: 0.9680281682043074\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03266415884002156\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081263929450594\n",
      "std: 0.006673886162147722\n",
      "min: 1.3379747655965302\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081255713054672\n",
      "std: 0.006720586603527032\n",
      "min: 1.3379747655965302\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.029464320121839395\n",
      "min: 0.011403959170801142\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3157791942648622\n",
      "std: 0.3033820615431054\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071200908709378\n",
      "std: 0.1836022266156118\n",
      "min: 0.14810818784157048\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033262070263042884\n",
      "min: 0.13056046422770326\n",
      "max: 0.26691480912471316\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2173124121295522\n",
      "std: 0.07141655828941496\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2189953055090335\n",
      "std: 0.07496495648946601\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.029804607739720292\n",
      "min: 0.008137892369931258\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.339749102107945\n",
      "std: 0.3675822012543758\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4516892715967148\n",
      "std: 0.22342455205968978\n",
      "min: -0.11744174501600653\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03272226143097326\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090960627638853\n",
      "std: 0.002363662366941808\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090915048721206\n",
      "std: 0.0025365494285143897\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.029462212286782124\n",
      "min: 0.011869534702825424\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31465993601895176\n",
      "std: 0.303245322005462\n",
      "min: -0.7986681568822116\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6062422962457524\n",
      "std: 0.18305172983763052\n",
      "min: 0.1481092477402556\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03323572772156083\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1922034490986402\n",
      "std: 0.1790991642125677\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1939756696691552\n",
      "std: 0.1815428781110453\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.03108553323021016\n",
      "min: 0.0023448767340452452\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3402145337891077\n",
      "std: 0.36846801350669756\n",
      "min: -1.0771801916339685\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4517402390161796\n",
      "std: 0.2235128833620807\n",
      "min: -0.12012961953633251\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03267693975273955\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407830639180174\n",
      "std: 0.00832465093227545\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078269934284395\n",
      "std: 0.008493975572273407\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.02946664952860058\n",
      "min: 0.011200635120091671\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31532613272983456\n",
      "std: 0.30307886209787854\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6069592954455841\n",
      "std: 0.18360149949595253\n",
      "min: 0.1490201247181825\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033233037672723564\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2008999816302381\n",
      "std: 0.13108243302241318\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.202641935803733\n",
      "std: 0.13315281659324582\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.0301324458770979\n",
      "min: 0.0037371563448466154\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3339131624250534\n",
      "std: 0.3698406399542581\n",
      "min: -1.0772735203280668\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45660673735945406\n",
      "std: 0.2235944913667503\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03253497355435832\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087214205255807\n",
      "std: 0.0032987748490674053\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4087223575784322\n",
      "std: 0.003362303046837186\n",
      "min: 1.3808413703716922\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.029169684878313982\n",
      "min: 0.011689438611289918\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3135371320747859\n",
      "std: 0.30353846930563805\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6080786240671862\n",
      "std: 0.18288906501558352\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033187824961771535\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.198796432147819\n",
      "std: 0.14277039155439966\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2005902470635281\n",
      "std: 0.14545592299029197\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.030483081449610677\n",
      "min: 0.004074749627124124\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33433591549771524\n",
      "std: 0.3716904128165886\n",
      "min: -1.0772816066801212\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4560015641495064\n",
      "std: 0.22433064040685644\n",
      "min: -0.11415131062850675\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03254238412492634\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408466368473716\n",
      "std: 0.004617360890832895\n",
      "min: 1.3612026776250015\n",
      "max: 1.4139911658253619\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084721829930629\n",
      "std: 0.00469548517357393\n",
      "min: 1.3612026776250015\n",
      "max: 1.4139911658253619\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.029170600876749855\n",
      "min: 0.011528193131391022\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3129072296071697\n",
      "std: 0.3033339196680408\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6079559021693195\n",
      "std: 0.1827559981397016\n",
      "min: 0.14966656485135885\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03315185879124842\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1927774039967416\n",
      "std: 0.1741568824638936\n",
      "min: -0.21786463479911833\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.19460528528457\n",
      "std: 0.17555749172688934\n",
      "min: -0.21335910583442058\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.03062480768069554\n",
      "min: 0.0032079484930234194\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33846781878776105\n",
      "std: 0.36802962869641337\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043074\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45226258456105484\n",
      "std: 0.2233587301084466\n",
      "min: -0.11614260933525519\n",
      "max: 0.9680281682043074\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03266394350648448\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081355025289641\n",
      "std: 0.006642199503011756\n",
      "min: 1.3379747655965302\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408127279090893\n",
      "std: 0.006690826431556582\n",
      "min: 1.3379747655965302\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.02917148391206246\n",
      "min: 0.011249885430726353\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3157352046669891\n",
      "std: 0.30346823358504155\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6072356035272047\n",
      "std: 0.1835705169960746\n",
      "min: 0.14810818784157048\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033258291015104385\n",
      "min: 0.13056046422770326\n",
      "max: 0.26691480912471316\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.217676211962887\n",
      "std: 0.07129883114057267\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2193687910164372\n",
      "std: 0.07476469446219537\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.029507298328217135\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3397060356118308\n",
      "std: 0.36819551758918384\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4519728227964289\n",
      "std: 0.2234918482453113\n",
      "min: -0.11744174501600653\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0327213295339422\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.409094103551354\n",
      "std: 0.0023625350293737715\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090823259589307\n",
      "std: 0.002539632540483622\n",
      "min: 1.384810609031633\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.02916940387506045\n",
      "min: 0.011700629501731254\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3146237205126339\n",
      "std: 0.30333240129049766\n",
      "min: -0.7986681568822116\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6063661382719376\n",
      "std: 0.18302534460105538\n",
      "min: 0.1481092477402556\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03323210196964783\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.192844152915301\n",
      "std: 0.1783395452198723\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1946213133356067\n",
      "std: 0.1807555896007587\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.03077107074437707\n",
      "min: 0.002187964823642007\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.340173893664448\n",
      "std: 0.3690739428019421\n",
      "min: -1.0771801916339687\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4520253386125046\n",
      "std: 0.2235784517835717\n",
      "min: -0.12012961953633251\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032676542968924784\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078434650066023\n",
      "std: 0.008282928350313176\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407832459518177\n",
      "std: 0.008452917388318592\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.029173782087607743\n",
      "min: 0.011024509783950087\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31528321497536343\n",
      "std: 0.30316675141459337\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6070760285813576\n",
      "std: 0.18356838649136106\n",
      "min: 0.1490201247181825\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03322940277054712\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2013274115674868\n",
      "std: 0.13057752078087692\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2030364108808302\n",
      "std: 0.13260974677984586\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.029833111860289876\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3340495009144356\n",
      "std: 0.36981925140770955\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45586453800501736\n",
      "std: 0.22365788499068612\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032532924482396454\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087199887269481\n",
      "std: 0.0032969748510107235\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40871372513973\n",
      "std: 0.003366046599032793\n",
      "min: 1.3790865630090658\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.028882984552539796\n",
      "min: 0.011466554570268362\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31361550534765403\n",
      "std: 0.30355564360378967\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6079825784687848\n",
      "std: 0.18290566390829646\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03319193617621811\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1992462536460802\n",
      "std: 0.14229494685550145\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.201006117568226\n",
      "std: 0.14494140360123012\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.030179083621086733\n",
      "min: 0.00398037163533402\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3344722357649474\n",
      "std: 0.3716476137785296\n",
      "min: -1.077281606680121\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.455262827796075\n",
      "std: 0.2243842995438091\n",
      "min: -0.11415131062850675\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032540228154546505\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408467743308109\n",
      "std: 0.0046118866326863225\n",
      "min: 1.3600549606415753\n",
      "max: 1.4139911658253619\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084663069182473\n",
      "std: 0.004693604514737018\n",
      "min: 1.3600549606415753\n",
      "max: 1.4139911658253619\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.02888388860502328\n",
      "min: 0.011252002262662058\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3129902427752597\n",
      "std: 0.3033519227599903\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6078595768445385\n",
      "std: 0.18277282374928716\n",
      "min: 0.14966656485135885\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033156246644649244\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1933370536827046\n",
      "std: 0.17318692388457396\n",
      "min: -0.21786463479911827\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1951298019762389\n",
      "std: 0.17456347368000502\n",
      "min: -0.2133591058344205\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.030318926070059864\n",
      "min: 0.0032079484930234202\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3385599993255824\n",
      "std: 0.3680245799294146\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043074\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45156495704637845\n",
      "std: 0.2234125413052395\n",
      "min: -0.11614260933525519\n",
      "max: 0.9680281682043074\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0326606381081329\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081423233020622\n",
      "std: 0.006608228534032982\n",
      "min: 1.3379747655965302\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081269124791984\n",
      "std: 0.006660053360854106\n",
      "min: 1.3379747655965302\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.028884759957149456\n",
      "min: 0.01110264936796469\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31579387087736654\n",
      "std: 0.3034856067257638\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071465639715269\n",
      "std: 0.18358076851694735\n",
      "min: 0.14810818784157048\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033261821225612206\n",
      "min: 0.13056046422770326\n",
      "max: 0.26691480912471316\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2179352448762226\n",
      "std: 0.0711220640192588\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2195976985589507\n",
      "std: 0.07451170029533136\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.02921621132597779\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33978039791732223\n",
      "std: 0.3681848018093281\n",
      "min: -1.0765562360804253\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45127529326272187\n",
      "std: 0.22354490558947182\n",
      "min: -0.11744174501600653\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03271724403661236\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090896905932164\n",
      "std: 0.0023659289947395357\n",
      "min: 1.3846066531639973\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090708883456338\n",
      "std: 0.00254940785675141\n",
      "min: 1.3846066531639973\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.028882707153263427\n",
      "min: 0.011526725148242708\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31468966230008016\n",
      "std: 0.3033508711878654\n",
      "min: -0.7986681568822116\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6062855206035738\n",
      "std: 0.18303997353156012\n",
      "min: 0.1481092477402556\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033235763044940525\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.193399373300734\n",
      "std: 0.17743730993341197\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1951416518912528\n",
      "std: 0.17982554785574648\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.03046324639087401\n",
      "min: 0.0021879648236420076\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3402515718884431\n",
      "std: 0.36905719525134956\n",
      "min: -1.0771801916339683\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4513284523660905\n",
      "std: 0.22362870729377957\n",
      "min: -0.12012961953633251\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0326730378953135\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078533679895702\n",
      "std: 0.008245902879815739\n",
      "min: 1.3156862828233118\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40783521036865\n",
      "std: 0.008417643703129725\n",
      "min: 1.3156862828233118\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.028887027917331335\n",
      "min: 0.010812506996220378\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3153430027042445\n",
      "std: 0.30318589512633437\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6069881599848412\n",
      "std: 0.1835771647234034\n",
      "min: 0.1490201247181825\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03323308685331173\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2010517026519256\n",
      "std: 0.12992032420808386\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2028880170041043\n",
      "std: 0.13192724992969032\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.02953997945373991\n",
      "min: 0.0037371563448466163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3334067803260231\n",
      "std: 0.3692824523228983\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45540333407639577\n",
      "std: 0.22352484004136575\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03249710319033465\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087190612283111\n",
      "std: 0.0032836128293111454\n",
      "min: 1.3789892633656262\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4087170349796798\n",
      "std: 0.0033499252636915366\n",
      "min: 1.3790865630090663\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.028602202161833973\n",
      "min: 0.011416197503146668\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3135019424455506\n",
      "std: 0.3034828308434074\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895603\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6079578159629426\n",
      "std: 0.18285140677083173\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895603\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318501079460849\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.198997333837254\n",
      "std: 0.14146145394905668\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2008835952784545\n",
      "std: 0.14408445117945418\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.029881378011069135\n",
      "min: 0.00398037163533402\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33382916096311\n",
      "std: 0.3710929379778183\n",
      "min: -1.077281606680121\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45480535511840164\n",
      "std: 0.2242433874560966\n",
      "min: -0.11415131062850675\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03250432485172907\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084695495625288\n",
      "std: 0.004588748169866756\n",
      "min: 1.3600549606415757\n",
      "max: 1.4139911658253619\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084722903555618\n",
      "std: 0.004668417668117097\n",
      "min: 1.3600549606415757\n",
      "max: 1.4139911658253619\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.028603094365864376\n",
      "min: 0.011252002262662063\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31288111370302474\n",
      "std: 0.30327968488586976\n",
      "min: -0.7981271851124028\n",
      "max: 0.9345062847359751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.60783466396665\n",
      "std: 0.18271877873717685\n",
      "min: 0.14966656485135885\n",
      "max: 0.9345062847359751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033149579360078785\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1931384224070574\n",
      "std: 0.17231821844609918\n",
      "min: -0.21786463479911833\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.195056472227189\n",
      "std: 0.17368852395065926\n",
      "min: -0.21335910583442058\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.030019464932694393\n",
      "min: 0.003066114184488187\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.337875112836527\n",
      "std: 0.3675102505572045\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043074\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4511448964923743\n",
      "std: 0.22327548194686747\n",
      "min: -0.11614260933525519\n",
      "max: 0.9680281682043074\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032623777808406314\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408148382354627\n",
      "std: 0.006574310368045743\n",
      "min: 1.3379747655965302\n",
      "max: 1.4139917536538011\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081372011791895\n",
      "std: 0.00662516193725441\n",
      "min: 1.3379747655965302\n",
      "max: 1.4139917536538011\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.028603954671013402\n",
      "min: 0.011026238318052276\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3156609755840591\n",
      "std: 0.3034139742850949\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071287435197338\n",
      "std: 0.18352078278584008\n",
      "min: 0.14810818784157048\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03325435359793085\n",
      "min: 0.13056046422770326\n",
      "max: 0.26691480912471316\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2174542850504386\n",
      "std: 0.07095969771339461\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2192479515923138\n",
      "std: 0.07426410704292287\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.028931155287139264\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3390800162658971\n",
      "std: 0.36766878668302194\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4508545569799555\n",
      "std: 0.22340548351331138\n",
      "min: -0.11744174501600653\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032679771392658326\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090857604681097\n",
      "std: 0.0023595369480682426\n",
      "min: 1.3846066531639971\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090713412990514\n",
      "std: 0.002538171347449493\n",
      "min: 1.3846066531639971\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.028601928344812143\n",
      "min: 0.011450974568086124\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31456435694123325\n",
      "std: 0.3032801538724493\n",
      "min: -0.7986681568822116\n",
      "max: 0.911854092416326\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6062756216870887\n",
      "std: 0.18298435359220677\n",
      "min: 0.1481092477402556\n",
      "max: 0.911854092416326\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03322843918200989\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.19320520524798\n",
      "std: 0.17645289192314623\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.195073432537629\n",
      "std: 0.17882759360613093\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.03016186206747891\n",
      "min: 0.0021879648236420076\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33955353292341844\n",
      "std: 0.3685351745798482\n",
      "min: -1.0771801916339687\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45090905836331907\n",
      "std: 0.22348866730188424\n",
      "min: -0.12012961953633251\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03263601425526738\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407862901239773\n",
      "std: 0.008199653086718125\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156447\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078489913912346\n",
      "std: 0.008370177747305097\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156447\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.028606192838156314\n",
      "min: 0.010803103999723437\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31521117619324796\n",
      "std: 0.3031158588616867\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6069714464657273\n",
      "std: 0.1835158361559427\n",
      "min: 0.1490201247181825\n",
      "max: 0.9494609040688612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033225752061361476\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2012246291205102\n",
      "std: 0.12918458936420352\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2029754551430434\n",
      "std: 0.13120459536003426\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.02925286878816549\n",
      "min: 0.0037371563448466154\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33249494912534033\n",
      "std: 0.36921883798856076\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45538859663402076\n",
      "std: 0.22345236341988595\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03246811847943446\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087376973784311\n",
      "std: 0.0032669586849729247\n",
      "min: 1.3789892633656264\n",
      "max: 1.4139905995955169\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4087435053875068\n",
      "std: 0.0033297444870926565\n",
      "min: 1.379086563009066\n",
      "max: 1.4139905995955169\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.02832715220692986\n",
      "min: 0.011338422774723047\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31334457433284596\n",
      "std: 0.30349984954435116\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895608\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6079699614674438\n",
      "std: 0.18282198198325403\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895608\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03317980058558102\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1991901938429455\n",
      "std: 0.14066944784389077\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2009899020074233\n",
      "std: 0.14330016684597813\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.029589824631894683\n",
      "min: 0.00398037163533402\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33291732377530886\n",
      "std: 0.3710102039231451\n",
      "min: -1.0772816066801212\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4547938933718185\n",
      "std: 0.2241637284187456\n",
      "min: -0.11415131062850675\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03247530196540799\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084907818700108\n",
      "std: 0.0045640926155563625\n",
      "min: 1.3600549606415757\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4085012826798193\n",
      "std: 0.004641250755732565\n",
      "min: 1.3600549606415757\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.02832803286243021\n",
      "min: 0.011156694630574926\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3127281082648734\n",
      "std: 0.3032971387680204\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6078466517751269\n",
      "std: 0.1826895846713153\n",
      "min: 0.14966656485135876\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03314462812484012\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.193383733028609\n",
      "std: 0.17141048265188585\n",
      "min: -0.21786463479911833\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1952142148281746\n",
      "std: 0.1727929782378899\n",
      "min: -0.21335910583442058\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.029726184947324395\n",
      "min: 0.0030661141844881873\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33692214282036853\n",
      "std: 0.36747196768571627\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043074\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4511683611178179\n",
      "std: 0.22320609326162966\n",
      "min: -0.11614260933525519\n",
      "max: 0.9680281682043074\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03259371099261023\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081739026395457\n",
      "std: 0.006536242373916743\n",
      "min: 1.3379747655965297\n",
      "max: 1.4139917536538014\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081705273911633\n",
      "std: 0.006585827407597809\n",
      "min: 1.3379747655965297\n",
      "max: 1.4139917536538014\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.028328882272243987\n",
      "min: 0.01095349301724157\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31548474795323483\n",
      "std: 0.3034324548467409\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071473779323323\n",
      "std: 0.1834857738533822\n",
      "min: 0.14810818784157068\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033248614412965775\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2174235053000297\n",
      "std: 0.07078578909781184\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2191336668464376\n",
      "std: 0.07411340693766388\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.028651936981443037\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3381123440431455\n",
      "std: 0.36762804041452424\n",
      "min: -1.0765562360804253\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4508764526340442\n",
      "std: 0.22333404782619742\n",
      "min: -0.11744174501600653\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032649022257513025\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4091010625874685\n",
      "std: 0.0023511227819352806\n",
      "min: 1.3846066531639976\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090945979663911\n",
      "std: 0.002523793878777394\n",
      "min: 1.3846066531639976\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.028326881923613857\n",
      "min: 0.011359412694154476\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3143957094516705\n",
      "std: 0.30329919110702525\n",
      "min: -0.7986681568822114\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6063020168071042\n",
      "std: 0.1829538369541319\n",
      "min: 0.14810924774025583\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03322284313162682\n",
      "min: 0.13097219002032656\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1934488893654014\n",
      "std: 0.17552036336801893\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1952298799397103\n",
      "std: 0.17790296327153443\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.029866724159499015\n",
      "min: 0.002187964823642007\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3385876280807898\n",
      "std: 0.368490726863051\n",
      "min: -1.0771801916339685\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.450934766842036\n",
      "std: 0.22341691723076246\n",
      "min: -0.12012961953633251\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03260586617744109\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078914317685431\n",
      "std: 0.008153008876449716\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156444\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407885339932714\n",
      "std: 0.008322125482558557\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156444\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.028331091464405277\n",
      "min: 0.010711925138644867\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3150359601984735\n",
      "std: 0.3031358494625324\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.60699122989611\n",
      "std: 0.1834795419177006\n",
      "min: 0.1490201247181825\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03322014833027574\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2013069030962527\n",
      "std: 0.12848864042382183\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.203118879726695\n",
      "std: 0.13050416621409686\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.02897161630058082\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33265273489087555\n",
      "std: 0.36953401390440604\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4556396594832559\n",
      "std: 0.22308800774007304\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03246314292972736\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087436275494793\n",
      "std: 0.0032484669638798\n",
      "min: 1.3789892633656264\n",
      "max: 1.4139905995955169\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4087502110242458\n",
      "std: 0.003309629600406223\n",
      "min: 1.379086563009066\n",
      "max: 1.4139905995955169\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.028057657096968436\n",
      "min: 0.011196551498882846\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3133343921771234\n",
      "std: 0.3035453820453103\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895608\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6079352829983153\n",
      "std: 0.18278272243281468\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895608\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03317715985597917\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1992914588699572\n",
      "std: 0.1399384636492993\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2011514292115921\n",
      "std: 0.14256146435851377\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.02930424617372747\n",
      "min: 0.00398037163533402\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3330757727961897\n",
      "std: 0.3713033899151563\n",
      "min: -1.077281606680121\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4550470790260719\n",
      "std: 0.22379296078647226\n",
      "min: -0.11415131062850675\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03247024717049963\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084998450477215\n",
      "std: 0.004536332958639087\n",
      "min: 1.360054960641576\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408511054108811\n",
      "std: 0.004612296430119654\n",
      "min: 1.360054960641576\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.028058526449687555\n",
      "min: 0.01103728248551237\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3127224544051976\n",
      "std: 0.3033433888552829\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6078117711560086\n",
      "std: 0.18265053116805346\n",
      "min: 0.14966656485135876\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03314225111476812\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1935514146332795\n",
      "std: 0.17045129082521418\n",
      "min: -0.21786463479911827\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1954410154324082\n",
      "std: 0.17183767514913376\n",
      "min: -0.2133591058344205\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.02943889792913481\n",
      "min: 0.0030661141844881873\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3370420595478955\n",
      "std: 0.3678029670246194\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043074\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45145784794440885\n",
      "std: 0.22284906854418313\n",
      "min: -0.11614260933525519\n",
      "max: 0.9680281682043074\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03258768577362747\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081858694901397\n",
      "std: 0.006496728795598191\n",
      "min: 1.33797476559653\n",
      "max: 1.4139917536538014\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081832779384997\n",
      "std: 0.006545644012191247\n",
      "min: 1.33797476559653\n",
      "max: 1.4139917536538014\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.02805936523902413\n",
      "min: 0.010855729273889418\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3154563695817786\n",
      "std: 0.3034785691429388\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6071190963588456\n",
      "std: 0.18344096052467754\n",
      "min: 0.14810818784157068\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324545149925841\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2173123101652659\n",
      "std: 0.07060020937394781\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2190866357173018\n",
      "std: 0.07389169912106817\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.028378381898962506\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3382161922815333\n",
      "std: 0.36795371196957394\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45116456096308044\n",
      "std: 0.22297591118311472\n",
      "min: -0.11744174501600653\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03264232401725208\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4091025345072763\n",
      "std: 0.0023412097462890214\n",
      "min: 1.3846066531639971\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090970006540853\n",
      "std: 0.0025107180940618077\n",
      "min: 1.3846066531639971\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.02805739026931289\n",
      "min: 0.011216864772161293\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31437451805732974\n",
      "std: 0.3033461904841803\n",
      "min: -0.7986681568822114\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6062814778881972\n",
      "std: 0.18291343036387683\n",
      "min: 0.14810924774025583\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033219825632449955\n",
      "min: 0.13097219002032656\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1936141231747783\n",
      "std: 0.17458385749734454\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.195454775824932\n",
      "std: 0.1769641150347072\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.02957763144633584\n",
      "min: 0.0021879648236420076\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33869461839901255\n",
      "std: 0.36880948462418767\n",
      "min: -1.0771801916339683\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4512247348223042\n",
      "std: 0.22305740462248716\n",
      "min: -0.12012961953633251\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032599641657698956\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079067690034537\n",
      "std: 0.008104556758991757\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156444\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407901485061668\n",
      "std: 0.008272635660512973\n",
      "min: 1.315686282823312\n",
      "max: 1.4140088846156444\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.028061546136585683\n",
      "min: 0.010614897842290529\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3150087544611473\n",
      "std: 0.3031836618091973\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6069641232153442\n",
      "std: 0.18343337761302295\n",
      "min: 0.1490201247181825\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03321712668887236\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.201530518357833\n",
      "std: 0.12795477766313468\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2032346773444038\n",
      "std: 0.1299661251630221\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.028696046005220084\n",
      "min: 0.0036524039405521997\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3337995943469086\n",
      "std: 0.369127008075567\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4544295179809924\n",
      "std: 0.22370138854876634\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032463601856947605\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408730002613606\n",
      "std: 0.0032436655277230724\n",
      "min: 1.3789892633656264\n",
      "max: 1.4139905995955169\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4087340791515095\n",
      "std: 0.0033022221376985393\n",
      "min: 1.3790865630090663\n",
      "max: 1.4139905995955169\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.02779354655430048\n",
      "min: 0.011002796792782982\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.313509877532405\n",
      "std: 0.3034664764019393\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895608\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6076897307851974\n",
      "std: 0.1827974804327929\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895608\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03317885059255548\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.199536583797546\n",
      "std: 0.13940808242201833\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2012880583849257\n",
      "std: 0.14202061897595286\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.029024451071401315\n",
      "min: 0.0038270795679947282\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3342220509652857\n",
      "std: 0.3708787516887824\n",
      "min: -1.077281606680121\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4538402238744261\n",
      "std: 0.22439583679574907\n",
      "min: -0.11415131062850675\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03247060937453618\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084890808490076\n",
      "std: 0.0045292790054116735\n",
      "min: 1.3600549606415757\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084977257136908\n",
      "std: 0.0046031039533410865\n",
      "min: 1.3600549606415757\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.027794405090375413\n",
      "min: 0.010780258892627393\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31290227053652275\n",
      "std: 0.30326531055931866\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6075659481580385\n",
      "std: 0.1826656149810529\n",
      "min: 0.14966656485135876\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033144193675316604\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1938783599780058\n",
      "std: 0.16958325237473884\n",
      "min: -0.21786463479911833\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1956584104691443\n",
      "std: 0.17096755027846403\n",
      "min: -0.21335910583442058\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.029157415302268546\n",
      "min: 0.0030661141844881864\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33814794326029185\n",
      "std: 0.36739952175740004\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043074\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45028851091171085\n",
      "std: 0.22344553573583203\n",
      "min: -0.11614260933525519\n",
      "max: 0.9680281682043074\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032587016153654544\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081791453423305\n",
      "std: 0.00646432802380184\n",
      "min: 1.3379747655965297\n",
      "max: 1.4139917536538014\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081740433723127\n",
      "std: 0.006512222254823333\n",
      "min: 1.3379747655965297\n",
      "max: 1.4139917536538014\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.027795233313256982\n",
      "min: 0.010688629496492436\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31561367096791887\n",
      "std: 0.3033992087073522\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6068801267120424\n",
      "std: 0.18344923402700453\n",
      "min: 0.14810818784157068\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324659957266781\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2173747452985915\n",
      "std: 0.07036855358081218\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2190432983122605\n",
      "std: 0.07365615855187767\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.028110289092995497\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3393053448529241\n",
      "std: 0.3675430690075845\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.449996452388714\n",
      "std: 0.22357048711405542\n",
      "min: -0.11744174501600653\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03264093710992047\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090860908712322\n",
      "std: 0.0023432585349967435\n",
      "min: 1.3846066531639973\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090781953967058\n",
      "std: 0.0025083635049237807\n",
      "min: 1.3846066531639973\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.02779328302648668\n",
      "min: 0.011096287186127879\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3145385961465415\n",
      "std: 0.30326820868939297\n",
      "min: -0.7986681568822114\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6060503890997729\n",
      "std: 0.18292526676967288\n",
      "min: 0.14810924774025583\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033221112866936346\n",
      "min: 0.13097219002032656\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.193936754177869\n",
      "std: 0.1737519802887886\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.19566822183658\n",
      "std: 0.17612323357770943\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.029294388797392535\n",
      "min: 0.0021879648236420076\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3397863293378696\n",
      "std: 0.36839285763133595\n",
      "min: -1.0771801916339683\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4500559742889502\n",
      "std: 0.223650374791206\n",
      "min: -0.12012961953633251\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03259874837465359\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407903237986031\n",
      "std: 0.008070836560081047\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156444\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078954557665893\n",
      "std: 0.008237501885708367\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156444\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.027797386898248826\n",
      "min: 0.010380432604220067\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3151671503512016\n",
      "std: 0.3031057982128195\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6067261301603911\n",
      "std: 0.18344031867991586\n",
      "min: 0.1490201247181825\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03321841192562974\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.201871268736955\n",
      "std: 0.12749350356993683\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2035401659977867\n",
      "std: 0.1294891324760069\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.02842596517823195\n",
      "min: 0.0036524039405521997\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33306083316033186\n",
      "std: 0.369230577735538\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45444303056392615\n",
      "std: 0.22374403895307737\n",
      "min: -0.10883049623165539\n",
      "max: 0.9704513583243347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0324421519725683\n",
      "min: 0.11804781246265544\n",
      "max: 0.26666446693282336\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408738464679919\n",
      "std: 0.003236336962319943\n",
      "min: 1.3789892633656264\n",
      "max: 1.4139905995955169\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4087397483886712\n",
      "std: 0.0032985550825916678\n",
      "min: 1.3790865630090663\n",
      "max: 1.4139905995955169\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.02753465710237604\n",
      "min: 0.010849444755045236\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3133927174625013\n",
      "std: 0.30345037301233424\n",
      "min: -0.7988196105866929\n",
      "max: 0.9125577534895608\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6076851201836442\n",
      "std: 0.18276689982406016\n",
      "min: 0.14911475972492566\n",
      "max: 0.9125577534895608\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03317648745554759\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1999073475478208\n",
      "std: 0.138769024069874\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2016229323970335\n",
      "std: 0.14136364168163684\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.02875021561937691\n",
      "min: 0.0038270795679947282\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33348251544049995\n",
      "std: 0.37096307072461404\n",
      "min: -1.077281606680121\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4538586537217692\n",
      "std: 0.2244307083680309\n",
      "min: -0.11415131062850675\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999996\n",
      "std: 0.03244906814759943\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4085003272472458\n",
      "std: 0.0045098578881762955\n",
      "min: 1.360054960641576\n",
      "max: 1.413991165825362\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40850613309269\n",
      "std: 0.004586418456085735\n",
      "min: 1.360054960641576\n",
      "max: 1.413991165825362\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.02753550486749068\n",
      "min: 0.010728500693068067\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3127891128325315\n",
      "std: 0.3032497899797256\n",
      "min: -0.7981271851124025\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6075614978327849\n",
      "std: 0.18263526854731918\n",
      "min: 0.14966656485135876\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033142069817399145\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1942837613984496\n",
      "std: 0.16902098125369897\n",
      "min: -0.21786463479911833\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1960270878262385\n",
      "std: 0.17039475054745162\n",
      "min: -0.21335910583442058\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.028881597314254367\n",
      "min: 0.002890479896101231\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3373696879690382\n",
      "std: 0.36752630275436576\n",
      "min: -1.0768943753517408\n",
      "max: 0.9680281682043074\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45034155262033526\n",
      "std: 0.22349146552347485\n",
      "min: -0.11614260933525519\n",
      "max: 0.9680281682043074\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03256454127411166\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081925453023447\n",
      "std: 0.006441505092526391\n",
      "min: 1.33797476559653\n",
      "max: 1.4139917536538014\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081846979492367\n",
      "std: 0.00649148123433503\n",
      "min: 1.33797476559653\n",
      "max: 1.4139917536538014\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.02753632323198202\n",
      "min: 0.010449649868488653\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31547842125660097\n",
      "std: 0.30338426187665246\n",
      "min: -0.7991462627239702\n",
      "max: 0.9192195195019688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.606882022115982\n",
      "std: 0.1834132057665696\n",
      "min: 0.14810818784157068\n",
      "max: 0.9192195195019688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033243712731285055\n",
      "min: 0.1305604642277033\n",
      "max: 0.2669148091247132\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.217548749339785\n",
      "std: 0.07021448548961669\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2191844321219367\n",
      "std: 0.07346671775369487\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.027847500881966285\n",
      "min: 0.007579173812029776\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33851344970845976\n",
      "std: 0.367668378695773\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813372\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45004981249344145\n",
      "std: 0.2236144994116787\n",
      "min: -0.11744174501600653\n",
      "max: 0.9594521654813372\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03261783303193191\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090906405008308\n",
      "std: 0.0023407664504493312\n",
      "min: 1.384189186334456\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090801340627792\n",
      "std: 0.0025097181166776556\n",
      "min: 1.384189186334456\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.027534396795908807\n",
      "min: 0.010866771854344348\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31441051999353514\n",
      "std: 0.3032539836745481\n",
      "min: -0.7986681568822114\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6060597656231512\n",
      "std: 0.1828935292964842\n",
      "min: 0.14810924774025583\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03321835933251666\n",
      "min: 0.13097219002032656\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.194347599280329\n",
      "std: 0.17303926449219473\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1960430781529152\n",
      "std: 0.175395132828787\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.02901682342802481\n",
      "min: 0.0021879648236420076\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.338995455116982\n",
      "std: 0.36851158018003505\n",
      "min: -1.0771801916339683\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4501110391772215\n",
      "std: 0.2236930463692212\n",
      "min: -0.12012961953633251\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032576129615832415\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40791969569528\n",
      "std: 0.008033760873241041\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156444\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079091956757783\n",
      "std: 0.008201657934369028\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156444\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.027538449768473968\n",
      "min: 0.010270453037805652\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31503293760402334\n",
      "std: 0.3030923395036349\n",
      "min: -0.7982867040747371\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6067292078135926\n",
      "std: 0.18340311731428174\n",
      "min: 0.1490201247181825\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03321565749863817\n",
      "min: 0.1307286395969958\n",
      "max: 0.2668705165537986\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.201985296265355\n",
      "std: 0.12671148567946336\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.203706086631875\n",
      "std: 0.12870099799972587\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.028161155768753218\n",
      "min: 0.0036524039405521997\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33294545400626235\n",
      "std: 0.3694066020325811\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4549078890367819\n",
      "std: 0.22358285324122604\n",
      "min: -0.10883049623165524\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03243445174955564\n",
      "min: 0.11804781246265542\n",
      "max: 0.2666644669328233\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087245406163433\n",
      "std: 0.0032296349507245285\n",
      "min: 1.3789892633656264\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408724181374509\n",
      "std: 0.0032882266264667487\n",
      "min: 1.3790865630090658\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.02728083184061103\n",
      "min: 0.010820654191631408\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3133290459852892\n",
      "std: 0.30351570407436584\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895606\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6077597580501074\n",
      "std: 0.18276835364882252\n",
      "min: 0.14911475972492574\n",
      "max: 0.9125577534895606\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033175072698994314\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2000435313882714\n",
      "std: 0.13787879740397058\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.201810190901938\n",
      "std: 0.1404662708705881\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.02848136485447108\n",
      "min: 0.0038270795679947282\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3333667786982243\n",
      "std: 0.3711195024544265\n",
      "min: -1.077281606680121\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45432701048539\n",
      "std: 0.22426346411452466\n",
      "min: -0.11415131062850674\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0324413260146124\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084888615191002\n",
      "std: 0.004489855419054699\n",
      "min: 1.3600549606415757\n",
      "max: 1.4139911658253619\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408492975367948\n",
      "std: 0.004563670345117011\n",
      "min: 1.3600549606415757\n",
      "max: 1.4139911658253619\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.02728166907043946\n",
      "min: 0.01066248455806933\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31272950335971955\n",
      "std: 0.3033157901958792\n",
      "min: -0.7981271851124024\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6076362483280531\n",
      "std: 0.18263693351954363\n",
      "min: 0.14966656485135874\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03314089758223494\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1944707860405608\n",
      "std: 0.1680175989635398\n",
      "min: -0.21786463479911833\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1962641690640754\n",
      "std: 0.16939429695966637\n",
      "min: -0.21335910583442058\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.028611181013313985\n",
      "min: 0.0028904798961012315\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33721746814138626\n",
      "std: 0.36771881951633656\n",
      "min: -1.076894375351741\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45084285863517937\n",
      "std: 0.2233407014015269\n",
      "min: -0.11614260933525508\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03255587282135676\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081843827297191\n",
      "std: 0.006412065920087682\n",
      "min: 1.33797476559653\n",
      "max: 1.4139917536538014\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081749123477387\n",
      "std: 0.006460370085620535\n",
      "min: 1.33797476559653\n",
      "max: 1.4139917536538014\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782605\n",
      "std: 0.027282477640901973\n",
      "min: 0.010394292004280816\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3153971752422273\n",
      "std: 0.30345032066758654\n",
      "min: -0.7991462627239704\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6069630064484433\n",
      "std: 0.18340964329647438\n",
      "min: 0.1481081878415704\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324178643758444\n",
      "min: 0.13056046422770326\n",
      "max: 0.26691480912471316\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2174573273122702\n",
      "std: 0.07002561712165087\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2191477446642605\n",
      "std: 0.07324046897845375\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.027589872638684964\n",
      "min: 0.007579173812029774\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3383466287738008\n",
      "std: 0.36785624560797164\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4505485050471043\n",
      "std: 0.22346228400150503\n",
      "min: -0.11744174501600664\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03260852446406392\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090723757027703\n",
      "std: 0.0023477124125770663\n",
      "min: 1.3841891863344558\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090604007794112\n",
      "std: 0.002510497855496924\n",
      "min: 1.3841891863344558\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.027280574748723908\n",
      "min: 0.01082237288868864\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3143362773209409\n",
      "std: 0.3033207546018177\n",
      "min: -0.7986681568822114\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6061477582715628\n",
      "std: 0.18289440396055318\n",
      "min: 0.14810924774025572\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03321656798884414\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1945393517586576\n",
      "std: 0.17194570596145847\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1962854237658063\n",
      "std: 0.17429893233386795\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.02874471005843638\n",
      "min: 0.002187964823642008\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33883080401376026\n",
      "std: 0.3686939649611366\n",
      "min: -1.0771801916339687\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45061337556269265\n",
      "std: 0.2235393895946741\n",
      "min: -0.12012961953633242\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03256732477229093\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079145319384383\n",
      "std: 0.007991596785940126\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156444\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079024231891848\n",
      "std: 0.008157727955794843\n",
      "min: 1.3156862828233122\n",
      "max: 1.4140088846156444\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02173913043478261\n",
      "std: 0.027284577767626005\n",
      "min: 0.010167253061403394\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.314952788974952\n",
      "std: 0.30316000988506336\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6068113736046971\n",
      "std: 0.18339840957554776\n",
      "min: 0.14902012471818257\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033213863206763776\n",
      "min: 0.13072863959699577\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2017239097265604\n",
      "std: 0.1262538883733394\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2034081939558008\n",
      "std: 0.12825140020712703\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.027901586381329085\n",
      "min: 0.0031024090435135517\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33334991652573315\n",
      "std: 0.36931748271273207\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4543485191328321\n",
      "std: 0.22344354326193164\n",
      "min: -0.10883049623165524\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03245157258798737\n",
      "min: 0.11804781246265542\n",
      "max: 0.2666644669328233\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087027562790364\n",
      "std: 0.0032405355607915713\n",
      "min: 1.3789892633656264\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4086941618336488\n",
      "std: 0.0033070826786494494\n",
      "min: 1.3790865630090658\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.027031920497325182\n",
      "min: 0.010655425353900946\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3134542037626436\n",
      "std: 0.30353048880886185\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895606\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6077317864445432\n",
      "std: 0.18276151131366247\n",
      "min: 0.14911475972492574\n",
      "max: 0.9125577534895606\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03317737442696303\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1997992317837898\n",
      "std: 0.13746104567361153\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2015287295848622\n",
      "std: 0.14004911325514413\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.02821787499037879\n",
      "min: 0.0033692519883650423\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3337717127469368\n",
      "std: 0.37101234855848936\n",
      "min: -1.077281606680121\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45377012489704016\n",
      "std: 0.22411689285714506\n",
      "min: -0.11415131062850674\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03245834701043713\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084692064923423\n",
      "std: 0.004493191027654317\n",
      "min: 1.3589294307862594\n",
      "max: 1.4139911658253619\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084650317377112\n",
      "std: 0.0045724027184729805\n",
      "min: 1.3589294307862594\n",
      "max: 1.4139911658253619\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.027032747627751017\n",
      "min: 0.010406000036642375\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31285891782120856\n",
      "std: 0.3033314110423859\n",
      "min: -0.7981271851124024\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6076079454382058\n",
      "std: 0.18263038199584247\n",
      "min: 0.14966656485135874\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033143447804654856\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1943284105865175\n",
      "std: 0.16705006515273135\n",
      "min: -0.21786463479911833\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1960834272112706\n",
      "std: 0.16843966693991366\n",
      "min: -0.21335910583442058\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.028346086575703533\n",
      "min: 0.002890479896101232\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3375841877705782\n",
      "std: 0.3676408790382747\n",
      "min: -1.076894375351741\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4503224632968528\n",
      "std: 0.22319509608234395\n",
      "min: -0.11614260933525508\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03257184956020045\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408169038475151\n",
      "std: 0.006391256891919626\n",
      "min: 1.33797476559653\n",
      "max: 1.4139917536538014\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081513610172784\n",
      "std: 0.006443670147240507\n",
      "min: 1.33797476559653\n",
      "max: 1.4139917536538014\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.027033546416793328\n",
      "min: 0.01028322408940362\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3155051409871873\n",
      "std: 0.3034647321168354\n",
      "min: -0.7991462627239704\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6069412110944726\n",
      "std: 0.18339755276220182\n",
      "min: 0.1481081878415704\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324358334433478\n",
      "min: 0.13056046422770326\n",
      "max: 0.26691480912471316\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.217050374272406\n",
      "std: 0.06990326747364302\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.218706105915385\n",
      "std: 0.07312553473641943\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.02733727258442166\n",
      "min: 0.007249589589230065\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33869773660851926\n",
      "std: 0.3677722186512731\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4500268201633703\n",
      "std: 0.22331568876991906\n",
      "min: -0.11744174501600664\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03262379247538356\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090482747119237\n",
      "std: 0.0023707187442122924\n",
      "min: 1.384189186334456\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.409028214757732\n",
      "std: 0.0025422508497067943\n",
      "min: 1.384189186334456\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.027031666485915574\n",
      "min: 0.010692720256701222\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31445064743210716\n",
      "std: 0.30333641529037414\n",
      "min: -0.7986681568822114\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6061329741371594\n",
      "std: 0.18288627699704918\n",
      "min: 0.14810924774025572\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03321849234675303\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1943860063345537\n",
      "std: 0.1710928922700785\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1960942429782997\n",
      "std: 0.17345054380849\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.028477992762434123\n",
      "min: 0.002187964823642008\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3391848439133353\n",
      "std: 0.36860513544652584\n",
      "min: -1.0771801916339687\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45009318911816165\n",
      "std: 0.22339164093237124\n",
      "min: -0.12012961953633242\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03258311429594579\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079015942127153\n",
      "std: 0.007969049738444174\n",
      "min: 1.313220878600713\n",
      "max: 1.4140088846156444\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078813030373925\n",
      "std: 0.008137475416719529\n",
      "min: 1.313220878600713\n",
      "max: 1.4140088846156444\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02150537634408602\n",
      "std: 0.027035621129181307\n",
      "min: 0.009945814116597456\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3150619490448464\n",
      "std: 0.30317602621559514\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6067904237488378\n",
      "std: 0.18338518638657372\n",
      "min: 0.14902012471818257\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03321579965084817\n",
      "min: 0.13072863959699577\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2021895740611097\n",
      "std: 0.1257920411196776\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2038867290616129\n",
      "std: 0.1277779914580092\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.02764700702406542\n",
      "min: 0.0031024090435135534\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33374266575179834\n",
      "std: 0.36942521900033654\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45430516263534565\n",
      "std: 0.22324795358809837\n",
      "min: -0.10883049623165524\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032466685560406265\n",
      "min: 0.11804781246265542\n",
      "max: 0.2666644669328233\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087088250630448\n",
      "std: 0.0032316026673114197\n",
      "min: 1.3789892633656264\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4086953362133132\n",
      "std: 0.003301373098071731\n",
      "min: 1.3790865630090663\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.02678777837748772\n",
      "min: 0.010560587227660049\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3135306753718364\n",
      "std: 0.30360350988353746\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895606\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6076879179140401\n",
      "std: 0.18276939079322743\n",
      "min: 0.14911475972492574\n",
      "max: 0.9125577534895606\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03318015345972663\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2002871130272221\n",
      "std: 0.13692202265516243\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.202028724190952\n",
      "std: 0.1394972647718463\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.027959446387225348\n",
      "min: 0.0033692519883650423\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33416421235338556\n",
      "std: 0.37110200603616483\n",
      "min: -1.077281606680121\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4537306351830564\n",
      "std: 0.2239149345851117\n",
      "min: -0.11415131062850674\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032473395293729106\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084778264020732\n",
      "std: 0.00447562901567672\n",
      "min: 1.3589294307862592\n",
      "max: 1.4139911658253619\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408468710282546\n",
      "std: 0.004557062097430225\n",
      "min: 1.3589294307862592\n",
      "max: 1.4139911658253619\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021276595744680854\n",
      "std: 0.026788595515227318\n",
      "min: 0.010406000036642373\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31293938497369156\n",
      "std: 0.30340523793860075\n",
      "min: -0.7981271851124024\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6075640516460475\n",
      "std: 0.18263842933594798\n",
      "min: 0.14966656485135874\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033146465454913975\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1948703491881947\n",
      "std: 0.1663786177967821\n",
      "min: -0.21786463479911833\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1966365723229535\n",
      "std: 0.16776414825207847\n",
      "min: -0.21335910583442058\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.028086147458027077\n",
      "min: 0.002890479896101232\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3379391092569067\n",
      "std: 0.3677605150099928\n",
      "min: -1.076894375351741\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4503158260058801\n",
      "std: 0.22300222197404726\n",
      "min: -0.11614260933525508\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03258583337823383\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081806715943481\n",
      "std: 0.006362816017590761\n",
      "min: 1.33797476559653\n",
      "max: 1.4139917536538014\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081581220639956\n",
      "std: 0.006416898622730702\n",
      "min: 1.33797476559653\n",
      "max: 1.4139917536538014\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.02678938489886855\n",
      "min: 0.010176375299846756\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31556467012880984\n",
      "std: 0.30353790221555427\n",
      "min: -0.7991462627239704\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6069034004650548\n",
      "std: 0.18340018400321734\n",
      "min: 0.1481081878415704\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324586359591839\n",
      "min: 0.13056046422770326\n",
      "max: 0.26691480912471316\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2173683816860006\n",
      "std: 0.06970428247639002\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2190391693394955\n",
      "std: 0.07289638189941412\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.02708949159835908\n",
      "min: 0.00724958958923007\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3390387457256335\n",
      "std: 0.3678869837080652\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45002071646439595\n",
      "std: 0.22312171935956807\n",
      "min: -0.11744174501600664\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03263710170468215\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090508060915061\n",
      "std: 0.002368760557306732\n",
      "min: 1.384189186334456\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090259775105538\n",
      "std: 0.0025435682224061056\n",
      "min: 1.384189186334456\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.02678752740102709\n",
      "min: 0.01055830251454279\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3145167481729603\n",
      "std: 0.30341058445660435\n",
      "min: -0.7986681568822114\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6061023845740098\n",
      "std: 0.18289281451601797\n",
      "min: 0.14810924774025572\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03322090204951488\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1949252994918438\n",
      "std: 0.17042803686654737\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1966452383517714\n",
      "std: 0.17277832344323948\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021276595744680847\n",
      "std: 0.028216445128971607\n",
      "min: 0.002181503785771067\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3395281587642848\n",
      "std: 0.36871473793249926\n",
      "min: -1.0771801916339687\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4500880553264557\n",
      "std: 0.22319676884685388\n",
      "min: -0.12012961953633242\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03259697914547527\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079160438304692\n",
      "std: 0.007933680307559329\n",
      "min: 1.313220878600713\n",
      "max: 1.4140088846156444\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078909161362587\n",
      "std: 0.008102777418009174\n",
      "min: 1.313220878600713\n",
      "max: 1.4140088846156444\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.026791434573334053\n",
      "min: 0.009940788145058551\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3151226678939337\n",
      "std: 0.3032508424349837\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6067535379987209\n",
      "std: 0.1833866347868984\n",
      "min: 0.14902012471818257\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03321821854128554\n",
      "min: 0.13072863959699577\n",
      "max: 0.2668705165537987\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.202849914166861\n",
      "std: 0.1252882495526344\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2046711006600632\n",
      "std: 0.12728448187758382\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.02739727450340936\n",
      "min: 0.0031024090435135534\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33397877127070436\n",
      "std: 0.36939877506273605\n",
      "min: -1.0772735203280666\n",
      "max: 0.9704513583243345\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4542118537057773\n",
      "std: 0.22330304890495656\n",
      "min: -0.10883049623165524\n",
      "max: 0.9704513583243345\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03246553152041727\n",
      "min: 0.11804781246265542\n",
      "max: 0.2666644669328233\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4087190207920686\n",
      "std: 0.0032176781324067187\n",
      "min: 1.3789892633656264\n",
      "max: 1.4139905995955164\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4087112005139923\n",
      "std: 0.0032842763564700497\n",
      "min: 1.3790865630090663\n",
      "max: 1.4139905995955164\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.026548266688987496\n",
      "min: 0.010450855449339038\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3135216812616751\n",
      "std: 0.3035987085756167\n",
      "min: -0.7988196105866927\n",
      "max: 0.9125577534895606\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.607613341972941\n",
      "std: 0.1827359603103761\n",
      "min: 0.14911475972492574\n",
      "max: 0.9125577534895606\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033177972260392166\n",
      "min: 0.1308270098194005\n",
      "max: 0.2668768295081656\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.200970011530044\n",
      "std: 0.13628876540741247\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2028349426168683\n",
      "std: 0.1388739238014173\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02105263157894737\n",
      "std: 0.027705943460914977\n",
      "min: 0.0033692519883650423\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3343996904036366\n",
      "std: 0.3710579257336322\n",
      "min: -1.077281606680121\n",
      "max: 1.0031226127594255\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4536411541582902\n",
      "std: 0.2239627967920215\n",
      "min: -0.11415131062850674\n",
      "max: 1.0031226127594255\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03247215593881961\n",
      "min: 0.11782966247484128\n",
      "max: 0.26670196032932025\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084906014635932\n",
      "std: 0.004452329684783653\n",
      "min: 1.3589294307862592\n",
      "max: 1.4139911658253619\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084871057637265\n",
      "std: 0.004531583411912482\n",
      "min: 1.3589294307862592\n",
      "max: 1.4139911658253619\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.02654907401430579\n",
      "min: 0.010328234979181202\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3129342653663518\n",
      "std: 0.303401188903252\n",
      "min: -0.7981271851124024\n",
      "max: 0.9345062847359747\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6074895365022626\n",
      "std: 0.18260525376079637\n",
      "min: 0.14966656485135874\n",
      "max: 0.9345062847359747\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03314451324708116\n",
      "min: 0.13098150831459748\n",
      "max: 0.2668450878915493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.195595343443695\n",
      "std: 0.1657266780309064\n",
      "min: -0.21786463479911833\n",
      "max: 1.413112543706404\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1974839116547584\n",
      "std: 0.1671297448946536\n",
      "min: -0.21335910583442058\n",
      "max: 1.413112543706404\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.02783118647148574\n",
      "min: 0.002775915674891503\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33813888127599884\n",
      "std: 0.3677464946943531\n",
      "min: -1.076894375351741\n",
      "max: 0.9680281682043077\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45025841327373034\n",
      "std: 0.2230594009221959\n",
      "min: -0.11614260933525508\n",
      "max: 0.9680281682043077\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0325836617437714\n",
      "min: 0.11730985224476702\n",
      "max: 0.2671094496837809\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081955661342846\n",
      "std: 0.006335101070650267\n",
      "min: 1.33797476559653\n",
      "max: 1.4139917536538014\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081786987148341\n",
      "std: 0.006387928165459173\n",
      "min: 1.33797476559653\n",
      "max: 1.4139917536538014\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.0265498543225612\n",
      "min: 0.010062105079493648\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31553914605905636\n",
      "std: 0.30353355551407674\n",
      "min: -0.7991462627239704\n",
      "max: 0.9192195195019691\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6068347658799373\n",
      "std: 0.18336147699455774\n",
      "min: 0.1481081878415704\n",
      "max: 0.9192195195019691\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03324320452753138\n",
      "min: 0.13056046422770326\n",
      "max: 0.26691480912471316\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2178721935532837\n",
      "std: 0.06947804439334711\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2196698798826862\n",
      "std: 0.07266114722159575\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.026846412085085654\n",
      "min: 0.00724958958923007\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3392257737236425\n",
      "std: 0.3678698519555359\n",
      "min: -1.0765562360804255\n",
      "max: 0.9594521654813373\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4499634739887926\n",
      "std: 0.22317827681819388\n",
      "min: -0.11744174501600664\n",
      "max: 0.9594521654813373\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.03263433336081128\n",
      "min: 0.11878810475429609\n",
      "max: 0.2665703589568522\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4090572613457006\n",
      "std: 0.0023608223237713798\n",
      "min: 1.384189186334456\n",
      "max: 1.413990778937722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4090382269520125\n",
      "std: 0.002530488403587249\n",
      "min: 1.384189186334456\n",
      "max: 1.413990778937722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.02654801869491264\n",
      "min: 0.010492042090723682\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3144978414829668\n",
      "std: 0.3034072698563716\n",
      "min: -0.7986681568822114\n",
      "max: 0.9118540924163262\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6060407232542527\n",
      "std: 0.18285799288218157\n",
      "min: 0.14810924774025572\n",
      "max: 0.9118540924163262\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033218375566533266\n",
      "min: 0.13097219002032653\n",
      "max: 0.2668987734245041\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1956529014307336\n",
      "std: 0.16966920169385843\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1974958304374124\n",
      "std: 0.17203288024164112\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947364\n",
      "std: 0.027959901891787653\n",
      "min: 0.0021815037857710667\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3397165014153214\n",
      "std: 0.3686900647548977\n",
      "min: -1.0771801916339687\n",
      "max: 0.9667459598634702\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45003207215608526\n",
      "std: 0.22325074640682155\n",
      "min: -0.12012961953633242\n",
      "max: 0.9667459598634702\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.032594656390889376\n",
      "min: 0.11712467665367406\n",
      "max: 0.2670578082177354\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079338632440213\n",
      "std: 0.007895428863146349\n",
      "min: 1.313220878600713\n",
      "max: 1.4140088846156444\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079144422688992\n",
      "std: 0.008063110373549141\n",
      "min: 1.313220878600713\n",
      "max: 1.4140088846156444\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02105263157894737\n",
      "std: 0.026551879418747797\n",
      "min: 0.009868871770752258\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3150983169372424\n",
      "std: 0.3032480258045883\n",
      "min: -0.7982867040747372\n",
      "max: 0.9494609040688611\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6066859388586573\n",
      "std: 0.18334682076465222\n",
      "min: 0.14902012471818257\n",
      "max: 0.9494609040688611\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.033215688262217935\n",
      "min: 0.13072863959699577\n",
      "max: 0.2668705165537987\n",
      "Test translation: je suis fatigué -> principal\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8752530362684428\n",
      "std: 0.3638685977164651\n",
      "min: -0.6827337799836616\n",
      "max: 1.413273325417982\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.8752530362684428\n",
      "std: 0.3638685977164651\n",
      "min: -0.6827337799836616\n",
      "max: 1.413273325417982\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.010526315789473682\n",
      "std: 0.0021369776054186566\n",
      "min: 0.0016546866928553088\n",
      "max: 0.06140418092291397\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1425663242307287\n",
      "std: 0.46493512138936854\n",
      "min: -1.0576266827162468\n",
      "max: 1.413913861766096\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1425663242307287\n",
      "std: 0.46493512138936854\n",
      "min: -1.0576266827162468\n",
      "max: 1.413913861766096\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.010526315789473684\n",
      "std: 0.002498250319641955\n",
      "min: 0.0010182440658336735\n",
      "max: 0.07651498641875214\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4113182340624673\n",
      "std: 0.0007336068564112406\n",
      "min: 1.4102557543740661\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4113182340624673\n",
      "std: 0.0007336068564112406\n",
      "min: 1.4102557543740661\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 1.0\n",
      "std: 0.0\n",
      "min: 1.0\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31256773545393396\n",
      "std: 0.32393448840777445\n",
      "min: -0.8493143005256294\n",
      "max: 0.8453066327275717\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.41467713939916984\n",
      "std: 0.3226957728763639\n",
      "min: -0.2989247471940194\n",
      "max: 0.8453066327275717\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05507075528033022\n",
      "min: 0.09405929060583498\n",
      "max: 0.2882100908925449\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4137606581916595\n",
      "std: 0.00013908044678360727\n",
      "min: 1.4136328627612107\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4137606581916595\n",
      "std: 0.00013908044678360727\n",
      "min: 1.4136328627612107\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 1.0\n",
      "std: 0.0\n",
      "min: 1.0\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3051710660847911\n",
      "std: 0.2834314188530664\n",
      "min: -0.7381092125530452\n",
      "max: 0.9291196960283645\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5150689940360635\n",
      "std: 0.3644366341233194\n",
      "min: -0.2991542924313511\n",
      "max: 0.9291196960283645\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0629069661989032\n",
      "min: 0.08637221057194587\n",
      "max: 0.2898013651680009\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1963623061909985\n",
      "std: 0.22168255608041917\n",
      "min: 0.8476747683893139\n",
      "max: 1.4123025686197597\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2650026332042277\n",
      "std: 0.2093357704790612\n",
      "min: 0.9124721050936906\n",
      "max: 1.4123025686197597\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.2518618548026998\n",
      "min: 0.37769058979187176\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3211782158573474\n",
      "std: 0.3475927182871198\n",
      "min: -0.9182658000633804\n",
      "max: 0.9663616649140455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4121477043992711\n",
      "std: 0.3286932177885226\n",
      "min: -0.46065965189701097\n",
      "max: 0.9663616649140455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05590507752244272\n",
      "min: 0.07667747542821851\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4089383929194907\n",
      "std: 0.005811390121923698\n",
      "min: 1.3953003878804866\n",
      "max: 1.4139771965086931\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4102495242050115\n",
      "std: 0.0056973505811315816\n",
      "min: 1.3953003878804866\n",
      "max: 1.4139771965086931\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.23571393049809722\n",
      "min: 0.4954518594515494\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3140586158429648\n",
      "std: 0.2878160629340133\n",
      "min: -0.7693730995035949\n",
      "max: 0.929546393434597\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5048649005748599\n",
      "std: 0.36420762475776\n",
      "min: -0.3432547761616461\n",
      "max: 0.929546393434597\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999998\n",
      "std: 0.06292110501807696\n",
      "min: 0.08326892393427666\n",
      "max: 0.297340095733209\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9311392748460531\n",
      "std: 0.5200042157371114\n",
      "min: 0.06308843307539107\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.092094570120888\n",
      "std: 0.47992343647084595\n",
      "min: 0.0945946245166937\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.29976242841654843\n",
      "min: 0.2109675039341757\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.1342609495347308\n",
      "std: 0.3413120861367817\n",
      "min: -0.8493143005256294\n",
      "max: 1.0096434888388919\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4662235530643043\n",
      "std: 0.2878814144582163\n",
      "min: -0.2989247471940194\n",
      "max: 1.0096434888388919\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.04638219744674556\n",
      "min: 0.09405929060583498\n",
      "max: 0.28821009089254496\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3986948312970213\n",
      "std: 0.015585832174625017\n",
      "min: 1.376511348380308\n",
      "max: 1.4139771965086931\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4033809579836152\n",
      "std: 0.015066966310096888\n",
      "min: 1.376511348380308\n",
      "max: 1.4139771965086931\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.23579065147968462\n",
      "min: 0.49072850799068624\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.28267585351805374\n",
      "std: 0.2900147901317236\n",
      "min: -0.7381092125530451\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5284552523099745\n",
      "std: 0.3607655813968999\n",
      "min: -0.29915429243135105\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0621691644940903\n",
      "min: 0.08532928957731421\n",
      "max: 0.2942828571287649\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8806036235418093\n",
      "std: 0.5638278344719377\n",
      "min: -0.07777795867923404\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0577907928586716\n",
      "std: 0.5233245226550282\n",
      "min: -0.057988019018108516\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.3092163277732682\n",
      "min: 0.18673836015167006\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.23301964591492552\n",
      "std: 0.3032590584504884\n",
      "min: -0.8493143005256294\n",
      "max: 0.8453066327275717\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36320364101887137\n",
      "std: 0.29715024385846683\n",
      "min: -0.2989247471940194\n",
      "max: 0.8453066327275717\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.04672395626117528\n",
      "min: 0.09405929060583498\n",
      "max: 0.28821009089254496\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.383575632128965\n",
      "std: 0.030786310505134785\n",
      "min: 1.3455552878704182\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3936763627304583\n",
      "std: 0.02890583707976349\n",
      "min: 1.3455552878704182\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.23602991095943676\n",
      "min: 0.48298513109974356\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30949639679995883\n",
      "std: 0.29207425754179756\n",
      "min: -0.7415642198780452\n",
      "max: 0.941807766584605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.518605207421061\n",
      "std: 0.3692941593811593\n",
      "min: -0.33741216513780026\n",
      "max: 0.941807766584605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06281408105777762\n",
      "min: 0.08637221057194588\n",
      "max: 0.29478093067049915\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7506384432892446\n",
      "std: 0.66634164900538\n",
      "min: -0.09647691344892374\n",
      "max: 1.41412238185193\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9718514371427064\n",
      "std: 0.6265292132993461\n",
      "min: -0.09647691344892374\n",
      "max: 1.41412238185193\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.33393944927010755\n",
      "min: 0.18090931757814332\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.04645127376566043\n",
      "std: 0.35564100689134903\n",
      "min: -0.8493143005256294\n",
      "max: 0.8453066327275717\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.33805790705085903\n",
      "std: 0.26531801937749544\n",
      "min: -0.2989247471940194\n",
      "max: 0.8453066327275717\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.04035753643643766\n",
      "min: 0.09405929060583498\n",
      "max: 0.28821009089254496\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3724492131552077\n",
      "std: 0.044738381794166615\n",
      "min: 1.3027125877092702\n",
      "max: 1.414015070723829\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3866776479412428\n",
      "std: 0.040857288838874954\n",
      "min: 1.3027125877092702\n",
      "max: 1.414015070723829\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.23633852192478605\n",
      "min: 0.472203069583255\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2732062908246288\n",
      "std: 0.2816119428837457\n",
      "min: -0.7381092125530451\n",
      "max: 0.9291196960283649\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.502984876965451\n",
      "std: 0.349000582453543\n",
      "min: -0.29915429243135105\n",
      "max: 0.9291196960283649\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06024520979178079\n",
      "min: 0.08637221057194588\n",
      "max: 0.29141152464102815\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9483295474094224\n",
      "std: 0.5109892073587207\n",
      "min: -0.02905747130271812\n",
      "max: 1.4137919023565602\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.102249871529562\n",
      "std: 0.4708734966189789\n",
      "min: -0.011290172094139345\n",
      "max: 1.4137919023565602\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.29673510939503395\n",
      "min: 0.19386611073883797\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.19053882560426547\n",
      "std: 0.2962851561892651\n",
      "min: -0.8493143005256294\n",
      "max: 0.8453066327275717\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3347298444724511\n",
      "std: 0.2929805404834859\n",
      "min: -0.2989247471940194\n",
      "max: 0.8453066327275717\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.044117820838907654\n",
      "min: 0.09405929060583498\n",
      "max: 0.28821009089254496\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3971852825946025\n",
      "std: 0.018295417402148295\n",
      "min: 1.3603877391620711\n",
      "max: 1.4139771965086931\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4025878103727878\n",
      "std: 0.01734157298833794\n",
      "min: 1.3603877391620711\n",
      "max: 1.4139771965086931\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.23581469723512874\n",
      "min: 0.48669418740425896\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2947636995341622\n",
      "std: 0.28442257621978995\n",
      "min: -0.7381092125530451\n",
      "max: 0.9523249607302066\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5118624273110597\n",
      "std: 0.35807174140114917\n",
      "min: -0.29915429243135105\n",
      "max: 0.9523249607302066\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06209390704500425\n",
      "min: 0.08579075391105533\n",
      "max: 0.29452367034268373\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1748716814975388\n",
      "std: 0.21585164020611053\n",
      "min: 0.805551952401327\n",
      "max: 1.4123025686197597\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2284351063099628\n",
      "std: 0.21669056828450103\n",
      "min: 0.8544662153487507\n",
      "max: 1.4123025686197597\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.24861177813466626\n",
      "min: 0.23443909030689963\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34132327045985084\n",
      "std: 0.36269042741949103\n",
      "min: -0.969690583510834\n",
      "max: 0.9663616649140455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.40539994580653504\n",
      "std: 0.3349407653967485\n",
      "min: -0.5144220913896679\n",
      "max: 0.9663616649140455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05647339662875887\n",
      "min: 0.07667747542821851\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074506060954028\n",
      "std: 0.005687219739010537\n",
      "min: 1.3945542148332448\n",
      "max: 1.4139771965086931\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4085974186587062\n",
      "std: 0.006129749265495801\n",
      "min: 1.3945542148332448\n",
      "max: 1.4139771965086931\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.23571201490965168\n",
      "min: 0.33025830481534185\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32107814504154997\n",
      "std: 0.29170041763500354\n",
      "min: -0.7909899406319494\n",
      "max: 0.929546393434597\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4993782405235551\n",
      "std: 0.36506466988313907\n",
      "min: -0.3711081087972109\n",
      "max: 0.929546393434597\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.06302936284990183\n",
      "min: 0.08268588180820804\n",
      "max: 0.2978492189069125\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8749350193827582\n",
      "std: 0.4497770940866647\n",
      "min: 0.06308843307539107\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0047956294937386\n",
      "std: 0.45550345480441856\n",
      "min: 0.0945946245166937\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.2850626518997712\n",
      "min: 0.17007493119185874\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.21319561671779824\n",
      "std: 0.3842365380733518\n",
      "min: -0.9892422714506508\n",
      "max: 1.0096434888388919\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.45358241893540263\n",
      "std: 0.31204411003146754\n",
      "min: -0.49309214785122607\n",
      "max: 1.0096434888388919\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05060066769582718\n",
      "min: 0.07546533690690091\n",
      "max: 0.31536441298685036\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3958991011517765\n",
      "std: 0.017093818237539297\n",
      "min: 1.3620652574853442\n",
      "max: 1.4139771965086931\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.399920787194236\n",
      "std: 0.01691125522583432\n",
      "min: 1.3621467482306926\n",
      "max: 1.4139771965086931\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.23578130129706232\n",
      "min: 0.3231623814836283\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2967761919156285\n",
      "std: 0.294419492944041\n",
      "min: -0.7867394271150369\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.518779044136854\n",
      "std: 0.3624949851148916\n",
      "min: -0.35375011227297715\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999998\n",
      "std: 0.062423185884228266\n",
      "min: 0.08264773603825515\n",
      "max: 0.29748909503410564\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9308050071691591\n",
      "std: 0.41965173401719086\n",
      "min: 0.1593609256324407\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0491273856700547\n",
      "std: 0.4186511356163475\n",
      "min: 0.1593609256324407\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.26706613930160994\n",
      "min: 0.1702328061857205\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.24122275975236265\n",
      "std: 0.34360416033584373\n",
      "min: -0.9182658000633804\n",
      "max: 0.9663616649140455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4446154019582675\n",
      "std: 0.3030424612801628\n",
      "min: -0.46065965189701097\n",
      "max: 0.9663616649140455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.050670491513443\n",
      "min: 0.07667747542821851\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4013805401314143\n",
      "std: 0.010717534359390202\n",
      "min: 1.3832532719740256\n",
      "max: 1.4139771965086931\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4039128458257126\n",
      "std: 0.01131799096205204\n",
      "min: 1.3832532719740256\n",
      "max: 1.4139771965086931\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.23572424344769105\n",
      "min: 0.3292845546604853\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30647099560351715\n",
      "std: 0.2915909629733239\n",
      "min: -0.7693730995035949\n",
      "max: 0.9419110036744668\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5110427975539145\n",
      "std: 0.3635525453093751\n",
      "min: -0.3432547761616461\n",
      "max: 0.9419110036744668\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06273927518125867\n",
      "min: 0.08326892393427666\n",
      "max: 0.297340095733209\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8109572123003389\n",
      "std: 0.5252062043159589\n",
      "min: -0.2941077066191615\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9558382248241438\n",
      "std: 0.5260365563866248\n",
      "min: -0.2941077066191615\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.2939262426839983\n",
      "min: 0.10266640668548715\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2898146817593496\n",
      "std: 0.35109142368573465\n",
      "min: -0.989637386167658\n",
      "max: 0.9100507245717214\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3788091974549553\n",
      "std: 0.32071395719565504\n",
      "min: -0.5107852900881654\n",
      "max: 0.9100507245717214\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05131413863446827\n",
      "min: 0.07580509197373064\n",
      "max: 0.3138770916726905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3820762169363685\n",
      "std: 0.03196674765060083\n",
      "min: 1.319172227548471\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3895798660663818\n",
      "std: 0.031126355602957217\n",
      "min: 1.319172227548471\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.23598475732951285\n",
      "min: 0.3146278776275763\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32187327671199084\n",
      "std: 0.29526923186241\n",
      "min: -0.7915201716103981\n",
      "max: 0.941807766584605\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5086739821193565\n",
      "std: 0.3699745300548471\n",
      "min: -0.374305426010419\n",
      "max: 0.941807766584605\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06305148858186466\n",
      "min: 0.08235666430901115\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7744623754352606\n",
      "std: 0.5495160597829207\n",
      "min: 0.023304721427690203\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9319499297900787\n",
      "std: 0.549781204669337\n",
      "min: 0.023304721427690203\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.28533765727765087\n",
      "min: 0.16508929563220068\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.29080467135882804\n",
      "std: 0.3297256674522311\n",
      "min: -0.9182658000633804\n",
      "max: 0.9663616649140455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3764285781063675\n",
      "std: 0.31289760404302097\n",
      "min: -0.46065965189701097\n",
      "max: 0.9663616649140455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.050531630377667745\n",
      "min: 0.07667747542821851\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3871351916774548\n",
      "std: 0.02769272109139167\n",
      "min: 1.340246034994033\n",
      "max: 1.4139771965086931\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.393460784645221\n",
      "std: 0.026903277172983228\n",
      "min: 1.3411395329149332\n",
      "max: 1.4139771965086931\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.2357990749377554\n",
      "min: 0.3226878293369128\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3208824801165978\n",
      "std: 0.2948407871069037\n",
      "min: -0.7730141157447741\n",
      "max: 0.929546393434597\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5059368160829408\n",
      "std: 0.3684114854370731\n",
      "min: -0.3815620607805023\n",
      "max: 0.929546393434597\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06305807879413686\n",
      "min: 0.08326892393427666\n",
      "max: 0.297340095733209\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1708351085391293\n",
      "std: 0.1869859006572501\n",
      "min: 0.8055519524013274\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2127137458214494\n",
      "std: 0.19737938074259095\n",
      "min: 0.8544662153487502\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.22961736700686555\n",
      "min: 0.1853587758408729\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.356296193860363\n",
      "std: 0.3713467691052588\n",
      "min: -1.0393086302630352\n",
      "max: 0.9663616649140456\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.41111550267362473\n",
      "std: 0.34103131263812503\n",
      "min: -0.5302423323732633\n",
      "max: 0.9663616649140456\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05711211611900228\n",
      "min: 0.0766774754282185\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407652466657118\n",
      "std: 0.00487380281368123\n",
      "min: 1.3945542148332446\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4085551497065212\n",
      "std: 0.0054097357602641075\n",
      "min: 1.3945542148332446\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.21985560921052374\n",
      "min: 0.2481986809997506\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32299303524830986\n",
      "std: 0.29337769606101755\n",
      "min: -0.7909899406319494\n",
      "max: 0.929546393434597\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4994918502730489\n",
      "std: 0.3649570885549479\n",
      "min: -0.3711081087972109\n",
      "max: 0.929546393434597\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06301317637498272\n",
      "min: 0.08268588180820804\n",
      "max: 0.2978492189069125\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8891511669698786\n",
      "std: 0.44689857501812136\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9878465316708818\n",
      "std: 0.45428587844210516\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.2589986821600784\n",
      "min: 0.08616557489792928\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2584436459158867\n",
      "std: 0.3970542403680094\n",
      "min: -1.0441664747471735\n",
      "max: 1.009643488838892\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4531930907037533\n",
      "std: 0.3246842455998886\n",
      "min: -0.5129390818988486\n",
      "max: 1.009643488838892\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.052859930195438755\n",
      "min: 0.07546533690690091\n",
      "max: 0.3182313330194352\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3972769082767813\n",
      "std: 0.016515561333942105\n",
      "min: 1.3620652574853445\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4002605822443577\n",
      "std: 0.016272047439316126\n",
      "min: 1.362146748230693\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.21991192494004771\n",
      "min: 0.24230737307595257\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3030019637722725\n",
      "std: 0.29577999569189406\n",
      "min: -0.786739427115037\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5159976853341947\n",
      "std: 0.3627907641334675\n",
      "min: -0.35375011227297737\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0625083951668822\n",
      "min: 0.08264773603825515\n",
      "max: 0.29748909503410564\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9316990458457172\n",
      "std: 0.4011981105887229\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0231731356213796\n",
      "std: 0.40751534668343553\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.24611845255094672\n",
      "min: 0.09769427941573716\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.27670074119599924\n",
      "std: 0.364870028918816\n",
      "min: -1.0406485396783056\n",
      "max: 0.9663616649140456\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4478697452602639\n",
      "std: 0.31684736713911593\n",
      "min: -0.5049491309430121\n",
      "max: 0.9663616649140456\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05266050193439425\n",
      "min: 0.0766774754282185\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4019099770314267\n",
      "std: 0.010067229623420881\n",
      "min: 1.3832532719740256\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4039204316814744\n",
      "std: 0.010389691780164897\n",
      "min: 1.3832532719740256\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.21986682808060087\n",
      "min: 0.24615299573817842\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3102070469102449\n",
      "std: 0.29382074723107315\n",
      "min: -0.7838914077761377\n",
      "max: 0.9419110036744669\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5107580171362766\n",
      "std: 0.36355437921927386\n",
      "min: -0.3432547761616462\n",
      "max: 0.9419110036744669\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06274390461586407\n",
      "min: 0.08326892393427666\n",
      "max: 0.297340095733209\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8443061490327828\n",
      "std: 0.5061438207953619\n",
      "min: -0.2941077066191617\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9511161467790437\n",
      "std: 0.5095685451728392\n",
      "min: -0.2941077066191617\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.2653662493820915\n",
      "min: 0.07293152928685523\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32062025636424196\n",
      "std: 0.3676208046881897\n",
      "min: -1.0462977647854377\n",
      "max: 0.9100507245717211\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3945523604178921\n",
      "std: 0.33300009441427814\n",
      "min: -0.5239590510647911\n",
      "max: 0.9100507245717211\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999998\n",
      "std: 0.05360142490019668\n",
      "min: 0.07580509197373064\n",
      "max: 0.31744221058397815\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.385276789137425\n",
      "std: 0.031529344058553184\n",
      "min: 1.319172227548471\n",
      "max: 1.4139848306068203\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.390567577061692\n",
      "std: 0.030685953153994836\n",
      "min: 1.319172227548471\n",
      "max: 1.4139848306068203\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.39999999999999997\n",
      "std: 0.22007875902474477\n",
      "min: 0.23447111057710066\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3256368677006101\n",
      "std: 0.2961340673766978\n",
      "min: -0.791520171610398\n",
      "max: 0.9418077665846053\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5067875210652434\n",
      "std: 0.36932910056035223\n",
      "min: -0.37430542601041905\n",
      "max: 0.9418077665846053\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06308463519153727\n",
      "min: 0.08235666430901115\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9370663802514149\n",
      "std: 0.4076149624836101\n",
      "min: 0.1265687730872469\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.027778659738246\n",
      "std: 0.4117992096336931\n",
      "min: 0.14847232270936514\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.39999999999999997\n",
      "std: 0.2411076334826278\n",
      "min: 0.14764759365348262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.28246756874359175\n",
      "std: 0.3642320579754712\n",
      "min: -0.9696905835108341\n",
      "max: 0.9663616649140456\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.44528645164640057\n",
      "std: 0.32265304659659305\n",
      "min: -0.5144220913896679\n",
      "max: 0.9663616649140456\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05306002073134683\n",
      "min: 0.0766774754282185\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.403415669180602\n",
      "std: 0.008024875827420673\n",
      "min: 1.3873544993148614\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4051415569413093\n",
      "std: 0.008432260383159421\n",
      "min: 1.3873544993148614\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.21985872943168402\n",
      "min: 0.2475802429135943\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3138872436381298\n",
      "std: 0.2935091428411697\n",
      "min: -0.7909899406319494\n",
      "max: 0.9329248125854106\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5081988873828085\n",
      "std: 0.3644649183312524\n",
      "min: -0.3711081087972109\n",
      "max: 0.9329248125854106\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06285743260886112\n",
      "min: 0.08268588180820804\n",
      "max: 0.2978492189069125\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1822303510492187\n",
      "std: 0.170414813819749\n",
      "min: 0.8055519524013274\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2159428865332884\n",
      "std: 0.18092053697155946\n",
      "min: 0.8544662153487502\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333333\n",
      "std: 0.2104321660495947\n",
      "min: 0.14732430296998564\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3546350741440612\n",
      "std: 0.3703716989370599\n",
      "min: -1.0393086302630352\n",
      "max: 0.9663616649140456\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3970006476376868\n",
      "std: 0.3424969430138948\n",
      "min: -0.5302423323732633\n",
      "max: 0.9663616649140456\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057137746792817384\n",
      "min: 0.0766774754282185\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080202189310231\n",
      "std: 0.004436824900085203\n",
      "min: 1.394554214833245\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408774715367547\n",
      "std: 0.004949783980432126\n",
      "min: 1.394554214833245\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.33333333333333337\n",
      "std: 0.20276437194087985\n",
      "min: 0.19845989105960682\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32376706430003194\n",
      "std: 0.29344415172942284\n",
      "min: -0.7909899406319494\n",
      "max: 0.9295463934345971\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49646020813839287\n",
      "std: 0.3647572461319801\n",
      "min: -0.3711081087972108\n",
      "max: 0.9295463934345971\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999996\n",
      "std: 0.06297304822776635\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.938532950715296\n",
      "std: 0.41779785903733235\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.012797618697749\n",
      "std: 0.42375298488144797\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333334\n",
      "std: 0.23391045961741766\n",
      "min: 0.0828389111440554\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2752935617791713\n",
      "std: 0.39450393025460695\n",
      "min: -1.0441664747471735\n",
      "max: 1.009643488838892\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.433455796269463\n",
      "std: 0.33117591107412736\n",
      "min: -0.5129390818988486\n",
      "max: 1.009643488838892\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05381596501955458\n",
      "min: 0.07546533690690091\n",
      "max: 0.3182313330194352\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.399137387026185\n",
      "std: 0.015404026602603095\n",
      "min: 1.3620652574853442\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4013906757983383\n",
      "std: 0.015152809382957159\n",
      "min: 1.3621467482306935\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.33333333333333337\n",
      "std: 0.20280940854618962\n",
      "min: 0.1941647365950618\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3066622266191623\n",
      "std: 0.2955430550303993\n",
      "min: -0.7867394271150365\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5107638474444096\n",
      "std: 0.3629644073301\n",
      "min: -0.35413389468020073\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.06253952837668042\n",
      "min: 0.08264773603825515\n",
      "max: 0.2974890950341056\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9724614645415912\n",
      "std: 0.37545323528005364\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0418796229379248\n",
      "std: 0.3803765951882272\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.33333333333333326\n",
      "std: 0.22414953339507948\n",
      "min: 0.08930966514056929\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.28856454957363276\n",
      "std: 0.36784947735127427\n",
      "min: -1.0406485396783056\n",
      "max: 0.9663616649140456\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4300322246121259\n",
      "std: 0.323962099853\n",
      "min: -0.5056720428949861\n",
      "max: 0.9663616649140456\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.053552409898806184\n",
      "min: 0.0766774754282185\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4031020944744135\n",
      "std: 0.009355907148219683\n",
      "min: 1.3832532719740256\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4046794488818513\n",
      "std: 0.00950606706111024\n",
      "min: 1.3832532719740256\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.33333333333333326\n",
      "std: 0.20277365736972575\n",
      "min: 0.19729642014475723\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31247678542810425\n",
      "std: 0.29410145873614196\n",
      "min: -0.7838914077761377\n",
      "max: 0.9419110036744671\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5068933586591948\n",
      "std: 0.36354667134699437\n",
      "min: -0.3549082589093404\n",
      "max: 0.9419110036744671\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999996\n",
      "std: 0.06273247460186707\n",
      "min: 0.08326892393427665\n",
      "max: 0.297340095733209\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.884367729663889\n",
      "std: 0.4980022952919234\n",
      "min: -0.3220562513263309\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9667922364951866\n",
      "std: 0.4990224105295292\n",
      "min: -0.3220562513263309\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333333\n",
      "std: 0.23962375552540674\n",
      "min: 0.05101998228411438\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32806007926777764\n",
      "std: 0.36871748427179474\n",
      "min: -1.0462977647854377\n",
      "max: 0.9100507245717211\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3844373494334386\n",
      "std: 0.33632691882334376\n",
      "min: -0.5239590510647911\n",
      "max: 0.9100507245717211\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.054508213971523216\n",
      "min: 0.07580509197373064\n",
      "max: 0.31744221058397815\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3886442650547102\n",
      "std: 0.030341971892246203\n",
      "min: 1.319172227548471\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.392509652074159\n",
      "std: 0.02952939374702302\n",
      "min: 1.319172227548471\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333333\n",
      "std: 0.20294733118290512\n",
      "min: 0.18697576341745442\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32714577936249106\n",
      "std: 0.29558153420678196\n",
      "min: -0.791520171610398\n",
      "max: 0.9418077665846053\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5022496556069984\n",
      "std: 0.3687091819873464\n",
      "min: -0.37430542601041916\n",
      "max: 0.9418077665846053\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06306031524265032\n",
      "min: 0.08235666430901113\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9748892280187182\n",
      "std: 0.3855939455922153\n",
      "min: 0.1265687730872469\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0443287192222501\n",
      "std: 0.38762518219120834\n",
      "min: 0.14847232270936514\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333333\n",
      "std: 0.22058800650973923\n",
      "min: 0.08485825115146074\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2938860429922987\n",
      "std: 0.36863865555863906\n",
      "min: -0.9696905835108341\n",
      "max: 0.9663616649140456\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.42737848238133447\n",
      "std: 0.3293527556972023\n",
      "min: -0.5144220913896679\n",
      "max: 0.9663616649140456\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.05395236688125215\n",
      "min: 0.0766774754282185\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4043465597767453\n",
      "std: 0.007334531131570048\n",
      "min: 1.3873544993148617\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405699443072686\n",
      "std: 0.007700191884509681\n",
      "min: 1.3873544993148617\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.33333333333333326\n",
      "std: 0.20276718805740998\n",
      "min: 0.1978925204509157\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31554460340353774\n",
      "std: 0.29377834422634486\n",
      "min: -0.7909899406319494\n",
      "max: 0.9329248125854105\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5047454847786725\n",
      "std: 0.36430745861479136\n",
      "min: -0.3711081087972108\n",
      "max: 0.9329248125854105\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06282997043007757\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1775929551477997\n",
      "std: 0.1675137080631079\n",
      "min: 0.7740393198270334\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2089957707392895\n",
      "std: 0.17770670871182323\n",
      "min: 0.8154559782521462\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.19362650070920634\n",
      "min: 0.1143876940702646\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33966947054525404\n",
      "std: 0.37175985238131354\n",
      "min: -1.0393086302630352\n",
      "max: 0.9663616649140456\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.39451629590212733\n",
      "std: 0.33724435501903743\n",
      "min: -0.5302423323732633\n",
      "max: 0.9663616649140456\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0563864011982738\n",
      "min: 0.0766774754282185\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407511640871508\n",
      "std: 0.004990538229914257\n",
      "min: 1.3884483872227988\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082841221006834\n",
      "std: 0.0054490408988960145\n",
      "min: 1.3884483872227988\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.28571428571428575\n",
      "std: 0.1871787770323162\n",
      "min: 0.16412201924099243\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32265106597507465\n",
      "std: 0.2931683775773442\n",
      "min: -0.7909899406319494\n",
      "max: 0.9295463934345971\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4942437412822373\n",
      "std: 0.36370871478396805\n",
      "min: -0.3711081087972108\n",
      "max: 0.9295463934345971\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0628355754967446\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9672918345730364\n",
      "std: 0.38950443963982023\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0282432084662023\n",
      "std: 0.3965029523289134\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.21285884755912013\n",
      "min: 0.06927779248720833\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.27278581707219923\n",
      "std: 0.3924670508506561\n",
      "min: -1.0441664747471735\n",
      "max: 1.009643488838892\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.42762084939946327\n",
      "std: 0.3285213319774057\n",
      "min: -0.5129390818988486\n",
      "max: 1.009643488838892\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05368668440774503\n",
      "min: 0.07546533690690091\n",
      "max: 0.3182313330194352\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3997287527522222\n",
      "std: 0.014560469849036837\n",
      "min: 1.3620652574853442\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4016314937370122\n",
      "std: 0.014416450559971088\n",
      "min: 1.3621467482306935\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.187215793388038\n",
      "min: 0.1616465847009711\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3076471773672355\n",
      "std: 0.2949818622402409\n",
      "min: -0.7867394271150365\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5070120456305488\n",
      "std: 0.36217674516863463\n",
      "min: -0.3541338946802007\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06245571694909147\n",
      "min: 0.08264773603825515\n",
      "max: 0.2974890950341056\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9947071922746292\n",
      "std: 0.3574912189779483\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0522512647622226\n",
      "std: 0.3626660803825417\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.2051958611764854\n",
      "min: 0.06515184149231606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.28298290519224584\n",
      "std: 0.36999744656934314\n",
      "min: -1.0406485396783056\n",
      "max: 0.9663616649140456\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4249630449422018\n",
      "std: 0.32180181308112626\n",
      "min: -0.5056720428949861\n",
      "max: 0.9663616649140456\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05336062530477234\n",
      "min: 0.0766774754282185\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4031856090460204\n",
      "std: 0.00924896848089023\n",
      "min: 1.3798310498099915\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4045938919007062\n",
      "std: 0.009356600544957568\n",
      "min: 1.3824176065297522\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.18718672726698327\n",
      "min: 0.16380967334819427\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31259005687893426\n",
      "std: 0.29391206625447636\n",
      "min: -0.7838914077761377\n",
      "max: 0.9419110036744671\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.503965982310848\n",
      "std: 0.3626657089292622\n",
      "min: -0.3549082589093403\n",
      "max: 0.9419110036744671\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06262210767081888\n",
      "min: 0.08326892393427665\n",
      "max: 0.297340095733209\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9109373901171417\n",
      "std: 0.47964602217052527\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9791344387046328\n",
      "std: 0.48144574185331346\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.28571428571428575\n",
      "std: 0.2178997417336621\n",
      "min: 0.03912628490824474\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31937638962828235\n",
      "std: 0.37058986941549255\n",
      "min: -1.0462977647854377\n",
      "max: 0.9100507245717211\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3849028859801216\n",
      "std: 0.33289727020285115\n",
      "min: -0.5239590510647911\n",
      "max: 0.9100507245717211\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05435401065153757\n",
      "min: 0.07580509197373064\n",
      "max: 0.31744221058397815\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3904092093817702\n",
      "std: 0.029098925438594245\n",
      "min: 1.319172227548471\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3934928389964594\n",
      "std: 0.028453514152088324\n",
      "min: 1.319172227548471\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.18733230466395406\n",
      "min: 0.1558572939243566\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32638020594590017\n",
      "std: 0.2949065926464863\n",
      "min: -0.791520171610398\n",
      "max: 0.9418077665846053\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4990286034440029\n",
      "std: 0.36731212083064696\n",
      "min: -0.37430542601041916\n",
      "max: 0.9418077665846053\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06293035004679172\n",
      "min: 0.08235666430901113\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.994895729589764\n",
      "std: 0.3708894433486788\n",
      "min: 0.1265687730872469\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.052888254222003\n",
      "std: 0.37264820641403834\n",
      "min: 0.14847232270936514\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.28571428571428575\n",
      "std: 0.20253249812380433\n",
      "min: 0.07007452924393023\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.287975406157664\n",
      "std: 0.37169707539082003\n",
      "min: -0.9696905835108341\n",
      "max: 0.9663616649140456\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4222457436045333\n",
      "std: 0.326928139624959\n",
      "min: -0.5144220913896679\n",
      "max: 0.9663616649140456\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.053771581389488066\n",
      "min: 0.0766774754282185\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.404306360373637\n",
      "std: 0.007346559656845834\n",
      "min: 1.3873544993148617\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4055225916408223\n",
      "std: 0.007730504027628123\n",
      "min: 1.3873544993148617\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.1871813072431169\n",
      "min: 0.16453768041304048\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3152143012651115\n",
      "std: 0.2936015256180044\n",
      "min: -0.7909899406319494\n",
      "max: 0.9329248125854105\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5020620988904508\n",
      "std: 0.36330902694096084\n",
      "min: -0.3711081087972108\n",
      "max: 0.9329248125854105\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06270634308756191\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1857691004514663\n",
      "std: 0.15726815873594216\n",
      "min: 0.7740393198270334\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.211563814571216\n",
      "std: 0.167366920288674\n",
      "min: 0.8154559782521462\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.24999999999999997\n",
      "std: 0.17895142736543732\n",
      "min: 0.10568892954053766\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3378521050556513\n",
      "std: 0.3690784028702339\n",
      "min: -1.0393086302630352\n",
      "max: 0.9663616649140456\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.39150145708625467\n",
      "std: 0.3349012444400707\n",
      "min: -0.5302423323732633\n",
      "max: 0.9663616649140456\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05624734153287168\n",
      "min: 0.0766774754282185\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407351832222315\n",
      "std: 0.005001122525383297\n",
      "min: 1.3857512534144307\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078894634059047\n",
      "std: 0.005533630519473278\n",
      "min: 1.3857512534144307\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.17350383684021795\n",
      "min: 0.14046881367549308\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32380479661261324\n",
      "std: 0.29314559124521317\n",
      "min: -0.7909899406319494\n",
      "max: 0.9295463934345971\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49181206928696314\n",
      "std: 0.3635850676632945\n",
      "min: -0.3711081087972108\n",
      "max: 0.9295463934345971\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06283731242712251\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9998140831592611\n",
      "std: 0.371022206197589\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.048257394480739\n",
      "std: 0.3765243218405848\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.19520345275767548\n",
      "min: 0.06139433050355361\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2799854124289378\n",
      "std: 0.3884326531055321\n",
      "min: -1.0441664747471735\n",
      "max: 1.009643488838892\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4216289590313014\n",
      "std: 0.32781249090975745\n",
      "min: -0.5129390818988486\n",
      "max: 1.009643488838892\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05395914489570505\n",
      "min: 0.07546533690690091\n",
      "max: 0.3182313330194352\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4003528946085615\n",
      "std: 0.014090744068257888\n",
      "min: 1.360676305023632\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4017803018077604\n",
      "std: 0.013991810856479625\n",
      "min: 1.360676305023632\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.1735355174461931\n",
      "min: 0.13784145059587796\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3104916936469256\n",
      "std: 0.2948054242039794\n",
      "min: -0.7867394271150365\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5032922171283623\n",
      "std: 0.3622925061161609\n",
      "min: -0.3605064422548931\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06250431676790563\n",
      "min: 0.08264773603825515\n",
      "max: 0.2974890950341056\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0237946927910373\n",
      "std: 0.3382417485226483\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0695985230342904\n",
      "std: 0.3423140723771682\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.18882259930793827\n",
      "min: 0.05753863614276312\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2878887534337973\n",
      "std: 0.3686093485288363\n",
      "min: -1.0406485396783056\n",
      "max: 0.9663616649140456\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4197947455194501\n",
      "std: 0.32154354841872285\n",
      "min: -0.5056720428949861\n",
      "max: 0.9663616649140456\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05360654839845825\n",
      "min: 0.0766774754282185\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4034381272049625\n",
      "std: 0.008949518576071305\n",
      "min: 1.3798310498099915\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4044869274408711\n",
      "std: 0.009073265093131118\n",
      "min: 1.3824176065297522\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.24999999999999997\n",
      "std: 0.17351073200645076\n",
      "min: 0.14011698894159033\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3147457971915016\n",
      "std: 0.2939636616601377\n",
      "min: -0.7838914077761377\n",
      "max: 0.9419110036744671\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5008899687748227\n",
      "std: 0.3626985119218379\n",
      "min: -0.3609862441400947\n",
      "max: 0.9419110036744671\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264818461886537\n",
      "min: 0.08326892393427665\n",
      "max: 0.297340095733209\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0223301577201815\n",
      "std: 0.3562925544439312\n",
      "min: 0.1265687730872469\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.068753911258899\n",
      "std: 0.35663853597960454\n",
      "min: 0.14847232270936514\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.18676679379100716\n",
      "min: 0.058706747353306395\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2928200158581616\n",
      "std: 0.3707576864862071\n",
      "min: -0.9696905835108341\n",
      "max: 0.9663616649140456\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4170506120461827\n",
      "std: 0.32641608057377897\n",
      "min: -0.5144220913896679\n",
      "max: 0.9663616649140456\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.054028876426563115\n",
      "min: 0.0766774754282185\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4044204012499821\n",
      "std: 0.007293192125227159\n",
      "min: 1.383057071533761\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4053062212073222\n",
      "std: 0.007705791822952128\n",
      "min: 1.383057071533761\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.17350621422033496\n",
      "min: 0.14052945274970746\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3170792287498557\n",
      "std: 0.2936639439014798\n",
      "min: -0.7909899406319494\n",
      "max: 0.9329248125854105\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4991231609533102\n",
      "std: 0.36325590869456137\n",
      "min: -0.3711081087972108\n",
      "max: 0.9329248125854105\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06272308523412735\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9454575061747871\n",
      "std: 0.46399200092280934\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.999880026684365\n",
      "std: 0.46464953834584066\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.19963942586551692\n",
      "min: 0.036934374599274934\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32181755434409554\n",
      "std: 0.36869908997311257\n",
      "min: -1.0462977647854377\n",
      "max: 0.9100507245717211\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.38378415671839283\n",
      "std: 0.3316079626400629\n",
      "min: -0.5239590510647911\n",
      "max: 0.9100507245717211\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.054608824709656195\n",
      "min: 0.07580509197373064\n",
      "max: 0.31744221058397815\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.39199162384357\n",
      "std: 0.028246907454128348\n",
      "min: 1.3110262304266747\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.394312709298799\n",
      "std: 0.027703836251405878\n",
      "min: 1.3110262304266747\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.17363625489297338\n",
      "min: 0.13204058883429168\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32771849679143944\n",
      "std: 0.2945526580057011\n",
      "min: -0.791520171610398\n",
      "max: 0.9418077665846053\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4958755427256185\n",
      "std: 0.3669069244245154\n",
      "min: -0.37430542601041916\n",
      "max: 0.9418077665846053\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06293804596089031\n",
      "min: 0.08235666430901113\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1904032120524954\n",
      "std: 0.1493078517904957\n",
      "min: 0.7740393198270334\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.212460989600017\n",
      "std: 0.15971583933784203\n",
      "min: 0.8154559782521462\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.16630548608070012\n",
      "min: 0.09027777403900655\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3365092439481777\n",
      "std: 0.3707940385075143\n",
      "min: -1.0393086302630352\n",
      "max: 0.9663616649140456\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.39060987262573904\n",
      "std: 0.334482949973978\n",
      "min: -0.5302423323732633\n",
      "max: 0.9663616649140456\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05609737783946759\n",
      "min: 0.0766774754282185\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075133762984653\n",
      "std: 0.004704977611072777\n",
      "min: 1.385751253414431\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407997814362184\n",
      "std: 0.0052207427276526035\n",
      "min: 1.385751253414431\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.16160000322021362\n",
      "min: 0.12328501452690793\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32286538029896483\n",
      "std: 0.2932960063369459\n",
      "min: -0.7909899406319494\n",
      "max: 0.9295463934345971\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49145757521933275\n",
      "std: 0.36296343245040646\n",
      "min: -0.3711081087972108\n",
      "max: 0.9295463934345971\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06274779369989227\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0206970173688812\n",
      "std: 0.3614403810697916\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0610213001680557\n",
      "std: 0.36595060293906373\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.180400955350615\n",
      "min: 0.04622834601720121\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2855542230738556\n",
      "std: 0.38865739221671586\n",
      "min: -1.0441664747471735\n",
      "max: 1.009643488838892\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4181239380694882\n",
      "std: 0.3285529528770481\n",
      "min: -0.5235296623687883\n",
      "max: 1.009643488838892\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05411433259037995\n",
      "min: 0.07546533690690091\n",
      "max: 0.3182313330194352\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4010880490630604\n",
      "std: 0.013670858380481684\n",
      "min: 1.3606763050236321\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4023035859818702\n",
      "std: 0.01355981188335885\n",
      "min: 1.3606763050236321\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.16162771838742573\n",
      "min: 0.12047236693082813\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31082806995425855\n",
      "std: 0.29473999340520807\n",
      "min: -0.7867394271150365\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5019266352294833\n",
      "std: 0.3617996526918109\n",
      "min: -0.360506442254893\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.062448768362392146\n",
      "min: 0.08264773603825515\n",
      "max: 0.2974890950341056\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0420540891617087\n",
      "std: 0.32690840671236776\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0802328733853956\n",
      "std: 0.3303916701750517\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.17493835491310208\n",
      "min: 0.04492634349452921\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.29183101382614735\n",
      "std: 0.37122341761926203\n",
      "min: -1.0406485396783056\n",
      "max: 0.9663616649140456\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.416852438519137\n",
      "std: 0.3227648048046401\n",
      "min: -0.5196896951894002\n",
      "max: 0.9663616649140456\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05375534216291147\n",
      "min: 0.0766774754282185\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4038731972547542\n",
      "std: 0.00872175362797138\n",
      "min: 1.3798310498099913\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4047916800137439\n",
      "std: 0.008775380678751958\n",
      "min: 1.382417606529752\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.1616061962188575\n",
      "min: 0.12258499768762472\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31459773073428665\n",
      "std: 0.29409721606287575\n",
      "min: -0.783891407776138\n",
      "max: 0.9419110036744671\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49996009424200893\n",
      "std: 0.36217666407082716\n",
      "min: -0.36098624414009467\n",
      "max: 0.9419110036744671\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0625780388244528\n",
      "min: 0.08326892393427665\n",
      "max: 0.297340095733209\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0405102258787786\n",
      "std: 0.3433820833404961\n",
      "min: 0.1265687730872469\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.079262016700038\n",
      "std: 0.3436314168863258\n",
      "min: 0.14847232270936514\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.1732437509327321\n",
      "min: 0.047702548032173234\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2964950169960125\n",
      "std: 0.3734684610964996\n",
      "min: -0.9696905835108341\n",
      "max: 0.9663616649140456\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.41417429892240676\n",
      "std: 0.3273472337462818\n",
      "min: -0.5250693367388602\n",
      "max: 0.9663616649140456\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.054159075645842165\n",
      "min: 0.0766774754282185\n",
      "max: 0.31945911848756386\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.404788628908994\n",
      "std: 0.006981563518220184\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4055632233709519\n",
      "std: 0.00736384123377301\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.1616021908679637\n",
      "min: 0.12322549913439564\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3166834017529455\n",
      "std: 0.293817386370404\n",
      "min: -0.7909899406319494\n",
      "max: 0.9329248125854105\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49831694034055224\n",
      "std: 0.3626637322891078\n",
      "min: -0.3711081087972108\n",
      "max: 0.9329248125854105\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264395869564332\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9732177791670495\n",
      "std: 0.44939514187407614\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0181000495196548\n",
      "std: 0.4495575540685571\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.18425166240813853\n",
      "min: 0.03076942045461365\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3233496247099772\n",
      "std: 0.3707675682966124\n",
      "min: -1.046297764785438\n",
      "max: 0.9100507245717211\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3843632099230706\n",
      "std: 0.3319289402982292\n",
      "min: -0.528487400894024\n",
      "max: 0.9100507245717211\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05472944303140649\n",
      "min: 0.07580509197373064\n",
      "max: 0.31744221058397804\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3935757746809283\n",
      "std: 0.02741323254270491\n",
      "min: 1.3110262304266747\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3954755787776405\n",
      "std: 0.026927405875672314\n",
      "min: 1.3110262304266747\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.16171599885877225\n",
      "min: 0.11619557917851737\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3267753698148709\n",
      "std: 0.29446264325565036\n",
      "min: -0.791520171610398\n",
      "max: 0.9418077665846053\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4950522942470544\n",
      "std: 0.36602392458633226\n",
      "min: -0.37430542601041916\n",
      "max: 0.9418077665846053\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06284973083763484\n",
      "min: 0.08235666430901113\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1977718055010287\n",
      "std: 0.14013648985366703\n",
      "min: 0.7740393198270334\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2177496409257516\n",
      "std: 0.15017248666358232\n",
      "min: 0.8154559782521462\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.15532053838156537\n",
      "min: 0.08313808348406977\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34481401741774886\n",
      "std: 0.37216608765696335\n",
      "min: -1.0393086302630352\n",
      "max: 0.9803880741750408\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3952939617610514\n",
      "std: 0.3401650676339711\n",
      "min: -0.5302423323732633\n",
      "max: 0.9803880741750408\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057021214799454975\n",
      "min: 0.07160298582685132\n",
      "max: 0.3234874903109341\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078906505908038\n",
      "std: 0.004394883854826205\n",
      "min: 1.385751253414431\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082738482290298\n",
      "std: 0.004864632873454972\n",
      "min: 1.385751253414431\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.15121829791589858\n",
      "min: 0.11020092267877442\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.323382785981402\n",
      "std: 0.29344001755348353\n",
      "min: -0.7909899406319494\n",
      "max: 0.9295463934345971\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4921371575723174\n",
      "std: 0.3633484521936805\n",
      "min: -0.3711081087972108\n",
      "max: 0.9295463934345971\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06282941129350467\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.043203733430588\n",
      "std: 0.34937877494876113\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0779680136437\n",
      "std: 0.3532737274687107\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.16770384843306657\n",
      "min: 0.041203480605189045\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2993096102555235\n",
      "std: 0.38970004302819883\n",
      "min: -1.0441664747471735\n",
      "max: 1.009643488838892\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.42068087505430074\n",
      "std: 0.33492515165556797\n",
      "min: -0.5235296623687883\n",
      "max: 1.009643488838892\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05530256098392046\n",
      "min: 0.07116112433950786\n",
      "max: 0.32405280291066013\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4021075239913656\n",
      "std: 0.013109603845855028\n",
      "min: 1.3606763050236321\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.403088471320467\n",
      "std: 0.012973389377815113\n",
      "min: 1.3606763050236321\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.15124265831070297\n",
      "min: 0.10756281217160459\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.312396813875924\n",
      "std: 0.29475708746673707\n",
      "min: -0.7867394271150365\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5017621935450464\n",
      "std: 0.3622824177436228\n",
      "min: -0.360506442254893\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256035191186382\n",
      "min: 0.08264773603825515\n",
      "max: 0.2974890950341056\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0624549937038035\n",
      "std: 0.31531670209048257\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0954389242414926\n",
      "std: 0.31817572589583193\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.16295359305994658\n",
      "min: 0.03969392280289475\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30449342754243613\n",
      "std: 0.37405382870337195\n",
      "min: -1.0406485396783056\n",
      "max: 0.9963964395634071\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.41993427078109136\n",
      "std: 0.3297493280150079\n",
      "min: -0.5196896951894002\n",
      "max: 0.9963964395634071\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.054958298494046535\n",
      "min: 0.07114479798970588\n",
      "max: 0.32377126761983455\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4046266270625924\n",
      "std: 0.008289894884638955\n",
      "min: 1.3798310498099913\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405369280335127\n",
      "std: 0.008287269007840993\n",
      "min: 1.382417606529752\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.15122375450912898\n",
      "min: 0.1093666065957923\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3157921764889601\n",
      "std: 0.29424242453596045\n",
      "min: -0.783891407776138\n",
      "max: 0.9419110036744671\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5001208145629992\n",
      "std: 0.36264165512518404\n",
      "min: -0.36098624414009467\n",
      "max: 0.9419110036744671\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06267763139272725\n",
      "min: 0.08315323520473039\n",
      "max: 0.2973709460758802\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0604496011440168\n",
      "std: 0.33378444874016505\n",
      "min: 0.029367885362486208\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0940207245282425\n",
      "std: 0.3334409920950127\n",
      "min: 0.030474529199092004\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.16153310686726052\n",
      "min: 0.03607247136422158\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.30891620285418386\n",
      "std: 0.3762107799736545\n",
      "min: -1.0246855128865584\n",
      "max: 0.9955971047261697\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4172513184403235\n",
      "std: 0.33399070958806215\n",
      "min: -0.5250693367388602\n",
      "max: 0.9955971047261697\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05533763946035973\n",
      "min: 0.07095027915742903\n",
      "max: 0.3243917572117832\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4054530076377851\n",
      "std: 0.006610985394480358\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4060706929645335\n",
      "std: 0.006931858866358222\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.15122024566556955\n",
      "min: 0.10978775463698462\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31768465907578036\n",
      "std: 0.29397920594487037\n",
      "min: -0.7909899406319494\n",
      "max: 0.9329248125854105\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49860041085942985\n",
      "std: 0.3630775508416031\n",
      "min: -0.3711081087972108\n",
      "max: 0.9329248125854105\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06273662872042972\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0012609260388132\n",
      "std: 0.4322528294927507\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0395767942570076\n",
      "std: 0.43236562111042975\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.1710918061682626\n",
      "min: 0.028446366338657006\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33403731469142006\n",
      "std: 0.3727363977757429\n",
      "min: -1.046297764785438\n",
      "max: 0.9871106042339212\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3900582088635951\n",
      "std: 0.3384327571857594\n",
      "min: -0.528487400894024\n",
      "max: 0.9871106042339212\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.055897123761524496\n",
      "min: 0.07120819774983717\n",
      "max: 0.32369681102135534\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.395251782396038\n",
      "std: 0.02648577319292456\n",
      "min: 1.3110262304266747\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3967748764967172\n",
      "std: 0.02603956148688861\n",
      "min: 1.3110262304266747\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.15132089177039143\n",
      "min: 0.10286557183991636\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32728047092565493\n",
      "std: 0.2944303079272107\n",
      "min: -0.791520171610398\n",
      "max: 0.9418077665846053\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.495373164968002\n",
      "std: 0.36619903732634224\n",
      "min: -0.37430542601041916\n",
      "max: 0.9418077665846053\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0629353163288007\n",
      "min: 0.08235666430901113\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.195861948758639\n",
      "std: 0.13714127305968538\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2132991211929303\n",
      "std: 0.1474409815550569\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.14578356822785954\n",
      "min: 0.06362103680521326\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35325377171853717\n",
      "std: 0.3673181899862932\n",
      "min: -1.0393086302630352\n",
      "max: 0.9803880741750409\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3827287496224799\n",
      "std: 0.34369300139750714\n",
      "min: -0.5302423323732633\n",
      "max: 0.9803880741750409\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05725006692486216\n",
      "min: 0.07160298582685132\n",
      "max: 0.3234874903109341\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407789024831958\n",
      "std: 0.004357715593738314\n",
      "min: 1.385751253414431\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081979869985812\n",
      "std: 0.0047807125271570675\n",
      "min: 1.385751253414431\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.1421160593754732\n",
      "min: 0.09834324967411454\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32525795399205126\n",
      "std: 0.2930819611564194\n",
      "min: -0.7909899406319494\n",
      "max: 0.9295463934345971\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49056177791516054\n",
      "std: 0.36386526093709637\n",
      "min: -0.3711081087972108\n",
      "max: 0.9295463934345971\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.06293465427712495\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0542488052190893\n",
      "std: 0.33909639900548655\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.083929455561233\n",
      "std: 0.34301031165521345\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.15680504233879938\n",
      "min: 0.033930323552858785\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3123910440934432\n",
      "std: 0.38491308084877945\n",
      "min: -1.0441664747471735\n",
      "max: 1.009643488838892\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.40615568153150167\n",
      "std: 0.3400424174761938\n",
      "min: -0.5235296623687883\n",
      "max: 1.009643488838892\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05574655386356775\n",
      "min: 0.07116112433950787\n",
      "max: 0.3240528029106603\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4023892293630171\n",
      "std: 0.012839897384136574\n",
      "min: 1.3606763050236321\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4033105644846713\n",
      "std: 0.012708505433027463\n",
      "min: 1.3606763050236321\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.14213792638738376\n",
      "min: 0.09625458648621844\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3151597030741878\n",
      "std: 0.29432298975726\n",
      "min: -0.7867394271150365\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4994773901694211\n",
      "std: 0.3629322333408745\n",
      "min: -0.360506442254893\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06269153590372945\n",
      "min: 0.08264773603825515\n",
      "max: 0.2974890950341056\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0717435551213887\n",
      "std: 0.3040260478274845\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.099927789499865\n",
      "std: 0.3070978200959853\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.15260821368111557\n",
      "min: 0.03969392280289474\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31664832656850456\n",
      "std: 0.37036146540914083\n",
      "min: -1.0406485396783056\n",
      "max: 0.9963964395634075\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4057048611223068\n",
      "std: 0.3351201880997466\n",
      "min: -0.5196896951894002\n",
      "max: 0.9963964395634075\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999996\n",
      "std: 0.05540186001882725\n",
      "min: 0.07114479798970584\n",
      "max: 0.32377126761983455\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4047454596970124\n",
      "std: 0.008094659235484974\n",
      "min: 1.3798310498099913\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4054663770032778\n",
      "std: 0.008063554730387877\n",
      "min: 1.382417606529752\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.14212098529390513\n",
      "min: 0.09803790815163559\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.318262179906869\n",
      "std: 0.29390228082666925\n",
      "min: -0.783891407776138\n",
      "max: 0.9419110036744671\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49808212990580897\n",
      "std: 0.36326377612036115\n",
      "min: -0.36098624414009467\n",
      "max: 0.9419110036744671\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06279946882216911\n",
      "min: 0.08315323520473039\n",
      "max: 0.2973709460758802\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0698168619401731\n",
      "std: 0.3215880100113002\n",
      "min: 0.02936788536248615\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0985369007875194\n",
      "std: 0.32168248740034117\n",
      "min: 0.03047452919909194\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.15137804118617462\n",
      "min: 0.03607247136422158\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32082321462458957\n",
      "std: 0.3725206556842881\n",
      "min: -1.024685512886558\n",
      "max: 0.9955971047261697\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4031597818090745\n",
      "std: 0.33905164065015675\n",
      "min: -0.5250693367388602\n",
      "max: 0.9955971047261697\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05576231130794307\n",
      "min: 0.07095027915742905\n",
      "max: 0.3243917572117832\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4055175447895356\n",
      "std: 0.006493857399527007\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061269131266334\n",
      "std: 0.00678399739114583\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.14211785377664568\n",
      "min: 0.09822846385810119\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3199972378207063\n",
      "std: 0.29364875566755727\n",
      "min: -0.7909899406319494\n",
      "max: 0.9329248125854105\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4966473828156944\n",
      "std: 0.3636524246250528\n",
      "min: -0.3711081087972108\n",
      "max: 0.9329248125854105\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06285248094510214\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0168053395076109\n",
      "std: 0.41662118172918977\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0492905175101166\n",
      "std: 0.4172022502141292\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.1598239176917562\n",
      "min: 0.028340512297233274\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3443560859443182\n",
      "std: 0.3685711432291526\n",
      "min: -1.046297764785438\n",
      "max: 0.9871106042339215\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37814524076958156\n",
      "std: 0.3423153199276099\n",
      "min: -0.528487400894024\n",
      "max: 0.9871106042339215\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999996\n",
      "std: 0.056306876704006414\n",
      "min: 0.07120819774983717\n",
      "max: 0.3236968110213554\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3961589393525842\n",
      "std: 0.0256670370223617\n",
      "min: 1.3110262304266747\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3975084581713062\n",
      "std: 0.025293230030445032\n",
      "min: 1.3110262304266747\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.1422079844652427\n",
      "min: 0.09248580802024571\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32910646780247854\n",
      "std: 0.2939317026631314\n",
      "min: -0.791520171610398\n",
      "max: 0.9418077665846053\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4934768549694921\n",
      "std: 0.36655191291192674\n",
      "min: -0.37430542601041916\n",
      "max: 0.9418077665846053\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0630415276449746\n",
      "min: 0.08235666430901113\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1973324341058826\n",
      "std: 0.13027951681792846\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2134321774315346\n",
      "std: 0.14042983500275633\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.1373727640104741\n",
      "min: 0.06362103680521326\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3513858951567145\n",
      "std: 0.36612358986337534\n",
      "min: -1.0393086302630352\n",
      "max: 0.9803880741750409\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3810872139622164\n",
      "std: 0.34404345520861007\n",
      "min: -0.5302423323732633\n",
      "max: 0.9803880741750409\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05739372026775387\n",
      "min: 0.07160298582685132\n",
      "max: 0.3234874903109341\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077129506773038\n",
      "std: 0.004324647481733206\n",
      "min: 1.385751253414431\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408066414640206\n",
      "std: 0.004766314177151004\n",
      "min: 1.385751253414431\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.13408459168424153\n",
      "min: 0.08938546441416478\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3248773107194718\n",
      "std: 0.2926903161192213\n",
      "min: -0.7909899406319494\n",
      "max: 0.9295463934345971\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.490059550715188\n",
      "std: 0.36366752402548524\n",
      "min: -0.3711081087972108\n",
      "max: 0.9295463934345971\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.06292604201132196\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0684464871580779\n",
      "std: 0.3233331884268305\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.094668329219953\n",
      "std: 0.3274177449021428\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.14725537939787184\n",
      "min: 0.033930323552858785\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3140074339373814\n",
      "std: 0.38258918132218794\n",
      "min: -1.0441664747471735\n",
      "max: 1.009643488838892\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4030740481116466\n",
      "std: 0.340966612083046\n",
      "min: -0.5235296623687883\n",
      "max: 1.009643488838892\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05604524730497601\n",
      "min: 0.07116112433950787\n",
      "max: 0.3240528029106603\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4027400258393325\n",
      "std: 0.012384326537129772\n",
      "min: 1.3606763050236321\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.403528691660045\n",
      "std: 0.012291905465516404\n",
      "min: 1.3606763050236321\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.1341042718001182\n",
      "min: 0.08797262077692934\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3154781456710864\n",
      "std: 0.29380999891857945\n",
      "min: -0.7867394271150365\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4983901802175997\n",
      "std: 0.36280646008434153\n",
      "min: -0.360506442254893\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06270148533498764\n",
      "min: 0.08264773603825515\n",
      "max: 0.2974890950341056\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0841598208421552\n",
      "std: 0.29095666318679564\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.109130473916918\n",
      "std: 0.2940554754118304\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.1435173657520412\n",
      "min: 0.03969392280289474\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31753753030978227\n",
      "std: 0.3692367258802963\n",
      "min: -1.0406485396783056\n",
      "max: 0.9963964395634075\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.40280112542908125\n",
      "std: 0.3363238937990179\n",
      "min: -0.5196896951894002\n",
      "max: 0.9963964395634075\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05570588187075621\n",
      "min: 0.07114479798970584\n",
      "max: 0.32377126761983455\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4049049930086042\n",
      "std: 0.007828136112750083\n",
      "min: 1.3798310498099913\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4055270714017853\n",
      "std: 0.007823055386487785\n",
      "min: 1.382417606529752\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.13408904127506213\n",
      "min: 0.08941364404816839\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3183435532834931\n",
      "std: 0.2934840732617876\n",
      "min: -0.783891407776138\n",
      "max: 0.9419110036744671\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49719125732434305\n",
      "std: 0.3631278653313352\n",
      "min: -0.36098624414009467\n",
      "max: 0.9419110036744671\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06280243977924797\n",
      "min: 0.08315323520473039\n",
      "max: 0.2973709460758802\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0822026289760718\n",
      "std: 0.30831755697587726\n",
      "min: 0.02936788536248615\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1076732148579607\n",
      "std: 0.3086133610780753\n",
      "min: 0.03047452919909194\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.14244277757102822\n",
      "min: 0.03607247136422158\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3215449255765715\n",
      "std: 0.37141322644121816\n",
      "min: -1.024685512886558\n",
      "max: 0.9955971047261697\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.40036235062171827\n",
      "std: 0.34005733327857895\n",
      "min: -0.5250693367388602\n",
      "max: 0.9955971047261697\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05605282383422025\n",
      "min: 0.07095027915742905\n",
      "max: 0.3243917572117832\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4056117626156999\n",
      "std: 0.006346018748205771\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061359904525481\n",
      "std: 0.00665820786039226\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.13408624196436134\n",
      "min: 0.08944592959154317\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3199343655058946\n",
      "std: 0.29324026198138736\n",
      "min: -0.7909899406319494\n",
      "max: 0.9329248125854105\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49583457786446805\n",
      "std: 0.36347188033890254\n",
      "min: -0.3711081087972108\n",
      "max: 0.9329248125854105\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06284965529789527\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0321125730641103\n",
      "std: 0.4025862452958594\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0608108503544147\n",
      "std: 0.40345045860754286\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.15000618095516027\n",
      "min: 0.024747470962023538\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34380207260433643\n",
      "std: 0.3674659870220775\n",
      "min: -1.046297764785438\n",
      "max: 0.9871106042339215\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37709736786197745\n",
      "std: 0.3430147640183859\n",
      "min: -0.528487400894024\n",
      "max: 0.9871106042339215\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05658131405679065\n",
      "min: 0.07120819774983717\n",
      "max: 0.3236968110213554\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.396880916442296\n",
      "std: 0.02510335023410265\n",
      "min: 1.3091517863633093\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3980268319079034\n",
      "std: 0.024786495879701297\n",
      "min: 1.3091517863633093\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.13416795871947645\n",
      "min: 0.08338222896906121\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32861618939213155\n",
      "std: 0.29342581191550954\n",
      "min: -0.791520171610398\n",
      "max: 0.9418077665846053\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4927137338645014\n",
      "std: 0.36618642056872447\n",
      "min: -0.37430542601041916\n",
      "max: 0.9418077665846053\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06303014179730014\n",
      "min: 0.08235666430901113\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1999715101906454\n",
      "std: 0.12714295241342474\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2140432009987183\n",
      "std: 0.1371258863747304\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.12993926563171831\n",
      "min: 0.05473353682697026\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34752331501165085\n",
      "std: 0.3643690292636601\n",
      "min: -1.0393086302630352\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3851045998518156\n",
      "std: 0.34388799187555785\n",
      "min: -0.5302423323732633\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0572821779129634\n",
      "min: 0.0716029858268513\n",
      "max: 0.3234874903109341\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407693843676325\n",
      "std: 0.004185941178886718\n",
      "min: 1.385751253414431\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079778940736696\n",
      "std: 0.004619101030399401\n",
      "min: 1.385751253414431\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.126951769540286\n",
      "min: 0.08210735473147426\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3239123083755548\n",
      "std: 0.29245882229311215\n",
      "min: -0.7909899406319494\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4908979642232724\n",
      "std: 0.3633032106258385\n",
      "min: -0.3711081087972108\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06289131485163309\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.080897271076852\n",
      "std: 0.3133900829817476\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.103555280674754\n",
      "std: 0.3173085836350668\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.13889218441496348\n",
      "min: 0.03393032355285879\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31305050643702936\n",
      "std: 0.3796207508155377\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4058271683507704\n",
      "std: 0.34097406034082506\n",
      "min: -0.5235296623687883\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056049403077852125\n",
      "min: 0.07116112433950786\n",
      "max: 0.3240528029106602\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4030698487373074\n",
      "std: 0.012073088048180521\n",
      "min: 1.3606763050236321\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4037285764997096\n",
      "std: 0.011976840061146526\n",
      "min: 1.3606763050236321\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.12696970377005684\n",
      "min: 0.08011378067343829\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3151211629723202\n",
      "std: 0.29346188522234595\n",
      "min: -0.7867394271150365\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49871927617577244\n",
      "std: 0.36248817713538367\n",
      "min: -0.360506442254893\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06268302167256164\n",
      "min: 0.08264773603825515\n",
      "max: 0.2974890950341056\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0953792184272748\n",
      "std: 0.2814619218958998\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1169457049617888\n",
      "std: 0.28446106677182154\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.1355200429650201\n",
      "min: 0.03298208696718896\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3160061983387018\n",
      "std: 0.3672849100893468\n",
      "min: -1.0406485396783056\n",
      "max: 1.0586274842736008\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.40571440852016477\n",
      "std: 0.33661571959247477\n",
      "min: -0.5196896951894002\n",
      "max: 1.0586274842736008\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05571524253753953\n",
      "min: 0.07114479798970585\n",
      "max: 0.3237712676198345\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4050610518105136\n",
      "std: 0.007695161067625451\n",
      "min: 1.379298376755652\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405580421491942\n",
      "std: 0.007662479793108538\n",
      "min: 1.382417606529752\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615388\n",
      "std: 0.12695587362414507\n",
      "min: 0.08148236182410652\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31778864855931144\n",
      "std: 0.29320955782550734\n",
      "min: -0.783891407776138\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4976764856260792\n",
      "std: 0.36280271738380704\n",
      "min: -0.36098624414009467\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06277789768287646\n",
      "min: 0.08315323520473039\n",
      "max: 0.29737094607588016\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0933686041775823\n",
      "std: 0.2987929692731875\n",
      "min: 0.02936788536248615\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1154033575522362\n",
      "std: 0.29912687619991085\n",
      "min: 0.03047452919909194\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.13457050936261164\n",
      "min: 0.034403236017276115\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3198716017941249\n",
      "std: 0.36947437401433314\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.40335694284421814\n",
      "std: 0.34018115094485774\n",
      "min: -0.5250693367388602\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05605266824272499\n",
      "min: 0.07095027915742903\n",
      "max: 0.3243917572117832\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405717050540514\n",
      "std: 0.006177293640916303\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061486720660634\n",
      "std: 0.0064739679820449226\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.1269533046870205\n",
      "min: 0.08179108856539738\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3192527075942182\n",
      "std: 0.2929856765553312\n",
      "min: -0.7909899406319494\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49639717676347317\n",
      "std: 0.3631131132459662\n",
      "min: -0.3711081087972108\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0628201765637117\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0473925987137664\n",
      "std: 0.38917507941306645\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0721087617838119\n",
      "std: 0.39017995244868325\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.1413947619017349\n",
      "min: 0.023115433230658088\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3409593698706362\n",
      "std: 0.36568323351966187\n",
      "min: -1.046297764785438\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3817125929265431\n",
      "std: 0.3431730581507752\n",
      "min: -0.528487400894024\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05656937497751352\n",
      "min: 0.07120819774983717\n",
      "max: 0.32369681102135534\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3975402671024468\n",
      "std: 0.02463648555715336\n",
      "min: 1.3091517863633093\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3984992192499723\n",
      "std: 0.02434908826394336\n",
      "min: 1.3091517863633093\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.12702804377426616\n",
      "min: 0.07620708190602384\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32753506619203604\n",
      "std: 0.2931053359086392\n",
      "min: -0.791520171610398\n",
      "max: 0.9443537500238719\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4933721206590132\n",
      "std: 0.36567007203224033\n",
      "min: -0.37430542601041916\n",
      "max: 0.9443537500238719\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06299294821177913\n",
      "min: 0.08235666430901113\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1056221976763916\n",
      "std: 0.2747788494505487\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1246336027388548\n",
      "std: 0.277579112955338\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.1284190164667233\n",
      "min: 0.026478447798692538\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31674149430127135\n",
      "std: 0.36600846102434476\n",
      "min: -1.0406485396783056\n",
      "max: 1.0586274842736008\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4019511631030385\n",
      "std: 0.33637418645550043\n",
      "min: -0.5196896951894002\n",
      "max: 1.0586274842736008\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05568349154250771\n",
      "min: 0.07114479798970585\n",
      "max: 0.3237712676198345\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4052899422155847\n",
      "std: 0.007558643267071186\n",
      "min: 1.379298376755652\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405753126056098\n",
      "std: 0.007521474277238443\n",
      "min: 1.382417606529752\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12058123686584529\n",
      "min: 0.0752794737957633\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3177022703321246\n",
      "std: 0.2931238241159732\n",
      "min: -0.783891407776138\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4968452661838484\n",
      "std: 0.36259092903427703\n",
      "min: -0.36098624414009467\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06275509097686963\n",
      "min: 0.08315323520473039\n",
      "max: 0.29737094607588016\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.092227326991291\n",
      "std: 0.3057918759596843\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1122022278129127\n",
      "std: 0.3094872171983005\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.13148417257233316\n",
      "min: 0.027419760266060942\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3142237640598084\n",
      "std: 0.3774985555348187\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4019627517583778\n",
      "std: 0.3405062962227979\n",
      "min: -0.5235296623687883\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056009114809026\n",
      "min: 0.07116112433950786\n",
      "max: 0.3240528029106602\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.403445370777196\n",
      "std: 0.011781546474950192\n",
      "min: 1.3606763050236321\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.404026800869566\n",
      "std: 0.01169922217835634\n",
      "min: 1.3606763050236321\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12059388646440719\n",
      "min: 0.07397080421412211\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31519490929224325\n",
      "std: 0.2933147799720735\n",
      "min: -0.7867394271150365\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4977605437286897\n",
      "std: 0.3622821785602434\n",
      "min: -0.360506442254893\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266474892719191\n",
      "min: 0.08264773603825515\n",
      "max: 0.2974890950341056\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2036019684170436\n",
      "std: 0.12194006283195523\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2161585681844094\n",
      "std: 0.13191118491567025\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12330161709519544\n",
      "min: 0.05473353682697026\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34615663908470407\n",
      "std: 0.36305416010551006\n",
      "min: -1.0393086302630352\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.38242878605919295\n",
      "std: 0.34301414789484097\n",
      "min: -0.5302423323732633\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05713963639982735\n",
      "min: 0.0716029858268513\n",
      "max: 0.3234874903109341\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077696123028558\n",
      "std: 0.004061702803077881\n",
      "min: 1.385751253414431\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408022636677287\n",
      "std: 0.00449352222092036\n",
      "min: 1.385751253414431\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12057743579931009\n",
      "min: 0.07589194138160596\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32345960879688285\n",
      "std: 0.29239996302003246\n",
      "min: -0.7909899406319494\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4903909550108293\n",
      "std: 0.3630389799888991\n",
      "min: -0.3711081087972108\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06285910707322134\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1037030541728647\n",
      "std: 0.2914767502404046\n",
      "min: 0.02936788536248615\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1231472772744584\n",
      "std: 0.2917889893856169\n",
      "min: 0.03047452919909194\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12756624741726644\n",
      "min: 0.026715183547143192\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32042469595144374\n",
      "std: 0.36821216954478136\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3996810106494719\n",
      "std: 0.3397816215829038\n",
      "min: -0.5250693367388602\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056009305950931176\n",
      "min: 0.07095027915742903\n",
      "max: 0.3243917572117832\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4058957435948105\n",
      "std: 0.006086922578000261\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4062797400581328\n",
      "std: 0.006374083930888862\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12057888238349852\n",
      "min: 0.0754450611713259\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31905752767480866\n",
      "std: 0.2929113932477859\n",
      "min: -0.7909899406319494\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4956222217489859\n",
      "std: 0.3628676069378732\n",
      "min: -0.3711081087972108\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06279289352978265\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.060752334788989\n",
      "std: 0.37999278317991564\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.082491078713544\n",
      "std: 0.38100300238459844\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.13378056398255883\n",
      "min: 0.017954246835429514\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34048188453358025\n",
      "std: 0.3644548226462404\n",
      "min: -1.046297764785438\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37943624166024364\n",
      "std: 0.34243943711159125\n",
      "min: -0.528487400894024\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05651135019539292\n",
      "min: 0.07120819774983717\n",
      "max: 0.32369681102135534\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3982343295405757\n",
      "std: 0.024136210650821322\n",
      "min: 1.3091517863633093\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3990683406478917\n",
      "std: 0.023881429658493037\n",
      "min: 1.3091517863633093\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12064759290180928\n",
      "min: 0.07060143865534614\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3269678858384466\n",
      "std: 0.29296806858905927\n",
      "min: -0.791520171610398\n",
      "max: 0.9443537500238719\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49269192786782523\n",
      "std: 0.36528038241480604\n",
      "min: -0.37430542601041916\n",
      "max: 0.9443537500238719\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0629578690081011\n",
      "min: 0.08235666430901113\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1152079841775198\n",
      "std: 0.26737838824009624\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1323003534152447\n",
      "std: 0.27004325970178006\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.12206577385010225\n",
      "min: 0.026227873314977022\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3154929131858479\n",
      "std: 0.36790939770158343\n",
      "min: -1.0406485396783056\n",
      "max: 1.0586274842736008\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.40234481464533484\n",
      "std: 0.3363076149124265\n",
      "min: -0.5196896951894002\n",
      "max: 1.0586274842736008\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.055666271367026926\n",
      "min: 0.07114479798970585\n",
      "max: 0.3237712676198345\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4054581791032685\n",
      "std: 0.007348558883603237\n",
      "min: 1.379298376755652\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4058902362213346\n",
      "std: 0.0073183009126644456\n",
      "min: 1.382417606529752\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.11485111505958731\n",
      "min: 0.07023472841536149\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31723495369097177\n",
      "std: 0.29324097878774047\n",
      "min: -0.783891407776138\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4964960106433458\n",
      "std: 0.3622778456009029\n",
      "min: -0.36098624414009467\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06270135469386084\n",
      "min: 0.08315323520473039\n",
      "max: 0.29737094607588016\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1027282183298774\n",
      "std: 0.29670703178131175\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1206768690694429\n",
      "std: 0.3002999255677482\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.12487047515439215\n",
      "min: 0.02741976026606093\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3132969349277248\n",
      "std: 0.3785100558411359\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4022419799263476\n",
      "std: 0.34020790333219403\n",
      "min: -0.5235296623687883\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05597993714035611\n",
      "min: 0.07116112433950786\n",
      "max: 0.3240528029106602\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4037286264260476\n",
      "std: 0.011426028279359741\n",
      "min: 1.3606763050236321\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4042634144772659\n",
      "std: 0.011357425019009918\n",
      "min: 1.3606763050236321\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.11486274278900321\n",
      "min: 0.06892650588185832\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31486652125298586\n",
      "std: 0.2933799021996776\n",
      "min: -0.7867394271150365\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49730805210276524\n",
      "std: 0.36197429609317516\n",
      "min: -0.360506442254893\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261522258221927\n",
      "min: 0.08264773603825515\n",
      "max: 0.2974890950341056\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1137327492611302\n",
      "std: 0.28136618794680884\n",
      "min: 0.02936788536248615\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.131211514049171\n",
      "std: 0.28175742881617566\n",
      "min: 0.03047452919909194\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.1212836570030641\n",
      "min: 0.026715183547143175\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3189750603273388\n",
      "std: 0.3700997852743495\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4001939728037102\n",
      "std: 0.339576453107711\n",
      "min: -0.5250693367388602\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05597866536496199\n",
      "min: 0.07095027915742903\n",
      "max: 0.3243917572117832\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4060306133452591\n",
      "std: 0.005930365310843438\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4063904235768137\n",
      "std: 0.006215602936595146\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.1148489492327582\n",
      "min: 0.07030017777976881\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3184869002405436\n",
      "std: 0.29304561723816885\n",
      "min: -0.7909899406319494\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4953391734742285\n",
      "std: 0.36252507835442255\n",
      "min: -0.3711081087972108\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06273501581660135\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2063605038307645\n",
      "std: 0.11897493199435479\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2179154743874465\n",
      "std: 0.12847261734113635\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.11735329742864557\n",
      "min: 0.04964114403860137\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34312785255448486\n",
      "std: 0.36504112090439866\n",
      "min: -1.0393086302630352\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3837188676469941\n",
      "std: 0.3425060704868736\n",
      "min: -0.5302423323732633\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05702746263151925\n",
      "min: 0.0716029858268513\n",
      "max: 0.3234874903109341\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077737935514665\n",
      "std: 0.0040261580824680525\n",
      "min: 1.385751253414431\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080184093754555\n",
      "std: 0.004446023670958168\n",
      "min: 1.385751253414431\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.11484761105207085\n",
      "min: 0.07022828219446671\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32267248680711264\n",
      "std: 0.2925480862644349\n",
      "min: -0.7909899406319494\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4903277015512716\n",
      "std: 0.36268568131802037\n",
      "min: -0.3711081087972108\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06279756798503114\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0719392263524368\n",
      "std: 0.3725719552797353\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0914924966616801\n",
      "std: 0.3735511461682475\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.12700013474911007\n",
      "min: 0.015757041134209386\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3380755399647577\n",
      "std: 0.3663933356185122\n",
      "min: -1.046297764785438\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.381068353282639\n",
      "std: 0.3421093335972262\n",
      "min: -0.528487400894024\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056462798882362705\n",
      "min: 0.07120819774983717\n",
      "max: 0.32369681102135534\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3988290323003232\n",
      "std: 0.023475418382418536\n",
      "min: 1.3091517863633093\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3995764120464695\n",
      "std: 0.023262463187757553\n",
      "min: 1.3091517863633093\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.11491233507918074\n",
      "min: 0.06617155078782395\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3260645235258008\n",
      "std: 0.29305826828053577\n",
      "min: -0.791520171610398\n",
      "max: 0.9443537500238719\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49248525042235086\n",
      "std: 0.3648151414957578\n",
      "min: -0.37430542601041916\n",
      "max: 0.9443537500238719\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06289346413134934\n",
      "min: 0.08235666430901113\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.124836866588275\n",
      "std: 0.2607258193888906\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1402854082370841\n",
      "std: 0.2632202368324842\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.1163471071670282\n",
      "min: 0.023171579463964566\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31749902135152364\n",
      "std: 0.3655120506140045\n",
      "min: -1.0406485396783056\n",
      "max: 1.0586274842736008\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4009462099301453\n",
      "std: 0.3366672354193364\n",
      "min: -0.5196896951894002\n",
      "max: 1.0586274842736008\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05573249578704777\n",
      "min: 0.07114479798970585\n",
      "max: 0.3237712676198345\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4057281242347355\n",
      "std: 0.007151692317951818\n",
      "min: 1.379298376755652\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061182119650915\n",
      "std: 0.007110194831867415\n",
      "min: 1.382417606529752\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.10967249616894811\n",
      "min: 0.06531288709002835\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3177600446546957\n",
      "std: 0.29315672678203664\n",
      "min: -0.783891407776138\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49617004454042746\n",
      "std: 0.3624111420386763\n",
      "min: -0.36098624414009467\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06273549833660806\n",
      "min: 0.08315323520473039\n",
      "max: 0.29737094607588016\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1130019420602433\n",
      "std: 0.2899977982655302\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.129222879074529\n",
      "std: 0.2933963880739951\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.11893582680332188\n",
      "min: 0.023517495753197924\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31562208048436247\n",
      "std: 0.3755166652458029\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4007474552928444\n",
      "std: 0.34038843455445966\n",
      "min: -0.5235296623687883\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056039197757535505\n",
      "min: 0.07116112433950786\n",
      "max: 0.3240528029106602\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4040970464981521\n",
      "std: 0.01113235205938064\n",
      "min: 1.3606763050236321\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4045771931566848\n",
      "std: 0.011064773712853799\n",
      "min: 1.3606763050236321\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.10968325853207331\n",
      "min: 0.06424217992044708\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31551775017837436\n",
      "std: 0.2932544969490696\n",
      "min: -0.7867394271150365\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4968864975080599\n",
      "std: 0.36211327333568294\n",
      "min: -0.360506442254893\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626532433590531\n",
      "min: 0.08264773603825515\n",
      "max: 0.2974890950341056\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1229960326666169\n",
      "std: 0.27695757326730663\n",
      "min: 0.019312793458887326\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1388332385496842\n",
      "std: 0.27712542100515963\n",
      "min: 0.019312793458887326\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.11564292366491467\n",
      "min: 0.020662304654860537\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3208658129681897\n",
      "std: 0.36762689088893724\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.398831086691613\n",
      "std: 0.3398047841814701\n",
      "min: -0.5250693367388602\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056034424631986934\n",
      "min: 0.07095027915742903\n",
      "max: 0.3243917572117832\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4062646640265386\n",
      "std: 0.005799712964362723\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065891327466908\n",
      "std: 0.00606220468850672\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.10967049829603207\n",
      "min: 0.06551967261668809\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3189333049739945\n",
      "std: 0.29296585008627\n",
      "min: -0.7909899406319494\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49505437900176125\n",
      "std: 0.36263483027136145\n",
      "min: -0.3711081087972108\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0627659624251474\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2106234234851423\n",
      "std: 0.11603035629403743\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2212325006504832\n",
      "std: 0.1250406226079052\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.11198475095012063\n",
      "min: 0.04759232420676906\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.343527208964752\n",
      "std: 0.36255030071816524\n",
      "min: -1.0393086302630352\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.38316164746790826\n",
      "std: 0.3424167959865292\n",
      "min: -0.5302423323732633\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057009113693317674\n",
      "min: 0.0716029858268513\n",
      "max: 0.3234874903109341\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079180741295476\n",
      "std: 0.0038964469985978494\n",
      "min: 1.385751253414431\n",
      "max: 1.4139771965086936\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081390185804963\n",
      "std: 0.004292723590179478\n",
      "min: 1.385751253414431\n",
      "max: 1.4139771965086936\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.10966924050001106\n",
      "min: 0.06588290837690779\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3229039737764991\n",
      "std: 0.2924736506720058\n",
      "min: -0.7909899406319494\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4902598640841749\n",
      "std: 0.36278053551787554\n",
      "min: -0.3711081087972108\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0628239854963974\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0838460030121724\n",
      "std: 0.36432049737454575\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1014631239778574\n",
      "std: 0.36530844038657884\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.12091235984661657\n",
      "min: 0.015219574377605705\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33910484420071596\n",
      "std: 0.36395148212191325\n",
      "min: -1.046297764785438\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.380774583579914\n",
      "std: 0.34217450348656914\n",
      "min: -0.528487400894024\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05650584797835188\n",
      "min: 0.07120819774983717\n",
      "max: 0.32369681102135534\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3995213409370102\n",
      "std: 0.022838849576907332\n",
      "min: 1.3091517863633093\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4001779876113625\n",
      "std: 0.02265756002165427\n",
      "min: 1.3091517863633093\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.10972923289881104\n",
      "min: 0.061140261914922105\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3262074379774595\n",
      "std: 0.2929269091370589\n",
      "min: -0.791520171610398\n",
      "max: 0.9443537500238719\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49228832130667544\n",
      "std: 0.36481135752799626\n",
      "min: -0.37430542601041916\n",
      "max: 0.9443537500238719\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06291837381815546\n",
      "min: 0.08235666430901113\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1305373326431396\n",
      "std: 0.2564752120170327\n",
      "min: 0.057924141187968514\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.144386643854974\n",
      "std: 0.2588743155167232\n",
      "min: 0.057924141187968514\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.11118543081604296\n",
      "min: 0.020081627700605197\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3211331644158566\n",
      "std: 0.3651696200337159\n",
      "min: -1.0406485396783056\n",
      "max: 1.0586274842736008\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3984010865178666\n",
      "std: 0.3375337454317016\n",
      "min: -0.5229623659896986\n",
      "max: 1.0586274842736008\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.055899562274164816\n",
      "min: 0.07114479798970585\n",
      "max: 0.3237712676198345\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4059069462165543\n",
      "std: 0.007059585883978277\n",
      "min: 1.379298376755652\n",
      "max: 1.4139805769802904\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4062685928138723\n",
      "std: 0.007013464584526055\n",
      "min: 1.382417606529752\n",
      "max: 1.4139805769802904\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.10496904157857223\n",
      "min: 0.06111016411126276\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3180328599062585\n",
      "std: 0.2930789193621756\n",
      "min: -0.783891407776138\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49617741493395895\n",
      "std: 0.3624448416882734\n",
      "min: -0.36098624414009467\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06274912319180441\n",
      "min: 0.08315323520473039\n",
      "max: 0.29737094607588016\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.119551180245686\n",
      "std: 0.2841725657805883\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.134093568683933\n",
      "std: 0.2875015800531937\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.11358201735446864\n",
      "min: 0.02281705614202005\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31950436948230937\n",
      "std: 0.37461516494531605\n",
      "min: -1.0441664747471735\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3981385322944886\n",
      "std: 0.34107815461718965\n",
      "min: -0.5246927125975386\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05619826717171171\n",
      "min: 0.07116112433950786\n",
      "max: 0.3240528029106602\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4043587228544703\n",
      "std: 0.01099749375316978\n",
      "min: 1.3589376881487736\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4048001844185356\n",
      "std: 0.010931918121312367\n",
      "min: 1.3589376881487736\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.10497908029395536\n",
      "min: 0.05966141372783177\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3158958665612272\n",
      "std: 0.293140003702409\n",
      "min: -0.7867394271150365\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4968178256633754\n",
      "std: 0.3621489253981961\n",
      "min: -0.360506442254893\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06267002685372206\n",
      "min: 0.08264773603825515\n",
      "max: 0.2974890950341056\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.128900026795452\n",
      "std: 0.2709782450709404\n",
      "min: 0.019312793458887294\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.143104257395409\n",
      "std: 0.27124863331037113\n",
      "min: 0.019312793458887294\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.11053600120971575\n",
      "min: 0.02066230465486054\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3243737788225684\n",
      "std: 0.3672408903276578\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3963525798813873\n",
      "std: 0.3405502181951568\n",
      "min: -0.5260523152021972\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056191440205477054\n",
      "min: 0.07095027915742903\n",
      "max: 0.3243917572117832\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064195779473634\n",
      "std: 0.005738975992024735\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139800835404732\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067204653826308\n",
      "std: 0.005991291482187859\n",
      "min: 1.3830570715337611\n",
      "max: 1.4139800835404732\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.10496717976594529\n",
      "min: 0.061294121101799326\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31913759404389513\n",
      "std: 0.2928939603907054\n",
      "min: -0.7909899406319494\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4951000584106972\n",
      "std: 0.36264828767343565\n",
      "min: -0.3711081087972108\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06277680557178711\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2122237860506726\n",
      "std: 0.11357319680373577\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2217727128305405\n",
      "std: 0.12242934956205948\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1176470588235294\n",
      "std: 0.10711969797875424\n",
      "min: 0.041892149035940525\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3456937007851436\n",
      "std: 0.3620345980306534\n",
      "min: -1.0393086302630352\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.38137680246972705\n",
      "std: 0.3428313427221597\n",
      "min: -0.5302423323732633\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05709571591613874\n",
      "min: 0.07160298582685129\n",
      "max: 0.3234874903109342\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080194725911248\n",
      "std: 0.003814734172221973\n",
      "min: 1.385751253414431\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082253031251697\n",
      "std: 0.004202283738280326\n",
      "min: 1.385751253414431\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.10496598555494116\n",
      "min: 0.06153832301051043\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3229143799788239\n",
      "std: 0.29241159481969625\n",
      "min: -0.7909899406319494\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49049981712203683\n",
      "std: 0.3627832102377046\n",
      "min: -0.3711081087972108\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06283073207777604\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0933123904634945\n",
      "std: 0.3534957340981665\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1090047014973625\n",
      "std: 0.35467418213754076\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.11541355265212909\n",
      "min: 0.01521957437760571\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34182580081932673\n",
      "std: 0.3635385206463726\n",
      "min: -1.046297764785438\n",
      "max: 1.0542347607461076\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3792464235821062\n",
      "std: 0.34270195398825526\n",
      "min: -0.528487400894024\n",
      "max: 1.0542347607461076\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056649174416978136\n",
      "min: 0.07120819774983718\n",
      "max: 0.32369681102135534\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4000694587083262\n",
      "std: 0.022350492794815546\n",
      "min: 1.3091517863633093\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4006585982140654\n",
      "std: 0.022195047508390294\n",
      "min: 1.3091517863633093\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.1050219213015842\n",
      "min: 0.0573228543544339\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3261245406382213\n",
      "std: 0.2928213353537802\n",
      "min: -0.791520171610398\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4924231516578622\n",
      "std: 0.3647232333244907\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06292331049292832\n",
      "min: 0.08235666430901113\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1341856520638218\n",
      "std: 0.2489986801304884\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1473630594593875\n",
      "std: 0.251613357159496\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10648330732519647\n",
      "min: 0.020081627700605197\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32324862458892506\n",
      "std: 0.3644667001287251\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.393450300828466\n",
      "std: 0.3386438364219473\n",
      "min: -0.5272362232139789\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05598211108875399\n",
      "min: 0.07114479798970585\n",
      "max: 0.32377126761983455\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4059922509910525\n",
      "std: 0.006854781350342082\n",
      "min: 1.3792983767556517\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4063220520116204\n",
      "std: 0.006816911753720455\n",
      "min: 1.3824176065297522\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10067759313934115\n",
      "min: 0.05800470566174643\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3181091735202883\n",
      "std: 0.2930082730716811\n",
      "min: -0.7838914077761377\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49564113673804583\n",
      "std: 0.3623476156317744\n",
      "min: -0.3609862441400947\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06273967343567317\n",
      "min: 0.08315323520473039\n",
      "max: 0.2973709460758802\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1237769512033906\n",
      "std: 0.2760986329940047\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1375824599893531\n",
      "std: 0.27963001832189804\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10871550712864182\n",
      "min: 0.022817056142020065\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32186785382973837\n",
      "std: 0.37341221069408476\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3931139874272575\n",
      "std: 0.3420535713103706\n",
      "min: -0.5293750311605184\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056275249195251\n",
      "min: 0.07116112433950787\n",
      "max: 0.3240528029106602\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4045323607592957\n",
      "std: 0.010680882951954204\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.404932798146257\n",
      "std: 0.010628003311242397\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10068695948139886\n",
      "min: 0.05690818963780095\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31606811775722177\n",
      "std: 0.29303937168465416\n",
      "min: -0.7867394271150369\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49621504182174436\n",
      "std: 0.36205655059380787\n",
      "min: -0.36050644225489287\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626635785758908\n",
      "min: 0.08264773603825515\n",
      "max: 0.29748909503410564\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1323116075404558\n",
      "std: 0.2650698823774724\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1458392259596124\n",
      "std: 0.2655308582716011\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10588906539592922\n",
      "min: 0.020662304654860547\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.326417000499682\n",
      "std: 0.36649081535008043\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.39142175173707683\n",
      "std: 0.3415471830474104\n",
      "min: -0.5308491012462392\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05626694156627784\n",
      "min: 0.07095027915742905\n",
      "max: 0.32439175721178326\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064688768329177\n",
      "std: 0.005607953162319887\n",
      "min: 1.383057071533761\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40674360683154\n",
      "std: 0.005854472030428092\n",
      "min: 1.383057071533761\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10067586189344672\n",
      "min: 0.05805211701508107\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3191527040041311\n",
      "std: 0.292829593998822\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4946022666111969\n",
      "std: 0.3625323031336611\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06276494297610867\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2109750542469322\n",
      "std: 0.11217969129862335\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2203856425721715\n",
      "std: 0.12073138148280763\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10268842014649807\n",
      "min: 0.039340330023840624\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34660325724045504\n",
      "std: 0.361274458356921\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37709691172481075\n",
      "std: 0.3434969567535075\n",
      "min: -0.5320221780296848\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05711425801548546\n",
      "min: 0.0716029858268513\n",
      "max: 0.3234874903109342\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407967043343744\n",
      "std: 0.0038072846472888876\n",
      "min: 1.3857512534144307\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081562979709628\n",
      "std: 0.004177663707454445\n",
      "min: 1.3857512534144307\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10067474480918753\n",
      "min: 0.058002236717394726\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32276425152075466\n",
      "std: 0.29236146252578776\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49018157205978735\n",
      "std: 0.36265739876827524\n",
      "min: -0.37110810879721096\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06281593941448843\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.097975554879491\n",
      "std: 0.34665573158257745\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1128386361691742\n",
      "std: 0.34807281322765676\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.11043537351216054\n",
      "min: 0.012930616370502825\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34320635003889427\n",
      "std: 0.36281693455250513\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37512175498498623\n",
      "std: 0.34343699893573865\n",
      "min: -0.533715200357486\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0567135992735697\n",
      "min: 0.07120819774983718\n",
      "max: 0.32369681102135534\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.400399862873003\n",
      "std: 0.021968384221466967\n",
      "min: 1.3049084326204559\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4009290635894998\n",
      "std: 0.021836720898973868\n",
      "min: 1.3049084326204559\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10072716110384967\n",
      "min: 0.05359481893111497\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32587997719781414\n",
      "std: 0.2927262596278326\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4920000348575211\n",
      "std: 0.36451283893447156\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06290603903331582\n",
      "min: 0.0823566643090111\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1394329393823623\n",
      "std: 0.2450910617927797\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.151906034105091\n",
      "std: 0.24766302223989042\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.10219331363843935\n",
      "min: 0.01812938846249621\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3248284653135985\n",
      "std: 0.3656396289482514\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.39161309578576786\n",
      "std: 0.34029742884332764\n",
      "min: -0.529997000957434\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05614946480056613\n",
      "min: 0.07114479798970585\n",
      "max: 0.32377126761983455\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4060767126054063\n",
      "std: 0.00682062274004149\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406435318361924\n",
      "std: 0.006753524741082656\n",
      "min: 1.37650853464017\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.09674570422995901\n",
      "min: 0.05403294507244834\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31830764634422815\n",
      "std: 0.29311581530331116\n",
      "min: -0.7838914077761377\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4953199072542115\n",
      "std: 0.36238045038215194\n",
      "min: -0.3609862441400947\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06274656502844814\n",
      "min: 0.08315323520473039\n",
      "max: 0.2973709460758802\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1296734791131855\n",
      "std: 0.27105196100122964\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1427158015342327\n",
      "std: 0.27457183206516295\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.10427839000880576\n",
      "min: 0.019485629443467257\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32363265774749517\n",
      "std: 0.37411059151738424\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.39125592192156045\n",
      "std: 0.3435625284100279\n",
      "min: -0.5315491360765389\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056436012756871365\n",
      "min: 0.07116112433950787\n",
      "max: 0.3240528029106602\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4046923257368318\n",
      "std: 0.010497272028589591\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4051138097067852\n",
      "std: 0.010438087628581259\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.09675448111079513\n",
      "min: 0.05346950044138898\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31634924722013735\n",
      "std: 0.29312118771772233\n",
      "min: -0.7867394271150369\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4958416714345238\n",
      "std: 0.3620928514607866\n",
      "min: -0.36050644225489287\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626729955916413\n",
      "min: 0.08264773603825515\n",
      "max: 0.29748909503410564\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1379065237026125\n",
      "std: 0.25876759389586257\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1506976846712962\n",
      "std: 0.2593635317066025\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.10163616481461589\n",
      "min: 0.01870139704624331\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3278647692966057\n",
      "std: 0.3676652436411601\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.38967824977248283\n",
      "std: 0.34309786811966975\n",
      "min: -0.5326538039859695\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056424649249050426\n",
      "min: 0.07095027915742905\n",
      "max: 0.32439175721178326\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406535094017076\n",
      "std: 0.0055568085689087325\n",
      "min: 1.383057071533761\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4068424007946556\n",
      "std: 0.005768480038248263\n",
      "min: 1.383057071533761\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.0967440705229138\n",
      "min: 0.05445842229472282\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31929143900578816\n",
      "std: 0.2929476162015237\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4943190905348348\n",
      "std: 0.3625486626526607\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06276944142578302\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.212714589856319\n",
      "std: 0.10898141249985056\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2218340738569669\n",
      "std: 0.11734025144553174\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.09862854640645044\n",
      "min: 0.039340330023840624\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3470439178753374\n",
      "std: 0.3624310133124101\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37592368433609114\n",
      "std: 0.34481484707879373\n",
      "min: -0.5334860507637019\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057219602217708325\n",
      "min: 0.0716029858268513\n",
      "max: 0.3234874903109342\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407966551101632\n",
      "std: 0.0037917201047254177\n",
      "min: 1.3857512534144307\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081952498675125\n",
      "std: 0.0041061682209156845\n",
      "min: 1.3857512534144307\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.09674301157900295\n",
      "min: 0.05481410604263408\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3227527185873285\n",
      "std: 0.29248681408742305\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49006144723003686\n",
      "std: 0.3626642033391511\n",
      "min: -0.37110810879721096\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06281762413475446\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.105814754601201\n",
      "std: 0.33841671929375533\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1197559618368311\n",
      "std: 0.34003368394579236\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.10588867965644956\n",
      "min: 0.012930616370502822\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34401785574020494\n",
      "std: 0.36402501811760435\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.374140603021759\n",
      "std: 0.3448421836042259\n",
      "min: -0.5343211240066954\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05686005175320756\n",
      "min: 0.07120819774983718\n",
      "max: 0.32369681102135534\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4007792895848656\n",
      "std: 0.02149382280141742\n",
      "min: 1.3049084326204559\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4013095932476465\n",
      "std: 0.02138408213460648\n",
      "min: 1.3049084326204559\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.09679223053507727\n",
      "min: 0.05084204214225996\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3257786120701595\n",
      "std: 0.2928181530755398\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49180254963783027\n",
      "std: 0.3644462981393187\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06290588421739152\n",
      "min: 0.0823566643090111\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1422379450773068\n",
      "std: 0.2402399357649445\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1541732855912894\n",
      "std: 0.24283191153976796\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09825752208301565\n",
      "min: 0.01812938846249621\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3237325841518158\n",
      "std: 0.3658979111939054\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.39100382423735475\n",
      "std: 0.3391692563373577\n",
      "min: -0.529997000957434\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0560603536399084\n",
      "min: 0.07114479798970585\n",
      "max: 0.32377126761983455\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4061080736021405\n",
      "std: 0.006808714148987249\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406441303636703\n",
      "std: 0.0067797916827522795\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09312934698043192\n",
      "min: 0.051253038230877075\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3180410421338366\n",
      "std: 0.29308108744010014\n",
      "min: -0.7838914077761377\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4950934506340504\n",
      "std: 0.3621164394436002\n",
      "min: -0.3609862441400947\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06271193807855574\n",
      "min: 0.08315323520473039\n",
      "max: 0.2973709460758802\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1330672247097153\n",
      "std: 0.2651429145088307\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1455152172257346\n",
      "std: 0.26871192567498875\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.10021210652177409\n",
      "min: 0.018672845905404505\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3227004636563667\n",
      "std: 0.3739493926276824\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.39061666052586774\n",
      "std: 0.34232428544774995\n",
      "min: -0.5315491360765389\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05634058251695306\n",
      "min: 0.07116112433950787\n",
      "max: 0.3240528029106602\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.404795859027588\n",
      "std: 0.010349098083835013\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4051853221985187\n",
      "std: 0.010322731546449384\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09313760183023308\n",
      "min: 0.05054515957363019\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31615881193806106\n",
      "std: 0.2930640589273322\n",
      "min: -0.7867394271150369\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49556552420648\n",
      "std: 0.3618326479359476\n",
      "min: -0.36050644225489287\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264070200280936\n",
      "min: 0.08264773603825515\n",
      "max: 0.29748909503410564\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1405956057283326\n",
      "std: 0.25502764486288887\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1528411664689229\n",
      "std: 0.25560714480567914\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09774013417505435\n",
      "min: 0.017583490189147243\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32669891469642887\n",
      "std: 0.3679183768543253\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.38912059278984146\n",
      "std: 0.3418889108226338\n",
      "min: -0.5326538039859695\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05632983217723956\n",
      "min: 0.07095027915742905\n",
      "max: 0.32439175721178326\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065421770240158\n",
      "std: 0.005589717412321815\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4068275309418496\n",
      "std: 0.005838640234371783\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09312780774361637\n",
      "min: 0.05130531068878497\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31897551097946775\n",
      "std: 0.29292337500923\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49412143377213535\n",
      "std: 0.3622701137312162\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06273282997529397\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2121575168054353\n",
      "std: 0.10670275539996893\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2210925121783627\n",
      "std: 0.11481357437251218\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09490068299975439\n",
      "min: 0.03864356974827985\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3449669264227955\n",
      "std: 0.36283887344361215\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37592281393769034\n",
      "std: 0.3434650907911715\n",
      "min: -0.5334860507637019\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057082556860887666\n",
      "min: 0.0716029858268513\n",
      "max: 0.3234874903109342\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079225243534224\n",
      "std: 0.003821646714145337\n",
      "min: 1.3833005668824987\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081351922067553\n",
      "std: 0.004184641153122572\n",
      "min: 1.3833005668824987\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09312679391412472\n",
      "min: 0.051676374438989536\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3222971840840146\n",
      "std: 0.29247477153104295\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49002054302307857\n",
      "std: 0.36237863314467755\n",
      "min: -0.37110810879721096\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06277871089114942\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1101068134073115\n",
      "std: 0.3314849015679245\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1233593285208132\n",
      "std: 0.3332845433953961\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.1017302200747945\n",
      "min: 0.012930616370502822\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3422528489781883\n",
      "std: 0.36440424201019794\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37426607931303923\n",
      "std: 0.3435788150083611\n",
      "min: -0.5343211240066954\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0567533914037419\n",
      "min: 0.07120819774983718\n",
      "max: 0.32369681102135534\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40106242918781\n",
      "std: 0.021100168096050483\n",
      "min: 1.3049084326204559\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4015456325277575\n",
      "std: 0.02102411322117917\n",
      "min: 1.3049084326204559\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09317318764039594\n",
      "min: 0.04817790715408063\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32523348422397147\n",
      "std: 0.29277894301268487\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49168603700429886\n",
      "std: 0.36409526624393196\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06286471010131037\n",
      "min: 0.0823566643090111\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1468054846571816\n",
      "std: 0.23480438553223512\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1575071441788016\n",
      "std: 0.2373327577048103\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.09463063036400975\n",
      "min: 0.01812938846249621\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32347962723952306\n",
      "std: 0.36420820412096017\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3891664885857838\n",
      "std: 0.33955178230561095\n",
      "min: -0.5299970009574339\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05604729003479844\n",
      "min: 0.07114479798970585\n",
      "max: 0.32377126761983455\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4061923017870601\n",
      "std: 0.006658324631554426\n",
      "min: 1.3717877071493065\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065120657220693\n",
      "std: 0.006629640061133523\n",
      "min: 1.3736210995459537\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.08979138387604554\n",
      "min: 0.0490400804846995\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3173999860970441\n",
      "std: 0.29264369645396243\n",
      "min: -0.7838914077761377\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4949162266762455\n",
      "std: 0.36178880286163495\n",
      "min: -0.3609862441400947\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266944298247776\n",
      "min: 0.08315323520473039\n",
      "max: 0.2973709460758802\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1380938033808383\n",
      "std: 0.25891128912981887\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1492655497125346\n",
      "std: 0.26240884772492495\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.0964702229146673\n",
      "min: 0.01867284590540451\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32259470189455025\n",
      "std: 0.37190405689701306\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.38873874583744383\n",
      "std: 0.3425938098338406\n",
      "min: -0.531549136076539\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0563208094927857\n",
      "min: 0.07116112433950787\n",
      "max: 0.3240528029106602\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.404937406167814\n",
      "std: 0.010133048512185194\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4053079244782698\n",
      "std: 0.010111757611382603\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.08979917407332902\n",
      "min: 0.04804554996493004\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31558708214633846\n",
      "std: 0.2926041070476944\n",
      "min: -0.7867394271150369\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4953421858127258\n",
      "std: 0.3615085022949592\n",
      "min: -0.36050644225489287\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260031813902198\n",
      "min: 0.08264773603825515\n",
      "max: 0.29748909503410564\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1450910156677336\n",
      "std: 0.25029430873630615\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1560886799744972\n",
      "std: 0.2508441201275329\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.09414874377212358\n",
      "min: 0.017583490189147247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3263645156827974\n",
      "std: 0.3661803230288663\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.38731347547902684\n",
      "std: 0.34217919999586716\n",
      "min: -0.5326538039859694\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056308597483711496\n",
      "min: 0.07095027915742905\n",
      "max: 0.32439175721178326\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066056350980867\n",
      "std: 0.0054817887486421175\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4068809049300444\n",
      "std: 0.005720623022140411\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.08978993317206879\n",
      "min: 0.04917769783176296\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31828726285828024\n",
      "std: 0.2924922863875564\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49397254108439265\n",
      "std: 0.3619287634755379\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06268844333697698\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.213297432480516\n",
      "std: 0.10500779011451673\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2213043070694278\n",
      "std: 0.11291197162140194\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.09146344124859143\n",
      "min: 0.03251878823968577\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3438127996929432\n",
      "std: 0.3612196283725071\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3745853977571552\n",
      "std: 0.3435671821670351\n",
      "min: -0.5334860507637017\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057022378517607025\n",
      "min: 0.0716029858268513\n",
      "max: 0.3234874903109342\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079235605408429\n",
      "std: 0.0037616723530844807\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081316583410202\n",
      "std: 0.004109159680489339\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.08978897158664409\n",
      "min: 0.0492140286455985\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3214888602642091\n",
      "std: 0.2920630874156745\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4900076947364294\n",
      "std: 0.3620326465638753\n",
      "min: -0.37110810879721096\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06273239626247921\n",
      "min: 0.08268588180820804\n",
      "max: 0.29784921890691257\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1158138985226966\n",
      "std: 0.3253701236130728\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1277192177277187\n",
      "std: 0.3271331587150967\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.09790617131969744\n",
      "min: 0.010317216955760999\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3413896622436695\n",
      "std: 0.3627563153090087\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37306561407641015\n",
      "std: 0.3437537806248658\n",
      "min: -0.5343211240066953\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05672258706623918\n",
      "min: 0.07120819774983718\n",
      "max: 0.32369681102135534\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4013499428918954\n",
      "std: 0.020736146457622628\n",
      "min: 1.3049084326204559\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4018015309467917\n",
      "std: 0.020678642920774155\n",
      "min: 1.3049084326204559\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.08983284008373854\n",
      "min: 0.045617040170972276\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3243384512130351\n",
      "std: 0.2923401190569401\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4916057080169225\n",
      "std: 0.3636856232182446\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06281617804902145\n",
      "min: 0.0823566643090111\n",
      "max: 0.29788447509357874\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1482959783861464\n",
      "std: 0.22981324911421552\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1578363696813898\n",
      "std: 0.23244264459667674\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.09128113334821047\n",
      "min: 0.016328565126136847\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32624357623776506\n",
      "std: 0.36320268256672344\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.38636535438528097\n",
      "std: 0.3407753757970659\n",
      "min: -0.5370575288459383\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056272565741582035\n",
      "min: 0.07114479798970585\n",
      "max: 0.32377126761983455\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4061910144587753\n",
      "std: 0.006536293185681303\n",
      "min: 1.3717877071493065\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4064340086961509\n",
      "std: 0.006529244807462758\n",
      "min: 1.3736210995459537\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.08670032637127101\n",
      "min: 0.04672058261843606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3180019669989429\n",
      "std: 0.2927742899416861\n",
      "min: -0.7838914077761377\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49460265060028\n",
      "std: 0.36205560989903685\n",
      "min: -0.36144613152877986\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06272197416661544\n",
      "min: 0.08245349607185054\n",
      "max: 0.2996590121125362\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1399264752772207\n",
      "std: 0.2537823339208216\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1499063430189855\n",
      "std: 0.25732843841541064\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.09301959280408288\n",
      "min: 0.016619238648458257\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32548602249326736\n",
      "std: 0.37056770138823913\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.38589332211729466\n",
      "std: 0.3436995034206115\n",
      "min: -0.5383292218864671\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05653814456902008\n",
      "min: 0.07116112433950787\n",
      "max: 0.3240528029106602\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.404989048369083\n",
      "std: 0.009931374568372371\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405278366739328\n",
      "std: 0.009926578231644924\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.0867076975527371\n",
      "min: 0.04584930527400264\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31625513173073705\n",
      "std: 0.29272003104489436\n",
      "min: -0.7867394271150369\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4949869990067521\n",
      "std: 0.3617794345338251\n",
      "min: -0.3607653034392927\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06265502225265142\n",
      "min: 0.08249656320725772\n",
      "max: 0.29959544031476404\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.14646252803481\n",
      "std: 0.24611375115582756\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1562898492043965\n",
      "std: 0.24677386295209439\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.09083169186934739\n",
      "min: 0.016000796059946452\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32905452098099325\n",
      "std: 0.36509974505745885\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.38452349297945554\n",
      "std: 0.3433068999804266\n",
      "min: -0.5392821170808231\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05652594575827768\n",
      "min: 0.07095027915742905\n",
      "max: 0.32439175721178326\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065832628797634\n",
      "std: 0.005437572891414286\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406784603716233\n",
      "std: 0.005692183824864461\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.08669895970812544\n",
      "min: 0.046520397380845804\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31884972925666044\n",
      "std: 0.292625890535004\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49368126322311795\n",
      "std: 0.3621836858187465\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06273940710552295\n",
      "min: 0.08246919687927891\n",
      "max: 0.2996713435548299\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2117936442122883\n",
      "std: 0.10391463612872892\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2188974708387619\n",
      "std: 0.11187037298994473\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.08828482308915656\n",
      "min: 0.03187752219177068\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34573001300403644\n",
      "std: 0.36012709016295424\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37225299361982017\n",
      "std: 0.3445083123189658\n",
      "min: -0.539794853175667\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05719983129415713\n",
      "min: 0.0716029858268513\n",
      "max: 0.3234874903109342\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078519049034233\n",
      "std: 0.003741602169707314\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079912714091665\n",
      "std: 0.0041137403783573665\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.08669804014702252\n",
      "min: 0.04670438736096026\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3219298830113219\n",
      "std: 0.292199820052846\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4898460629716238\n",
      "std: 0.3622774886785448\n",
      "min: -0.37110810879721096\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06278066760049647\n",
      "min: 0.0825143060068001\n",
      "max: 0.29965744652892107\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1185269311439952\n",
      "std: 0.3191554215260823\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1291630660523841\n",
      "std: 0.32104592684629185\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.09438026594593599\n",
      "min: 0.010317216955760999\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3436014493112984\n",
      "std: 0.3616849144870118\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3708406566381642\n",
      "std: 0.34474950424393563\n",
      "min: -0.540950592985104\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05693007556667926\n",
      "min: 0.07120819774983718\n",
      "max: 0.32369681102135534\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4015541897765467\n",
      "std: 0.020315237959026157\n",
      "min: 1.3049084326204559\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4019134095794237\n",
      "std: 0.020276128603986456\n",
      "min: 1.3049084326204559\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.08673959434870103\n",
      "min: 0.043508515955837546\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32471102179700184\n",
      "std: 0.29244861558345125\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4913789974698289\n",
      "std: 0.36387310364096626\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06286313290742412\n",
      "min: 0.0823566643090111\n",
      "max: 0.29965566160232054\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1514099551067811\n",
      "std: 0.22598340783584805\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1602544549993137\n",
      "std: 0.22864735895372906\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08817844722402741\n",
      "min: 0.016328565126136844\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3321045128070716\n",
      "std: 0.3636380928648815\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3821441033225024\n",
      "std: 0.3429653307771911\n",
      "min: -0.5657284121931527\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056474113532299954\n",
      "min: 0.07114479798970585\n",
      "max: 0.32377126761983455\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406311421644552\n",
      "std: 0.0064543468380623015\n",
      "min: 1.3717877071493065\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065567129289471\n",
      "std: 0.00643627339018316\n",
      "min: 1.3736210995459537\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08382924927440671\n",
      "min: 0.04440393708735345\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3185244854413735\n",
      "std: 0.2929194953616327\n",
      "min: -0.7838914077761377\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4943884093928061\n",
      "std: 0.36214551986366456\n",
      "min: -0.3614461315287798\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06273732329729297\n",
      "min: 0.08245349607185054\n",
      "max: 0.2996590121125362\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.143368891974862\n",
      "std: 0.2502645246169652\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1526228865022294\n",
      "std: 0.25380312998897425\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.0898256769653966\n",
      "min: 0.015691326148363275\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33145770860019236\n",
      "std: 0.37070729285881504\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3816487626218043\n",
      "std: 0.34578110608048446\n",
      "min: -0.5673172434034092\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05673358633258507\n",
      "min: 0.07116112433950787\n",
      "max: 0.3240528029106602\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405155425191877\n",
      "std: 0.009808811464114747\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4054432658942646\n",
      "std: 0.009799959958118387\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08383625035240753\n",
      "min: 0.04357121733415177\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3168346427027381\n",
      "std: 0.29285195831462546\n",
      "min: -0.7867394271150369\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4947397124153967\n",
      "std: 0.3618723064378285\n",
      "min: -0.36076530343929275\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06267220005457075\n",
      "min: 0.08249656320725772\n",
      "max: 0.299595440314764\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1496726851860568\n",
      "std: 0.2417057727875067\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1587883333000648\n",
      "std: 0.24247197121124434\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08775457950009836\n",
      "min: 0.016000796059946452\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3348283001688902\n",
      "std: 0.3654645303903045\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3803465087504931\n",
      "std: 0.3453971042205961\n",
      "min: -0.5679072723852119\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05671923156826035\n",
      "min: 0.07095027915742905\n",
      "max: 0.32439175721178326\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066896904852433\n",
      "std: 0.005368893785878421\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4068959239060028\n",
      "std: 0.005606205105217512\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.0838279511582316\n",
      "min: 0.04457661716054689\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31933421669303\n",
      "std: 0.2927768179319392\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49349318055178254\n",
      "std: 0.36226311654991866\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06275325336907775\n",
      "min: 0.08246919687927891\n",
      "max: 0.29967134355482994\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2124055266015503\n",
      "std: 0.10298400298092704\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2190339139602375\n",
      "std: 0.11081084400389159\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08533445083134386\n",
      "min: 0.028452937912743996\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3507686184166314\n",
      "std: 0.3603555124765669\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36850892882695996\n",
      "std: 0.34637769621677583\n",
      "min: -0.5681843471301149\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05735689798465067\n",
      "min: 0.0716029858268513\n",
      "max: 0.3234874903109342\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079159061032793\n",
      "std: 0.003697555230475552\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080640612033033\n",
      "std: 0.004044720397576811\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08382707263649113\n",
      "min: 0.04473970684328065\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3222996564231643\n",
      "std: 0.29235428444337147\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48978046861775887\n",
      "std: 0.3623494160335107\n",
      "min: -0.37110810879721096\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06279229604910506\n",
      "min: 0.08251430600680011\n",
      "max: 0.29965744652892107\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1232220726529973\n",
      "std: 0.3132745386124027\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1330457719429445\n",
      "std: 0.31528564753405164\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.09111582932757985\n",
      "min: 0.010317216955760999\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3488894926853514\n",
      "std: 0.36198622148275617\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36719675679086056\n",
      "std: 0.34665280395157794\n",
      "min: -0.5694771861836201\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057112877049447994\n",
      "min: 0.07120819774983718\n",
      "max: 0.32369681102135534\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4018659606450325\n",
      "std: 0.019997047456977363\n",
      "min: 1.3049084326204559\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4022133034251647\n",
      "std: 0.019969575569809727\n",
      "min: 1.3049084326204559\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08386655821507513\n",
      "min: 0.041261460593276816\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3250095145670977\n",
      "std: 0.29258165479378034\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4912568756152552\n",
      "std: 0.3638903462222616\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06287301276099777\n",
      "min: 0.0823566643090111\n",
      "max: 0.2996556616023205\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1515026389564034\n",
      "std: 0.22235509820301258\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1600122352181905\n",
      "std: 0.22513408176610572\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08529355296013909\n",
      "min: 0.016328565126136844\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33396444990956\n",
      "std: 0.36284600636181435\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37855557328110406\n",
      "std: 0.34425683146141917\n",
      "min: -0.5657284121931527\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05660361049114738\n",
      "min: 0.07114479798970585\n",
      "max: 0.32377126761983455\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064011509366408\n",
      "std: 0.006339730127879793\n",
      "min: 1.3717877071493065\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066355752606672\n",
      "std: 0.006327983495387457\n",
      "min: 1.3736210995459537\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08115501655553076\n",
      "min: 0.04250689972219125\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31873332642857205\n",
      "std: 0.2928243696198849\n",
      "min: -0.7838914077761377\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49389943981885487\n",
      "std: 0.3621807555436934\n",
      "min: -0.3614461315287798\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06274950544198579\n",
      "min: 0.08245349607185054\n",
      "max: 0.2996590121125362\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.143933813608003\n",
      "std: 0.2452786718918229\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1528181860666888\n",
      "std: 0.24895974024117712\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08685540387412556\n",
      "min: 0.015691326148363275\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33341938729135673\n",
      "std: 0.36963700288482537\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37806317140436624\n",
      "std: 0.3469742617600603\n",
      "min: -0.5673172434034092\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05685739911136021\n",
      "min: 0.07116112433950787\n",
      "max: 0.3240528029106602\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405300016501186\n",
      "std: 0.009596487265054056\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4055731256531117\n",
      "std: 0.00959831517809351\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08116166642736306\n",
      "min: 0.04182894769319724\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31709556473321293\n",
      "std: 0.29274554365260874\n",
      "min: -0.7867394271150369\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49422154704968096\n",
      "std: 0.3619108063165888\n",
      "min: -0.36076530343929275\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06268605919009802\n",
      "min: 0.08249656320725772\n",
      "max: 0.299595440314764\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1499082816346937\n",
      "std: 0.23698394546065452\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1586725302066725\n",
      "std: 0.2379408246586984\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.084891648306264\n",
      "min: 0.016000796059946452\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3366259861473833\n",
      "std: 0.3646328012941895\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3768179740951214\n",
      "std: 0.34660211731352186\n",
      "min: -0.5679072723852119\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056843185714824385\n",
      "min: 0.07095027915742905\n",
      "max: 0.32439175721178326\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4067580365580499\n",
      "std: 0.005262528941410422\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069560086908228\n",
      "std: 0.005503352474518605\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08115378090929093\n",
      "min: 0.04266851630185935\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31950736999933743\n",
      "std: 0.2926871738560805\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4930298160004264\n",
      "std: 0.3622880852745488\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06276405564896319\n",
      "min: 0.08246919687927891\n",
      "max: 0.29967134355482994\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2101131387557849\n",
      "std: 0.10148580649760916\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2166021437138976\n",
      "std: 0.10933254036945683\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08258699695789651\n",
      "min: 0.028452937912743996\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3519361053213288\n",
      "std: 0.35956513374967797\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36539462588057325\n",
      "std: 0.3474256811928662\n",
      "min: -0.5681843471301149\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0574506903515698\n",
      "min: 0.0716029858268513\n",
      "max: 0.3234874903109342\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079270581500463\n",
      "std: 0.003631090678478222\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080713293980647\n",
      "std: 0.003979181864259189\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08115294268537561\n",
      "min: 0.042861933766532405\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3223709319247725\n",
      "std: 0.29227265588443013\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48943725788550096\n",
      "std: 0.36236741879568923\n",
      "min: -0.37110810879721096\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06280136346122166\n",
      "min: 0.08251430600680011\n",
      "max: 0.29965744652892107\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1240970244366697\n",
      "std: 0.3089556565278314\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1335135147781585\n",
      "std: 0.3111109398635553\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08808543165642585\n",
      "min: 0.008725245544753972\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3502453268479334\n",
      "std: 0.3611618761420389\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36414277826428826\n",
      "std: 0.347706176082443\n",
      "min: -0.5694771861836201\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057225578169064484\n",
      "min: 0.07120819774983718\n",
      "max: 0.32369681102135534\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4021036047115876\n",
      "std: 0.019723279059494458\n",
      "min: 1.3037286007872158\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4024292887999559\n",
      "std: 0.019709856224309857\n",
      "min: 1.3037286007872158\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08119056073220575\n",
      "min: 0.03942197727143135\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3250116163898778\n",
      "std: 0.2924746028285599\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4908535807234233\n",
      "std: 0.36385684699559895\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06288019208284894\n",
      "min: 0.0823566643090111\n",
      "max: 0.2996556616023205\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1528225850991962\n",
      "std: 0.2183395719853991\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1608410602081987\n",
      "std: 0.22116870560613144\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.08260364834648468\n",
      "min: 0.016328565126136844\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3279504358283645\n",
      "std: 0.36673038226201826\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.38120274228005485\n",
      "std: 0.34363761656204544\n",
      "min: -0.5657284121931526\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05638518128518945\n",
      "min: 0.07114479798970585\n",
      "max: 0.32377126761983455\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065013884637458\n",
      "std: 0.00626660167469172\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067167318315121\n",
      "std: 0.006259323557013778\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.07865765556453491\n",
      "min: 0.0406040933461085\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31815994390184044\n",
      "std: 0.2931092231538491\n",
      "min: -0.7838914077761377\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4941258505598808\n",
      "std: 0.36200120266565633\n",
      "min: -0.3614461315287798\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06271099851609949\n",
      "min: 0.08245349607185054\n",
      "max: 0.2996590121125362\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1455709838254988\n",
      "std: 0.2408433657556408\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1539362232398176\n",
      "std: 0.2445618891934316\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.08408948544995866\n",
      "min: 0.01569132614836328\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32749741889774586\n",
      "std: 0.3731435619730774\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3807048106669883\n",
      "std: 0.3462731457174402\n",
      "min: -0.5673172434034092\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05663461283894668\n",
      "min: 0.07116112433950787\n",
      "max: 0.3240528029106602\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4054456158034123\n",
      "std: 0.009435830446530643\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4056967003304515\n",
      "std: 0.009444815495877737\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.07866398878835877\n",
      "min: 0.040074589962734275\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31656953200819965\n",
      "std: 0.29301533797113216\n",
      "min: -0.7867394271150369\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4944227036104041\n",
      "std: 0.36173251656075633\n",
      "min: -0.36076530343929275\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264902018040408\n",
      "min: 0.08249656320725773\n",
      "max: 0.29959544031476404\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.151218551380381\n",
      "std: 0.23320040682691187\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1594805220256095\n",
      "std: 0.23423887605720123\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.08222373502343094\n",
      "min: 0.015651474057096063\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33054505775678156\n",
      "std: 0.3685028190030407\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37950627222882366\n",
      "std: 0.3459297115805828\n",
      "min: -0.5679072723852119\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05661924023696585\n",
      "min: 0.07095027915742905\n",
      "max: 0.32439175721178326\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068419598448696\n",
      "std: 0.005222624781600274\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070232716139277\n",
      "std: 0.005463035662516712\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.07865647893770347\n",
      "min: 0.04072127749793758\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31889801065152773\n",
      "std: 0.2929795825901683\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49328113819602526\n",
      "std: 0.3620993831708016\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06272412860019372\n",
      "min: 0.0824691968792789\n",
      "max: 0.2996713435548299\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.208998343136975\n",
      "std: 0.10130205670105107\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2151757071253435\n",
      "std: 0.10893166852206827\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.08002464751370875\n",
      "min: 0.025832038177094833\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3453286944785062\n",
      "std: 0.36373650623491516\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36842491670736677\n",
      "std: 0.34675175588415125\n",
      "min: -0.5681843471301149\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05720336626511393\n",
      "min: 0.0716029858268513\n",
      "max: 0.3234874903109342\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407969520521166\n",
      "std: 0.0036030067700092284\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081004668164296\n",
      "std: 0.003949003146250459\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.07865567410193046\n",
      "min: 0.04085818729522498\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3216729065777575\n",
      "std: 0.29257585228702937\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4897934904258445\n",
      "std: 0.3621778425736346\n",
      "min: -0.37110810879721096\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0627601145654988\n",
      "min: 0.08251430600680011\n",
      "max: 0.29965744652892123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.126275769363519\n",
      "std: 0.3041186210161017\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.135128820189108\n",
      "std: 0.30636022708107546\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.08526355011936756\n",
      "min: 0.008725245544753972\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34376855559151515\n",
      "std: 0.36527446676991737\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36727891089038517\n",
      "std: 0.3470846791578228\n",
      "min: -0.56947718618362\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056994052487719715\n",
      "min: 0.07120819774983718\n",
      "max: 0.32369681102135534\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4023634315897189\n",
      "std: 0.019403640152045924\n",
      "min: 1.3037286007872158\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40265979899853\n",
      "std: 0.019404337464772294\n",
      "min: 1.3037286007872158\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.07869155901809664\n",
      "min: 0.037937926448925394\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3242415130221049\n",
      "std: 0.29276611133530894\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49116403392891944\n",
      "std: 0.3636191930816892\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0628369651168558\n",
      "min: 0.0823566643090111\n",
      "max: 0.29965566160232054\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1544581590074072\n",
      "std: 0.214299833323294\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1619480636354893\n",
      "std: 0.21723064928593894\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.08008830612712703\n",
      "min: 0.01496309527221537\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32798526797024075\n",
      "std: 0.36494080727984224\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3828191331235562\n",
      "std: 0.34269233147351785\n",
      "min: -0.5657284121931526\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05628638257021226\n",
      "min: 0.07114479798970585\n",
      "max: 0.32377126761983455\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065012169483417\n",
      "std: 0.0061581023096027735\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066545626648819\n",
      "std: 0.006169107201861854\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07631981124894874\n",
      "min: 0.03924292015547823\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3181502716035821\n",
      "std: 0.2928503035420203\n",
      "min: -0.7838914077761377\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49415432751644484\n",
      "std: 0.3618314709969081\n",
      "min: -0.3614461315287798\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06269615434995017\n",
      "min: 0.08245349607185054\n",
      "max: 0.2996590121125362\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1474375067775886\n",
      "std: 0.2368205086449866\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.155252702376493\n",
      "std: 0.24060087106470793\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.08150558365090572\n",
      "min: 0.014998497372787259\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32761828473444576\n",
      "std: 0.3711428996882565\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3822884733938693\n",
      "std: 0.34525259497771554\n",
      "min: -0.5673172434034092\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05653132551476514\n",
      "min: 0.07116112433950787\n",
      "max: 0.3240528029106602\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4054793802383068\n",
      "std: 0.00930017792694291\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4056659698438478\n",
      "std: 0.009319451832447864\n",
      "min: 1.3589376881487738\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07632586296992797\n",
      "min: 0.03831091028569379\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3166062116787222\n",
      "std: 0.2927456649144382\n",
      "min: -0.7867394271150369\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49442323487551826\n",
      "std: 0.3615651047778338\n",
      "min: -0.36076530343929275\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06263562158901584\n",
      "min: 0.08249656320725773\n",
      "max: 0.29959544031476404\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1528405701544568\n",
      "std: 0.2292464675703079\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.160563668082829\n",
      "std: 0.23041461755068632\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07972844969279828\n",
      "min: 0.015651474057096063\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3305251939363548\n",
      "std: 0.36668556141347625\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3811458463804399\n",
      "std: 0.34493366901532785\n",
      "min: -0.5679072723852119\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056516153778016075\n",
      "min: 0.07095027915742905\n",
      "max: 0.32439175721178326\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406829222893738\n",
      "std: 0.00516063200720731\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069501770716486\n",
      "std: 0.005413726653183175\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07631869028893196\n",
      "min: 0.03924839979000717\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3188583439788591\n",
      "std: 0.29272345754911433\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4933268143718157\n",
      "std: 0.3619210393848842\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999998\n",
      "std: 0.06270808185181373\n",
      "min: 0.0824691968792789\n",
      "max: 0.2996713435548299\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2084088856305428\n",
      "std: 0.1003601295710616\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2142138719717885\n",
      "std: 0.10800551617686956\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07762637775664788\n",
      "min: 0.025832038177094833\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3447715224258501\n",
      "std: 0.36200522467287155\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37037223457186397\n",
      "std: 0.3457428334605047\n",
      "min: -0.5681843471301149\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05707652478703037\n",
      "min: 0.0716029858268513\n",
      "max: 0.3234874903109342\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079224505398107\n",
      "std: 0.0035795083302103425\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079961524002473\n",
      "std: 0.003942876963741757\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.0763179177776888\n",
      "min: 0.039308364160251595\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.321545747581079\n",
      "std: 0.2923286735434326\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4899363206627121\n",
      "std: 0.3619962847138614\n",
      "min: -0.37110810879721096\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06274250968728252\n",
      "min: 0.08251430600680011\n",
      "max: 0.29965744652892123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.128785538969472\n",
      "std: 0.29916466891749427\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.137043086580984\n",
      "std: 0.3015196796313535\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.08262773871144748\n",
      "min: 0.008725245544753972\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34338023726132744\n",
      "std: 0.3635337908519694\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3693117027299787\n",
      "std: 0.34611252609391796\n",
      "min: -0.56947718618362\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056883658671783\n",
      "min: 0.07120819774983718\n",
      "max: 0.32369681102135534\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40250285740998\n",
      "std: 0.01913271478214778\n",
      "min: 1.2967991228546623\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4027284108486737\n",
      "std: 0.019146168012019106\n",
      "min: 1.2967991228546623\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07635222867956001\n",
      "min: 0.036098692496840404\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3240523003561938\n",
      "std: 0.29250178257681675\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49126385729477406\n",
      "std: 0.3633928146453137\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06281768956774819\n",
      "min: 0.0823566643090111\n",
      "max: 0.29965566160232054\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1565635573310584\n",
      "std: 0.21084297124979362\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1635395969494864\n",
      "std: 0.2137693839485271\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.077731779269\n",
      "min: 0.012953919620569458\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33219763117794615\n",
      "std: 0.3652415544914682\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.38105603596823456\n",
      "std: 0.34441977570254484\n",
      "min: -0.5937646458571719\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05655560370526865\n",
      "min: 0.07114479798970585\n",
      "max: 0.327839078615085\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065080856438066\n",
      "std: 0.006099870101036463\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066044984897623\n",
      "std: 0.006126135713920936\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.0741263522115601\n",
      "min: 0.03750027037830272\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3187927923773835\n",
      "std: 0.2929790392324081\n",
      "min: -0.7856144696346393\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4939247221233313\n",
      "std: 0.3620441076630295\n",
      "min: -0.3638666689688304\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06272794808060074\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1498256999510301\n",
      "std: 0.23258857381223028\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1571063069009042\n",
      "std: 0.2363731633238916\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.07908499908047198\n",
      "min: 0.01409781528698875\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3318800013798909\n",
      "std: 0.37121147354560446\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.380502008963769\n",
      "std: 0.3468920963511917\n",
      "min: -0.5944037525937598\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05679328524979725\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4055252104577514\n",
      "std: 0.00920592015688664\n",
      "min: 1.3566951501356845\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4056524502233188\n",
      "std: 0.009232377970916538\n",
      "min: 1.3571113015496106\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.07413214555240735\n",
      "min: 0.036633236022108114\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3172891862158398\n",
      "std: 0.29286775451749114\n",
      "min: -0.7867394271150369\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4941691989551325\n",
      "std: 0.36178007639231596\n",
      "min: -0.3632423277784515\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266870754540231\n",
      "min: 0.0822143147394386\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.155017512017319\n",
      "std: 0.22542432664548506\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1622164799212644\n",
      "std: 0.22662253085575945\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.0773891069435158\n",
      "min: 0.013022107073856507\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33466507114405036\n",
      "std: 0.36692349462194046\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3794188250813166\n",
      "std: 0.3465918218174704\n",
      "min: -0.5951601980640531\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05677839141794389\n",
      "min: 0.07095027915742905\n",
      "max: 0.3279843393966789\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406824847071738\n",
      "std: 0.0051388136093960925\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406890287753903\n",
      "std: 0.005402815897800187\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.07412528095030463\n",
      "min: 0.037623559633728446\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3194720370727865\n",
      "std: 0.29285583906523877\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49311673265219197\n",
      "std: 0.3621258948696776\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06273878262356677\n",
      "min: 0.08218608005805053\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2085415991742836\n",
      "std: 0.09893750413337861\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2139679586878507\n",
      "std: 0.10648910905424047\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.0753768000335011\n",
      "min: 0.025832038177094833\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3483946412213691\n",
      "std: 0.36218561903307767\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36894727254275494\n",
      "std: 0.3472838767515208\n",
      "min: -0.5957196914962362\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05731260105658204\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407887199604101\n",
      "std: 0.003576415259628501\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407908289375447\n",
      "std: 0.003960425256418133\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.07412453677650478\n",
      "min: 0.0377893143009445\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32207322567995544\n",
      "std: 0.29246129958811395\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48981878839769705\n",
      "std: 0.36219399436026056\n",
      "min: -0.37110810879721096\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06277148438227567\n",
      "min: 0.08224047526152704\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1319218430677593\n",
      "std: 0.2935440209235757\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1396000386308112\n",
      "std: 0.29597046101729846\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.08015875516479014\n",
      "min: 0.008725245544753972\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3471620491500615\n",
      "std: 0.3637254144953223\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36794225690165516\n",
      "std: 0.34768817607957336\n",
      "min: -0.5962792947525847\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057135983478719246\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.402654845651836\n",
      "std: 0.018877638679044947\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4028155271779934\n",
      "std: 0.018901140095933987\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.07415739626602169\n",
      "min: 0.03471569185223966\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3245228538023589\n",
      "std: 0.2926170694728517\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49110215745042185\n",
      "std: 0.3635498426259636\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06284506964878898\n",
      "min: 0.08217236485510233\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1596624058087734\n",
      "std: 0.20777262796063076\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.166704778785736\n",
      "std: 0.21068216047370908\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07551893946747394\n",
      "min: 0.012953919620569458\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3331620699701661\n",
      "std: 0.3654088685007884\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37970170478057585\n",
      "std: 0.3443496682966055\n",
      "min: -0.5937646458571719\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056527044608726235\n",
      "min: 0.07114479798970585\n",
      "max: 0.327839078615085\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066081545678317\n",
      "std: 0.005995545783530496\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066927158208777\n",
      "std: 0.006017843606651779\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.0720640052271855\n",
      "min: 0.03624721522137104\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31929410923166435\n",
      "std: 0.29314669326450116\n",
      "min: -0.7908255271605958\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49361289054722673\n",
      "std: 0.3621951279512679\n",
      "min: -0.36463610948806113\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0627485435330702\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1531055603658726\n",
      "std: 0.2297749435250652\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1604343655291638\n",
      "std: 0.23353599115793966\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.0768145590219702\n",
      "min: 0.012277480605241307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3329113632706185\n",
      "std: 0.3711620625765071\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37914034088820536\n",
      "std: 0.34675620879133495\n",
      "min: -0.5944037525937598\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05676045462372696\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4056580356923667\n",
      "std: 0.009066195110044174\n",
      "min: 1.3566951501356845\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4057712837849472\n",
      "std: 0.009090912370912337\n",
      "min: 1.3571113015496106\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07206955726884566\n",
      "min: 0.0354298891179092\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31783010748996937\n",
      "std: 0.29302850546325326\n",
      "min: -0.7898685652934799\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.493836715430195\n",
      "std: 0.36193367226000395\n",
      "min: -0.3639715909071613\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06269059192078193\n",
      "min: 0.0822143147394386\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1580618926375552\n",
      "std: 0.22321365023210674\n",
      "min: -0.05614650130534389\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1653220798107622\n",
      "std: 0.2243910896282456\n",
      "min: -0.05614650130534389\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07519334633471095\n",
      "min: 0.010485201568579247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33557357938955135\n",
      "std: 0.3670499618983672\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3780926076648528\n",
      "std: 0.34646839377314237\n",
      "min: -0.5951601980640531\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056744529299442396\n",
      "min: 0.07095027915742905\n",
      "max: 0.3279843393966789\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069125969613705\n",
      "std: 0.005073874864561151\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406967728547208\n",
      "std: 0.00532564499840817\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.072062981163069\n",
      "min: 0.036206172149767867\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3199480670935056\n",
      "std: 0.2930259863991276\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4928210969783757\n",
      "std: 0.3622695933708504\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06275837324253573\n",
      "min: 0.08218608005805053\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2099341868967088\n",
      "std: 0.09781297241237366\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2155538652122142\n",
      "std: 0.1050772853299988\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.073262409785151\n",
      "min: 0.02477128742990695\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34883361881049185\n",
      "std: 0.3623597926290765\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3679253521791468\n",
      "std: 0.3470752406471243\n",
      "min: -0.5957196914962362\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05725785064513859\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079427443237496\n",
      "std: 0.0035221600786112285\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079557254236106\n",
      "std: 0.003891344110733102\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07206226458637327\n",
      "min: 0.036597686075293644\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32246855970007626\n",
      "std: 0.2926335914850598\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48961382997794595\n",
      "std: 0.36233131654398737\n",
      "min: -0.37110810879721096\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0627895622926239\n",
      "min: 0.08224047526152704\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1359413318446028\n",
      "std: 0.2894693039530021\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1436252093184869\n",
      "std: 0.2919618780971457\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07784336400620516\n",
      "min: 0.007525264474855244\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34774810255392774\n",
      "std: 0.3638940583432455\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36698500781537313\n",
      "std: 0.347512826939713\n",
      "min: -0.5962792947525847\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0570959351812445\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.402898250899509\n",
      "std: 0.018533322224972604\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.403038928147087\n",
      "std: 0.018565416476639285\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07209375412820676\n",
      "min: 0.034070946331311074\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3248667061693623\n",
      "std: 0.2927759603467148\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4908566285938891\n",
      "std: 0.36365057436501824\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06286190019794695\n",
      "min: 0.08217236485510233\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1634110417449117\n",
      "std: 0.2050169071917968\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.170461964058004\n",
      "std: 0.20793380436115305\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07343643621865699\n",
      "min: 0.012243285406212305\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3331700497954004\n",
      "std: 0.3656282086651165\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.380328962116891\n",
      "std: 0.3443460221018876\n",
      "min: -0.5937646458571723\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05657740071142093\n",
      "min: 0.07114479798970585\n",
      "max: 0.3278390786150851\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066988692235953\n",
      "std: 0.005911351734586815\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067928422137639\n",
      "std: 0.005926633554618452\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07012110068506261\n",
      "min: 0.03493525968437256\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31912721909149455\n",
      "std: 0.29318755851112377\n",
      "min: -0.7908255271605962\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4935947941401687\n",
      "std: 0.36211714277336804\n",
      "min: -0.36463610948806113\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06273362586119935\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1571170968526703\n",
      "std: 0.22635575088804794\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1644370851871362\n",
      "std: 0.23013408578280703\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07467775669338882\n",
      "min: 0.012277480605241307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33297285854945613\n",
      "std: 0.371182881665329\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.379760902900592\n",
      "std: 0.34669074980364994\n",
      "min: -0.5944037525937597\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056806275321402915\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4057766114028687\n",
      "std: 0.00895788717566596\n",
      "min: 1.3566951501356845\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4058974439877034\n",
      "std: 0.008979614346509929\n",
      "min: 1.3571113015496101\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07012643203325895\n",
      "min: 0.03426942015454117\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3176995864577406\n",
      "std: 0.2930614235906846\n",
      "min: -0.78986856529348\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4937998947728336\n",
      "std: 0.36185790464962375\n",
      "min: -0.3639715909071615\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626768855705481\n",
      "min: 0.0822143147394386\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1618860703985565\n",
      "std: 0.2200269261143127\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1691465542809765\n",
      "std: 0.22124746381816096\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137932\n",
      "std: 0.07312498301499394\n",
      "min: 0.010485201568579247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33552482227595715\n",
      "std: 0.36725178884734544\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37876125690665446\n",
      "std: 0.3464219953257545\n",
      "min: -0.595160198064053\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05679037690900129\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069950726165315\n",
      "std: 0.005000847097090686\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070611112125937\n",
      "std: 0.005240132693446344\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07012011784935514\n",
      "min: 0.035059051491411614\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3197552381783695\n",
      "std: 0.2930722304293332\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49282197518466625\n",
      "std: 0.36218496125366817\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06274245652685573\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2120827631757418\n",
      "std: 0.09607097009199113\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2178267551364617\n",
      "std: 0.10320416152162208\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07127031986107514\n",
      "min: 0.024771287429906946\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.348352050876416\n",
      "std: 0.36263380500096415\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36885284492922077\n",
      "std: 0.3469930212929229\n",
      "min: -0.595719691496236\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05728293507406859\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079982887383293\n",
      "std: 0.003475500795314845\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080241269141351\n",
      "std: 0.0038254828807155325\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07011942820020028\n",
      "min: 0.0352640138304187\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3222026101762255\n",
      "std: 0.2926873305906931\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4896963770933697\n",
      "std: 0.3622433685428791\n",
      "min: -0.37110810879721096\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06277237262064934\n",
      "min: 0.08224047526152704\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1406974809866481\n",
      "std: 0.2846942354385943\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1483372069799707\n",
      "std: 0.2872644462052873\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07566483780388689\n",
      "min: 0.007525264474855244\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3473867954462553\n",
      "std: 0.3641505968494581\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36797394967859887\n",
      "std: 0.3474636793693586\n",
      "min: -0.5962792947525848\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05713405897194485\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4031218955274665\n",
      "std: 0.01823718755323106\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4032653240910888\n",
      "std: 0.018277379066991045\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07014965948326501\n",
      "min: 0.03268984251814061\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32454768903527553\n",
      "std: 0.2928205163995201\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4909036886661647\n",
      "std: 0.3635275922734322\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0628433964350118\n",
      "min: 0.08217236485510235\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1651666980007107\n",
      "std: 0.2013204643321795\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1719338844621765\n",
      "std: 0.2042574154012622\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.0714730727502398\n",
      "min: 0.012243285406212305\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3314699213659265\n",
      "std: 0.3640323707782962\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37904466877934684\n",
      "std: 0.3431456749563006\n",
      "min: -0.5937646458571723\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05643940022320983\n",
      "min: 0.07114479798970585\n",
      "max: 0.3278390786150851\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4067282745096659\n",
      "std: 0.0058352835056457745\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406801539912276\n",
      "std: 0.00586235685665765\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.06828732228451746\n",
      "min: 0.03377286060678673\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31881167414423284\n",
      "std: 0.29310400357471195\n",
      "min: -0.7908255271605962\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4933022450437375\n",
      "std: 0.3619127930166183\n",
      "min: -0.36463610948806113\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06269897152510791\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.159087885081485\n",
      "std: 0.22219335256546704\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1661070232206756\n",
      "std: 0.22599463466263547\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.07266456328913375\n",
      "min: 0.012277480605241307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33132422609596335\n",
      "std: 0.3694235870924478\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37846774128875393\n",
      "std: 0.3454402149897488\n",
      "min: -0.5944037525937597\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05666465318219619\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4058359305254735\n",
      "std: 0.008832006278841231\n",
      "min: 1.3566951501356845\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4059342915992044\n",
      "std: 0.008863448000399928\n",
      "min: 1.3571113015496101\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.06829244584876507\n",
      "min: 0.03310888128321399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3174181633654814\n",
      "std: 0.29297006661808034\n",
      "min: -0.78986856529348\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49348895479830274\n",
      "std: 0.3616558650077463\n",
      "min: -0.3639715909071615\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264333212332601\n",
      "min: 0.0822143147394386\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.163588449564584\n",
      "std: 0.21687462626824588\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1705582712609557\n",
      "std: 0.21812670573061105\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.07117611979522989\n",
      "min: 0.010485201568579247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33377829938536663\n",
      "std: 0.3656348717742818\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3774978789840244\n",
      "std: 0.34517589225709855\n",
      "min: -0.595160198064053\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05664831387099854\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407014194072203\n",
      "std: 0.004968045923870136\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070609363219342\n",
      "std: 0.0052144017783254375\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.06828638010818294\n",
      "min: 0.033637334975515194\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3194162536901267\n",
      "std: 0.2929923551173948\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49254315067090015\n",
      "std: 0.36197382235562864\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0627068731047421\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2120921741944064\n",
      "std: 0.09484559352882398\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2176532502568582\n",
      "std: 0.10189624547524433\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.06939213619957917\n",
      "min: 0.02427694678421792\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34620189175746424\n",
      "std: 0.36114756256773456\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36785336743211644\n",
      "std: 0.3456869237373355\n",
      "min: -0.595719691496236\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05712370525623504\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079916192571946\n",
      "std: 0.0034578810265610866\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080000801293848\n",
      "std: 0.003815145117343866\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.06828571366973857\n",
      "min: 0.03378166341207172\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3217966728386651\n",
      "std: 0.2926168594657512\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4894970526735741\n",
      "std: 0.3620278429235446\n",
      "min: -0.37110810879721096\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06273569246929582\n",
      "min: 0.08224047526152704\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1430668772615553\n",
      "std: 0.2800858482323788\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1503813966159713\n",
      "std: 0.2827085906937287\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.07361413921440073\n",
      "min: 0.007525264474855244\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34533705755773303\n",
      "std: 0.36263837969887386\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3670178466781875\n",
      "std: 0.34616915520228786\n",
      "min: -0.5962792947525848\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05698533432230351\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.403269788060067\n",
      "std: 0.017969540905044375\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4033866526494063\n",
      "std: 0.018020247497762282\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.06831478222589087\n",
      "min: 0.0315146628367286\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3240871428770376\n",
      "std: 0.2927397586566194\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4906690271421409\n",
      "std: 0.36327810735720606\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.062805083272483\n",
      "min: 0.08217236485510235\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1660093184576692\n",
      "std: 0.19784924720139188\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1724721288403828\n",
      "std: 0.2008637839077574\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06961935940681127\n",
      "min: 0.012243285406212305\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3314539004999737\n",
      "std: 0.3649244475852803\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3778246910079875\n",
      "std: 0.3430305220770618\n",
      "min: -0.5937646458571723\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05643585945448951\n",
      "min: 0.07114479798970585\n",
      "max: 0.3278390786150851\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406834940155917\n",
      "std: 0.00575065646069797\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069059425358657\n",
      "std: 0.0057789921734832835\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06655351420905349\n",
      "min: 0.03261298927097795\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3185639972050695\n",
      "std: 0.2931616360087071\n",
      "min: -0.7908255271605962\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49306733378301504\n",
      "std: 0.3617441234442973\n",
      "min: -0.36463610948806113\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266987100422244\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1601240983036027\n",
      "std: 0.21848996470387322\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1668257088534872\n",
      "std: 0.2223535187016317\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.07076484907455269\n",
      "min: 0.012277480605241307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33135368210600963\n",
      "std: 0.3701237581844722\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37723807287056077\n",
      "std: 0.34526334776114825\n",
      "min: -0.5944037525937597\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05665646423283184\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4059714745371845\n",
      "std: 0.00870402021297757\n",
      "min: 1.3566951501356845\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4060659361676884\n",
      "std: 0.00873888620169626\n",
      "min: 1.3571113015496101\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06655844426249591\n",
      "min: 0.032105568821074626\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3172025606587525\n",
      "std: 0.2930205572719901\n",
      "min: -0.78986856529348\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49323858255803466\n",
      "std: 0.3614890660410499\n",
      "min: -0.3639715909071615\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261523216100245\n",
      "min: 0.0822143147394386\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.164470357590451\n",
      "std: 0.2132921098525775\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1711279066591072\n",
      "std: 0.21465623468714098\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06933488350717894\n",
      "min: 0.010485201568579247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33370870588455304\n",
      "std: 0.36650178354536017\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3762998839070045\n",
      "std: 0.3450092130770497\n",
      "min: -0.595160198064053\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056639800154121615\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407111546985254\n",
      "std: 0.004905828665062811\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071571859409933\n",
      "std: 0.005148950608806111\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06655260862699422\n",
      "min: 0.03267862554261561\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3191464599697909\n",
      "std: 0.29305463532233433\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49232311171145116\n",
      "std: 0.3617985867760143\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06267684367710322\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.211319504368197\n",
      "std: 0.09407490375711496\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2166714140479755\n",
      "std: 0.10109060836168923\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06761745211456427\n",
      "min: 0.022280841443085894\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34576366366272154\n",
      "std: 0.3620736080083344\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36689324700837933\n",
      "std: 0.3454607277652494\n",
      "min: -0.595719691496236\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057098256997073146\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080575457464448\n",
      "std: 0.003419246092254995\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080669422634244\n",
      "std: 0.0037689551212011702\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06655196571120092\n",
      "min: 0.032795384228324766\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3214644767853367\n",
      "std: 0.2926861705131983\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48935161480093475\n",
      "std: 0.3618495028774541\n",
      "min: -0.37110810879721096\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999998\n",
      "std: 0.0627047569133754\n",
      "min: 0.08224047526152704\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1447548148644233\n",
      "std: 0.2751081386253739\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1517219100142333\n",
      "std: 0.27782780469101787\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.07167851306700457\n",
      "min: 0.007525264474855244\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3449995273608136\n",
      "std: 0.36356000590936316\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36611167738381045\n",
      "std: 0.34595307603418435\n",
      "min: -0.5962792947525848\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05697098811599768\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4034921833389777\n",
      "std: 0.01768777618142618\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4036013944308006\n",
      "std: 0.01774657806774207\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06657994418900406\n",
      "min: 0.03055686179011595\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.323704150676919\n",
      "std: 0.2928017986024397\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49049260676408085\n",
      "std: 0.3630683976528165\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06277270446375788\n",
      "min: 0.08217236485510235\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1667219038093712\n",
      "std: 0.19543605916756498\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1728486273171959\n",
      "std: 0.19846312938132146\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.0678663780364848\n",
      "min: 0.01065291048590247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33260721531394843\n",
      "std: 0.36445657697579903\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37540837218440565\n",
      "std: 0.34297014477001864\n",
      "min: -0.5937646458571723\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056414392018771506\n",
      "min: 0.07114479798970585\n",
      "max: 0.3278390786150851\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068698134297466\n",
      "std: 0.005672440587816114\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406916492121887\n",
      "std: 0.005706810301915964\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.064911533485609\n",
      "min: 0.03164151587758937\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3186173755732829\n",
      "std: 0.29329015172806955\n",
      "min: -0.7908255271605962\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49279469773057116\n",
      "std: 0.36174810815387975\n",
      "min: -0.36463610948806113\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266490320977257\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1610304387775914\n",
      "std: 0.215731735435333\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.167383640790088\n",
      "std: 0.21959278812155855\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.0689688893704885\n",
      "min: 0.011473070600501548\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3325520575491757\n",
      "std: 0.36950683352145175\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.374814593286488\n",
      "std: 0.3451555630614924\n",
      "min: -0.5944037525937597\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05663130404098398\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4060326859680123\n",
      "std: 0.00859037842883095\n",
      "min: 1.3566951501356845\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061013554701147\n",
      "std: 0.008629705750805433\n",
      "min: 1.3571113015496101\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06491628449989768\n",
      "min: 0.03096939210026705\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31728699773067215\n",
      "std: 0.2931445067355067\n",
      "min: -0.78986856529348\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49295054994981674\n",
      "std: 0.3614957550309652\n",
      "min: -0.3639715909071615\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999998\n",
      "std: 0.06261131967184619\n",
      "min: 0.0822143147394386\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1652546674235638\n",
      "std: 0.21042634328406415\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1715701351169325\n",
      "std: 0.211816385517823\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06759286114171822\n",
      "min: 0.010485201568579247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3348182184412275\n",
      "std: 0.36600975868240243\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3739210703122281\n",
      "std: 0.34490816422728404\n",
      "min: -0.595160198064053\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05661508444237542\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071362390888893\n",
      "std: 0.00484343565163351\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071586929381819\n",
      "std: 0.005088498469670633\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06491066132620651\n",
      "min: 0.031741498198526216\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31917859246642066\n",
      "std: 0.2931870247642272\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4920662665390816\n",
      "std: 0.3617969507282189\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06267109721263346\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2106612686777831\n",
      "std: 0.09314985731181781\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2157562428633526\n",
      "std: 0.10011788725691813\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06593725396035433\n",
      "min: 0.022280841443085894\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3465153091840564\n",
      "std: 0.3616135306878831\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3647490222588596\n",
      "std: 0.3452710142641929\n",
      "min: -0.595719691496236\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05705767015957986\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080509544869273\n",
      "std: 0.0033998669603678574\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080391503234713\n",
      "std: 0.0037510834888216933\n",
      "min: 1.3833005668824983\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06491004117667946\n",
      "min: 0.03183620850838592\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3214353475911665\n",
      "std: 0.29282272501428397\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4891662507229147\n",
      "std: 0.36184368977254683\n",
      "min: -0.37110810879721096\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06269799779565557\n",
      "min: 0.08224047526152704\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.145963554019295\n",
      "std: 0.2720914858314582\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1525590281601514\n",
      "std: 0.2748426317138535\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06985005560575314\n",
      "min: 0.006186380336109203\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.345850048092761\n",
      "std: 0.3630809043724464\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36398465311333855\n",
      "std: 0.3457759785157626\n",
      "min: -0.5962792947525848\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05693933780582151\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4036190031070206\n",
      "std: 0.017479148126259884\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4036995947624038\n",
      "std: 0.017545135705621544\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.0649370202092318\n",
      "min: 0.029206194874832503\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3236281284903777\n",
      "std: 0.2929278123215085\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49027353458625733\n",
      "std: 0.36303220398442065\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06276451045721647\n",
      "min: 0.08217236485510235\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.168915812570452\n",
      "std: 0.1938382198884879\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1747949632169299\n",
      "std: 0.19681455050222826\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06620561651138787\n",
      "min: 0.010119371837119922\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3335615283005786\n",
      "std: 0.36502525737448305\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37298695378122265\n",
      "std: 0.34382220390789303\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056418750726649404\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068482600902565\n",
      "std: 0.005671998768854648\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406896277745407\n",
      "std: 0.005714938371685204\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06335411069468455\n",
      "min: 0.030362678297744264\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3189294981257247\n",
      "std: 0.2934025786121103\n",
      "min: -0.790825527160596\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4922736476770977\n",
      "std: 0.36183150909285056\n",
      "min: -0.3705716567475959\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266972032411688\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.16340937557553\n",
      "std: 0.21412048855141863\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1695041467004479\n",
      "std: 0.21791539151913397\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06726817019599714\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3335420203686819\n",
      "std: 0.3699168477460765\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37239265426880774\n",
      "std: 0.34595279580935306\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05663183997686549\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4060329722346148\n",
      "std: 0.008582904159063421\n",
      "min: 1.3506838144968856\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061018388947768\n",
      "std: 0.008629319347442611\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06335870107099406\n",
      "min: 0.029592911610458298\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3176261883313904\n",
      "std: 0.2932523029674883\n",
      "min: -0.78986856529348\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49241612111534944\n",
      "std: 0.36158116822630504\n",
      "min: -0.3699403475327378\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261699150165853\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1675358455072562\n",
      "std: 0.20801628052237728\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.173596395956649\n",
      "std: 0.20940329790537984\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06594214159982008\n",
      "min: 0.010485201568579247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3357175784677894\n",
      "std: 0.36654962649766926\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37153329562648657\n",
      "std: 0.3457102418289219\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056614790429554765\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071104260148142\n",
      "std: 0.004860635245008859\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071352224862077\n",
      "std: 0.005110709506946034\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.063353269149093\n",
      "min: 0.030445625025564815\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31947031136813636\n",
      "std: 0.29330217957514093\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.491558909244473\n",
      "std: 0.3618745805574776\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06267510172553509\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.211787201045519\n",
      "std: 0.09193615190639365\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2167023147493492\n",
      "std: 0.09879837560561405\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06434365086653013\n",
      "min: 0.0222808414430859\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34706979009700684\n",
      "std: 0.3621957103612257\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3626016672300495\n",
      "std: 0.3459816476451069\n",
      "min: -0.6034392487620788\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05704234082375025\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080106686502447\n",
      "std: 0.0034118676355732154\n",
      "min: 1.3821938696936509\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080025404164371\n",
      "std: 0.0037686906444529605\n",
      "min: 1.3821938696936509\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06335266641528361\n",
      "min: 0.030588737112789473\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32166519466313254\n",
      "std: 0.2929399695072889\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4887298914001878\n",
      "std: 0.3619142948461782\n",
      "min: -0.3717341235297415\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06270083921269724\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1490136582869406\n",
      "std: 0.2688901848123671\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1553250003197033\n",
      "std: 0.271633987674884\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06811769468393278\n",
      "min: 0.006166630372460981\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.346487394912885\n",
      "std: 0.3636545804096305\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3618652129271169\n",
      "std: 0.3464960167712812\n",
      "min: -0.604656284537755\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05693255680226998\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4036965881585082\n",
      "std: 0.017309084840100023\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4037745337697056\n",
      "std: 0.01738512374805229\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06337871780762183\n",
      "min: 0.02819106303708063\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3238132931518217\n",
      "std: 0.2930358773894251\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4898047810737262\n",
      "std: 0.36307407539006165\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06276599548228076\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.171091526919481\n",
      "std: 0.19146190529573084\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1769468997790897\n",
      "std: 0.19438877265230017\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06462870655505434\n",
      "min: 0.010119371837119922\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33400857646018917\n",
      "std: 0.36519786391136677\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37421063200988874\n",
      "std: 0.3440375039370668\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056494145033694425\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068893732455092\n",
      "std: 0.005612392303772899\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069085902108671\n",
      "std: 0.0056666200470121735\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.061874715104379904\n",
      "min: 0.029677196829957623\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31891469881839396\n",
      "std: 0.2934759927934905\n",
      "min: -0.790825527160596\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4922126962314501\n",
      "std: 0.3618307389683952\n",
      "min: -0.3705716567475959\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266618375067635\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.165770022551329\n",
      "std: 0.21109452508062762\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1718299467312454\n",
      "std: 0.21484833504810652\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06565365634808731\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3340194151341373\n",
      "std: 0.3699439036909205\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37361534311110245\n",
      "std: 0.3461162181928301\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0567031370273376\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4060988649232915\n",
      "std: 0.008455874675294487\n",
      "min: 1.3506838144968856\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406137700852328\n",
      "std: 0.008510631801552251\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.061879145438854595\n",
      "min: 0.029304602606473062\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31763752278365887\n",
      "std: 0.29332140694757464\n",
      "min: -0.78986856529348\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49234376244316097\n",
      "std: 0.3615819436695253\n",
      "min: -0.3699403475327378\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261431975913037\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.169742947914815\n",
      "std: 0.205463016882291\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.175774293697292\n",
      "std: 0.20682627592416156\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06437511101894926\n",
      "min: 0.010213283256333729\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3361206732161049\n",
      "std: 0.3666955180567161\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3727830629456041\n",
      "std: 0.3458882152132187\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056686338683684195\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071432928654433\n",
      "std: 0.004820238466382115\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071402375528916\n",
      "std: 0.005078179658945194\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.061873902885507356\n",
      "min: 0.02973871779155569\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31943734005227087\n",
      "std: 0.29337897980494865\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4915116225465378\n",
      "std: 0.3618691730028183\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06267090176793598\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2127157057283837\n",
      "std: 0.0909631877241077\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2176778977145364\n",
      "std: 0.09759190391253098\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06283048989788019\n",
      "min: 0.021532927098359758\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3471580223094303\n",
      "std: 0.36240019266611095\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3640504831337344\n",
      "std: 0.34615891206811744\n",
      "min: -0.6034392487620788\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05709934047284883\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080186550605738\n",
      "std: 0.0034055394254400638\n",
      "min: 1.3821938696936509\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407984234689458\n",
      "std: 0.003771175132220064\n",
      "min: 1.3821938696936509\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.061873319620226734\n",
      "min: 0.029739932575913033\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3215772895907496\n",
      "std: 0.2930216481776215\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4887461681262895\n",
      "std: 0.36190633030895575\n",
      "min: -0.3717341235297415\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06269571174359281\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1516532674205808\n",
      "std: 0.2656292293797735\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.157915316681855\n",
      "std: 0.26837087591437725\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06647477434593503\n",
      "min: 0.006166630372460981\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34665617488322575\n",
      "std: 0.36383890171046435\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36335058309407314\n",
      "std: 0.34669235864172726\n",
      "min: -0.604656284537755\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05699812717715804\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4038378974814105\n",
      "std: 0.01703285836658007\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4038831113589156\n",
      "std: 0.01711718147025164\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.061898476115904266\n",
      "min: 0.027856629323408346\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32368215623362157\n",
      "std: 0.2931104804250076\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48979306182828714\n",
      "std: 0.3630388824613698\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0627596166281312\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1721928683342804\n",
      "std: 0.18881196127060942\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1776020523649096\n",
      "std: 0.1917610689019523\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06313003076147403\n",
      "min: 0.010119371837119922\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33483297051333827\n",
      "std: 0.36533654999654336\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3736107087149878\n",
      "std: 0.3441600188411552\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056584597684238506\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069245309554765\n",
      "std: 0.0055406772401926044\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069333695262387\n",
      "std: 0.005593081074519504\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06046749246310951\n",
      "min: 0.028833617859775867\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3188469413557496\n",
      "std: 0.29360574254888683\n",
      "min: -0.790825527160596\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4922532164782198\n",
      "std: 0.36184601054424786\n",
      "min: -0.3705716567475959\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626707465194437\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1670129707100976\n",
      "std: 0.2081468920677371\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.172618155429508\n",
      "std: 0.21190384644677276\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06412014390536155\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3348750969941181\n",
      "std: 0.3699472190602343\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3730071227719068\n",
      "std: 0.3461918621310378\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05678979222698169\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4061546633157738\n",
      "std: 0.008351838214870604\n",
      "min: 1.3506838144968856\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061820558275842\n",
      "std: 0.008406101747456492\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06047177593982262\n",
      "min: 0.028234329879313694\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31759582244234824\n",
      "std: 0.293447422536197\n",
      "min: -0.78986856529348\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4923724548847112\n",
      "std: 0.3615992519399639\n",
      "min: -0.3699403475327378\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261979384974119\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.17079019015614\n",
      "std: 0.20343473430050027\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1763705564234812\n",
      "std: 0.2048293991545831\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06288644158429962\n",
      "min: 0.010002868444101837\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3369085487745711\n",
      "std: 0.36679708635967606\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37219657601914125\n",
      "std: 0.34596901313662537\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0567729283404571\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407169196029657\n",
      "std: 0.00476784484811595\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407156724748701\n",
      "std: 0.0050201209249390285\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06046670807454432\n",
      "min: 0.028873835285982842\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3193534030162696\n",
      "std: 0.2935112563004964\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4915636636285929\n",
      "std: 0.3618802662428199\n",
      "min: -0.37110810879721096\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06267489872073803\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2126000147774323\n",
      "std: 0.09037101247786003\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.217173187962128\n",
      "std: 0.09699983928292402\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06139204248077031\n",
      "min: 0.019740216752738418\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34764351819011774\n",
      "std: 0.3625632946675824\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3636672148040978\n",
      "std: 0.3462103549208799\n",
      "min: -0.6034392487620788\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057172360551376936\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080213254641323\n",
      "std: 0.0033779243319185387\n",
      "min: 1.3821938696936509\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079787915858704\n",
      "std: 0.0037348457447426656\n",
      "min: 1.3821938696936509\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.060466143047569504\n",
      "min: 0.028904214731196327\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3214417384838512\n",
      "std: 0.2931609400561361\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48885938698191284\n",
      "std: 0.3619160146802749\n",
      "min: -0.3717341235297415\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06269884899511709\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1532156303344248\n",
      "std: 0.2622243276354653\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1590075812748764\n",
      "std: 0.2649829043119522\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06491444545559857\n",
      "min: 0.006166630372460981\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34721482584238633\n",
      "std: 0.3639826031876123\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36299914946843564\n",
      "std: 0.3467533007944904\n",
      "min: -0.604656284537755\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05707914347937662\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4039443568529537\n",
      "std: 0.016865465756021807\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.403976360698293\n",
      "std: 0.0169523799623239\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06049048188214663\n",
      "min: 0.02646452320204286\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32350503020725624\n",
      "std: 0.29324165696436805\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4898811896479192\n",
      "std: 0.36302222158019776\n",
      "min: -0.37430542601041916\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06276163865743341\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1718696418998795\n",
      "std: 0.18606933836203432\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1772592196910254\n",
      "std: 0.18903858599288156\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.061703745133410065\n",
      "min: 0.010119371837119922\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3366722186529176\n",
      "std: 0.3651738678825939\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3707432920152495\n",
      "std: 0.34464874772958726\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05664569293346641\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069339797568523\n",
      "std: 0.0054823903633415706\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069141745425024\n",
      "std: 0.005557525279797326\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.05912716387426215\n",
      "min: 0.027991775758831848\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31913642581998897\n",
      "std: 0.29369390225837366\n",
      "min: -0.790825527160596\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4918400561457155\n",
      "std: 0.36188483847759784\n",
      "min: -0.37398509321533907\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06267731272788737\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1668252821629572\n",
      "std: 0.2054858796178428\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1724025369492677\n",
      "std: 0.2092528860395025\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.06266135901447199\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3367518413178378\n",
      "std: 0.3696607471800061\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37013716933602075\n",
      "std: 0.34663497289237255\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05684787467471076\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4061834587628226\n",
      "std: 0.008261029098515131\n",
      "min: 1.3506838144968856\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061813720182907\n",
      "std: 0.008330995629361864\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.05913130979551363\n",
      "min: 0.02740487066310008\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.317910643875746\n",
      "std: 0.29353281212173604\n",
      "min: -0.78986856529348\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4919479607640468\n",
      "std: 0.3616403191397509\n",
      "min: -0.37344593929423825\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06262721345788706\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1705238701942344\n",
      "std: 0.2002927120769439\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1760787079639836\n",
      "std: 0.2017414893198439\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.06146857159874451\n",
      "min: 0.010002868444101837\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3387091712623372\n",
      "std: 0.3666028132203558\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.369354361903168\n",
      "std: 0.34640886285309846\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05683055926133445\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407171577840045\n",
      "std: 0.004739595843530342\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407131276131175\n",
      "std: 0.005012625458154073\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.05912640610741962\n",
      "min: 0.027951098103166094\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31962720163302183\n",
      "std: 0.2936016995519938\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4911618366096254\n",
      "std: 0.361914736658885\n",
      "min: -0.37428429813389813\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06268089539738099\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.211162944866511\n",
      "std: 0.08940570098067045\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2157749787821899\n",
      "std: 0.09592489324465335\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.06002200812367253\n",
      "min: 0.019740216752738418\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34915587115894053\n",
      "std: 0.36238307438954515\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3610201965085283\n",
      "std: 0.34657811381601045\n",
      "min: -0.6034392487620788\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0572168670411656\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080016461414713\n",
      "std: 0.003384778110062466\n",
      "min: 1.3810492880477454\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079326748356178\n",
      "std: 0.003765371784159315\n",
      "min: 1.3810492880477454\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.059125858288856255\n",
      "min: 0.0279719395933822\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32166475207187917\n",
      "std: 0.29325472492829757\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4885184614371569\n",
      "std: 0.36194664784809416\n",
      "min: -0.37515817449463473\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06270404304198965\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.153515556824762\n",
      "std: 0.2585467114033872\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1592613255291218\n",
      "std: 0.26135766708761643\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.0634298855542131\n",
      "min: 0.006166630372460981\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34881221907518545\n",
      "std: 0.3638003160807227\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36037249285079903\n",
      "std: 0.3471230733050342\n",
      "min: -0.604656284537755\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05713175467154351\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40403223585518\n",
      "std: 0.016671596124213553\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4040328608753398\n",
      "std: 0.016768093418839284\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.05914942096504617\n",
      "min: 0.02593267233714464\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3236909294523873\n",
      "std: 0.2933268495861131\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48951160743852096\n",
      "std: 0.36302756562326566\n",
      "min: -0.37495931146305067\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06276563566087567\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1720967243234948\n",
      "std: 0.18446705558713014\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1775616832438514\n",
      "std: 0.18736002551928116\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.060345412552073416\n",
      "min: 0.009317739624232905\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3376796551715535\n",
      "std: 0.36555355422886915\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3711536086729647\n",
      "std: 0.34517649440647663\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05672095279043926\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069805586159172\n",
      "std: 0.005434238961174225\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069711411085206\n",
      "std: 0.005504238029213416\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.057848957884761965\n",
      "min: 0.027031909627465055\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31918484226386484\n",
      "std: 0.2936751735713963\n",
      "min: -0.790825527160596\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49187714858744847\n",
      "std: 0.36184558157296276\n",
      "min: -0.373985093215339\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06267495062974739\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1672261474239969\n",
      "std: 0.20329731180645655\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.172868752105229\n",
      "std: 0.20701245902468596\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.06127198089949303\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.337789095006651\n",
      "std: 0.3699163561704418\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3705531461022512\n",
      "std: 0.34711888132824387\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05691994135048069\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4062502252143523\n",
      "std: 0.008175367836093577\n",
      "min: 1.3506838144968856\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4062576342353643\n",
      "std: 0.0082446759813325\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.057852973845847026\n",
      "min: 0.02653708729878518\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.317981785922671\n",
      "std: 0.29351098702627426\n",
      "min: -0.78986856529348\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49197612339625435\n",
      "std: 0.3616026976017778\n",
      "min: -0.3734459392942381\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06262560192091506\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1708380160879313\n",
      "std: 0.1979996816018393\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1764620065928815\n",
      "std: 0.19942194113387907\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.06011780409527324\n",
      "min: 0.009430200681931684\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33967495597614605\n",
      "std: 0.36695897721257914\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36979569248785965\n",
      "std: 0.34690234179714896\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05690209948021308\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072118312998538\n",
      "std: 0.004694829833171887\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071826996663535\n",
      "std: 0.004960148334018622\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.05784822371904757\n",
      "min: 0.02712877235847921\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31966035636442985\n",
      "std: 0.29358613970594744\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49121102684585544\n",
      "std: 0.3618718890537892\n",
      "min: -0.37428429813389824\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06267797110942719\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2103994112634346\n",
      "std: 0.08940739210304599\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2151401204473065\n",
      "std: 0.09559611137681341\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.05871625800223185\n",
      "min: 0.018961525349030825\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34986452487589487\n",
      "std: 0.36277687967405636\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3616375573811221\n",
      "std: 0.3470628809613112\n",
      "min: -0.6034392487620788\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05727722448324579\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080211696401652\n",
      "std: 0.00334981648786524\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079645989619989\n",
      "std: 0.0037175088184288707\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.057847691626834126\n",
      "min: 0.027379661012140677\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32165102064120926\n",
      "std: 0.2932433350809404\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48862386391350426\n",
      "std: 0.36190285236603587\n",
      "min: -0.37515817449463496\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0627004218675719\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.154475693991284\n",
      "std: 0.25468850053994646\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.160266790933832\n",
      "std: 0.25751952400036554\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.062016007271664904\n",
      "min: 0.006166630372460981\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34957476190502673\n",
      "std: 0.36417210981684495\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3610268926832386\n",
      "std: 0.34760945611380756\n",
      "min: -0.604656284537755\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057198050533131435\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4041606030182512\n",
      "std: 0.016458017942208605\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.404168774390884\n",
      "std: 0.016559367857778742\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.057870519329192745\n",
      "min: 0.025333449783313096\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3236380600592028\n",
      "std: 0.29330842944259156\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4895954107311318\n",
      "std: 0.3629585615568844\n",
      "min: -0.37495931146305067\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06276082474257226\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1739888519841233\n",
      "std: 0.18250914576274518\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.179221682006701\n",
      "std: 0.18535838988322237\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05904893116680001\n",
      "min: 0.009304979576478311\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33783320083886903\n",
      "std: 0.3655083071662614\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37181530913842964\n",
      "std: 0.34594090932672544\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05678529310532888\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40695030194457\n",
      "std: 0.005403540048688166\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069281594062988\n",
      "std: 0.0054872160763603855\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.056628551782202795\n",
      "min: 0.026387124740815227\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3194133777277449\n",
      "std: 0.2937108608884059\n",
      "min: -0.790825527160596\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49164681093741625\n",
      "std: 0.3619784653406267\n",
      "min: -0.373985093215339\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06269364716959287\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1692362710177036\n",
      "std: 0.2012351797639728\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1746396112188686\n",
      "std: 0.20489497263144196\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05994656143111053\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3379621161719636\n",
      "std: 0.36976257873449575\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37121762138770426\n",
      "std: 0.34784130113843836\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056980641546678146\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4062360688896185\n",
      "std: 0.008124269778783529\n",
      "min: 1.3506838144968856\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4062300680591864\n",
      "std: 0.00820351228809545\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05663244746289286\n",
      "min: 0.025694102862231612\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31823191074423135\n",
      "std: 0.2935445137887549\n",
      "min: -0.78986856529348\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.491737139423247\n",
      "std: 0.3617377498192648\n",
      "min: -0.3734459392942381\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264505519650028\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1727534068313696\n",
      "std: 0.19597235740865016\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1781403800580066\n",
      "std: 0.1973745797070376\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05882889295096384\n",
      "min: 0.008665723397299947\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3397852028651271\n",
      "std: 0.36689754458417634\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3704821870139405\n",
      "std: 0.34763521013804616\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056962608175880065\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071767870840262\n",
      "std: 0.0047033733813781585\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071355201555522\n",
      "std: 0.004977807557453451\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05662784159748415\n",
      "min: 0.0263240870466726\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31987427599488905\n",
      "std: 0.29362421669991556\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49099088493680915\n",
      "std: 0.36200103632617436\n",
      "min: -0.37428429813389824\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06269614636481703\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.211295472097498\n",
      "std: 0.08851621059388293\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.215850492330234\n",
      "std: 0.09460208688081696\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.057469493016496835\n",
      "min: 0.01833100890741517\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34971927547507375\n",
      "std: 0.3627722161471569\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3624998417739906\n",
      "std: 0.34778260713822995\n",
      "min: -0.6034392487620788\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.05732630040405851\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079705030098004\n",
      "std: 0.003362900459274508\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079029694371372\n",
      "std: 0.0037405516761657262\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.056627323155892424\n",
      "min: 0.026446793506531643\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32181853644926434\n",
      "std: 0.2932845306614042\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4884585408821028\n",
      "std: 0.3620279811845903\n",
      "min: -0.37515817449463496\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06271774173047283\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1567499852449405\n",
      "std: 0.2521870769345427\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1622914650934715\n",
      "std: 0.254992520686534\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.06066817947417005\n",
      "min: 0.005570598384979188\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34948185719672714\n",
      "std: 0.36415744461811894\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3619121550105037\n",
      "std: 0.3483414460707288\n",
      "min: -0.604656284537755\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057252979310842805\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.404204226819703\n",
      "std: 0.016278834335854538\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.404197461296869\n",
      "std: 0.016388544986610413\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05664946238784717\n",
      "min: 0.02451024295948366\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3237693465757817\n",
      "std: 0.2933426788187543\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4894066317930975\n",
      "std: 0.36306162308577755\n",
      "min: -0.37495931146305067\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0627770975674\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1765729941411154\n",
      "std: 0.18025693167781254\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1814238027241384\n",
      "std: 0.18300086951055025\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.057810043134269115\n",
      "min: 0.009287357660340029\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3387796714155771\n",
      "std: 0.3656715612697611\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3728585841690663\n",
      "std: 0.3462445117703612\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05686308867374341\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070309152861369\n",
      "std: 0.005350822311150389\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070217979813437\n",
      "std: 0.005433090743069363\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.055462015144880535\n",
      "min: 0.02572834788141927\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3193358596235118\n",
      "std: 0.2937684738239519\n",
      "min: -0.790825527160596\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49167230312193705\n",
      "std: 0.3619087965276276\n",
      "min: -0.373985093215339\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06268336489437842\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1719386045788835\n",
      "std: 0.1985422121358312\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1769541115608275\n",
      "std: 0.20209976186532316\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05868026380919208\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.338922829800473\n",
      "std: 0.36981016012608153\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37225875324865076\n",
      "std: 0.34810110879873796\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05705470343293497\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4063366383612184\n",
      "std: 0.008038063403881433\n",
      "min: 1.3506838144968856\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406342941972264\n",
      "std: 0.008117266329137911\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05546579481186564\n",
      "min: 0.025194933674013015\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31817409032645383\n",
      "std: 0.2935992258256236\n",
      "min: -0.78986856529348\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49175512318686754\n",
      "std: 0.36166959389039155\n",
      "min: -0.3734459392942381\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06263546104415191\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.175405654045885\n",
      "std: 0.19320432398908813\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1804057154532046\n",
      "std: 0.1945304501887069\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05759681721971782\n",
      "min: 0.008665723397299947\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3406927924829393\n",
      "std: 0.36703471779099783\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3715517870311927\n",
      "std: 0.34790902838877297\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05703719551675467\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072534057497592\n",
      "std: 0.0046554183218680805\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407225942011456\n",
      "std: 0.004925541808137922\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05546132606932809\n",
      "min: 0.025847627836113052\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31978171252309656\n",
      "std: 0.2936845509375755\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4910288560960891\n",
      "std: 0.361927780377267\n",
      "min: -0.37428429813389824\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626853475386517\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.212834551007623\n",
      "std: 0.08758232748769636\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.217051219865862\n",
      "std: 0.09347847530281106\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05627791277400411\n",
      "min: 0.018331008907415167\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3503889990228224\n",
      "std: 0.3629523444415901\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36371213328513663\n",
      "std: 0.3480571325948536\n",
      "min: -0.6034392487620788\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05739013279389209\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408027973704206\n",
      "std: 0.0033335543951658222\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079750816132586\n",
      "std: 0.0037038208231686804\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05546082235022943\n",
      "min: 0.02583568953288817\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3216842486259664\n",
      "std: 0.29335020722955574\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48854520231722237\n",
      "std: 0.3619537247814103\n",
      "min: -0.37515817449463496\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06270629944420716\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1596082664266307\n",
      "std: 0.24950883221929285\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1647558699349558\n",
      "std: 0.25223199480413233\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05938099020050422\n",
      "min: 0.005402427103959512\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35020123890245464\n",
      "std: 0.36431630166124696\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3631551172945606\n",
      "std: 0.3486228597377931\n",
      "min: -0.604656284537755\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057322239311329945\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4043520957502216\n",
      "std: 0.016109730624260212\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4043562914632053\n",
      "std: 0.01622251785323289\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05548231149871151\n",
      "min: 0.024053885361110583\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3235982009641379\n",
      "std: 0.29340302226244935\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48947246480483925\n",
      "std: 0.36296498232217833\n",
      "min: -0.37495931146305067\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06276454408598718\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1765630325907366\n",
      "std: 0.17760056595562015\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1810553857849029\n",
      "std: 0.180364804757051\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.056625685770372865\n",
      "min: 0.009287357660340029\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.337229247061685\n",
      "std: 0.3642728319141045\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37247957757105565\n",
      "std: 0.3451419316924448\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05674914320865355\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070920446766217\n",
      "std: 0.005275115823708679\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070936394051288\n",
      "std: 0.005357099389126545\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05434577398467738\n",
      "min: 0.0251597304591793\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31904532904807986\n",
      "std: 0.29366381059313956\n",
      "min: -0.790825527160596\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4915722858528816\n",
      "std: 0.36177511320908334\n",
      "min: -0.373985093215339\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266470808815865\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1720188825045323\n",
      "std: 0.19583509642697852\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1766700145400395\n",
      "std: 0.19939777535162634\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.0574702844416835\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.337392029975468\n",
      "std: 0.3683191530442122\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37187663656373116\n",
      "std: 0.34696512253080747\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056937682700905226\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064148018622171\n",
      "std: 0.007924504209638819\n",
      "min: 1.3506838144968856\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406431052395583\n",
      "std: 0.008005325163675166\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.054349442892059875\n",
      "min: 0.0247331403052161\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3179037753524825\n",
      "std: 0.2934920716135966\n",
      "min: -0.78986856529348\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.491646624641231\n",
      "std: 0.36153766505799007\n",
      "min: -0.3734459392942381\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261748260428027\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1753751163702064\n",
      "std: 0.1908737289957967\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1800131488754908\n",
      "std: 0.19222262754519065\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05641949432949584\n",
      "min: 0.008665723397299947\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3391109719866885\n",
      "std: 0.3656187056512755\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3711897610405511\n",
      "std: 0.34677720617937324\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05692043663665192\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073073076972449\n",
      "std: 0.004591203800671179\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072913173318191\n",
      "std: 0.004857927294617118\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05434510539671973\n",
      "min: 0.025220280206829346\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3194777750429256\n",
      "std: 0.29358249513402224\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4909391422163362\n",
      "std: 0.36179054422151047\n",
      "min: -0.37428429813389824\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626662016173784\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2117662328853656\n",
      "std: 0.08718525638528067\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2156642864649478\n",
      "std: 0.09307130760369146\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05513861126248383\n",
      "min: 0.018331008907415167\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34858660791190726\n",
      "std: 0.3616304743115841\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3635008156798357\n",
      "std: 0.34690764889574116\n",
      "min: -0.6034392487620788\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057264519726782835\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080606907571043\n",
      "std: 0.0032885955480933546\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408020189209636\n",
      "std: 0.0036520487574638826\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.054344615893024695\n",
      "min: 0.02527211819377393\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3213407639400617\n",
      "std: 0.2932551087902382\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4885036843010827\n",
      "std: 0.3618150469937871\n",
      "min: -0.37515817449463496\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06268657229528457\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1598957508668528\n",
      "std: 0.2464362766693032\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1646684855539124\n",
      "std: 0.24918052630692988\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05815105961415135\n",
      "min: 0.005402427103959512\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3484450712728517\n",
      "std: 0.36296632201548074\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36296896503664977\n",
      "std: 0.34747787678539677\n",
      "min: -0.604656284537755\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05720111546955246\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4044758603577712\n",
      "std: 0.0159123662350241\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4044886445963682\n",
      "std: 0.016029086142942628\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05436548529338988\n",
      "min: 0.02351364650970505\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3232196858220487\n",
      "std: 0.29330287361562635\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4894099239358305\n",
      "std: 0.3628053397542704\n",
      "min: -0.37495931146305067\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06274370952189195\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1769416969407975\n",
      "std: 0.1762503452720106\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1815698114753348\n",
      "std: 0.17900838627675117\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05549253554092786\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3358271737453398\n",
      "std: 0.3655490577772488\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3726862299272824\n",
      "std: 0.34470753249080693\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05671875171815681\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071145736573032\n",
      "std: 0.0052271222271829156\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071404458706305\n",
      "std: 0.005308675029131261\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05327656927840296\n",
      "min: 0.024448733075047146\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.318641909734495\n",
      "std: 0.29388657024741727\n",
      "min: -0.790825527160596\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4916285820798533\n",
      "std: 0.3616180603213151\n",
      "min: -0.37398509321533907\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06263813776896984\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1725320327744615\n",
      "std: 0.19392811135982535\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1773128881005908\n",
      "std: 0.19749197233055998\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05631261322375504\n",
      "min: 0.008105277866865783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3360071015280208\n",
      "std: 0.3694787992390807\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37208189738607245\n",
      "std: 0.3464958110533783\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056904466045077984\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064527081914457\n",
      "std: 0.007839868600095296\n",
      "min: 1.3506838144968856\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4064925779731237\n",
      "std: 0.00792270672749702\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.053280134227170275\n",
      "min: 0.02401138520323987\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31751895957058074\n",
      "std: 0.293712006365132\n",
      "min: -0.78986856529348\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4916959890716937\n",
      "std: 0.3613820496591258\n",
      "min: -0.373445939294238\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259154991138882\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1758192039036341\n",
      "std: 0.18878300557917868\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1805894664657652\n",
      "std: 0.19015319476864834\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05529230103802724\n",
      "min: 0.008665723397299947\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33767257391302313\n",
      "std: 0.3668761562218785\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3714149709568554\n",
      "std: 0.34631224682587625\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056887027060357045\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073255847713273\n",
      "std: 0.004548143619551629\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073344794077478\n",
      "std: 0.004811559515561374\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.053275919524034106\n",
      "min: 0.024463642203173167\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31906168399644186\n",
      "std: 0.2938089383756818\n",
      "min: -0.7909899406319492\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49100473486015817\n",
      "std: 0.3616304901999776\n",
      "min: -0.37428429813389824\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06263918370047351\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.211385636260251\n",
      "std: 0.08632074672320827\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2154575460542372\n",
      "std: 0.09210387311473947\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05404717888868345\n",
      "min: 0.018331008907415163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34693929889440056\n",
      "std: 0.36298515338659304\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3638765478490366\n",
      "std: 0.34643892831233525\n",
      "min: -0.6034392487620788\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05722229951920936\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080621288914343\n",
      "std: 0.003269380632270135\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080472740368044\n",
      "std: 0.0036236864771747417\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05327544326981951\n",
      "min: 0.02445184668465924\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3208864649755613\n",
      "std: 0.2934875542377546\n",
      "min: -0.7909899406319492\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4886161288495083\n",
      "std: 0.36165467991742106\n",
      "min: -0.3751581744946348\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06265901867682046\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1608020019583902\n",
      "std: 0.24363418482064095\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.165693293712616\n",
      "std: 0.24641550398475218\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.056974002961303866\n",
      "min: 0.005036729970517471\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34683420457468767\n",
      "std: 0.3642933201251303\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3633677389277065\n",
      "std: 0.34700833586708874\n",
      "min: -0.604656284537755\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05716325144118263\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4045613848558542\n",
      "std: 0.01573144750541513\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4045966249084822\n",
      "std: 0.015853060258574924\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.0532957269412649\n",
      "min: 0.022805539127960024\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3227304483749398\n",
      "std: 0.29353287708464343\n",
      "min: -0.7915201716103982\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48950466633104356\n",
      "std: 0.3626242336536079\n",
      "min: -0.3749593114630508\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06271512641207323\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1766938238088294\n",
      "std: 0.17502178763405057\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1813523491401787\n",
      "std: 0.17770409032837137\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05440700931554552\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3367791820349287\n",
      "std: 0.36603237578202635\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37027130286668847\n",
      "std: 0.3453393395940724\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05674217339793517\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071062062208504\n",
      "std: 0.005181865149530587\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407121527194516\n",
      "std: 0.005268079733928426\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05225141674308613\n",
      "min: 0.023899749454353397\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3189616072895714\n",
      "std: 0.29402054746396133\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4910951978647964\n",
      "std: 0.3616939800789293\n",
      "min: -0.3887925499428951\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626426979357331\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1723903742645676\n",
      "std: 0.1926414420981804\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.177194557203235\n",
      "std: 0.1961323158000797\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05520412953513183\n",
      "min: 0.008105277866865783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33697657519332963\n",
      "std: 0.36986351087787134\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3696659229081899\n",
      "std: 0.34708980308152027\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05692487798674362\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064585600670692\n",
      "std: 0.007777263557036448\n",
      "min: 1.3506838144968856\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406487326280547\n",
      "std: 0.007863595435622902\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05225488473279827\n",
      "min: 0.023300073464182905\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3178572694417061\n",
      "std: 0.2938448532582051\n",
      "min: -0.7971594015816316\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4911553409192666\n",
      "std: 0.3614600651814111\n",
      "min: -0.3883083708185302\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259676456656421\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1756110544989653\n",
      "std: 0.18719507796756463\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1804080766311529\n",
      "std: 0.18851304120404097\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05421256412037885\n",
      "min: 0.008210139074399584\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33859010286577496\n",
      "std: 0.36733800917110043\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36901925485455395\n",
      "std: 0.34690860375987626\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05690735900889513\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073137250041308\n",
      "std: 0.004520763894021976\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073126341343318\n",
      "std: 0.004785523427068764\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05225078542826612\n",
      "min: 0.02391551196088474\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.319369965404044\n",
      "std: 0.2939447101203193\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4904801383191256\n",
      "std: 0.36170322519758014\n",
      "min: -0.3890895033732395\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264334116515695\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2103860042068464\n",
      "std: 0.08643127854678935\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.21452296467087\n",
      "std: 0.09193743922136875\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05300133010381332\n",
      "min: 0.01656583730500829\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3476471290578232\n",
      "std: 0.3634759713387253\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36163494441667854\n",
      "std: 0.34697737601418566\n",
      "min: -0.6034392487620788\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057233620477383985\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408035602064581\n",
      "std: 0.0032698973133768205\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080114935364563\n",
      "std: 0.0036231897518902365\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05225032165413041\n",
      "min: 0.023937901446547397\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32115524679160495\n",
      "std: 0.2936250541684237\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4881388989268945\n",
      "std: 0.36172292753161395\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266252404901071\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.161058612196397\n",
      "std: 0.24113495946988006\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1659609445865302\n",
      "std: 0.24389879536695436\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.0558471162262531\n",
      "min: 0.005036729970517471\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3475787976694809\n",
      "std: 0.36477235689065146\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36113871993513436\n",
      "std: 0.3475395875068535\n",
      "min: -0.604656284537755\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05717870413243995\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4046171078706866\n",
      "std: 0.015564957665879451\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.404640002786663\n",
      "std: 0.01569048940220579\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05227005091188808\n",
      "min: 0.02222119957060416\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32296836240443655\n",
      "std: 0.2936642636088075\n",
      "min: -0.7974335654434678\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48900701198258223\n",
      "std: 0.3626739265440209\n",
      "min: -0.3895482882391525\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06271769133267825\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1793738001171032\n",
      "std: 0.17399983610105338\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1838159148388405\n",
      "std: 0.1765799723792145\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.053365459248199416\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3373950505355216\n",
      "std: 0.366402445478205\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37072727162597474\n",
      "std: 0.34591250060135703\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05683450643702679\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407182085289721\n",
      "std: 0.005144150965222357\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072098061700855\n",
      "std: 0.005230330792651444\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.0512675837602107\n",
      "min: 0.02323263082224028\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31901598418749244\n",
      "std: 0.29400492776523096\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4910967064385228\n",
      "std: 0.36170547818296084\n",
      "min: -0.38879254994289497\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.062645714244738\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1751840559993354\n",
      "std: 0.19126313453709087\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.179766450538659\n",
      "std: 0.1946535817755504\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05414063954561685\n",
      "min: 0.008105277866865783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3376080960492734\n",
      "std: 0.37014302398936827\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37012667248348613\n",
      "std: 0.34762847015086407\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05701429079499637\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065498191341883\n",
      "std: 0.007708062432541042\n",
      "min: 1.3506838144968856\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065904121770143\n",
      "std: 0.0077962770952010405\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.051270958438409876\n",
      "min: 0.022761353587945832\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31792854648123137\n",
      "std: 0.2938273828644122\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4911511966672078\n",
      "std: 0.36147289868621535\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260035918399295\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1783132897622803\n",
      "std: 0.18600600945439055\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1828906503516152\n",
      "std: 0.18724460692546532\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05317659997005294\n",
      "min: 0.007350254367341712\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33917488673659363\n",
      "std: 0.3676872103216703\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3694963451695024\n",
      "std: 0.34745537409478777\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05699674378931266\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073855076079076\n",
      "std: 0.004487938941933268\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073974338858108\n",
      "std: 0.0047501709026497715\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05126696942773546\n",
      "min: 0.023317399501020755\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31941321791758415\n",
      "std: 0.29393062680576865\n",
      "min: -0.7978409502088328\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4904908979845037\n",
      "std: 0.36171206736424005\n",
      "min: -0.3890895033732396\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264597294138548\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2123756118207136\n",
      "std: 0.08602262817688983\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.21632510824597\n",
      "std: 0.09133311664764164\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05199735020562879\n",
      "min: 0.015962127648045187\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3480315871091885\n",
      "std: 0.3638685955444273\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.362253709334115\n",
      "std: 0.3475194051131284\n",
      "min: -0.6034392487620788\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057314096892255466\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080931461867081\n",
      "std: 0.0032437803456687574\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080826440750622\n",
      "std: 0.0035922732019795936\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05126651717524665\n",
      "min: 0.023409147053111576\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.321162052154595\n",
      "std: 0.29361506718784\n",
      "min: -0.7976242858584903\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4881936581006037\n",
      "std: 0.36173075942876565\n",
      "min: -0.38967766754115846\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266458226563115\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1640854078459149\n",
      "std: 0.23935342739957313\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1687584522469543\n",
      "std: 0.2420490480231712\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05476648735394323\n",
      "min: 0.005036729970517471\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34799832916000956\n",
      "std: 0.36514871449766184\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36177570471104237\n",
      "std: 0.34808373207498783\n",
      "min: -0.604656284537755\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05726339805075701\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40475045796894\n",
      "std: 0.015414031077875003\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4047842281216574\n",
      "std: 0.015543112722376056\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.051285721032469714\n",
      "min: 0.021675893672294638\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32294387525120294\n",
      "std: 0.2936496112832422\n",
      "min: -0.7974335654434678\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4890446352414492\n",
      "std: 0.36266290343971985\n",
      "min: -0.38954828823915255\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06271883844059946\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.180609997006428\n",
      "std: 0.1716852578768217\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.184887217769129\n",
      "std: 0.1742688165575916\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05236496546793809\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33818199232456087\n",
      "std: 0.3658087835076033\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.37114873714764257\n",
      "std: 0.3458855107635484\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05687022097729006\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407249759954272\n",
      "std: 0.0050974774958085925\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072688606004524\n",
      "std: 0.0051779957372394035\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05032256170136117\n",
      "min: 0.022710735977149555\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.319027940051316\n",
      "std: 0.2939744097537591\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49121023377889295\n",
      "std: 0.36171078789879524\n",
      "min: -0.38879254994289497\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06265046043480825\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1765018198282946\n",
      "std: 0.18885818312726235\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1809142126663765\n",
      "std: 0.19225104577750404\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.053119425898490884\n",
      "min: 0.008105277866865783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3384082176562441\n",
      "std: 0.36947262182302537\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.370546614087487\n",
      "std: 0.3475709072348952\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05704730543907245\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066320909376213\n",
      "std: 0.007632512750628938\n",
      "min: 1.3506838144968856\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066635877775187\n",
      "std: 0.007717452266027893\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05032584757301508\n",
      "min: 0.022306252443628164\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31795705594702334\n",
      "std: 0.2937956450120147\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49125935580975355\n",
      "std: 0.36148000351472287\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260572239321784\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1795658795918962\n",
      "std: 0.18364723124653928\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.183974396200863\n",
      "std: 0.1849079100697555\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.052181490338141644\n",
      "min: 0.007350254367341712\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33993429296032657\n",
      "std: 0.36707959595010387\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3699370481478801\n",
      "std: 0.34740617479592373\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05703002189884932\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074477513901906\n",
      "std: 0.00444319561496442\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074516032604802\n",
      "std: 0.004698395773915514\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05032196349729897\n",
      "min: 0.022744521023807158\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31941420037551516\n",
      "std: 0.2939021850270534\n",
      "min: -0.7978409502088328\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4906136306073653\n",
      "std: 0.36171498546683784\n",
      "min: -0.3890895033732396\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06265035033020884\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2127679827274327\n",
      "std: 0.08512954297177887\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2165832667615888\n",
      "std: 0.09040855838307299\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05103315128263795\n",
      "min: 0.015962127648045187\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3486000446999267\n",
      "std: 0.3632929923507612\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36281823432643256\n",
      "std: 0.3474632836898718\n",
      "min: -0.6034392487620788\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057339368591518336\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081394908635392\n",
      "std: 0.003208720623395866\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408121804972756\n",
      "std: 0.003548480285382181\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05032152248983127\n",
      "min: 0.02285756674741562\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32112823060741214\n",
      "std: 0.29359044230773096\n",
      "min: -0.7976242858584903\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48835721132671117\n",
      "std: 0.3617328559574671\n",
      "min: -0.38967766754115846\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266836954571946\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1656572385058346\n",
      "std: 0.2362782908161177\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1701508654147403\n",
      "std: 0.23899881437729223\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.053728932565740316\n",
      "min: 0.005036729970517471\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34860660610207417\n",
      "std: 0.36456372030887974\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3623594739132068\n",
      "std: 0.348035090619853\n",
      "min: -0.604656284537755\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05729286606663131\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4048687395665589\n",
      "std: 0.01526490663108981\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4048926988177388\n",
      "std: 0.015394075135150374\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05034022690251111\n",
      "min: 0.021150505247768073\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32288026567448835\n",
      "std: 0.2936208509878381\n",
      "min: -0.7974335654434678\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4891932499276868\n",
      "std: 0.36264733385165887\n",
      "min: -0.38954828823915255\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06272180568062678\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1805192098430863\n",
      "std: 0.1698971542060297\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.184675385698884\n",
      "std: 0.17250433363046028\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.05140424371635753\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3385296986277905\n",
      "std: 0.36513228967626804\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36974122592169284\n",
      "std: 0.3460847551545293\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056847174392460786\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407267668183637\n",
      "std: 0.0050511604168118375\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073063971170128\n",
      "std: 0.005120290553425121\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.04941404345750973\n",
      "min: 0.02218521740840824\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31893891383555345\n",
      "std: 0.29390232742551586\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4910959633074971\n",
      "std: 0.36161790499331214\n",
      "min: -0.38879254994289486\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264241357415949\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1765049824186076\n",
      "std: 0.18685606327640808\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1807922197824274\n",
      "std: 0.1902648099553863\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.05213893880148369\n",
      "min: 0.008105277866865783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3387721078528062\n",
      "std: 0.3687195327595595\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3691397303667555\n",
      "std: 0.3477385310644086\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05702192115297729\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066625965554165\n",
      "std: 0.007552313499668846\n",
      "min: 1.3506838144968856\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067132393952053\n",
      "std: 0.00763111526526816\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.04941724452728956\n",
      "min: 0.02182330941857501\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3178841781457937\n",
      "std: 0.293722168804136\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4911401219169504\n",
      "std: 0.3613888895184913\n",
      "min: -0.3883083708185305\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259824421865605\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1794997016661053\n",
      "std: 0.18164517316685858\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1837839682941098\n",
      "std: 0.18294857347934715\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.051225781977055934\n",
      "min: 0.007350254367341714\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3402549041986426\n",
      "std: 0.3663838094738626\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3685422288101487\n",
      "std: 0.34757665005331806\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05700442198382713\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407461794946515\n",
      "std: 0.0044045573591192265\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074858018604783\n",
      "std: 0.004644654362232665\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.0494134607469367\n",
      "min: 0.022217586584075643\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31931499951665787\n",
      "std: 0.2938318666910872\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4905073573382685\n",
      "std: 0.36161952341833875\n",
      "min: -0.3890895033732396\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264194821859988\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2119575770921778\n",
      "std: 0.08453475134319013\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.21568015606471\n",
      "std: 0.0897940496726094\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.05010667850334672\n",
      "min: 0.015720911602309328\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34874229885812247\n",
      "std: 0.3626393116736574\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3615551038087317\n",
      "std: 0.3476018505465607\n",
      "min: -0.6034392487620788\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05730682635610003\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081384820136205\n",
      "std: 0.0031879839251268516\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408141555949623\n",
      "std: 0.0035052452016861688\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.049413030555177824\n",
      "min: 0.022351733076344808\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32099555913556665\n",
      "std: 0.2935247705817808\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4882913263023412\n",
      "std: 0.3616357129849253\n",
      "min: -0.3896776675411588\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06265942506475855\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.165933759744005\n",
      "std: 0.23367595728903512\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1702945665289464\n",
      "std: 0.23642550464262793\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.05273279545638075\n",
      "min: 0.004900611357952902\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34878735796229576\n",
      "std: 0.3638946349613612\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3611150867830696\n",
      "std: 0.348169351135868\n",
      "min: -0.604656284537755\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05726411260461764\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4049350931316997\n",
      "std: 0.015108119994153275\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4049773255177274\n",
      "std: 0.015237364178930141\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.04943125801928135\n",
      "min: 0.020618341793844672\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32271972285133593\n",
      "std: 0.2935512021947307\n",
      "min: -0.7974335654434678\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48911223625904626\n",
      "std: 0.36253326709570727\n",
      "min: -0.38954828823915255\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0627120734540858\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1811351403408477\n",
      "std: 0.16825329601951497\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1851085827722072\n",
      "std: 0.17082055629659346\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.05048025432904138\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3385509501735712\n",
      "std: 0.3647335685063445\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36918709074195694\n",
      "std: 0.3459066557696889\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056838289804815235\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072564692525027\n",
      "std: 0.0050123098038994136\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072718771965682\n",
      "std: 0.0050895430951028555\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.04853990371841346\n",
      "min: 0.021794993029187627\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3189652733348922\n",
      "std: 0.2938991717186152\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49092287490847336\n",
      "std: 0.3616005786342079\n",
      "min: -0.38879254994289486\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06263872630604199\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1772054897125084\n",
      "std: 0.18491622282826467\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.181306146196155\n",
      "std: 0.18827597855652053\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.05119615864500564\n",
      "min: 0.007471783927356017\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3388082379970421\n",
      "std: 0.36824718125487055\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3685880852980333\n",
      "std: 0.34753319258722143\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05701070806461906\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066634880734934\n",
      "std: 0.007470683699469408\n",
      "min: 1.3506838144968856\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406690322325265\n",
      "std: 0.007555251225669291\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.04854302344769331\n",
      "min: 0.02142935453116012\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3179264813492217\n",
      "std: 0.29371769153950444\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49096162657507414\n",
      "std: 0.3613730041540515\n",
      "min: -0.3883083708185305\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259509277416583\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1801400750377649\n",
      "std: 0.17977930054228325\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1842382899643806\n",
      "std: 0.18106666467241825\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.05030656293651893\n",
      "min: 0.007292912968699337\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.340250549515299\n",
      "std: 0.36596875865711226\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3680048626528494\n",
      "std: 0.347376439785106\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0569932845045263\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407445644846601\n",
      "std: 0.004378392242549488\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407446735543826\n",
      "std: 0.004624566675915336\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.04853933587785269\n",
      "min: 0.021791612073063363\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31933209707497806\n",
      "std: 0.29382987971603486\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4903414557875726\n",
      "std: 0.3615995564886953\n",
      "min: -0.3890895033732396\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06263791996696204\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2118562412770693\n",
      "std: 0.08396583984366361\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2154213369252953\n",
      "std: 0.08912357161540821\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.049215384252141024\n",
      "min: 0.015354345068632645\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3485715391263071\n",
      "std: 0.36227104614215355\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36113853575688004\n",
      "std: 0.34738344784796205\n",
      "min: -0.6034392487620788\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05728893518595076\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081057158449943\n",
      "std: 0.003192432449917483\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080865771088062\n",
      "std: 0.0035162636557483835\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.048538916197592145\n",
      "min: 0.0217857572625974\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32098181264920594\n",
      "std: 0.2935263686921629\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48816358779192026\n",
      "std: 0.3616140191716392\n",
      "min: -0.3896776675411588\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06265494749876979\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.166806509648464\n",
      "std: 0.23142025237441652\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.17097566103319\n",
      "std: 0.23414391026512588\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.051775342106333305\n",
      "min: 0.004900611357952902\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3486479428407186\n",
      "std: 0.36351268450256696\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36071307202635616\n",
      "std: 0.34795452761629864\n",
      "min: -0.604656284537755\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05724964380927121\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4049707604844097\n",
      "std: 0.014943924087015606\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4049885448356119\n",
      "std: 0.01507668286105901\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.04855668702484541\n",
      "min: 0.020270808098860872\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3226783339254503\n",
      "std: 0.29354888385503847\n",
      "min: -0.7974335654434678\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4889690491533101\n",
      "std: 0.362495932073993\n",
      "min: -0.38954828823915255\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06270676143949099\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1823281896208975\n",
      "std: 0.16688909391087303\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.186225592277248\n",
      "std: 0.16947152345731623\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.049591039727646676\n",
      "min: 0.007137886790462734\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33927677224420577\n",
      "std: 0.36551349428467217\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3697505393601694\n",
      "std: 0.34627075227051934\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05692113832930843\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072949614543149\n",
      "std: 0.0049712519186831195\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073127607638178\n",
      "std: 0.005043715733095553\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.04769818077240538\n",
      "min: 0.021236771663429296\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.319094072747673\n",
      "std: 0.2939904616488015\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49099486004117293\n",
      "std: 0.3616509996472491\n",
      "min: -0.38879254994289486\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264865821584288\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1784831142219403\n",
      "std: 0.1834262583352426\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.18250397543275\n",
      "std: 0.18679145874831019\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.050289058776002545\n",
      "min: 0.007471783927356017\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33954611134173557\n",
      "std: 0.36894905104505954\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36915623912230705\n",
      "std: 0.3478700704344869\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0570911536061473\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406714714584454\n",
      "std: 0.007394317053706951\n",
      "min: 1.3506838144968856\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067435200013378\n",
      "std: 0.007476996723320749\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.04770122322354115\n",
      "min: 0.020904894864197505\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3180700039568378\n",
      "std: 0.2938083823669757\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4910293363730207\n",
      "std: 0.3614249608357473\n",
      "min: -0.3883083708185305\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260556809774163\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1813680269363878\n",
      "std: 0.17807459998860106\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1853870601429302\n",
      "std: 0.17940136105402696\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.04942179553070967\n",
      "min: 0.007292912968699337\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3409486487646812\n",
      "std: 0.3667340540265917\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3685878469624818\n",
      "std: 0.34771959824105686\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05707376200396017\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074797714695968\n",
      "std: 0.004331098019849304\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074837191712384\n",
      "std: 0.004571813050294981\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.047697626509316415\n",
      "min: 0.021300076786974736\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3194516934626412\n",
      "std: 0.29392318243084703\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49042149224018083\n",
      "std: 0.3616481124917912\n",
      "min: -0.3890895033732396\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264756574073169\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.212445654540894\n",
      "std: 0.08317509517991796\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2159569709392406\n",
      "std: 0.08834510618307463\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.048357129168932665\n",
      "min: 0.015354345068632648\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34910618323585174\n",
      "std: 0.3630753079780983\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36184119608763954\n",
      "std: 0.34772909919750167\n",
      "min: -0.6034392487620788\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05736245906105393\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081261263123284\n",
      "std: 0.0031561803023146657\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081104721786628\n",
      "std: 0.003472335168991042\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.0476972166993877\n",
      "min: 0.02144087760917576\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32107011367023275\n",
      "std: 0.2936225778483831\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48828052240309905\n",
      "std: 0.36166166616942536\n",
      "min: -0.3896776675411588\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266406464006266\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1683396977794978\n",
      "std: 0.2292783853617092\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1724230102277382\n",
      "std: 0.23202180132358088\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.05085402894289532\n",
      "min: 0.004900611357952902\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34920720140474537\n",
      "std: 0.36430630411469095\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36143419369111796\n",
      "std: 0.34830219086184905\n",
      "min: -0.604656284537755\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05732641823983313\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405056456111037\n",
      "std: 0.014791565839733085\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405075640975334\n",
      "std: 0.014924556001736054\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.047714553358087074\n",
      "min: 0.019954203722508838\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32274008304068613\n",
      "std: 0.2936414295386855\n",
      "min: -0.7974335654434678\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4890731648026724\n",
      "std: 0.36252812083203095\n",
      "min: -0.38954828823915255\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06271517245669693\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1834968844976108\n",
      "std: 0.16559206866213558\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1870300307204185\n",
      "std: 0.16812309213831966\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04873467739599222\n",
      "min: 0.006749489675278262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34036663476426826\n",
      "std: 0.3645222399015398\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36901652539967117\n",
      "std: 0.34638733993091575\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0569929246265307\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073152596440577\n",
      "std: 0.00492260217556898\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407332304174811\n",
      "std: 0.004994968427952502\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04688706058162652\n",
      "min: 0.020848773225899113\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3192977095906346\n",
      "std: 0.29395846638382894\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4908403523346374\n",
      "std: 0.3617192580443888\n",
      "min: -0.38879254994289486\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266334601141865\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1797377550226034\n",
      "std: 0.18189410876048034\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1833907858053745\n",
      "std: 0.18520065361425248\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04941561327657629\n",
      "min: 0.0074304841430578895\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3406464863459562\n",
      "std: 0.3678991093099352\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36842533984647885\n",
      "std: 0.34795921215525033\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057160486825659135\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4067478540293343\n",
      "std: 0.007314407790350451\n",
      "min: 1.3506838144968856\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067754425314454\n",
      "std: 0.007397891484385838\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04689002933668977\n",
      "min: 0.02050571861785454\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.318287987371804\n",
      "std: 0.2937759257384354\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49086989031221734\n",
      "std: 0.36149479540885654\n",
      "min: -0.3883083708185305\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06262077491017386\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1825623074662577\n",
      "std: 0.17655272528504423\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1862138751152902\n",
      "std: 0.1778514431754043\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.0485697250294887\n",
      "min: 0.007261371971477695\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3420129899920693\n",
      "std: 0.3657274168555948\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36787028249513487\n",
      "std: 0.3478115169902296\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05714329486722086\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074959960640012\n",
      "std: 0.00428908809285068\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407499589438218\n",
      "std: 0.004527894126181911\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.046886519773947394\n",
      "min: 0.020870445551339815\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31964668036123856\n",
      "std: 0.29389224185623336\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49027400809808624\n",
      "std: 0.36171420238881935\n",
      "min: -0.3890895033732396\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266196919053595\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.213020741796593\n",
      "std: 0.08254264074044255\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2161858410457804\n",
      "std: 0.08766245311903126\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04753036124055223\n",
      "min: 0.014964023336498619\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35000580739391\n",
      "std: 0.3620909657209781\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3612380157129391\n",
      "std: 0.347802688065288\n",
      "min: -0.6034392487620788\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057424712260277504\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408129290100698\n",
      "std: 0.003129139012121337\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081137950716147\n",
      "std: 0.0034417664230353665\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04688611944352747\n",
      "min: 0.020944331540985267\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32123504651694396\n",
      "std: 0.29359447868641747\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4881690356586487\n",
      "std: 0.36172584405695907\n",
      "min: -0.3896776675411588\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06267794642181415\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.169753203277316\n",
      "std: 0.22752157608932913\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1734645412073141\n",
      "std: 0.2302175793761013\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04996718811257991\n",
      "min: 0.004622232797715273\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3501367951332986\n",
      "std: 0.3633162165924629\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3608451675064248\n",
      "std: 0.3483756767871554\n",
      "min: -0.604656284537755\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05739218808579131\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405122708534762\n",
      "std: 0.014644339013116315\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4051401173732863\n",
      "std: 0.014778478538949369\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04690304153619284\n",
      "min: 0.01950155813639525\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3228796790325377\n",
      "std: 0.29360859037155795\n",
      "min: -0.7974335654434678\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48894736955265417\n",
      "std: 0.36257731537325216\n",
      "min: -0.38954828823915255\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06272835009231884\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1847986611626504\n",
      "std: 0.1640980282618453\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1881333531897287\n",
      "std: 0.1666003807653965\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.047909043749169246\n",
      "min: 0.006749489675278261\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33929033864975255\n",
      "std: 0.36479745845437145\n",
      "min: -1.0406485396783056\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3694131846704475\n",
      "std: 0.34661095819807247\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056952244636244403\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073400011988693\n",
      "std: 0.004884291612788418\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073648080421677\n",
      "std: 0.004954137961630607\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.04610486423719316\n",
      "min: 0.020426656040330164\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31897049965346824\n",
      "std: 0.29400190420719613\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4910578813668709\n",
      "std: 0.3616440110327915\n",
      "min: -0.38879254994289486\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06265058187321648\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1811158327435758\n",
      "std: 0.18019127519414838\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.184567133478058\n",
      "std: 0.18346215848902067\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.048573681064362696\n",
      "min: 0.007430484143057889\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3395813334296014\n",
      "std: 0.3680991135745477\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36882476057533997\n",
      "std: 0.3481557455079123\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05711771887762599\n",
      "min: 0.07116112433950787\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4067852612523655\n",
      "std: 0.007242426835480029\n",
      "min: 1.3506838144968856\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40682025725255\n",
      "std: 0.007324895805751948\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.046107762478649304\n",
      "min: 0.02002262014854173\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31797436549498337\n",
      "std: 0.2938178784986315\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642874\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4910834488215453\n",
      "std: 0.36142077395574423\n",
      "min: -0.3883083708185305\n",
      "max: 0.9800013732642874\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260848348032101\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.18386839567449\n",
      "std: 0.1750523401598539\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.187319266692129\n",
      "std: 0.17633261894847896\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.04774829983749487\n",
      "min: 0.007209387012694378\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.340914133508061\n",
      "std: 0.36598620567210066\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3682806546142397\n",
      "std: 0.34801417390330847\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05710061352517832\n",
      "min: 0.07095027915742905\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075165690213705\n",
      "std: 0.004263122164769923\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40752843409663\n",
      "std: 0.004496309652822936\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.046104336457524986\n",
      "min: 0.020421661322056885\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31931044366392386\n",
      "std: 0.29393736674405163\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4904995479443535\n",
      "std: 0.361637192378759\n",
      "min: -0.3890895033732396\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264891848441714\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2137110356813707\n",
      "std: 0.08199176436468139\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2166975873450163\n",
      "std: 0.08703900505690605\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.04673314483929775\n",
      "min: 0.014489802841169812\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34876312798680903\n",
      "std: 0.36241996237025836\n",
      "min: -1.0393086302630352\n",
      "max: 1.0469816906073963\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36175728538511753\n",
      "std: 0.3480054738264678\n",
      "min: -0.6034392487620788\n",
      "max: 1.0469816906073963\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057376397816106726\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408135896932836\n",
      "std: 0.0031182996880057784\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081291483922276\n",
      "std: 0.003421777994268095\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.04610394512672183\n",
      "min: 0.020471521436029243\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3208720792379261\n",
      "std: 0.2936446596833937\n",
      "min: -0.7976242858584907\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48842787352896855\n",
      "std: 0.3616492697378375\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266451820347757\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1712909898868789\n",
      "std: 0.22552568051569907\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1747961418213015\n",
      "std: 0.22819998264810307\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.0491124447727528\n",
      "min: 0.004622232797715271\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3489133095480822\n",
      "std: 0.36362482875854524\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3613818002968664\n",
      "std: 0.3485757231600203\n",
      "min: -0.604656284537755\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05734638908731835\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4051864285527467\n",
      "std: 0.014515258315519962\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4052108735844837\n",
      "std: 0.014649858665170004\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.046120472122663785\n",
      "min: 0.019042018667804007\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3224902256018546\n",
      "std: 0.2936568672507833\n",
      "min: -0.7974335654434678\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48919399195198543\n",
      "std: 0.3624852707841089\n",
      "min: -0.38954828823915255\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06271411943267163\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1856381426781566\n",
      "std: 0.16237687890933664\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1887882975237587\n",
      "std: 0.16486691905162223\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04711260887922426\n",
      "min: 0.006749489675278261\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3396555236547931\n",
      "std: 0.36436620219255966\n",
      "min: -1.040648539678306\n",
      "max: 1.0586274842736012\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3684111427654597\n",
      "std: 0.3467693867676757\n",
      "min: -0.6024608062844782\n",
      "max: 1.0586274842736012\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0569475659993573\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073584301145061\n",
      "std: 0.004836885152338845\n",
      "min: 1.3717877071493068\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073764618781246\n",
      "std: 0.004899890477860206\n",
      "min: 1.3736210995459532\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.045350035055920904\n",
      "min: 0.01996325734330683\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31910590741118783\n",
      "std: 0.2939368302404344\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49082184693602693\n",
      "std: 0.36167376228875175\n",
      "min: -0.38879254994289486\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06265609280933142\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1820200447955886\n",
      "std: 0.17841979107091185\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1852837591080492\n",
      "std: 0.18166628085751685\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.047761706782293946\n",
      "min: 0.007430484143057889\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3399550845037868\n",
      "std: 0.3676081814783753\n",
      "min: -1.0441664747471735\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3678250113712994\n",
      "std: 0.3482890136227731\n",
      "min: -0.6034800669618647\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057110894579570054\n",
      "min: 0.07116112433950784\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068140051838418\n",
      "std: 0.007172993279427964\n",
      "min: 1.3506838144968853\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406841913201922\n",
      "std: 0.0072508221132245\n",
      "min: 1.3511947150280328\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04535286634456709\n",
      "min: 0.019567040436303335\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31812313342691817\n",
      "std: 0.2937523583160237\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49084325882531604\n",
      "std: 0.3614521810615759\n",
      "min: -0.3883083708185302\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261447689233633\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1847329852250952\n",
      "std: 0.17316503560550675\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1879964751160157\n",
      "std: 0.17444656866253863\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04695575455677234\n",
      "min: 0.007209387012694378\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34125381364520474\n",
      "std: 0.36554573969391\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.367296510665526\n",
      "std: 0.3481515393261433\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05709397927449832\n",
      "min: 0.07095027915742903\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075320661133308\n",
      "std: 0.004223911634544839\n",
      "min: 1.37475789423909\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407537517993974\n",
      "std: 0.004447471222796336\n",
      "min: 1.37475789423909\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04000000000000001\n",
      "std: 0.045349519625549055\n",
      "min: 0.020014784417609198\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3194373682034325\n",
      "std: 0.2938736073287914\n",
      "min: -0.797840950208833\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4902704663678985\n",
      "std: 0.3616647469387825\n",
      "min: -0.38908950337323944\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06265413931808729\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.213941191130323\n",
      "std: 0.0812270257057268\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2167623523991355\n",
      "std: 0.0862397971980865\n",
      "min: 0.7199851205004337\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04596391863728755\n",
      "min: 0.014489802841169812\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34895740374217216\n",
      "std: 0.3620091893929749\n",
      "min: -1.0393086302630352\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36087758589677094\n",
      "std: 0.3481186297871403\n",
      "min: -0.6034392487620789\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05736369366030275\n",
      "min: 0.07160298582685132\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408140676863098\n",
      "std: 0.003091038473239875\n",
      "min: 1.3810492880477452\n",
      "max: 1.4139807655137453\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081280390776931\n",
      "std: 0.003382594995449277\n",
      "min: 1.3810492880477452\n",
      "max: 1.4139807655137453\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04534913695027362\n",
      "min: 0.02010673906790552\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3209706519097209\n",
      "std: 0.2935833774759864\n",
      "min: -0.7976242858584903\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4882323241971206\n",
      "std: 0.3616742278343087\n",
      "min: -0.3896776675411588\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626692322366851\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1723608887578016\n",
      "std: 0.22343149840400778\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1756744068774176\n",
      "std: 0.22609189390125617\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04828818729478291\n",
      "min: 0.004622232797715271\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34913154091333815\n",
      "std: 0.36320812420618204\n",
      "min: -1.0462977647854375\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3605117509768729\n",
      "std: 0.3486877657263474\n",
      "min: -0.6046562845377553\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05733639156047931\n",
      "min: 0.07120819774983717\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4052508392532606\n",
      "std: 0.014362807337778505\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4052675935666672\n",
      "std: 0.014496506295704068\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.0453652832970698\n",
      "min: 0.01858006457113336\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3225655281950088\n",
      "std: 0.2935921682581275\n",
      "min: -0.797433565443468\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48898519902057525\n",
      "std: 0.36249696346307086\n",
      "min: -0.3895482882391525\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0627181634991035\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1868903929317247\n",
      "std: 0.16131284554613448\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1899595820223838\n",
      "std: 0.16380483642094415\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04634411817580324\n",
      "min: 0.006710811012526809\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33960535412244597\n",
      "std: 0.3650616899594119\n",
      "min: -1.0406485396783058\n",
      "max: 1.0586274842736012\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36848193337775187\n",
      "std: 0.3465945813140025\n",
      "min: -0.6024608062844781\n",
      "max: 1.0586274842736012\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056939767197213685\n",
      "min: 0.07114479798970587\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073849175286888\n",
      "std: 0.004815460305693842\n",
      "min: 1.3717877071493068\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074131076223713\n",
      "std: 0.0048711388153863866\n",
      "min: 1.3736210995459532\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.039215686274509796\n",
      "std: 0.0446211278497192\n",
      "min: 0.01951538879964127\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3190253061902375\n",
      "std: 0.2940512001698364\n",
      "min: -0.7978768618452209\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4908585315253479\n",
      "std: 0.3616042320670849\n",
      "min: -0.3887925499428949\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264289804620883\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.183361479531304\n",
      "std: 0.17700352748877066\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1865413020099198\n",
      "std: 0.18024863077615774\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04697820681433993\n",
      "min: 0.00668439443831623\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3399122638624217\n",
      "std: 0.3682355959540868\n",
      "min: -1.0441664747471737\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36790043493376445\n",
      "std: 0.3480911850512612\n",
      "min: -0.6034800669618647\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05710109101092232\n",
      "min: 0.07116112433950787\n",
      "max: 0.32793413246265274\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068515207273042\n",
      "std: 0.007123814688250667\n",
      "min: 1.3506838144968853\n",
      "max: 1.4139812651754062\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406889228405432\n",
      "std: 0.007197289145658033\n",
      "min: 1.3511947150280326\n",
      "max: 1.4139812651754062\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04462389513095418\n",
      "min: 0.01917482581608878\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31805488382078867\n",
      "std: 0.29386591792384564\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49087686858978796\n",
      "std: 0.36138386838653636\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260171926170904\n",
      "min: 0.0822143147394386\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1860168874407933\n",
      "std: 0.17178511615422218\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1891968444727052\n",
      "std: 0.1730896967142505\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.046190925801724014\n",
      "min: 0.007209387012694376\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3411793091148215\n",
      "std: 0.36622904188401456\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3673836761880997\n",
      "std: 0.34795865630223793\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057084256718088276\n",
      "min: 0.07095027915742906\n",
      "max: 0.32798433939667904\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407555956107075\n",
      "std: 0.004200954202632674\n",
      "min: 1.3747578942390895\n",
      "max: 1.4139800835404732\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075719707931689\n",
      "std: 0.004415623457515504\n",
      "min: 1.3747578942390895\n",
      "max: 1.4139800835404732\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04462062382246967\n",
      "min: 0.019558553643353807\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3193485083618749\n",
      "std: 0.2939897004772631\n",
      "min: -0.7978409502088328\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4903141972726963\n",
      "std: 0.36159343084329815\n",
      "min: -0.38908950337323944\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264067378330611\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2146979681007342\n",
      "std: 0.08065808195005038\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2174549373602648\n",
      "std: 0.08566240465523446\n",
      "min: 0.7199851205004337\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04522123795839489\n",
      "min: 0.013311520165241128\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34874424107984553\n",
      "std: 0.36273840083772024\n",
      "min: -1.0393086302630354\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3610663120156432\n",
      "std: 0.34792057703682283\n",
      "min: -0.6034392487620789\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05734832047289219\n",
      "min: 0.0716029858268513\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408155528389339\n",
      "std: 0.0030756997424454674\n",
      "min: 1.3810492880477452\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081537848217087\n",
      "std: 0.0033552848567099005\n",
      "min: 1.3810492880477452\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04462024920043042\n",
      "min: 0.019607354179578353\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32085526144635984\n",
      "std: 0.29370259578327246\n",
      "min: -0.7976242858584907\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48830809141049736\n",
      "std: 0.36160214618580616\n",
      "min: -0.3896776675411588\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06265535373747669\n",
      "min: 0.08224047526152704\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1738689282279946\n",
      "std: 0.22172044836155058\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1770951180585836\n",
      "std: 0.22438489387634783\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.047492904721139144\n",
      "min: 0.004181555809506524\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3489380686560982\n",
      "std: 0.36392622221415594\n",
      "min: -1.0462977647854377\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36071282855879533\n",
      "std: 0.3484900841106788\n",
      "min: -0.6046562845377551\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05732344782459593\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405319414512661\n",
      "std: 0.01424308381492532\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4053455288805476\n",
      "std: 0.014375594543020256\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04463603380829323\n",
      "min: 0.018287651598621182\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3224263060878753\n",
      "std: 0.2937096702531698\n",
      "min: -0.7974335654434678\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4890493128523177\n",
      "std: 0.3624115370863804\n",
      "min: -0.3895482882391525\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999998\n",
      "std: 0.06270358997011197\n",
      "min: 0.08217236485510235\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1870234798279626\n",
      "std: 0.16000976431560046\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1900389324231742\n",
      "std: 0.16247658717598273\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03846153846153846\n",
      "std: 0.045601986469845916\n",
      "min: 0.006710811012526809\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3378452204237553\n",
      "std: 0.36588275013406757\n",
      "min: -1.0406485396783058\n",
      "max: 1.0586274842736012\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36805017954414415\n",
      "std: 0.3460362518725646\n",
      "min: -0.602460806284478\n",
      "max: 1.0586274842736012\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05686058424763644\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073897772967974\n",
      "std: 0.004768204574870481\n",
      "min: 1.3717877071493068\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074303961620966\n",
      "std: 0.0048227052138133265\n",
      "min: 1.3736210995459535\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.043916796238366536\n",
      "min: 0.019301278168087483\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3187631266677449\n",
      "std: 0.2941371975948206\n",
      "min: -0.797876861845221\n",
      "max: 0.947109988485612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49079078332466863\n",
      "std: 0.36150717048417347\n",
      "min: -0.3887925499428949\n",
      "max: 0.947109988485612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06262449062144342\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1835582072988857\n",
      "std: 0.17565702854934193\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1866804311920813\n",
      "std: 0.17887189221565472\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.046221867141682145\n",
      "min: 0.00668439443831623\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33816367706848793\n",
      "std: 0.368990695542311\n",
      "min: -1.0441664747471737\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36746953691725043\n",
      "std: 0.3475139676516522\n",
      "min: -0.6034800669618645\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057020246594245115\n",
      "min: 0.07116112433950784\n",
      "max: 0.32793413246265274\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068665725415193\n",
      "std: 0.0070564226230348795\n",
      "min: 1.3506838144968858\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069163595638903\n",
      "std: 0.007129572862931433\n",
      "min: 1.3511947150280326\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.04391950213495366\n",
      "min: 0.018893576475046393\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3178051126007945\n",
      "std: 0.29395077282094756\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49080531878215294\n",
      "std: 0.36128808576386073\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258373921241309\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1861315496519427\n",
      "std: 0.17078731816467238\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1892557864689732\n",
      "std: 0.17207198539210186\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.045452552734782284\n",
      "min: 0.006410717386126359\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3393996079411053\n",
      "std: 0.36704291764989816\n",
      "min: -1.024685512886558\n",
      "max: 1.058495256595823\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36696395491616257\n",
      "std: 0.34738359182954465\n",
      "min: -0.6038458408294995\n",
      "max: 1.058495256595823\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057003360427394165\n",
      "min: 0.07095027915742903\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407557378971572\n",
      "std: 0.004166750365012545\n",
      "min: 1.3747578942390897\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407586225558051\n",
      "std: 0.004377017471347792\n",
      "min: 1.3747578942390897\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.0439163037008157\n",
      "min: 0.01929864976698176\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31907861174380814\n",
      "std: 0.29407748421065066\n",
      "min: -0.7978409502088327\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49025286894592096\n",
      "std: 0.36149454816139165\n",
      "min: -0.38908950337323944\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06262200505120147\n",
      "min: 0.08218608005805053\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2143034494199965\n",
      "std: 0.08063600069749075\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2170226504336819\n",
      "std: 0.08552563080167652\n",
      "min: 0.7199851205004337\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.044504027257254886\n",
      "min: 0.012434515686955576\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3468330864125878\n",
      "std: 0.36362634936116206\n",
      "min: -1.0393086302630354\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36074632991636346\n",
      "std: 0.3473325920009702\n",
      "min: -0.6034392487620787\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057262134106605765\n",
      "min: 0.07160298582685132\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408145364085468\n",
      "std: 0.0030627397525053533\n",
      "min: 1.3810492880477452\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081567126202006\n",
      "std: 0.0033341199409703624\n",
      "min: 1.3810492880477452\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.0439159372247192\n",
      "min: 0.01929255898036735\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32056110440662744\n",
      "std: 0.29379477960812217\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4882782591797096\n",
      "std: 0.3615027031071866\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06263638938880266\n",
      "min: 0.08224047526152704\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1742214434981921\n",
      "std: 0.2200720447849135\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1773854126898022\n",
      "std: 0.22272326739752576\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.04672528442452626\n",
      "min: 0.004181555809506524\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34704458262800764\n",
      "std: 0.36480562600436717\n",
      "min: -1.0462977647854377\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36040306454097326\n",
      "std: 0.34790454968615564\n",
      "min: -0.604656284537755\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057239774718643006\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4053626767636656\n",
      "std: 0.014111960371337\n",
      "min: 1.296028188559864\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4054004384301728\n",
      "std: 0.014245967145369508\n",
      "min: 1.296028188559864\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.043931373744481896\n",
      "min: 0.01788999483999424\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3221081950058056\n",
      "std: 0.29380117976564907\n",
      "min: -0.7974335654434678\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4890075560499379\n",
      "std: 0.3622992136496736\n",
      "min: -0.3895482882391525\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06268392076088558\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1874366689225022\n",
      "std: 0.15872855515688875\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1904394204902655\n",
      "std: 0.16119145906153348\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04488451941583117\n",
      "min: 0.006140696417090343\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3385864635555329\n",
      "std: 0.36599436459407014\n",
      "min: -1.0406485396783058\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3679898446670165\n",
      "std: 0.34609261653562784\n",
      "min: -0.602460806284478\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0568637035254429\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074172692084264\n",
      "std: 0.004738085940617062\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802904\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074622338610423\n",
      "std: 0.004784262119268203\n",
      "min: 1.373621099545953\n",
      "max: 1.4139805769802904\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.0432357899509511\n",
      "min: 0.01878130458590092\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31876553636073945\n",
      "std: 0.2940847328390602\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4908625266150933\n",
      "std: 0.3614503612697578\n",
      "min: -0.3887925499428951\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261952900814603\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.184033475198632\n",
      "std: 0.17427444834617428\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.187140469206794\n",
      "std: 0.1774798043915325\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.0454907790233211\n",
      "min: 0.006684394438316229\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33891404155870797\n",
      "std: 0.36904283624161155\n",
      "min: -1.0441664747471737\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36741020527360985\n",
      "std: 0.3475473010397658\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05702158492071706\n",
      "min: 0.07116112433950784\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069038259788913\n",
      "std: 0.0070057596940596946\n",
      "min: 1.3506838144968853\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069576941656121\n",
      "std: 0.007073557845153829\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04323843716734144\n",
      "min: 0.018424345008812622\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3178195515975262\n",
      "std: 0.29389759274162214\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4908734714384793\n",
      "std: 0.3612325850829794\n",
      "min: -0.3883083708185302\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257921005095124\n",
      "min: 0.0822143147394386\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1865821097272162\n",
      "std: 0.16907252983693585\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1896913454486713\n",
      "std: 0.17037250152952196\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.0447384083941289\n",
      "min: 0.006410717386126359\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34012099627852194\n",
      "std: 0.3671395910418658\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3669184771081122\n",
      "std: 0.34742097960823304\n",
      "min: -0.6038458408294993\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05700488430681373\n",
      "min: 0.07095027915742903\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407581736622078\n",
      "std: 0.004129807098275384\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40761528669922\n",
      "std: 0.004330247471152651\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.043235307752607866\n",
      "min: 0.018889475872713155\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31907367520976687\n",
      "std: 0.2940261719829725\n",
      "min: -0.7978409502088328\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49033127989605363\n",
      "std: 0.3614362407166711\n",
      "min: -0.38908950337323966\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261681707259383\n",
      "min: 0.08218608005805052\n",
      "max: 0.2997505107912778\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.214217471339358\n",
      "std: 0.08005889221529625\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2169408419061234\n",
      "std: 0.08489321113091673\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04381040484071032\n",
      "min: 0.012434515686955574\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3474253173301471\n",
      "std: 0.3637499235639106\n",
      "min: -1.0393086302630354\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3607905991453909\n",
      "std: 0.34736633792807936\n",
      "min: -0.6034392487620788\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057258467985010233\n",
      "min: 0.07160298582685132\n",
      "max: 0.32752045013828757\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081601562979185\n",
      "std: 0.0030398969814688947\n",
      "min: 1.3810492880477452\n",
      "max: 1.4139807655137453\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081765653259806\n",
      "std: 0.0032978201404921994\n",
      "min: 1.3810492880477452\n",
      "max: 1.4139807655137453\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04323494904298947\n",
      "min: 0.01900683666423802\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32053195660744377\n",
      "std: 0.29374681966910055\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48838641078302586\n",
      "std: 0.3614443160055649\n",
      "min: -0.3896776675411586\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06263086476562045\n",
      "min: 0.08224047526152704\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.174937585073549\n",
      "std: 0.21793647279497513\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1780814543429088\n",
      "std: 0.22059733856043293\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04598321603469702\n",
      "min: 0.004181555809506525\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34765680265132415\n",
      "std: 0.36491683249800566\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3604619271260146\n",
      "std: 0.3479344126275211\n",
      "min: -0.6046562845377551\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057238428929667094\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4054273623062312\n",
      "std: 0.013995260668005912\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4054688267129414\n",
      "std: 0.01412780642479116\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.043250052880462395\n",
      "min: 0.017532808976838333\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3220570809145944\n",
      "std: 0.2937505901748897\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4891050647840732\n",
      "std: 0.36222787305682014\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06267776488409539\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.187453292706497\n",
      "std: 0.1574954819333942\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.190299910324214\n",
      "std: 0.1599491152719567\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.044190824255633525\n",
      "min: 0.006140696417090343\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33791704613033235\n",
      "std: 0.36533773929950725\n",
      "min: -1.0406485396783058\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3667881271790833\n",
      "std: 0.3458102267596092\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0568031479726381\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407411114518831\n",
      "std: 0.0047031268867962035\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407447434230105\n",
      "std: 0.004750198838177148\n",
      "min: 1.3736210995459537\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.042576941206470986\n",
      "min: 0.018386794890325953\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3187676807504842\n",
      "std: 0.2940321519658817\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4907124899500809\n",
      "std: 0.3613992171526905\n",
      "min: -0.38879254994289486\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261363214585496\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1841045414248639\n",
      "std: 0.17307698058718263\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1870524840693684\n",
      "std: 0.17626207729798757\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04478404934730151\n",
      "min: 0.006475206007519072\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33825125076704887\n",
      "std: 0.36833551873330656\n",
      "min: -1.0441664747471737\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3662101744374847\n",
      "std: 0.3472435484521704\n",
      "min: -0.6034800669618647\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05695916266977247\n",
      "min: 0.07116112433950784\n",
      "max: 0.3279341324626528\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069068798094286\n",
      "std: 0.006961736909419188\n",
      "min: 1.3506838144968853\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069518573921864\n",
      "std: 0.007029911318499359\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04257953266956589\n",
      "min: 0.01794559893423776\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31783323190251306\n",
      "std: 0.2938442507997923\n",
      "min: -0.7971594015816316\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49071955148074226\n",
      "std: 0.36118271235426613\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257370806619386\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.186592932978359\n",
      "std: 0.16801233543569702\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.189544041533197\n",
      "std: 0.16930952718566433\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04404810319513837\n",
      "min: 0.005740098898050175\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.339430519701538\n",
      "std: 0.366473666052186\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3657282540125968\n",
      "std: 0.3471183762739927\n",
      "min: -0.6038458408294995\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05694247694470045\n",
      "min: 0.07095027915742903\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407573086067682\n",
      "std: 0.004109521766486312\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075982784084355\n",
      "std: 0.004308393728435307\n",
      "min: 1.3747578942390895\n",
      "max: 1.413980083540473\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04257646960239183\n",
      "min: 0.018395129849847192\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31906905756013837\n",
      "std: 0.29397467645163555\n",
      "min: -0.7978409502088328\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49018653338633644\n",
      "std: 0.36138339393401653\n",
      "min: -0.3890895033732396\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261069070342966\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2137554287020562\n",
      "std: 0.0797911599129889\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.216336126498826\n",
      "std: 0.0845844088728\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04313960889127231\n",
      "min: 0.012434515686955574\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34660828275951866\n",
      "std: 0.36312998613876407\n",
      "min: -1.0393086302630354\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35969529947936396\n",
      "std: 0.34704024449930204\n",
      "min: -0.6034392487620787\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057191043907442556\n",
      "min: 0.07160298582685132\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081439100630386\n",
      "std: 0.003020923820758705\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081523249921706\n",
      "std: 0.0032778044661237993\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04257611785582555\n",
      "min: 0.01848838155598563\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32050322803934767\n",
      "std: 0.29369816281824723\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48827156411319667\n",
      "std: 0.3613899933500381\n",
      "min: -0.3896776675411586\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06262437210632305\n",
      "min: 0.08224047526152704\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.175178875589161\n",
      "std: 0.21629617102893192\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1781597834738846\n",
      "std: 0.21895016965667813\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.045266053885944346\n",
      "min: 0.004181555809506525\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34685663122365107\n",
      "std: 0.36428789847111587\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35937486958786\n",
      "std: 0.34760658811227585\n",
      "min: -0.6046562845377552\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057173107424312905\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4054600064428835\n",
      "std: 0.013875184647651789\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4054921795114375\n",
      "std: 0.014008873005822495\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04259090190450707\n",
      "min: 0.017088324545436913\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32200652914922523\n",
      "std: 0.29369984392189047\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4889785248423872\n",
      "std: 0.3621614417280233\n",
      "min: -0.3895482882391524\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06267060235430219\n",
      "min: 0.08217236485510233\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1885795729657773\n",
      "std: 0.15631605763942558\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1915610088238189\n",
      "std: 0.15880271412613214\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04351941550602679\n",
      "min: 0.006140696417090343\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33838084550619524\n",
      "std: 0.365192683298729\n",
      "min: -1.0406485396783058\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36607924349233606\n",
      "std: 0.34607905526839305\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05680834300515356\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074554336223595\n",
      "std: 0.0046710592584339895\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075051857761043\n",
      "std: 0.004712334733220019\n",
      "min: 1.3736210995459532\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04193915956843722\n",
      "min: 0.01812390597003676\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31872481661272695\n",
      "std: 0.2940225354580416\n",
      "min: -0.7978768618452209\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4906804308672809\n",
      "std: 0.3613631298654471\n",
      "min: -0.3887925499428951\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260955779389675\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.185298656727597\n",
      "std: 0.17164848403684052\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1883782284764355\n",
      "std: 0.17486468621514237\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04410002015723345\n",
      "min: 0.006475206007519074\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3387230238193022\n",
      "std: 0.368138309508412\n",
      "min: -1.0441664747471737\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36550530339152054\n",
      "std: 0.34748998854918983\n",
      "min: -0.6034800669618647\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05696264077138503\n",
      "min: 0.07116112433950784\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069604726138158\n",
      "std: 0.0069006192691784445\n",
      "min: 1.3506838144968853\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070186035299344\n",
      "std: 0.00696587360255621\n",
      "min: 1.3511947150280323\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04194169636498253\n",
      "min: 0.01784373554883921\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3178015296810347\n",
      "std: 0.2938344513719212\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4906847238674741\n",
      "std: 0.36114804117876004\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257004877542219\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1877214553593165\n",
      "std: 0.1668800037393363\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1908054964246182\n",
      "std: 0.16821938503201375\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04337989999202745\n",
      "min: 0.005740098898050175\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33987696238940995\n",
      "std: 0.36631553358722424\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36503069655375237\n",
      "std: 0.347368791742167\n",
      "min: -0.6038458408294995\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056946012214462195\n",
      "min: 0.07095027915742903\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076138760833619\n",
      "std: 0.0040810337586242645\n",
      "min: 1.3747578942390897\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40765285817986\n",
      "std: 0.004271341755888487\n",
      "min: 1.3747578942390897\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04193869782424683\n",
      "min: 0.018191229478484075\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31901971207611235\n",
      "std: 0.2939663382615916\n",
      "min: -0.7978409502088328\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49016042365049467\n",
      "std: 0.3613459334916146\n",
      "min: -0.3890895033732396\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260642112944277\n",
      "min: 0.0821860800580505\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2144156132249109\n",
      "std: 0.07929459284045888\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2171469286847258\n",
      "std: 0.08407670831752027\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04249015979534089\n",
      "min: 0.012308134224543887\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3469323837802197\n",
      "std: 0.3630026979314105\n",
      "min: -1.0393086302630354\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3590893405310152\n",
      "std: 0.34727558790754864\n",
      "min: -0.6034392487620788\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057189796829400855\n",
      "min: 0.07160298582685132\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081737990863892\n",
      "std: 0.0030063286605625694\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081963629174075\n",
      "std: 0.003250585842697866\n",
      "min: 1.381049288047745\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.0419383532542492\n",
      "min: 0.01821594582904953\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32043082835659253\n",
      "std: 0.29369299135401816\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4882738081963715\n",
      "std: 0.3613517804057038\n",
      "min: -0.3896776675411586\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626197636904417\n",
      "min: 0.08224047526152703\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1765217858552497\n",
      "std: 0.2146055059764856\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1796308110485167\n",
      "std: 0.21729762270328662\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.0445720249323198\n",
      "min: 0.004048918960777755\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3472001756124311\n",
      "std: 0.364148590925932\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35877726972877083\n",
      "std: 0.3478388213112747\n",
      "min: -0.6046562845377553\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05717398270578018\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405537399994062\n",
      "std: 0.01375790963807689\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4055824130603307\n",
      "std: 0.013891939442032196\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04195282957784902\n",
      "min: 0.016862764925673755\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3219134950879992\n",
      "std: 0.29369276102834185\n",
      "min: -0.797433565443468\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4889706214085514\n",
      "std: 0.3621115409903411\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266541833604627\n",
      "min: 0.08217236485510233\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1888314089034666\n",
      "std: 0.15498566009682538\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1917608625016494\n",
      "std: 0.1574891036690799\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.042869362242986715\n",
      "min: 0.006140696417090343\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.338548952923988\n",
      "std: 0.36469624257946415\n",
      "min: -1.0406485396783058\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3656885973166194\n",
      "std: 0.3463328251374504\n",
      "min: -0.6024608062844782\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05684607801501395\n",
      "min: 0.07114479798970585\n",
      "max: 0.327839078615085\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074907233684513\n",
      "std: 0.0046374108362841485\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075463932723677\n",
      "std: 0.004676655917070294\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.041321427093124516\n",
      "min: 0.01772171723691421\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31876784247015827\n",
      "std: 0.2939749274355025\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49054472726858567\n",
      "std: 0.36139792052255376\n",
      "min: -0.38879254994289497\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.062616341059823\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1856197084933369\n",
      "std: 0.170014124123151\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1886440837566818\n",
      "std: 0.17324495925772848\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04343779722370652\n",
      "min: 0.006475206007519074\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3388961981596438\n",
      "std: 0.36759668242225296\n",
      "min: -1.0441664747471737\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36511971640170826\n",
      "std: 0.34772465139166037\n",
      "min: -0.6034800669618647\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05699855542357658\n",
      "min: 0.07116112433950784\n",
      "max: 0.32793413246265274\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070049003272733\n",
      "std: 0.006835653591975542\n",
      "min: 1.3506838144968858\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070687127707273\n",
      "std: 0.006900459143285656\n",
      "min: 1.3511947150280326\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04132391116575456\n",
      "min: 0.017459998703354438\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3178554784948179\n",
      "std: 0.2937869226163653\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4905464070777839\n",
      "std: 0.361184342396714\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257725187653917\n",
      "min: 0.0822143147394386\n",
      "max: 0.29968399445139055\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.187983792789525\n",
      "std: 0.1655250922393762\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1910136656500456\n",
      "std: 0.16688897802558447\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04273288799903958\n",
      "min: 0.005740098898050175\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34002628254483147\n",
      "std: 0.3658107334300743\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3646542402995171\n",
      "std: 0.34760690867590865\n",
      "min: -0.6038458408294995\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05698210058741408\n",
      "min: 0.07095027915742903\n",
      "max: 0.3279843393966789\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076455275964028\n",
      "std: 0.004050810606793122\n",
      "min: 1.3747578942390895\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407690736027106\n",
      "std: 0.0042376620648392534\n",
      "min: 1.3747578942390895\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.041320974851895224\n",
      "min: 0.01776679377550143\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31905621079826013\n",
      "std: 0.29392012059900186\n",
      "min: -0.7978409502088328\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4900307343527894\n",
      "std: 0.36137927663041663\n",
      "min: -0.3890895033732395\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261301500680203\n",
      "min: 0.08218608005805053\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2141678039229817\n",
      "std: 0.07891787903554061\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2168609322784658\n",
      "std: 0.08369024990455114\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.0418612982553656\n",
      "min: 0.012308134224543887\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34696514382628035\n",
      "std: 0.36252782214588614\n",
      "min: -1.0393086302630354\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3587990451770137\n",
      "std: 0.34749963482060997\n",
      "min: -0.6034392487620788\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05722101528097677\n",
      "min: 0.07160298582685132\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081950859933836\n",
      "std: 0.0029816219387493745\n",
      "min: 1.3810492880477452\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082242758336752\n",
      "std: 0.003221184372238729\n",
      "min: 1.3810492880477452\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.0413206370134865\n",
      "min: 0.017906931686107446\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32044465936352323\n",
      "std: 0.29364949714601035\n",
      "min: -0.7976242858584903\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4881721208613375\n",
      "std: 0.36138358636568274\n",
      "min: -0.38967766754115857\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06262598590183503\n",
      "min: 0.08224047526152706\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1769746243100403\n",
      "std: 0.2125714143968738\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1800246166160298\n",
      "std: 0.21529029442458697\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04390022251348277\n",
      "min: 0.004048918960777755\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34724824894906753\n",
      "std: 0.36366660521835775\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3584957202840553\n",
      "std: 0.34806574058692996\n",
      "min: -0.6046562845377552\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057207203647112584\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4056074186370078\n",
      "std: 0.013629626064134398\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4056578273174605\n",
      "std: 0.013764769928717589\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.041334816315991\n",
      "min: 0.016608522183685904\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3219075030366992\n",
      "std: 0.2936465731844178\n",
      "min: -0.797433565443468\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48885869353191247\n",
      "std: 0.3621326689228682\n",
      "min: -0.3895482882391525\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626710928971648\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1894471880731892\n",
      "std: 0.1537702754984167\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1922552631074175\n",
      "std: 0.15628319040742794\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04223965751642871\n",
      "min: 0.006140696417090344\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3386459955582765\n",
      "std: 0.3646141369067326\n",
      "min: -1.0406485396783058\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3663708380686588\n",
      "std: 0.3464450638739147\n",
      "min: -0.6024608062844783\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0568469494893388\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075140201103244\n",
      "std: 0.004621132920557784\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075744726712445\n",
      "std: 0.0046624032369790135\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.040722790911753126\n",
      "min: 0.017341274653411603\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3186186368936972\n",
      "std: 0.2939298050683875\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4905859928374219\n",
      "std: 0.3613013274796186\n",
      "min: -0.3887925499428949\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260493810725455\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.186280618409345\n",
      "std: 0.16887786855275755\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.18918158345565\n",
      "std: 0.1721035960599215\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.042796533834094236\n",
      "min: 0.005991365314890132\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33899975648360625\n",
      "std: 0.3674642451408259\n",
      "min: -1.0441664747471737\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36580313386714436\n",
      "std: 0.34781641450970197\n",
      "min: -0.6034800669618645\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05699766811365117\n",
      "min: 0.07116112433950784\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407036146475146\n",
      "std: 0.0068015896169395865\n",
      "min: 1.3506838144968853\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071045624808485\n",
      "std: 0.006868026845413362\n",
      "min: 1.3511947150280326\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.040725225169202635\n",
      "min: 0.017058627814219535\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3177169346515604\n",
      "std: 0.2937413077832892\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4905852790852606\n",
      "std: 0.3610891377191247\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256624639903985\n",
      "min: 0.0822143147394386\n",
      "max: 0.29968399445139055\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.188613635581076\n",
      "std: 0.16420559913754285\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1915199711371733\n",
      "std: 0.1655938844504339\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04210608729031442\n",
      "min: 0.005740098898050176\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.340104933389375\n",
      "std: 0.3657156311136701\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36534673612372626\n",
      "std: 0.34770151892848755\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05698125862991343\n",
      "min: 0.07095027915742903\n",
      "max: 0.32798433939667904\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076666377929747\n",
      "std: 0.004042761101687108\n",
      "min: 1.3747578942390895\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077169324596612\n",
      "std: 0.004230238098570412\n",
      "min: 1.3747578942390895\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04072234787553958\n",
      "min: 0.017358586731577436\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31890065942699003\n",
      "std: 0.29387626362314795\n",
      "min: -0.797840950208833\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4900777273176876\n",
      "std: 0.36128139319103214\n",
      "min: -0.3890895033732395\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260142015102704\n",
      "min: 0.08218608005805052\n",
      "max: 0.2997505107912778\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2143174594517472\n",
      "std: 0.07871224856818508\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2169014365922037\n",
      "std: 0.08347068567713573\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04125197490097112\n",
      "min: 0.011660689369961615\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34693084097553856\n",
      "std: 0.36246983016309126\n",
      "min: -1.0393086302630354\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3595728003641348\n",
      "std: 0.3476016688423082\n",
      "min: -0.6034392487620789\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057215685202762066\n",
      "min: 0.07160298582685132\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408208476178792\n",
      "std: 0.0029777583089382743\n",
      "min: 1.3810492880477452\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082430920550397\n",
      "std: 0.0032173201383703907\n",
      "min: 1.3810492880477452\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04072201632393127\n",
      "min: 0.017433319600307882\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3202676707823343\n",
      "std: 0.2936091655576628\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48824574992629705\n",
      "std: 0.36128534348587255\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261407970082651\n",
      "min: 0.08224047526152704\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.177750565812012\n",
      "std: 0.2111965641837511\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.180675050277988\n",
      "std: 0.213912997199566\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04324974894009373\n",
      "min: 0.003580235298510747\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3472275714839287\n",
      "std: 0.3635963159916556\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3592819781224849\n",
      "std: 0.348165655308346\n",
      "min: -0.6046562845377552\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057203611869513254\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4056602670460792\n",
      "std: 0.013547437749908577\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4057150873284738\n",
      "std: 0.01368428669981298\n",
      "min: 1.2960281885598637\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04073591354190541\n",
      "min: 0.016078967451967272\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3217103649131117\n",
      "std: 0.29360477177610583\n",
      "min: -0.7974335654434678\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4889229562428171\n",
      "std: 0.3620230957178082\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06265860076904768\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1897720426502116\n",
      "std: 0.15269259460564902\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1924425994211834\n",
      "std: 0.15520097501128152\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.0416293634341582\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33914618895667714\n",
      "std: 0.36431282681310445\n",
      "min: -1.0406485396783058\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3663673053981458\n",
      "std: 0.3465625455655618\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05688284667009952\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407528366631528\n",
      "std: 0.00459081735311272\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075680555860368\n",
      "std: 0.004633407137502509\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.040142357105679254\n",
      "min: 0.017164565770904923\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31869295788463226\n",
      "std: 0.2939333647379449\n",
      "min: -0.7978768618452209\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4905310303186577\n",
      "std: 0.3613038825704446\n",
      "min: -0.38879254994289475\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260891692972097\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1866683752558482\n",
      "std: 0.16749698113658254\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.189429647574505\n",
      "std: 0.17071183738327494\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.042175031941662854\n",
      "min: 0.005991365314890132\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3395040338590822\n",
      "std: 0.36711290149314196\n",
      "min: -1.0441664747471737\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3657999319790477\n",
      "std: 0.3479130876419028\n",
      "min: -0.6034800669618647\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05703163633971799\n",
      "min: 0.07116112433950784\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070594839976531\n",
      "std: 0.006744358025874815\n",
      "min: 1.3506838144968853\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407106898323144\n",
      "std: 0.006811312403179134\n",
      "min: 1.3511947150280328\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.040144742766524064\n",
      "min: 0.016840321846985896\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31780178323309516\n",
      "std: 0.29374491883902426\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49052730685328194\n",
      "std: 0.36109302580930175\n",
      "min: -0.3883083708185302\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257061313960789\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1889726327531698\n",
      "std: 0.16275163033036488\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.191739145322494\n",
      "std: 0.1641568198128247\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.04149849138133396\n",
      "min: 0.005740098898050176\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34058595060586894\n",
      "std: 0.3653956701318808\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3653559392883351\n",
      "std: 0.3477994222060013\n",
      "min: -0.6038458408294994\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05701539215733239\n",
      "min: 0.07095027915742903\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076779050335007\n",
      "std: 0.0040148419861852835\n",
      "min: 1.3747578942390895\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077076961094968\n",
      "std: 0.004202510541013646\n",
      "min: 1.3747578942390895\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.04014192279634531\n",
      "min: 0.017224223052583917\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31896880710274184\n",
      "std: 0.2938806701877138\n",
      "min: -0.797840950208833\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4900286093577097\n",
      "std: 0.3612826539876165\n",
      "min: -0.3890895033732397\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260521718387718\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.21420641976878\n",
      "std: 0.07829922892599636\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.216664309966002\n",
      "std: 0.0830376654703447\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.04066126178378382\n",
      "min: 0.01148856370921786\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34730531291028394\n",
      "std: 0.3621769328945885\n",
      "min: -1.0393086302630354\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35965403674862445\n",
      "std: 0.3476991763962125\n",
      "min: -0.6034392487620788\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05724539947942712\n",
      "min: 0.07160298582685132\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408208866440006\n",
      "std: 0.0029694730979361304\n",
      "min: 1.3810492880477452\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082233800848367\n",
      "std: 0.0032099840917613224\n",
      "min: 1.3810492880477452\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.04014159775706234\n",
      "min: 0.017220857280709004\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3203156244972128\n",
      "std: 0.29361588210235984\n",
      "min: -0.7976242858584903\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48822191605390797\n",
      "std: 0.36128606018438275\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261759565670387\n",
      "min: 0.08224047526152703\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1782670031866895\n",
      "std: 0.2094859751876419\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1810490356038108\n",
      "std: 0.21219971268643625\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03448275862068966\n",
      "std: 0.04261936317554902\n",
      "min: 0.003580235298510747\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3476164481805566\n",
      "std: 0.36328845239940183\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35937342101131\n",
      "std: 0.3482599625120431\n",
      "min: -0.6046562845377552\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057235129881744756\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4057030072106824\n",
      "std: 0.01345161522663873\n",
      "min: 1.294791430757435\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4057366994776823\n",
      "std: 0.013588564455847456\n",
      "min: 1.294791430757435\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.04015522208875404\n",
      "min: 0.01575340272785361\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3217395295488448\n",
      "std: 0.2936089972521622\n",
      "min: -0.797433565443468\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4888894922654697\n",
      "std: 0.36201291255449813\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266157146021097\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1901622971998487\n",
      "std: 0.15183316497598956\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.192845007878766\n",
      "std: 0.15431700336357804\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.04103762633441271\n",
      "min: 0.0052508147561464\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3389282648062257\n",
      "std: 0.36464521226524577\n",
      "min: -1.0406485396783058\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36539879366485684\n",
      "std: 0.34674532009352693\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05688406079402163\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075138662396172\n",
      "std: 0.0045810747709083945\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075483781032134\n",
      "std: 0.004626019992519524\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.039579289274760183\n",
      "min: 0.016810175195219025\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3188245106854659\n",
      "std: 0.2939894718711806\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4904859274874579\n",
      "std: 0.36134926272498846\n",
      "min: -0.3887925499428949\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261586275044406\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1871128214368676\n",
      "std: 0.1665357079502117\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1898836829488968\n",
      "std: 0.16972268766193552\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.04157254783304485\n",
      "min: 0.005886533691104929\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3392915035066356\n",
      "std: 0.3673945170257893\n",
      "min: -1.0441664747471737\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3648330097830702\n",
      "std: 0.3480764554028466\n",
      "min: -0.6034800669618647\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05703118726412689\n",
      "min: 0.07116112433950784\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070518440253053\n",
      "std: 0.006722830479572318\n",
      "min: 1.3506838144968853\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407093887012568\n",
      "std: 0.006791141046693375\n",
      "min: 1.3511947150280326\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.039581629126154844\n",
      "min: 0.01640635291885317\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3179433869248716\n",
      "std: 0.29380108626746215\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4904794737360899\n",
      "std: 0.36113963796246784\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257792369291398\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1893551342404138\n",
      "std: 0.16204635905700815\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1921324321824183\n",
      "std: 0.16343055738434345\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.040909510731720236\n",
      "min: 0.005210908205748144\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3403511856732095\n",
      "std: 0.36571356319115306\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36439592665448217\n",
      "std: 0.34796463368476227\n",
      "min: -0.6038458408294995\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057014893730460633\n",
      "min: 0.07095027915742903\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407661096213566\n",
      "std: 0.004020252807251829\n",
      "min: 1.3744150834833977\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076859745419616\n",
      "std: 0.004207887845543563\n",
      "min: 1.3744150834833977\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.03957886364306771\n",
      "min: 0.016750783767591006\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3190947926590913\n",
      "std: 0.29393750985331707\n",
      "min: -0.7978409502088328\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4899883371993718\n",
      "std: 0.3613268659089105\n",
      "min: -0.3890895033732396\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261199996478192\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2142281378743514\n",
      "std: 0.07801454963703817\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2167093073749806\n",
      "std: 0.08266365985110524\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.04008829684584135\n",
      "min: 0.011488563709217862\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3469634504773416\n",
      "std: 0.3625341686997301\n",
      "min: -1.0393086302630354\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.358776680902465\n",
      "std: 0.34784533857299305\n",
      "min: -0.6034392487620788\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057240507386771756\n",
      "min: 0.07160298582685132\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081861093772183\n",
      "std: 0.0029803720662322673\n",
      "min: 1.3810492880477452\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081959579752763\n",
      "std: 0.003220536989287262\n",
      "min: 1.3810492880477452\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.039578544331997485\n",
      "min: 0.016889756933365935\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32042101305336823\n",
      "std: 0.29367473567770586\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4882068573578163\n",
      "std: 0.3613292652025699\n",
      "min: -0.38967766754115885\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06262404506165885\n",
      "min: 0.08224047526152703\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1788682812366282\n",
      "std: 0.2081095875830514\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.181656528827898\n",
      "std: 0.2108138570285094\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.04200825421814026\n",
      "min: 0.0035359243345667365\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3472881018021287\n",
      "std: 0.3636355701382683\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3585033813061228\n",
      "std: 0.34840520228377747\n",
      "min: -0.6046562845377553\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057232119743452554\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4057179994322464\n",
      "std: 0.013369331328148387\n",
      "min: 1.2926838961586116\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405746134268434\n",
      "std: 0.013507514154211272\n",
      "min: 1.2926838961586116\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.033898305084745756\n",
      "std: 0.03959190653362427\n",
      "min: 0.015457531822665228\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3218266677488764\n",
      "std: 0.293665759120384\n",
      "min: -0.797433565443468\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4888653830722372\n",
      "std: 0.3620458074689604\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266750193341392\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1899541825824695\n",
      "std: 0.15086459511684625\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.192763380674907\n",
      "std: 0.1533204176442962\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.040463444077170535\n",
      "min: 0.0052508147561464\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33906884862791625\n",
      "std: 0.36407380698496195\n",
      "min: -1.0406485396783058\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36558526920737366\n",
      "std: 0.34648808635056344\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05689992607672944\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407508363168989\n",
      "std: 0.00455544002761055\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407533650853485\n",
      "std: 0.00461038557016761\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333334\n",
      "std: 0.03903280048219527\n",
      "min: 0.016565333098482547\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31898595560927473\n",
      "std: 0.293961296490589\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49039636407868287\n",
      "std: 0.36138560998930946\n",
      "min: -0.3887925499428949\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06262354629362117\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.186967491029898\n",
      "std: 0.16528930735177108\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1898619837065136\n",
      "std: 0.16845053257101217\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.04098794835816976\n",
      "min: 0.005886533691104929\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3394368887823266\n",
      "std: 0.36678369123681115\n",
      "min: -1.0441664747471737\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3650247408474356\n",
      "std: 0.3478039013996305\n",
      "min: -0.6034800669618651\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05704554950042877\n",
      "min: 0.07116112433950784\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070536623129994\n",
      "std: 0.006676298572249012\n",
      "min: 1.3506838144968858\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070862831181514\n",
      "std: 0.006751332925846957\n",
      "min: 1.3511947150280326\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.03903509552426203\n",
      "min: 0.01628536024745516\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31811438162512756\n",
      "std: 0.2937731185676869\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4903873949268104\n",
      "std: 0.36117714188627925\n",
      "min: -0.3883083708185302\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258595466143553\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.189163513095205\n",
      "std: 0.16094730448125044\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1920655112423775\n",
      "std: 0.1623136225084988\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.04033787923007226\n",
      "min: 0.005210908205748144\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3404751190348164\n",
      "std: 0.3651321580017133\n",
      "min: -1.024685512886558\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36459699693519515\n",
      "std: 0.3476939648318878\n",
      "min: -0.6038458408294995\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05702937841697259\n",
      "min: 0.07095027915742903\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407653106766774\n",
      "std: 0.0040023010721207146\n",
      "min: 1.374415083483398\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407668992565011\n",
      "std: 0.004198877091005198\n",
      "min: 1.374415083483398\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.039032383075273396\n",
      "min: 0.01656340050784225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3192506823272779\n",
      "std: 0.29390993313204655\n",
      "min: -0.7978409502088328\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.489904109773478\n",
      "std: 0.3613619942195944\n",
      "min: -0.38908950337323944\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261952495439069\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2136310347642625\n",
      "std: 0.07781139540608734\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2162501528448355\n",
      "std: 0.08234263806185958\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.03953223393174502\n",
      "min: 0.011488563709217862\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34698426360136136\n",
      "std: 0.361983904746382\n",
      "min: -1.0393086302630354\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3590505684080836\n",
      "std: 0.3475745506817974\n",
      "min: -0.6034392487620789\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057250725892820986\n",
      "min: 0.07160298582685132\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081705256234678\n",
      "std: 0.0029792917163563425\n",
      "min: 1.380576698894642\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081716553783037\n",
      "std: 0.0032303601960082863\n",
      "min: 1.380576698894642\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.03903206968305799\n",
      "min: 0.01655838769927957\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32055693812348285\n",
      "std: 0.2936492192152588\n",
      "min: -0.7976242858584903\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48814695613971004\n",
      "std: 0.3613634356827151\n",
      "min: -0.38967766754115846\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626312702071214\n",
      "min: 0.08224047526152703\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1788288410540002\n",
      "std: 0.2066574857113128\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1817389484931478\n",
      "std: 0.20935171506586714\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.04141542665349876\n",
      "min: 0.0035359243345667365\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3473235307195128\n",
      "std: 0.3630768411273878\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3587860042177547\n",
      "std: 0.34813664108624226\n",
      "min: -0.6046562845377554\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05724417940320727\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405738810467848\n",
      "std: 0.013284429509712611\n",
      "min: 1.2926838961586116\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4057574075697028\n",
      "std: 0.013426418982903095\n",
      "min: 1.2926838961586116\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.039045179040914375\n",
      "min: 0.015232160060087641\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3219451750137932\n",
      "std: 0.2936376538136358\n",
      "min: -0.7974335654434678\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48879544286024135\n",
      "std: 0.36206990121120264\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06267418308650177\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.191120828295267\n",
      "std: 0.1496876849643549\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1939767431539972\n",
      "std: 0.15214862675592392\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.03990592597157447\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3396824052377097\n",
      "std: 0.36465930400280033\n",
      "min: -1.0406485396783058\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36644294638469227\n",
      "std: 0.3469072533715159\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05696921042351484\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075413270030408\n",
      "std: 0.004526212402050753\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075699003413464\n",
      "std: 0.004579427715860898\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.0385021518268789\n",
      "min: 0.01629642716954972\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31903913486054325\n",
      "std: 0.2940586703020178\n",
      "min: -0.7978768618452209\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49047413635087045\n",
      "std: 0.36142146809061576\n",
      "min: -0.3887925499428949\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06262832841886698\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1881759991251497\n",
      "std: 0.16406092798504657\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1911147209845465\n",
      "std: 0.16722604043722428\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.040420458229562056\n",
      "min: 0.0058865336911049304\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3400546761891182\n",
      "std: 0.36732074676902005\n",
      "min: -1.0441664747471737\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3658845290536066\n",
      "std: 0.34820456000335126\n",
      "min: -0.6034800669618651\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05711308693240198\n",
      "min: 0.07116112433950784\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070938696014366\n",
      "std: 0.006630885924046636\n",
      "min: 1.3506838144968858\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071296109230464\n",
      "std: 0.006704648317519449\n",
      "min: 1.3511947150280326\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.038504403716296286\n",
      "min: 0.01601191486779652\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3181771450170431\n",
      "std: 0.29387080505926594\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49046304752890424\n",
      "std: 0.3612143217036015\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259111239828472\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1903416264409294\n",
      "std: 0.15973156692346663\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1932884984879526\n",
      "std: 0.16111483036404103\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.03978285764348662\n",
      "min: 0.005210908205748144\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.341072057527231\n",
      "std: 0.36570328182242307\n",
      "min: -1.0365006499365943\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3654665214110652\n",
      "std: 0.3480983984245245\n",
      "min: -0.6038458408294995\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05709702646396956\n",
      "min: 0.07095027915742903\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076834536088285\n",
      "std: 0.003980060583742111\n",
      "min: 1.374415083483398\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407702881862042\n",
      "std: 0.0041734702184839855\n",
      "min: 1.374415083483398\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.03850174239069489\n",
      "min: 0.01629824470569032\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.319298554749094\n",
      "std: 0.29400851352748925\n",
      "min: -0.7978409502088328\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48998732879973317\n",
      "std: 0.36139704631792774\n",
      "min: -0.3890895033732396\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06262417594678397\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.214388902533023\n",
      "std: 0.07745638010541114\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2170649860843787\n",
      "std: 0.08195609841934505\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.038992299490917065\n",
      "min: 0.011488563709217864\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34748340304103137\n",
      "std: 0.3625821987833061\n",
      "min: -1.0393086302630354\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35998937611218973\n",
      "std: 0.347988467262972\n",
      "min: -0.6034392487620789\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057314251642485194\n",
      "min: 0.07138778157122715\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081924196879108\n",
      "std: 0.0029643425670692037\n",
      "min: 1.380576698894642\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081973924736293\n",
      "std: 0.0032110012796649403\n",
      "min: 1.380576698894642\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.03850143463715642\n",
      "min: 0.016363174727139173\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32058574858440475\n",
      "std: 0.29374982308113406\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48825346342764997\n",
      "std: 0.3613983251857258\n",
      "min: -0.38967766754115857\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626356437986987\n",
      "min: 0.08224047526152703\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1801946126981073\n",
      "std: 0.20491698734110267\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1831459716832224\n",
      "std: 0.2076262175690681\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.040839916123982516\n",
      "min: 0.003535924334566736\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3478324104176904\n",
      "std: 0.3636623798675609\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35973598794269473\n",
      "std: 0.3485481887893378\n",
      "min: -0.6046562845377554\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05730911898987415\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4057994321821516\n",
      "std: 0.013191150517901797\n",
      "min: 1.2926838961586116\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405821009233888\n",
      "std: 0.013333321547844817\n",
      "min: 1.2926838961586116\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.038514299186939105\n",
      "min: 0.015061394708449341\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3219564860136734\n",
      "std: 0.2937364788295744\n",
      "min: -0.797433565443468\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48889399782164483\n",
      "std: 0.3620947147628623\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06267805358299297\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1917331965804627\n",
      "std: 0.148368616736242\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.194528937064756\n",
      "std: 0.15082525255258986\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.039364466799707364\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33954880420758\n",
      "std: 0.364767941327481\n",
      "min: -1.0406485396783058\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36639314461576694\n",
      "std: 0.3464527046401752\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056934370696659756\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075630001468786\n",
      "std: 0.0045062461655632725\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075742875544348\n",
      "std: 0.004562615044012259\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.03798664866051809\n",
      "min: 0.015994530045097037\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31907164205921146\n",
      "std: 0.29407570987354087\n",
      "min: -0.7978768618452209\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4903828730526932\n",
      "std: 0.36138121018424396\n",
      "min: -0.38879254994289475\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06262494978590076\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.188824551439843\n",
      "std: 0.16269004200832404\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.191700956238744\n",
      "std: 0.16584535812237855\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.03986940145097745\n",
      "min: 0.0058865336911049304\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.339924408623184\n",
      "std: 0.3673868046017443\n",
      "min: -1.0441664747471737\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36583638637010985\n",
      "std: 0.3477344428939153\n",
      "min: -0.6034800669618651\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05707671244293665\n",
      "min: 0.07116112433950784\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071221567774066\n",
      "std: 0.006597171744759753\n",
      "min: 1.3506838144968858\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407140459186887\n",
      "std: 0.00667269653767315\n",
      "min: 1.3511947150280326\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.037988859144478755\n",
      "min: 0.01565103548032105\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31821889924098873\n",
      "std: 0.2938879575122223\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4903695861506139\n",
      "std: 0.36117528704079116\n",
      "min: -0.3883083708185302\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258807385363203\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1909509110401728\n",
      "std: 0.1585056796180498\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1938359048648388\n",
      "std: 0.15989217881425194\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612904\n",
      "std: 0.039243873781754625\n",
      "min: 0.005210908205748144\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.340921858036036\n",
      "std: 0.36580097137104456\n",
      "min: -1.0365006499365945\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36542499894269664\n",
      "std: 0.3476298957960774\n",
      "min: -0.6038458408294995\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05706070719866653\n",
      "min: 0.07095027915742903\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407703011685323\n",
      "std: 0.003969981737450299\n",
      "min: 1.3744150834833975\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077053434731992\n",
      "std: 0.004165402010424014\n",
      "min: 1.3744150834833975\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.03798624695483721\n",
      "min: 0.01595372321736806\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3193258433526538\n",
      "std: 0.2940265135245329\n",
      "min: -0.7978409502088328\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48990076401805754\n",
      "std: 0.3613556164030838\n",
      "min: -0.3890895033732396\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06262064137452639\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2145944220561817\n",
      "std: 0.07706339283111384\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2172194478638922\n",
      "std: 0.08152809822127854\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.038467862728211726\n",
      "min: 0.010583128182429364\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34723590902877277\n",
      "std: 0.3627129919219077\n",
      "min: -1.0393086302630354\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3600187178007515\n",
      "std: 0.34751745581860555\n",
      "min: -0.6034392487620789\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05727415176548934\n",
      "min: 0.07138778157122712\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408205781734132\n",
      "std: 0.0029608238318047076\n",
      "min: 1.3805766988946422\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081939709046545\n",
      "std: 0.0032102390061928446\n",
      "min: 1.3805766988946422\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.03798594453475098\n",
      "min: 0.016030828131419417\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3205943845867873\n",
      "std: 0.2937702155470738\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48818999230698423\n",
      "std: 0.3613561004107223\n",
      "min: -0.38967766754115857\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06263183801388379\n",
      "min: 0.08224047526152703\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1809633972241422\n",
      "std: 0.20321611539686257\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1838503631481365\n",
      "std: 0.20592330670495163\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.04028116366209304\n",
      "min: 0.003535924334566737\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34759528288911223\n",
      "std: 0.3637859846108004\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3597755442753618\n",
      "std: 0.3480754019839539\n",
      "min: -0.6046562845377554\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057270479967139444\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405848615473653\n",
      "std: 0.013105461450413788\n",
      "min: 1.2926838961586116\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4058526045250064\n",
      "std: 0.013248303321102552\n",
      "min: 1.2926838961586116\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.037998573050700445\n",
      "min: 0.014749019995255014\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.321948209188616\n",
      "std: 0.29375532718267\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.488822302022897\n",
      "std: 0.3620431291302595\n",
      "min: -0.38954828823915266\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626737700757795\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1931678203976637\n",
      "std: 0.1471733521523382\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1960207003191967\n",
      "std: 0.1496386590967127\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.03883833368548015\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3403626282037421\n",
      "std: 0.3650756254019359\n",
      "min: -1.0406485396783058\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3662916309566806\n",
      "std: 0.34679984591148016\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05698093660906306\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407590287459286\n",
      "std: 0.004469924556639853\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075949518660607\n",
      "std: 0.004525460605734558\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.03748563595839464\n",
      "min: 0.015812599983570957\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3189797465766886\n",
      "std: 0.2940390739308326\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49039091846201727\n",
      "std: 0.3612953977542831\n",
      "min: -0.3887925499428951\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626122345058057\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.190304018691259\n",
      "std: 0.16134014386540663\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1932358466119568\n",
      "std: 0.16449912443410233\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.03933395386590098\n",
      "min: 0.0058865336911049304\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34074005808092106\n",
      "std: 0.36765000830372213\n",
      "min: -1.0441664747471737\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3657370106960128\n",
      "std: 0.34806225868988494\n",
      "min: -0.6034800669618651\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05712146854199081\n",
      "min: 0.07116112433950784\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071565964851351\n",
      "std: 0.006551324995969356\n",
      "min: 1.3506838144968858\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40716813480533\n",
      "std: 0.006625707520838843\n",
      "min: 1.3511947150280326\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.037487806376910356\n",
      "min: 0.015470023055781826\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31813581824088755\n",
      "std: 0.29385114183019434\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4903759833665729\n",
      "std: 0.36109053122989965\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257567611947903\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1924050095935559\n",
      "std: 0.15716453864860108\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1953456653099999\n",
      "std: 0.1585713305760658\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.038720022587660566\n",
      "min: 0.005210908205748144\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34171760825100145\n",
      "std: 0.36609356056191295\n",
      "min: -1.0365006499365943\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3653328275939399\n",
      "std: 0.3479604192718616\n",
      "min: -0.6038458408294995\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05710551984905476\n",
      "min: 0.07095027915742903\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077289610682076\n",
      "std: 0.003940148973365757\n",
      "min: 1.374415083483398\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077248955843862\n",
      "std: 0.004132931548020138\n",
      "min: 1.374415083483398\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.03748524167114019\n",
      "min: 0.01581670367724956\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3192285388261673\n",
      "std: 0.2939908096016805\n",
      "min: -0.797840950208833\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4899141455996227\n",
      "std: 0.3612686863051977\n",
      "min: -0.3890895033732396\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260776296555987\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2156195162916725\n",
      "std: 0.0766987412812046\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2183125071103562\n",
      "std: 0.08112827211988279\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.037958128910553474\n",
      "min: 0.01058312818242936\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34793864950430947\n",
      "std: 0.36302730596578525\n",
      "min: -1.0393086302630354\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35999346428427587\n",
      "std: 0.34784416356928527\n",
      "min: -0.6034392487620789\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057315151153519185\n",
      "min: 0.07138778157122715\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082242616081928\n",
      "std: 0.0029419415095835837\n",
      "min: 1.380576698894642\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082063051028475\n",
      "std: 0.00318788266568878\n",
      "min: 1.380576698894642\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.037484944637456726\n",
      "min: 0.015812094114071248\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3204797570508268\n",
      "std: 0.2937375762212931\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4882253265428456\n",
      "std: 0.36126905003530346\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261874831480937\n",
      "min: 0.08224047526152703\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1825321992283402\n",
      "std: 0.2017222103073855\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1854728590675911\n",
      "std: 0.20443910185113176\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03174603174603175\n",
      "std: 0.039738331012480185\n",
      "min: 0.003535924334566737\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34830988173651406\n",
      "std: 0.36409193703607523\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35975726806125063\n",
      "std: 0.3483996869065073\n",
      "min: -0.6046562845377554\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05731291445313068\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4059026798863574\n",
      "std: 0.013014116919853793\n",
      "min: 1.2926838961586116\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4058998021186964\n",
      "std: 0.013156614836719269\n",
      "min: 1.2926838961586116\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.0374973449367609\n",
      "min: 0.014574749638645274\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32181687013056076\n",
      "std: 0.2937215944189624\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4888493221071386\n",
      "std: 0.3619467066212769\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266016963451247\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1940342909477746\n",
      "std: 0.14631116174318334\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1968146899454986\n",
      "std: 0.14873938374685552\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03832710214809469\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34070812499740505\n",
      "std: 0.36473416320542723\n",
      "min: -1.0406485396783058\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3653400125749196\n",
      "std: 0.3466026517882934\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05696830943377242\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407616309354502\n",
      "std: 0.004443150753821853\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076357377779685\n",
      "std: 0.004496444800825523\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03699849723988185\n",
      "min: 0.015497276156078613\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3191169216360632\n",
      "std: 0.2940647711725551\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49013624494758473\n",
      "std: 0.3613123579790161\n",
      "min: -0.3887925499428951\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261321827392623\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1912131929042657\n",
      "std: 0.16040520828470906\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1940706545421245\n",
      "std: 0.1635250501117807\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03881375250226981\n",
      "min: 0.00537788043977454\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34109002432665336\n",
      "std: 0.3672726247958003\n",
      "min: -1.0441664747471737\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36478916206614626\n",
      "std: 0.3478503018446436\n",
      "min: -0.6034800669618651\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05710754425655125\n",
      "min: 0.07116112433950784\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071892674847506\n",
      "std: 0.006511342474614491\n",
      "min: 1.3506838144968858\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072154105463632\n",
      "std: 0.006584889355365288\n",
      "min: 1.3511947150280326\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.037000628934452655\n",
      "min: 0.015190030153554057\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3182815819547226\n",
      "std: 0.29387703834842166\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49011934553850184\n",
      "std: 0.36110867908140787\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257697803223497\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1932803629248858\n",
      "std: 0.15624620878606216\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1961470683661797\n",
      "std: 0.15762534768475722\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.0382110196363703\n",
      "min: 0.005080774480528211\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34204749031461607\n",
      "std: 0.36574297741594414\n",
      "min: -1.0365006499365945\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3643910943620154\n",
      "std: 0.3477485622507801\n",
      "min: -0.6038458408294995\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057091538397819254\n",
      "min: 0.07095027915742903\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407753454065834\n",
      "std: 0.003917648259351846\n",
      "min: 1.3744150834833977\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077643713197496\n",
      "std: 0.004106513975800297\n",
      "min: 1.3744150834833977\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03699811005136623\n",
      "min: 0.015538342526373036\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31936076301752925\n",
      "std: 0.2940172753926376\n",
      "min: -0.797840950208833\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4896636208696291\n",
      "std: 0.3612844166639724\n",
      "min: -0.3890895033732396\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260858984263408\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2161654097974595\n",
      "std: 0.07634437151011327\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2187937281667809\n",
      "std: 0.08069696462187048\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.0374626289240835\n",
      "min: 0.01058312818242936\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3481766981472008\n",
      "std: 0.3626980139401523\n",
      "min: -1.0393086302630354\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35912125588094906\n",
      "std: 0.34761799021432294\n",
      "min: -0.6034392487620789\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05729749844719541\n",
      "min: 0.07138778157122715\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082418896079256\n",
      "std: 0.0029249170950079832\n",
      "min: 1.3805766988946417\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082391041346674\n",
      "std: 0.003164928130587056\n",
      "min: 1.3805766988946417\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03699781807614995\n",
      "min: 0.015631578912107376\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3205942030577248\n",
      "std: 0.2937658247653993\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4879972450334142\n",
      "std: 0.3612832411896497\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261931791983015\n",
      "min: 0.08224047526152703\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.183556757290942\n",
      "std: 0.2005045752834095\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1864207470840058\n",
      "std: 0.20319706715168132\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03921094211492515\n",
      "min: 0.003400302191169203\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34856061580186076\n",
      "std: 0.36375578400551256\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3588912710369124\n",
      "std: 0.3481725227014973\n",
      "min: -0.6046562845377554\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057296811917597376\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4059566136876271\n",
      "std: 0.012917737354481098\n",
      "min: 1.2926838961586116\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4059681318296815\n",
      "std: 0.013061544198745096\n",
      "min: 1.2926838961586116\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.0370099973086968\n",
      "min: 0.01438752133849886\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32191538646483725\n",
      "std: 0.29374777227894455\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4886124775919974\n",
      "std: 0.36195229113624866\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06266025862360039\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1937236374052533\n",
      "std: 0.1453410697324657\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1965990584806527\n",
      "std: 0.14777543862006165\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.0378299811087451\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3401888339355667\n",
      "std: 0.36537737554047073\n",
      "min: -1.0406485396783058\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36600281584846517\n",
      "std: 0.34638043175654454\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05694513100337527\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075979219285824\n",
      "std: 0.004438234305320124\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407628943456308\n",
      "std: 0.004488807486592456\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.03652465083385954\n",
      "min: 0.01526029816888354\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31909233758654104\n",
      "std: 0.29417077598749336\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49014016401727717\n",
      "std: 0.3612884024666048\n",
      "min: -0.3887925499428951\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260562703104666\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.190943491593333\n",
      "std: 0.15933181050398734\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1938944011476964\n",
      "std: 0.1624530529627842\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.038307955313561355\n",
      "min: 0.005377880439774539\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34057405683716846\n",
      "std: 0.36787331533826284\n",
      "min: -1.0441664747471737\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36545599532468503\n",
      "std: 0.34761445665980495\n",
      "min: -0.6034800669618651\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05708304815257052\n",
      "min: 0.07116112433950784\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071766467959423\n",
      "std: 0.006485606737355723\n",
      "min: 1.3506838144968858\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072142567046917\n",
      "std: 0.006557791803439405\n",
      "min: 1.3511947150280326\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.036526745063085536\n",
      "min: 0.014917705391232286\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31826527996640913\n",
      "std: 0.2939829659326154\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4901217019899603\n",
      "std: 0.3610857452706867\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256969657383829\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.192986489201982\n",
      "std: 0.15511091951977857\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1959471130038541\n",
      "std: 0.15650497561921664\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.03771601337852091\n",
      "min: 0.00508077448052821\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34151316863671777\n",
      "std: 0.366378894538373\n",
      "min: -1.0365006499365945\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3650643819287219\n",
      "std: 0.3475159085488026\n",
      "min: -0.6038458408294995\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05706709945474059\n",
      "min: 0.07095027915742903\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077333887831183\n",
      "std: 0.003921435569370858\n",
      "min: 1.3744150834833977\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077560842194103\n",
      "std: 0.004105000242221335\n",
      "min: 1.3744150834833977\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.03652427053203217\n",
      "min: 0.01526301337581462\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3193315361480203\n",
      "std: 0.29412441244102383\n",
      "min: -0.797840950208833\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48967187792496103\n",
      "std: 0.36125957589820545\n",
      "min: -0.3890895033732396\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260086603374529\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2155150750415864\n",
      "std: 0.07606766833680595\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2182475149920933\n",
      "std: 0.08037325760453948\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.03698074106632064\n",
      "min: 0.01058312818242936\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3475559246012009\n",
      "std: 0.3633719153632715\n",
      "min: -1.0393086302630354\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35985686357010194\n",
      "std: 0.3473904461307488\n",
      "min: -0.6034392487620789\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0572695826463792\n",
      "min: 0.07138778157122712\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408215290178138\n",
      "std: 0.002942130995207374\n",
      "min: 1.3805766988946422\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082245191117129\n",
      "std: 0.0031732970169575324\n",
      "min: 1.3805766988946422\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.03652398342664283\n",
      "min: 0.015274221572296513\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3205480962685792\n",
      "std: 0.293874826161771\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48802633747908997\n",
      "std: 0.36125807477743854\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261136825644711\n",
      "min: 0.08224047526152703\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1834248040632456\n",
      "std: 0.19900678002480113\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.186380272380878\n",
      "std: 0.20171122161733152\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.038698159373637867\n",
      "min: 0.003400302191169203\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3479502195462989\n",
      "std: 0.3644218398175095\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3596379819610083\n",
      "std: 0.34794728735401864\n",
      "min: -0.6046562845377554\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057270411113827066\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4059640052453992\n",
      "std: 0.012824556504382592\n",
      "min: 1.2926838961586113\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405986853509159\n",
      "std: 0.012969027360906235\n",
      "min: 1.2926838961586113\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.03653594864881857\n",
      "min: 0.014188044493456195\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32185318379123273\n",
      "std: 0.293856260397073\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48863423645475984\n",
      "std: 0.36191835494671704\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06265182588423157\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1941995966075316\n",
      "std: 0.1443213338498276\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.196905283049398\n",
      "std: 0.14673346279964444\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.037346330485315646\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3402315802115022\n",
      "std: 0.3650389572347156\n",
      "min: -1.0406485396783058\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3658610203922226\n",
      "std: 0.34621275863549444\n",
      "min: -0.6024608062844781\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056956780953139406\n",
      "min: 0.07114479798970585\n",
      "max: 0.32783907861508504\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076264500198967\n",
      "std: 0.004404193026742271\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076474955998666\n",
      "std: 0.004454157107379456\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.03606354651055267\n",
      "min: 0.015107421105050464\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31913319850727384\n",
      "std: 0.29419776564512934\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49005319160614\n",
      "std: 0.36130001660610916\n",
      "min: -0.3887925499428951\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260773670211225\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1914627741277453\n",
      "std: 0.15814456891718054\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1942419595442402\n",
      "std: 0.16123994322357676\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.0378159024097777\n",
      "min: 0.005377880439774539\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3406197473548449\n",
      "std: 0.36750165045819266\n",
      "min: -1.0441664747471737\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36531738721199086\n",
      "std: 0.34743294140328546\n",
      "min: -0.6034800669618651\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057093347646822126\n",
      "min: 0.07116112433950784\n",
      "max: 0.3279341324626527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072116852514767\n",
      "std: 0.006435117051072853\n",
      "min: 1.3506838144968858\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407239182367747\n",
      "std: 0.006506696018404668\n",
      "min: 1.3511947150280326\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.036065604263741224\n",
      "min: 0.014785232333871004\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31831421583306013\n",
      "std: 0.29401025979244766\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49003303106319646\n",
      "std: 0.3610984687393061\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257211203832247\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1934687758477704\n",
      "std: 0.15406923858270238\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.196258237782928\n",
      "std: 0.15544624633304785\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.03723444634153234\n",
      "min: 0.00508077448052821\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3415423793813042\n",
      "std: 0.3660330127020584\n",
      "min: -1.0365006499365945\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.364932732883646\n",
      "std: 0.34733639530023547\n",
      "min: -0.6038458408294995\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05707758792361286\n",
      "min: 0.07095027915742903\n",
      "max: 0.327984339396679\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077594478650484\n",
      "std: 0.0038905454222227867\n",
      "min: 1.3744150834833977\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407772377427859\n",
      "std: 0.004072402792622774\n",
      "min: 1.3744150834833977\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.03606317284763026\n",
      "min: 0.015137943243409408\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31936780448475605\n",
      "std: 0.2941522785060917\n",
      "min: -0.797840950208833\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4895895341882825\n",
      "std: 0.36127026998083\n",
      "min: -0.3890895033732396\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260285741083031\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.215654066865227\n",
      "std: 0.0757017660146007\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2182226861112317\n",
      "std: 0.0799785610900046\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.03651185586812918\n",
      "min: 0.010055160744903945\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3474987271637482\n",
      "std: 0.3630541183972451\n",
      "min: -1.0393086302630354\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3597889388793979\n",
      "std: 0.34720806029142026\n",
      "min: -0.6034392487620789\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05727655824029476\n",
      "min: 0.07138778157122715\n",
      "max: 0.3275204501382876\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082343068219232\n",
      "std: 0.0029230371108440968\n",
      "min: 1.3805766988946422\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082339890356554\n",
      "std: 0.0031521682282345974\n",
      "min: 1.3805766988946422\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.03606289067622152\n",
      "min: 0.0151422180595261\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32056769114643396\n",
      "std: 0.2939048418933346\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48796474965774256\n",
      "std: 0.3612680129203853\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261311212401821\n",
      "min: 0.08224047526152703\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.183982878541526\n",
      "std: 0.19790389160655644\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.186766149513744\n",
      "std: 0.20058189301634635\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.038199482058855275\n",
      "min: 0.003103809363328191\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34790035502074823\n",
      "std: 0.36409490447888243\n",
      "min: -1.0462977647854377\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.359576098295349\n",
      "std: 0.34776211063112844\n",
      "min: -0.6046562845377554\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0572785387820483\n",
      "min: 0.07120819774983718\n",
      "max: 0.327767556463597\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4060160104897783\n",
      "std: 0.012735514437626185\n",
      "min: 1.2926838961586116\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4060286615222086\n",
      "std: 0.012879533439052317\n",
      "min: 1.2926838961586116\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.03607464939006065\n",
      "min: 0.01397082956964343\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32185704217919814\n",
      "std: 0.29388455950352355\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48856481196476037\n",
      "std: 0.3619196765184389\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06265309407408835\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1951201601327974\n",
      "std: 0.1434628656605842\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1978573732043367\n",
      "std: 0.1458644355850612\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03687561983294247\n",
      "min: 0.004997925647148765\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34063534479121155\n",
      "std: 0.3659647885963733\n",
      "min: -1.0775097237334763\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3663146402265954\n",
      "std: 0.34663300643237444\n",
      "min: -0.6501803635779888\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0570091086521828\n",
      "min: 0.07034332619054123\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076559166147804\n",
      "std: 0.004382373327854659\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076786731527808\n",
      "std: 0.004434888524728237\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.035614665743516495\n",
      "min: 0.01478709403540941\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31917628302471335\n",
      "std: 0.29432098692546727\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49006528144203926\n",
      "std: 0.3613402774861549\n",
      "min: -0.3887925499428951\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626100254511322\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1924268269582725\n",
      "std: 0.15713086422666647\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1952360271831977\n",
      "std: 0.1602126208587662\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03733706429426692\n",
      "min: 0.005377880439774539\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3410242493935744\n",
      "std: 0.36838311430034926\n",
      "min: -1.0775186071203195\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3657748374136639\n",
      "std: 0.34783608815879846\n",
      "min: -0.6503864960984344\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057144041802250134\n",
      "min: 0.0703350309578788\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072478833610411\n",
      "std: 0.006391318392709108\n",
      "min: 1.3506838144968858\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407276981038061\n",
      "std: 0.006465031213524676\n",
      "min: 1.3511947150280326\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03561668812202615\n",
      "min: 0.014598491517523834\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31836498505373073\n",
      "std: 0.29413380782373794\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4900438408946494\n",
      "std: 0.361139665142421\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257468752620736\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.194408235431856\n",
      "std: 0.15301295478279694\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1972277744225421\n",
      "std: 0.1543932926100085\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03676570894716004\n",
      "min: 0.00508077448052821\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.341929902524047\n",
      "std: 0.3669443526283581\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3653963195746546\n",
      "std: 0.34774253330697324\n",
      "min: -0.6506039681624003\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05712840339536592\n",
      "min: 0.07033286141518683\n",
      "max: 0.3294534672190304\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077866987206828\n",
      "std: 0.0038707771135915296\n",
      "min: 1.374415083483398\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078015681507197\n",
      "std: 0.004054404460057119\n",
      "min: 1.374415083483398\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03561429845080465\n",
      "min: 0.014825267892513247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3194061318641652\n",
      "std: 0.2942763205755178\n",
      "min: -0.797840950208833\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48960644695341604\n",
      "std: 0.36130972354827096\n",
      "min: -0.3890895033732396\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260502403516867\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2162587506341045\n",
      "std: 0.07531467159451402\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2188664784630878\n",
      "std: 0.07954793406944063\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03605539109693043\n",
      "min: 0.010055160744903946\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34780478290661687\n",
      "std: 0.36399454229118783\n",
      "min: -1.076788275590154\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3603153043673321\n",
      "std: 0.3476192661217341\n",
      "min: -0.6508703458690508\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05732407218513208\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082539549543158\n",
      "std: 0.0029123209010614437\n",
      "min: 1.380576698894642\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082558002528849\n",
      "std: 0.0031429937281942017\n",
      "min: 1.380576698894642\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03561402095618692\n",
      "min: 0.014851624299730491\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3205897867798127\n",
      "std: 0.29403094336795593\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4880015478842995\n",
      "std: 0.3613070227385292\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261503203867244\n",
      "min: 0.08224047526152703\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1850335765340012\n",
      "std: 0.19675398434537236\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1878455587705685\n",
      "std: 0.19942594565414845\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.037714162524753826\n",
      "min: 0.0029581084628523247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34821216931710136\n",
      "std: 0.36502274704502785\n",
      "min: -1.0774167572242215\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3601101062622291\n",
      "std: 0.34816960999486973\n",
      "min: -0.6510132027569787\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05732700599382851\n",
      "min: 0.07035282456402321\n",
      "max: 0.3293850576520611\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4060676133065118\n",
      "std: 0.012656650723254772\n",
      "min: 1.2926838961586113\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406081856795298\n",
      "std: 0.01280172762212322\n",
      "min: 1.2926838961586113\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.035625580237205016\n",
      "min: 0.01375198327637499\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3218640307766143\n",
      "std: 0.29400906973383384\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48859435545697444\n",
      "std: 0.3619501370853339\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06265455250700726\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1958360250473428\n",
      "std: 0.14261762379684179\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1986521767593545\n",
      "std: 0.14498593372980434\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03641733886265108\n",
      "min: 0.004997925647148765\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34096585156795384\n",
      "std: 0.3662745069661175\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3660443241450836\n",
      "std: 0.3465170900433924\n",
      "min: -0.6501803635779888\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057025470114080504\n",
      "min: 0.07034332619054123\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076817437099696\n",
      "std: 0.004352371868536214\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077013642159224\n",
      "std: 0.004403804625237241\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.0351775172235263\n",
      "min: 0.014597417705082837\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3191638703500493\n",
      "std: 0.29436162849276853\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48994007469689577\n",
      "std: 0.3613124795939504\n",
      "min: -0.3887925499428951\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260468049410976\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1931834658358098\n",
      "std: 0.15618796854532094\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1960697588481568\n",
      "std: 0.15924009239889056\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.0368709308318623\n",
      "min: 0.005377880439774539\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34135703782999377\n",
      "std: 0.3686556528694162\n",
      "min: -1.0775186071203198\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36550659774345845\n",
      "std: 0.3477063896843928\n",
      "min: -0.6503864960984345\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05715900066118685\n",
      "min: 0.07033503095787877\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072793203740088\n",
      "std: 0.006346779409211804\n",
      "min: 1.3506838144968858\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073051637390257\n",
      "std: 0.006419672853614367\n",
      "min: 1.3511947150280326\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03517950550717636\n",
      "min: 0.014317117630567375\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.318360481917909\n",
      "std: 0.29417469559670456\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48991712423200695\n",
      "std: 0.36111300952898984\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256964230300723\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1951377378101136\n",
      "std: 0.15204899375777567\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1980351121908406\n",
      "std: 0.15340208970851826\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03630933953071557\n",
      "min: 0.00508077448052821\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34224556501082576\n",
      "std: 0.36724431012983555\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3651350894694635\n",
      "std: 0.3476139278642447\n",
      "min: -0.6506039681624001\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057143396942445565\n",
      "min: 0.07033286141518684\n",
      "max: 0.3294534672190304\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078109996863954\n",
      "std: 0.003845631341414088\n",
      "min: 1.374415083483398\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078228926314296\n",
      "std: 0.004026766091060826\n",
      "min: 1.374415083483398\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03517715617549973\n",
      "min: 0.014632956787940635\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31938934692754056\n",
      "std: 0.2943180178113083\n",
      "min: -0.797840950208833\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4894854597124358\n",
      "std: 0.36128098292758204\n",
      "min: -0.3890895033732396\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259955500162424\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2166758675401808\n",
      "std: 0.0749801467084059\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2193706535396434\n",
      "std: 0.07911484688101353\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03561089733971122\n",
      "min: 0.010055160744903946\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34804006830384804\n",
      "std: 0.36431873336162857\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36011597093180825\n",
      "std: 0.34748546213646503\n",
      "min: -0.6508703458690508\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057335891211332916\n",
      "min: 0.07043584963749587\n",
      "max: 0.3292999551626174\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082717674622989\n",
      "std: 0.0028953665795014997\n",
      "min: 1.3805766988946422\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40827085613405\n",
      "std: 0.0031226318273207066\n",
      "min: 1.3805766988946422\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03517688323141963\n",
      "min: 0.014650060395559186\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3205572331115124\n",
      "std: 0.294074762139518\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48790047282752247\n",
      "std: 0.36127738397510484\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260934215899017\n",
      "min: 0.08224047526152703\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1858906389167043\n",
      "std: 0.19554380420198922\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1887770824368982\n",
      "std: 0.1982055983138292\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.037241736366824596\n",
      "min: 0.0029581084628523247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3484554422753086\n",
      "std: 0.3653374502586198\n",
      "min: -1.0774167572242215\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35991515446807115\n",
      "std: 0.3480348716081344\n",
      "min: -0.6510132027569787\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05733988774341614\n",
      "min: 0.07035282456402321\n",
      "max: 0.3293850576520611\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4061174228323339\n",
      "std: 0.01256212405741112\n",
      "min: 1.2926838961586118\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061283168000926\n",
      "std: 0.012707250339208448\n",
      "min: 1.2926838961586118\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03518824833163152\n",
      "min: 0.013557433886801525\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3218167404904258\n",
      "std: 0.2940517359553497\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4884858478203249\n",
      "std: 0.36191273216424336\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264841779789644\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1960215750999377\n",
      "std: 0.1418169689437415\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1989092176489125\n",
      "std: 0.14416192788675103\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03597107175757497\n",
      "min: 0.004997925647148765\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34162633134911474\n",
      "std: 0.36632654031138767\n",
      "min: -1.0775097237334765\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3642555025148274\n",
      "std: 0.34703909711333003\n",
      "min: -0.674776812470629\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05705928733817351\n",
      "min: 0.07034332619054122\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076615371008858\n",
      "std: 0.00435124210209486\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076718524280398\n",
      "std: 0.004404528981552543\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03475163688909996\n",
      "min: 0.01428038059792609\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31923345735534164\n",
      "std: 0.2943498905063369\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4896714956576749\n",
      "std: 0.36133168560588713\n",
      "min: -0.3887925499428951\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260749968510183\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1934152307081576\n",
      "std: 0.15526014872638086\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1963711505785424\n",
      "std: 0.15829094468837673\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03641703647459984\n",
      "min: 0.005080353818882393\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3420204509396928\n",
      "std: 0.3686740527454287\n",
      "min: -1.0775186071203198\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36372074991951514\n",
      "std: 0.3482121079233416\n",
      "min: -0.6753792719766027\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05719149029596177\n",
      "min: 0.07033503095787877\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072643910755065\n",
      "std: 0.0063321688693425094\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072808157862198\n",
      "std: 0.00640617997510843\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03475359253269422\n",
      "min: 0.013923895706473583\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3184378931310861\n",
      "std: 0.29416336437876256\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4896470439068651\n",
      "std: 0.3611335089222402\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257276751255461\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.195321153479546\n",
      "std: 0.151323054494365\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.19828881869075\n",
      "std: 0.15265882355292912\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03586497579342166\n",
      "min: 0.00508077448052821\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34289208012032957\n",
      "std: 0.36728509160351286\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36335419644366596\n",
      "std: 0.3481190857458809\n",
      "min: -0.675715937021514\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05717579465264607\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077896294678165\n",
      "std: 0.00385265197183777\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407792388716899\n",
      "std: 0.004034186916021884\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03475128188847778\n",
      "min: 0.014270357459141217\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31945482871924336\n",
      "std: 0.2943069832645229\n",
      "min: -0.797840950208833\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4892205870052961\n",
      "std: 0.36129925162353443\n",
      "min: -0.3890895033732396\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260226140866534\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2165838490541854\n",
      "std: 0.07472539939595534\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2193574437131258\n",
      "std: 0.07877769965296555\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03517796365195428\n",
      "min: 0.009392358214265827\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3486051063168148\n",
      "std: 0.36437916804034043\n",
      "min: -1.076788275590154\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35840008855603867\n",
      "std: 0.34796599075280776\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057364999629403425\n",
      "min: 0.07043584963749587\n",
      "max: 0.3292999551626174\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082466906566067\n",
      "std: 0.0029076733421042164\n",
      "min: 1.3795947786130622\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082368956317963\n",
      "std: 0.0031350892535451976\n",
      "min: 1.3795947786130622\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03475101310887995\n",
      "min: 0.01434315450959364\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32060684737270256\n",
      "std: 0.29406570628802464\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4876557327126539\n",
      "std: 0.3612940676168954\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261180092310537\n",
      "min: 0.08224047526152703\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1862426285212522\n",
      "std: 0.19423461660779287\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1891964121505212\n",
      "std: 0.1968898047571223\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03678171632485782\n",
      "min: 0.002958108462852325\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.349030444062139\n",
      "std: 0.3653902175812475\n",
      "min: -1.0774167572242213\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.358200109963881\n",
      "std: 0.34851208697829456\n",
      "min: -0.6760788147460834\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05737009700327939\n",
      "min: 0.07035282456402321\n",
      "max: 0.3293850576520611\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406121159142759\n",
      "std: 0.012495530359636907\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406122589978524\n",
      "std: 0.012641291064706609\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.034762191573774866\n",
      "min: 0.013135393168988192\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3218524555057557\n",
      "std: 0.2940412999705595\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48823314856876815\n",
      "std: 0.3619218991202066\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06265045797075786\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1960074521216575\n",
      "std: 0.14116101585431703\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1987862470482498\n",
      "std: 0.14355074046522218\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.03553628490706359\n",
      "min: 0.004580657668410551\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3406022316891512\n",
      "std: 0.3659575082953999\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3644964204933413\n",
      "std: 0.34648086584369503\n",
      "min: -0.674776812470629\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057002015330474144\n",
      "min: 0.07034332619054122\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076523934820753\n",
      "std: 0.004340242643939567\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076578983069112\n",
      "std: 0.004397940845938342\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.03433658377804683\n",
      "min: 0.01414804332996219\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31919008989042785\n",
      "std: 0.29437322194665644\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4896982558133434\n",
      "std: 0.3613015002402467\n",
      "min: -0.3887925499428951\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260318485694591\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1934407960572644\n",
      "std: 0.15445906571809068\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1962866228925169\n",
      "std: 0.15752282587874314\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.03597488907933987\n",
      "min: 0.005080353818882393\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3409993707045126\n",
      "std: 0.368274605176532\n",
      "min: -1.0775186071203198\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36396553525641573\n",
      "std: 0.3476428852274348\n",
      "min: -0.6753792719766027\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05713320678596684\n",
      "min: 0.07033503095787877\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072604160383364\n",
      "std: 0.006304986435415257\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072719318157476\n",
      "std: 0.006381968801408075\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.0343385075716965\n",
      "min: 0.013856702119576621\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3184019770851902\n",
      "std: 0.2941866218015246\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4896726360025423\n",
      "std: 0.3611043220754701\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256873544441426\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1953173583682755\n",
      "std: 0.15053638761396373\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1981747640155647\n",
      "std: 0.15192576487016066\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.03543200050407013\n",
      "min: 0.00508077448052821\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3418550281017362\n",
      "std: 0.3669106339769215\n",
      "min: -1.0777584281638513\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3636039422929548\n",
      "std: 0.3475508527115003\n",
      "min: -0.675715937021514\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057117482690468284\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407779318802292\n",
      "std: 0.003846674521452831\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077774400225287\n",
      "std: 0.004031817005271015\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.03433623459903696\n",
      "min: 0.014146218945464717\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31940735511627133\n",
      "std: 0.29433101809191775\n",
      "min: -0.797840950208833\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48925133959468775\n",
      "std: 0.3612683645203432\n",
      "min: -0.3890895033732396\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259784190313576\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2162970091660992\n",
      "std: 0.074673610218756\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2189673882918324\n",
      "std: 0.07879905520297564\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.034756108797453486\n",
      "min: 0.009392358214265827\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3474927252536559\n",
      "std: 0.3640448684902505\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35870670518188047\n",
      "std: 0.34740001635427475\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05730381605643101\n",
      "min: 0.07043584963749587\n",
      "max: 0.3292999551626174\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082317920761844\n",
      "std: 0.002910517765114115\n",
      "min: 1.3795947786130622\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082175153942795\n",
      "std: 0.003141826353261269\n",
      "min: 1.3795947786130622\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.03433596998023762\n",
      "min: 0.014141825170713601\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3205447405253469\n",
      "std: 0.29409199488242926\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48770514807895654\n",
      "std: 0.36126308235928106\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260718753928546\n",
      "min: 0.08224047526152703\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1863502314002012\n",
      "std: 0.19327155743049673\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1891928780487668\n",
      "std: 0.19595526998537016\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.036333674468751465\n",
      "min: 0.002958108462852325\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3479241878199894\n",
      "std: 0.36504823427196176\n",
      "min: -1.0774167572242213\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3585137896052915\n",
      "std: 0.3479453755708678\n",
      "min: -0.6760788147460833\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057310055334292544\n",
      "min: 0.07035282456402321\n",
      "max: 0.32938505765206105\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4061352110218155\n",
      "std: 0.012413225133032104\n",
      "min: 1.2899779509647342\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061316767526273\n",
      "std: 0.012560301193351102\n",
      "min: 1.2899779509647342\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.034346966540617356\n",
      "min: 0.013135393168988194\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32177595894429234\n",
      "std: 0.29406663028509145\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48827576687865726\n",
      "std: 0.36188293828606777\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.062645396598681\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.195817029516808\n",
      "std: 0.14015767135141408\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.198462111819546\n",
      "std: 0.14256445963175554\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03511241202277192\n",
      "min: 0.004580657668410551\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34026171255233484\n",
      "std: 0.3659261118865618\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36525274007940434\n",
      "std: 0.3465274750902181\n",
      "min: -0.6747768124706293\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05700648357286458\n",
      "min: 0.07034332619054123\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076567753560358\n",
      "std: 0.0043180280645159445\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407674741894599\n",
      "std: 0.00436839442860497\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03393194038228817\n",
      "min: 0.013987648392129053\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3190680884833885\n",
      "std: 0.2943829114375212\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48979884135014135\n",
      "std: 0.3612654125671555\n",
      "min: -0.3887925499428951\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259909544666008\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.193273147145208\n",
      "std: 0.15351351167791888\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.195984132833084\n",
      "std: 0.15658374200921146\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03554392925460039\n",
      "min: 0.004951541197071224\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3406618982986571\n",
      "std: 0.36821064064137043\n",
      "min: -1.07751860712032\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36472296050426656\n",
      "std: 0.3476764704125413\n",
      "min: -0.6753792719766031\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05713643582652335\n",
      "min: 0.07033503095787877\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072698979455616\n",
      "std: 0.006271087951554806\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407293764251653\n",
      "std: 0.006343405283954895\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03393383331313971\n",
      "min: 0.013693703676125718\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31828732485675143\n",
      "std: 0.29419628852465823\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4897717835625094\n",
      "std: 0.3610692793415039\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256492642777946\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1951338035039833\n",
      "std: 0.14949185172021606\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1978560421389208\n",
      "std: 0.1509100395355095\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03500989930371865\n",
      "min: 0.00508077448052821\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34150325988264535\n",
      "std: 0.3668730089762712\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3643680814821435\n",
      "std: 0.34758840883501496\n",
      "min: -0.675715937021514\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05712092236513566\n",
      "min: 0.07033286141518683\n",
      "max: 0.3294534672190304\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077818055437281\n",
      "std: 0.003828623392744431\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077925667706406\n",
      "std: 0.004004397981779012\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03393159685827792\n",
      "min: 0.014031854616663024\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3192815470351579\n",
      "std: 0.29434164122018686\n",
      "min: -0.797840950208833\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4893558697130084\n",
      "std: 0.3612317317284798\n",
      "min: -0.3890895033732396\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259366580107815\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2157947021245312\n",
      "std: 0.07446892951885375\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2183364427140226\n",
      "std: 0.07861948864199285\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03434485647784458\n",
      "min: 0.009392358214265827\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3470702737366553\n",
      "std: 0.36403820101088263\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3595221172555419\n",
      "std: 0.34744489092004793\n",
      "min: -0.6755313865519571\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057304497837768954\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082279002727118\n",
      "std: 0.0029045090381687603\n",
      "min: 1.3795947786130622\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082264198952592\n",
      "std: 0.003122509532338233\n",
      "min: 1.3795947786130622\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03393133642474609\n",
      "min: 0.014076124496533362\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3204050232805049\n",
      "std: 0.29410510231402454\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48782731575792315\n",
      "std: 0.36122662582194554\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260282978584375\n",
      "min: 0.08224047526152703\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1862648831864953\n",
      "std: 0.19206970578033408\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1889712696674846\n",
      "std: 0.1947622995037352\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03589700254113138\n",
      "min: 0.002958108462852325\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3475071052088107\n",
      "std: 0.36503196566005003\n",
      "min: -1.0774167572242215\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35933984316877365\n",
      "std: 0.34798944756691946\n",
      "min: -0.6760788147460833\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05731174583896018\n",
      "min: 0.07035282456402321\n",
      "max: 0.3293850576520611\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406157150934715\n",
      "std: 0.012345175052891589\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061659461354932\n",
      "std: 0.012490362063129333\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.0339421575408592\n",
      "min: 0.012914973573250828\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3216219176377615\n",
      "std: 0.29407892938785235\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48839184027409177\n",
      "std: 0.3618386402986822\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264061222511531\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1961192743135434\n",
      "std: 0.13932430371644425\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.198533678885761\n",
      "std: 0.14170298683742938\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03469914568831481\n",
      "min: 0.00455777770589654\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34065842892434633\n",
      "std: 0.36546463942488056\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36555464553333417\n",
      "std: 0.3467290879531224\n",
      "min: -0.674776812470629\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057074838240914805\n",
      "min: 0.07034332619054123\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076745683879852\n",
      "std: 0.004285917600922179\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076951699385156\n",
      "std: 0.004335018785731861\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03353731109868574\n",
      "min: 0.013825920929536948\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3191213789546478\n",
      "std: 0.29434422321129117\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4896985764593854\n",
      "std: 0.36130367260279816\n",
      "min: -0.3887925499428951\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260773338030878\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.193616795889403\n",
      "std: 0.15244512697736756\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1960958384077687\n",
      "std: 0.15548352437191898\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03512370942517325\n",
      "min: 0.004951541197071224\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3410589339538148\n",
      "std: 0.367720971186767\n",
      "min: -1.07751860712032\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36502845698368824\n",
      "std: 0.3478645480099846\n",
      "min: -0.675379271976603\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0572033043974223\n",
      "min: 0.07033503095787877\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072934393188876\n",
      "std: 0.006217464097079656\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073198021454874\n",
      "std: 0.006289320046288803\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03353917363075522\n",
      "min: 0.013601290069800672\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3183476150083154\n",
      "std: 0.294158134239893\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4896702013379737\n",
      "std: 0.36110857840986293\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257383241969051\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1954585861514535\n",
      "std: 0.14841774616716147\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.197948591121612\n",
      "std: 0.14982294157401985\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.034598288543877434\n",
      "min: 0.0050136528108701\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3418859704282537\n",
      "std: 0.3664024285543661\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.364680094838055\n",
      "std: 0.3477788670890675\n",
      "min: -0.6757159370215139\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05718798097790256\n",
      "min: 0.07033286141518683\n",
      "max: 0.3294534672190304\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407797618476891\n",
      "std: 0.003799288077879834\n",
      "min: 1.3740240626115372\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078111502058996\n",
      "std: 0.0039726175566539915\n",
      "min: 1.3740240626115372\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.033536973057475834\n",
      "min: 0.013899361610995363\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3193308440089585\n",
      "std: 0.29430358027983206\n",
      "min: -0.797840950208833\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.489259610825593\n",
      "std: 0.36126920516426875\n",
      "min: -0.3890895033732396\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626022063742354\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2158073435717107\n",
      "std: 0.0741262333659157\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.218122153450356\n",
      "std: 0.07825682350122609\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.033943777890743106\n",
      "min: 0.009392358214265829\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34738191374667277\n",
      "std: 0.36358788814402065\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35988605465461043\n",
      "std: 0.34763788710768456\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05736855591936528\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082362460835145\n",
      "std: 0.0028880201810795023\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082377277738467\n",
      "std: 0.0031022824473540753\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.033536716761891426\n",
      "min: 0.013920343397721186\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32044047877217074\n",
      "std: 0.2940691912884229\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4877486473207895\n",
      "std: 0.36126341968398706\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261116457176938\n",
      "min: 0.08224047526152703\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1866595874540153\n",
      "std: 0.19092902023250247\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.189133234711454\n",
      "std: 0.19359448249860717\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03547127933085239\n",
      "min: 0.002958108462852325\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34782397773088736\n",
      "std: 0.3645728645677499\n",
      "min: -1.0774167572242215\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3597103673457112\n",
      "std: 0.348180010076498\n",
      "min: -0.6760788147460834\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05737670201795046\n",
      "min: 0.07035282456402321\n",
      "max: 0.3293850576520611\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4061940020427852\n",
      "std: 0.01225625087536922\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406205287194672\n",
      "std: 0.012401451470676134\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03354736636574382\n",
      "min: 0.012893066265396796\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3216440739484345\n",
      "std: 0.29404126048973805\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4883064475770825\n",
      "std: 0.36186818549404826\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264855800025533\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1969337086730705\n",
      "std: 0.13844553765464734\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.19938376068817\n",
      "std: 0.14081242041422853\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03429603605662164\n",
      "min: 0.004557777705896541\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34016943654917525\n",
      "std: 0.36605954158761767\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36573503868865426\n",
      "std: 0.3467074715117895\n",
      "min: -0.674776812470629\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057047725865654854\n",
      "min: 0.07034332619054122\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076971843720416\n",
      "std: 0.004265682639438676\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077128365914058\n",
      "std: 0.004317194639189878\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03315232050607327\n",
      "min: 0.013575526335263042\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3190541530612748\n",
      "std: 0.2943866688734417\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856123\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4896980428104363\n",
      "std: 0.36126873288926337\n",
      "min: -0.3887925499428951\n",
      "max: 0.9471099884856123\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260085936775303\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1944634725872745\n",
      "std: 0.1515097581975116\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1969770174299124\n",
      "std: 0.15453186270408853\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.034713892496544003\n",
      "min: 0.0049515411970712225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3405716051110068\n",
      "std: 0.36828055841924323\n",
      "min: -1.07751860712032\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3652122248214247\n",
      "std: 0.34782997489423606\n",
      "min: -0.6753792719766031\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057175000250400086\n",
      "min: 0.07033503095787877\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073218443304376\n",
      "std: 0.006179995111397425\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073431900641908\n",
      "std: 0.0062532248713078895\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03315415376899064\n",
      "min: 0.013385240592528441\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3182871690060367\n",
      "std: 0.29420073173985545\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4896687934955853\n",
      "std: 0.3610745873508992\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0625672138390401\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1962756135436463\n",
      "std: 0.14755615812536768\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1988004255115141\n",
      "std: 0.14895441145941288\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.034196840430613426\n",
      "min: 0.0050136528108701\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.341384390621589\n",
      "std: 0.36698873982646285\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36486785992445364\n",
      "std: 0.34774630780801286\n",
      "min: -0.675715937021514\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05715970450981819\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078185691894638\n",
      "std: 0.0037857897482913654\n",
      "min: 1.374024062611537\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078273141415687\n",
      "std: 0.003960549716861707\n",
      "min: 1.374024062611537\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.0331519878398495\n",
      "min: 0.013556014811508024\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31925980781240704\n",
      "std: 0.2943469058256611\n",
      "min: -0.797840950208833\n",
      "max: 0.9465937702192052\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48926308598804535\n",
      "std: 0.3612335798820572\n",
      "min: -0.3890895033732396\n",
      "max: 0.9465937702192052\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259523129166561\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2163350907399249\n",
      "std: 0.07385663369568542\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2186914117251457\n",
      "std: 0.0779345629036471\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03355250991822466\n",
      "min: 0.009392358214265829\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34681246106613617\n",
      "std: 0.36420822055671287\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3601292031606197\n",
      "std: 0.34760592768422793\n",
      "min: -0.6755313865519568\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057337768506700644\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082510062225495\n",
      "std: 0.002880135143177047\n",
      "min: 1.3795947786130622\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408247946508895\n",
      "std: 0.003096431449374576\n",
      "min: 1.3795947786130622\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03315173538602519\n",
      "min: 0.013621606269267263\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32035571627649584\n",
      "std: 0.2941146513230318\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48776950511851447\n",
      "std: 0.36122748489114426\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626040066105382\n",
      "min: 0.08224047526152703\n",
      "max: 0.29972117811909227\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1875868465010138\n",
      "std: 0.1898088156194753\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1900941289589226\n",
      "std: 0.19246376829980844\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03505607784093914\n",
      "min: 0.002958108462852325\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3472577722756611\n",
      "std: 0.3651842360655387\n",
      "min: -1.0774167572242215\n",
      "max: 1.054234760746108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35995859579178363\n",
      "std: 0.3481448137480652\n",
      "min: -0.6760788147460836\n",
      "max: 1.054234760746108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057346609493243314\n",
      "min: 0.07035282456402321\n",
      "max: 0.32938505765206105\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4062371037621229\n",
      "std: 0.012178534451171957\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4062434131537518\n",
      "std: 0.0123240498207736\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.033162218947753605\n",
      "min: 0.012724162023720629\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32154582984681246\n",
      "std: 0.294086056341642\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238722\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48832108246961625\n",
      "std: 0.3618251154315938\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238722\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06264098162568241\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1972081261920626\n",
      "std: 0.13785564540242617\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1996528188637128\n",
      "std: 0.14021097266322674\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.0339027952995726\n",
      "min: 0.003956627346677075\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3394810036650667\n",
      "std: 0.36560436219614567\n",
      "min: -1.0775097237334763\n",
      "max: 1.0586274842736008\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3656917120446164\n",
      "std: 0.3463591914812686\n",
      "min: -0.674776812470629\n",
      "max: 1.0586274842736008\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05699125710513029\n",
      "min: 0.07034332619054122\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077057030629792\n",
      "std: 0.004252461758363989\n",
      "min: 1.3717877071493065\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077163386310048\n",
      "std: 0.004301643474312089\n",
      "min: 1.3736210995459537\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03277661148552862\n",
      "min: 0.013333607464097267\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3189645022083808\n",
      "std: 0.29432820951455435\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4896857483787401\n",
      "std: 0.36122049307830684\n",
      "min: -0.38879254994289497\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0625953704778518\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.194775167567141\n",
      "std: 0.15073776108704418\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1972822077926997\n",
      "std: 0.15374480578257882\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03431412360109364\n",
      "min: 0.004636582542056037\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33988392519781147\n",
      "std: 0.3677993470983282\n",
      "min: -1.0775186071203195\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36517318929169373\n",
      "std: 0.3474707659561972\n",
      "min: -0.675379271976603\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.20000000000000004\n",
      "std: 0.057117507214575244\n",
      "min: 0.0703350309578788\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073351584016078\n",
      "std: 0.006150041920653455\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073514018359519\n",
      "std: 0.006221645069614255\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.032778416429079624\n",
      "min: 0.013086799746918381\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31820411361689505\n",
      "std: 0.2941424631574737\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48965546793248116\n",
      "std: 0.36102736338769487\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256197884118199\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1965642112904564\n",
      "std: 0.1467725688098615\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1990829114587802\n",
      "std: 0.14816378197325908\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.033805169042140454\n",
      "min: 0.0045879183321635725\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3406830612610639\n",
      "std: 0.3665289886130151\n",
      "min: -1.0777584281638515\n",
      "max: 1.058495256595823\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36483440480439283\n",
      "std: 0.3473888855443628\n",
      "min: -0.675715937021514\n",
      "max: 1.058495256595823\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057102297020724266\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078253767093096\n",
      "std: 0.0037734627454236343\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404732\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078292516623885\n",
      "std: 0.003944751316996856\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404732\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03277628390620983\n",
      "min: 0.013396647713755882\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.319166228233673\n",
      "std: 0.29428920418210114\n",
      "min: -0.7978409502088332\n",
      "max: 0.9465937702192049\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48925478698819796\n",
      "std: 0.3611846522137511\n",
      "min: -0.3890895033732397\n",
      "max: 0.9465937702192049\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258964207746678\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2163554793481897\n",
      "std: 0.07366287273808042\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2187118017189518\n",
      "std: 0.0776978129255705\n",
      "min: 0.7199851205004337\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03317071825119197\n",
      "min: 0.009392358214265829\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34604393530205\n",
      "std: 0.36378019720474475\n",
      "min: -1.076788275590154\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3601486513571147\n",
      "std: 0.3472471502343595\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05727791336836936\n",
      "min: 0.07043584963749591\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082526387285756\n",
      "std: 0.002874333997704188\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082449361777243\n",
      "std: 0.0030862256367684654\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03277603518977083\n",
      "min: 0.0134075194046214\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32024871512006114\n",
      "std: 0.2940591882704418\n",
      "min: -0.7976242858584903\n",
      "max: 0.9425121760623355\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4877780166090087\n",
      "std: 0.36117817632698573\n",
      "min: -0.38967766754115857\n",
      "max: 0.9425121760623355\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259822912420596\n",
      "min: 0.08224047526152704\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1879869099295137\n",
      "std: 0.18874327543302535\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1904865809856424\n",
      "std: 0.19139027802488745\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03465106464064914\n",
      "min: 0.00281082950672774\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3464934481209537\n",
      "std: 0.36474793916651227\n",
      "min: -1.0774167572242213\n",
      "max: 1.0542347607461076\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35998244424636133\n",
      "std: 0.3477826743592211\n",
      "min: -0.6760788147460834\n",
      "max: 1.0542347607461076\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05728750575122181\n",
      "min: 0.07035282456402321\n",
      "max: 0.32938505765206105\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4062645988955893\n",
      "std: 0.012111350489326229\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406265790960772\n",
      "std: 0.012256018617585317\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03278635812952886\n",
      "min: 0.012340941121172943\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3214258367461428\n",
      "std: 0.29402976552032717\n",
      "min: -0.797433565443468\n",
      "max: 0.9443537500238718\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.488323389465865\n",
      "std: 0.3617688225762359\n",
      "min: -0.3895482882391527\n",
      "max: 0.9443537500238718\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0626348022913307\n",
      "min: 0.08217236485510235\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1976137335127865\n",
      "std: 0.13716960701950437\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.199986323044619\n",
      "std: 0.13952771179304405\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.033518994607201875\n",
      "min: 0.0037371563448466163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33959943076868293\n",
      "std: 0.3655035858529811\n",
      "min: -1.077509723733476\n",
      "max: 1.0586274842736008\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3650985309666281\n",
      "std: 0.34646760045817737\n",
      "min: -0.674776812470629\n",
      "max: 1.0586274842736008\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057020745128351535\n",
      "min: 0.07034332619054122\n",
      "max: 0.32939818075364125\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077084906391628\n",
      "std: 0.0042377543890817606\n",
      "min: 1.3717877071493065\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407724711385762\n",
      "std: 0.004284884322471133\n",
      "min: 1.3736210995459537\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.032409844582880605\n",
      "min: 0.01314194972496963\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3189490885637722\n",
      "std: 0.29435973947222305\n",
      "min: -0.797876861845221\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4896284054120544\n",
      "std: 0.3612342073115653\n",
      "min: -0.38879254994289497\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259776079028757\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1952118886255723\n",
      "std: 0.1499195974378414\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1976459775834853\n",
      "std: 0.152922474347783\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.033924007606714865\n",
      "min: 0.004510304502820164\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34000181992700046\n",
      "std: 0.36766940301553697\n",
      "min: -1.0775186071203195\n",
      "max: 1.057799389898751\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36458118162048825\n",
      "std: 0.34756540321271967\n",
      "min: -0.6753792719766029\n",
      "max: 1.057799389898751\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057145606417290405\n",
      "min: 0.0703350309578788\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073434281382722\n",
      "std: 0.006124868142108132\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073651440786838\n",
      "std: 0.006195129284204078\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.032411622202785366\n",
      "min: 0.012880532010391913\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31819529802439567\n",
      "std: 0.2941743000011908\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4895968483770432\n",
      "std: 0.36104206877628425\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256462417211812\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1969731745665582\n",
      "std: 0.14603527992705545\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1994187057559582\n",
      "std: 0.1474385453215941\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.03342293821124141\n",
      "min: 0.004126493956970039\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.340788834149937\n",
      "std: 0.3664191250538401\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.364247277554855\n",
      "std: 0.3474853796787541\n",
      "min: -0.6757159370215142\n",
      "max: 1.0584952565958232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057130569274684136\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078273168375135\n",
      "std: 0.003763774830839395\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404732\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078369141486387\n",
      "std: 0.003931852100253867\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404732\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.032409522032992515\n",
      "min: 0.013165127429040012\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3191473092721239\n",
      "std: 0.2943213815196195\n",
      "min: -0.7978409502088328\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48920068392155563\n",
      "std: 0.36119770751529345\n",
      "min: -0.3890895033732396\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.19999999999999996\n",
      "std: 0.06259194824866192\n",
      "min: 0.08218608005805053\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2165152259071983\n",
      "std: 0.07334252544827095\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.218804012815865\n",
      "std: 0.07737803894047834\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.032798059018792965\n",
      "min: 0.009343892882096238\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3460816800032727\n",
      "std: 0.36369323888346416\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35961459871262547\n",
      "std: 0.34733537069724635\n",
      "min: -0.6755313865519569\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0573034654613369\n",
      "min: 0.07043584963749588\n",
      "max: 0.32929995516261745\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082507404570193\n",
      "std: 0.0028645420002923524\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082489012898336\n",
      "std: 0.003072528473245976\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.03240927682534116\n",
      "min: 0.013179232027100357\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32021654423374646\n",
      "std: 0.2940933018932714\n",
      "min: -0.7976242858584907\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48774071744857234\n",
      "std: 0.3611906277104252\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260033199490647\n",
      "min: 0.08224047526152704\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.188541947777195\n",
      "std: 0.18747904387763528\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1909672560161884\n",
      "std: 0.1901288433025459\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.03425582202642439\n",
      "min: 0.002810829506727741\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3465361119201645\n",
      "std: 0.36465411892920424\n",
      "min: -1.0774167572242215\n",
      "max: 1.0542347607461076\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35945205971688604\n",
      "std: 0.3478678703749933\n",
      "min: -0.6760788147460833\n",
      "max: 1.0542347607461076\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057313857682788995\n",
      "min: 0.07035282456402318\n",
      "max: 0.3293850576520611\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4062877191159129\n",
      "std: 0.012046710658356947\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4062943922533524\n",
      "std: 0.012190624500544422\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.03241944387273952\n",
      "min: 0.012194343291003756\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3213810615463622\n",
      "std: 0.29406302628087266\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238719\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4882801244223114\n",
      "std: 0.36177450947441525\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238719\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06263653494730463\n",
      "min: 0.08217236485510233\n",
      "max: 0.29970947002139076\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1972407773340854\n",
      "std: 0.13664403679367812\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1996057363523969\n",
      "std: 0.13897770636722653\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03314435786037688\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33918842705063756\n",
      "std: 0.3653111831918208\n",
      "min: -1.0775097237334763\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36540660318134677\n",
      "std: 0.34636267959178957\n",
      "min: -0.6747768124706292\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05700008000886664\n",
      "min: 0.07034332619054123\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077120744235458\n",
      "std: 0.0042103052045837875\n",
      "min: 1.3717877071493068\n",
      "max: 1.4139805769802902\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077383184957966\n",
      "std: 0.004255819852415139\n",
      "min: 1.3736210995459535\n",
      "max: 1.4139805769802902\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.032051696609733664\n",
      "min: 0.013059232380477993\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31884023753078566\n",
      "std: 0.2943992401332265\n",
      "min: -0.797876861845221\n",
      "max: 0.947109988485612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48968161131827126\n",
      "std: 0.3612054658757397\n",
      "min: -0.38879254994289497\n",
      "max: 0.947109988485612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259090750802954\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1948720315068002\n",
      "std: 0.14928980042190895\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1972973452089266\n",
      "std: 0.15226619931889387\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.033543229647245966\n",
      "min: 0.004074749627124123\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3395918692079184\n",
      "std: 0.36744994172470125\n",
      "min: -1.07751860712032\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36489267201669734\n",
      "std: 0.34744893823033596\n",
      "min: -0.6753792719766031\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057123847326515244\n",
      "min: 0.07033503095787877\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073521184014335\n",
      "std: 0.006083809830409222\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407383749809214\n",
      "std: 0.006153284331567088\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03205344745424547\n",
      "min: 0.012769576713002396\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3180926930779459\n",
      "std: 0.29421393320311\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4896493356747145\n",
      "std: 0.3610141868652924\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06255800377114999\n",
      "min: 0.08221431473943862\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1966106698856553\n",
      "std: 0.14537998863358903\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1990475001820002\n",
      "std: 0.14676990003693882\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.033049789086993235\n",
      "min: 0.004064766270489547\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34036507903283875\n",
      "std: 0.3662200624211923\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3645632388735452\n",
      "std: 0.34737076851570525\n",
      "min: -0.6757159370215139\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057108818583117775\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078296771861916\n",
      "std: 0.0037396781551592936\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078494709082436\n",
      "std: 0.003904881269351002\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03205137893415491\n",
      "min: 0.013089225030249091\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31903475086219213\n",
      "std: 0.2943616383507823\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48925770597141943\n",
      "std: 0.36116840550869794\n",
      "min: -0.38908950337323966\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258500086183458\n",
      "min: 0.08218608005805055\n",
      "max: 0.29975051079127774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2159279349350074\n",
      "std: 0.07321510937433336\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.218213324717104\n",
      "std: 0.07719057383447905\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03243420415360979\n",
      "min: 0.008628906921418267\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3455935623307273\n",
      "std: 0.3635222049707592\n",
      "min: -1.076788275590154\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3599794286283292\n",
      "std: 0.347222998826395\n",
      "min: -0.6755313865519568\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05727924882179776\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082485803557103\n",
      "std: 0.0028473599352996618\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137453\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082570216673858\n",
      "std: 0.003050848926844503\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137453\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03205113730957526\n",
      "min: 0.01314846273409917\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.320091418007679\n",
      "std: 0.2941357698318023\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48781359442538264\n",
      "std: 0.3611612081196534\n",
      "min: -0.38967766754115857\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259320876303036\n",
      "min: 0.08224047526152704\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1883186028577455\n",
      "std: 0.18639242970400116\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.190733857084258\n",
      "std: 0.18902992854110087\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03387005786586816\n",
      "min: 0.002810829506727741\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34605277380775384\n",
      "std: 0.3644762354484747\n",
      "min: -1.0774167572242213\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3598246298558613\n",
      "std: 0.3477541716989115\n",
      "min: -0.6760788147460836\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05729055407410067\n",
      "min: 0.07035282456402321\n",
      "max: 0.32938505765206105\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4063119979009018\n",
      "std: 0.011959713402080937\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4063285213791867\n",
      "std: 0.012103637151421176\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.0320611516421193\n",
      "min: 0.012194343291003754\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.321243482121305\n",
      "std: 0.29410511546210305\n",
      "min: -0.797433565443468\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4883477707591877\n",
      "std: 0.3617385011825374\n",
      "min: -0.38954828823915266\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06262905435048163\n",
      "min: 0.08217236485510235\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1974322332343923\n",
      "std: 0.13600715181601558\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1997900426102726\n",
      "std: 0.13833980970328247\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.03277844030689746\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33882817320589886\n",
      "std: 0.3649632962848698\n",
      "min: -1.0775097237334763\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36556318794826315\n",
      "std: 0.3461336136640057\n",
      "min: -0.674776812470629\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05699127306450114\n",
      "min: 0.07034332619054122\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077261912024088\n",
      "std: 0.00418016224970189\n",
      "min: 1.3717877071493065\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077470679752397\n",
      "std: 0.00422570282562295\n",
      "min: 1.3736210995459537\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.031701860584077035\n",
      "min: 0.012848685887444854\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31878579163303533\n",
      "std: 0.2943573605356525\n",
      "min: -0.797876861845221\n",
      "max: 0.947109988485612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4897137795653069\n",
      "std: 0.3611878799963751\n",
      "min: -0.3887925499428951\n",
      "max: 0.947109988485612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0625893076152104\n",
      "min: 0.08217901980142099\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1951006822335464\n",
      "std: 0.14846254465026149\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1975179446564514\n",
      "std: 0.1514328128518941\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.033171323435622416\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3392329401254931\n",
      "std: 0.36707590755801756\n",
      "min: -1.0775186071203195\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36505332590318146\n",
      "std: 0.3472094900396397\n",
      "min: -0.6753792719766031\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057113969775414344\n",
      "min: 0.07033503095787876\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073704241213014\n",
      "std: 0.006039224581945018\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073965998746152\n",
      "std: 0.006108669882409185\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.03170358533652208\n",
      "min: 0.012644866579964742\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3180445678299035\n",
      "std: 0.2941723086702076\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4896807073207184\n",
      "std: 0.3609975456941912\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0625566440459681\n",
      "min: 0.0822143147394386\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1968082887825016\n",
      "std: 0.14470586498759605\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.199237062029265\n",
      "std: 0.14610104730861823\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.03268532703190057\n",
      "min: 0.004064766270489547\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33999493946300824\n",
      "std: 0.36586463072750114\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3647279178889052\n",
      "std: 0.34713320939172804\n",
      "min: -0.6757159370215142\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057099069949241604\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078419401310402\n",
      "std: 0.003713725967406762\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078564822193227\n",
      "std: 0.003877999150545692\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.03170154767316945\n",
      "min: 0.01287720317238086\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31897713505640424\n",
      "std: 0.2943202156851985\n",
      "min: -0.7978409502088332\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4892933433119561\n",
      "std: 0.36115027318489995\n",
      "min: -0.38908950337323966\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258332167531765\n",
      "min: 0.08218608005805052\n",
      "max: 0.2997505107912778\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2158884325836996\n",
      "std: 0.07298052169187648\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2181713707600084\n",
      "std: 0.0769370041370423\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.03207878080496278\n",
      "min: 0.008628906921418262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34516157962591754\n",
      "std: 0.36319557970716054\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3601932853404551\n",
      "std: 0.34698652761232474\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05726723294198948\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082551540850954\n",
      "std: 0.0028284791566807106\n",
      "min: 1.3795947786130622\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082585246854897\n",
      "std: 0.0030306650010867723\n",
      "min: 1.3795947786130622\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.031701309558963664\n",
      "min: 0.012950414589789\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32002158639959366\n",
      "std: 0.2940964121239055\n",
      "min: -0.7976242858584903\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4878648744577199\n",
      "std: 0.3611429474903964\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259136620047803\n",
      "min: 0.08224047526152703\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1886007885638459\n",
      "std: 0.18555232040089267\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1910073974672766\n",
      "std: 0.18818516238875596\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.033493372564695235\n",
      "min: 0.0025321524639696897\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34562531191111256\n",
      "std: 0.3641393823825832\n",
      "min: -1.0774167572242213\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3600424681923214\n",
      "std: 0.3475164094878871\n",
      "min: -0.6760788147460836\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05727927427205239\n",
      "min: 0.07035282456402318\n",
      "max: 0.3293850576520611\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4063421894990578\n",
      "std: 0.011882324579682019\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4063533219327147\n",
      "std: 0.012025961212996613\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.03171117593378319\n",
      "min: 0.01197464943969851\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3211615639311285\n",
      "std: 0.29406487853927277\n",
      "min: -0.7974335654434677\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4883936412762156\n",
      "std: 0.3617138146424707\n",
      "min: -0.38954828823915255\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06262686067884302\n",
      "min: 0.08217236485510233\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1979561312418276\n",
      "std: 0.13522271647040024\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.200342053610426\n",
      "std: 0.13754372989396216\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.032420941294565804\n",
      "min: 0.0037371563448466163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33849635548269247\n",
      "std: 0.36473308181964226\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36435436130772514\n",
      "std: 0.3459561378049588\n",
      "min: -0.6747768124706292\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05694985391615553\n",
      "min: 0.07034332619054123\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077301274377398\n",
      "std: 0.004159174400817587\n",
      "min: 1.3717877071493065\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077494369049866\n",
      "std: 0.004206294041965488\n",
      "min: 1.3736210995459537\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.031360044010551154\n",
      "min: 0.01269682104140032\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31879835473306295\n",
      "std: 0.29435650226715393\n",
      "min: -0.797876861845221\n",
      "max: 0.947109988485612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48954182315416916\n",
      "std: 0.3611646061242765\n",
      "min: -0.38879254994289486\n",
      "max: 0.947109988485612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258588856840552\n",
      "min: 0.08217901980142096\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1956538205041254\n",
      "std: 0.14760001236789036\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.198097981479453\n",
      "std: 0.15055684436551964\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.032808033107500564\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3389030925425868\n",
      "std: 0.36682110973676846\n",
      "min: -1.0775186071203198\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3638474839272223\n",
      "std: 0.34702142915072803\n",
      "min: -0.6753792719766031\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0570716767780021\n",
      "min: 0.07033503095787878\n",
      "max: 0.32943950013225615\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073782587108699\n",
      "std: 0.006007658951651865\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074027847219857\n",
      "std: 0.006078266436392533\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.031361743596241796\n",
      "min: 0.01242318242317351\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3180632692479711\n",
      "std: 0.2941716197638333\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4895076907495451\n",
      "std: 0.36097518656029576\n",
      "min: -0.3883083708185305\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06255345393140802\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1973331928385291\n",
      "std: 0.1439483568484915\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1997891845174498\n",
      "std: 0.145337362287082\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.03232926627275631\n",
      "min: 0.004064766270489547\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33965220406707086\n",
      "std: 0.36562784539623217\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36352623522063365\n",
      "std: 0.34694432898997446\n",
      "min: -0.675715937021514\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05705670266681155\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407844616715648\n",
      "std: 0.003697782235758877\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078577337351348\n",
      "std: 0.0038629901582884012\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.031359735733132096\n",
      "min: 0.0126619462041884\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31898647217735865\n",
      "std: 0.29431985206838635\n",
      "min: -0.7978409502088327\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48912458760269883\n",
      "std: 0.361126331352023\n",
      "min: -0.38908950337323933\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257982569226368\n",
      "min: 0.08218608005805052\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2161717617259513\n",
      "std: 0.07268445658641819\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.218487439651347\n",
      "std: 0.07659784979606789\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.031731520337350896\n",
      "min: 0.008628906921418262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34475795620502936\n",
      "std: 0.36298324644117336\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3590411014502997\n",
      "std: 0.3467831612150801\n",
      "min: -0.6755313865519569\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057222602499903095\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082535309130246\n",
      "std: 0.0028180691255842365\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082556126409798\n",
      "std: 0.0030209954786326438\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.031359500962707204\n",
      "min: 0.012699876480096477\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3200188090924402\n",
      "std: 0.29409770121881146\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4877117398251381\n",
      "std: 0.36111813391187153\n",
      "min: -0.38967766754115857\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258770654230181\n",
      "min: 0.08224047526152706\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1892189711699297\n",
      "std: 0.1845752999310395\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1916518112951142\n",
      "std: 0.18720013585918177\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.03312542345229125\n",
      "min: 0.0025321524639696897\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.345226216993965\n",
      "std: 0.3639215887366207\n",
      "min: -1.0774167572242213\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.358892223200124\n",
      "std: 0.34731129551815487\n",
      "min: -0.6760788147460833\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05723542089468713\n",
      "min: 0.0703528245640232\n",
      "max: 0.329385057652061\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406363264186373\n",
      "std: 0.011815553953736563\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4063727453306423\n",
      "std: 0.011959710613747586\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.03136922390493837\n",
      "min: 0.011771965769492678\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3211469518870567\n",
      "std: 0.2940652828114557\n",
      "min: -0.797433565443468\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4882346067246434\n",
      "std: 0.36168282593283396\n",
      "min: -0.38954828823915255\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.062622832620386\n",
      "min: 0.08217236485510233\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.19847704747723\n",
      "std: 0.1345211460081383\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2008585428294256\n",
      "std: 0.1368231596084633\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.03207163157550212\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3386381637622516\n",
      "std: 0.36483498911485335\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36423265623238227\n",
      "std: 0.34607861389051875\n",
      "min: -0.674776812470629\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05696929635832314\n",
      "min: 0.07034332619054123\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077486444950766\n",
      "std: 0.004141871440967772\n",
      "min: 1.3717877071493065\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077748319628496\n",
      "std: 0.004187921843340646\n",
      "min: 1.3736210995459537\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.031025967807160038\n",
      "min: 0.012500073157919364\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3187170408753853\n",
      "std: 0.2942901704096746\n",
      "min: -0.797876861845221\n",
      "max: 0.947109988485612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4895678667407726\n",
      "std: 0.361103627666782\n",
      "min: -0.3887925499428951\n",
      "max: 0.947109988485612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258079886913381\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1962070062840051\n",
      "std: 0.1467566961279903\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1986456715020943\n",
      "std: 0.14969281616680064\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.03245307369072965\n",
      "min: 0.004074749627124123\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33904558788987477\n",
      "std: 0.3668967277632078\n",
      "min: -1.0775186071203198\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3637283965569054\n",
      "std: 0.3471320144962888\n",
      "min: -0.6753792719766029\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05708997784541392\n",
      "min: 0.07033503095787877\n",
      "max: 0.32943950013225615\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074014463370188\n",
      "std: 0.005974276473337973\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074327512675708\n",
      "std: 0.006044498780800426\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.03102764275822271\n",
      "min: 0.012280177406650014\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.317987941201329\n",
      "std: 0.294105535988162\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4895328726400351\n",
      "std: 0.36091514122158963\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06254859139329916\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1978607025654264\n",
      "std: 0.14316925908653036\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2003113268145162\n",
      "std: 0.14454753633310974\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.031981334104613596\n",
      "min: 0.004064766270489547\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3397833846556555\n",
      "std: 0.3657217965631324\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3634105521476822\n",
      "std: 0.347056442548042\n",
      "min: -0.6757159370215139\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05707513859040029\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407861628168794\n",
      "std: 0.003682932871724433\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078817664601462\n",
      "std: 0.00384599785744401\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.031025663986362622\n",
      "min: 0.012502103050686537\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3189020706243571\n",
      "std: 0.29425412742320883\n",
      "min: -0.7978409502088327\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4891538936090493\n",
      "std: 0.36106488417433774\n",
      "min: -0.38908950337323933\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257466707855645\n",
      "min: 0.08218608005805053\n",
      "max: 0.2997505107912778\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2164638175802986\n",
      "std: 0.07235833003428396\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2187793057939431\n",
      "std: 0.07622408907144418\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.03139215479241688\n",
      "min: 0.008628906921418267\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34482955415355176\n",
      "std: 0.36309847714696575\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3589730319667229\n",
      "std: 0.3468941052860924\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05723874304074917\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082655030367834\n",
      "std: 0.002808884509617833\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082747511232785\n",
      "std: 0.0030085064160844254\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.031025432487578795\n",
      "min: 0.012521975083733641\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3199227929442774\n",
      "std: 0.29403419056686664\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4877560011818719\n",
      "std: 0.36105667454270673\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258240141525741\n",
      "min: 0.08224047526152706\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1898719177830457\n",
      "std: 0.18337635097056162\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1922982000218536\n",
      "std: 0.18598971405295037\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.03276589193104593\n",
      "min: 0.00253215246396969\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34530156672605383\n",
      "std: 0.36403004571079667\n",
      "min: -1.0774167572242213\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3588288420673768\n",
      "std: 0.3474184881328891\n",
      "min: -0.6760788147460836\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057252205075411455\n",
      "min: 0.07035282456402321\n",
      "max: 0.32938505765206105\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4063976603727277\n",
      "std: 0.011752148214361595\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4064139413827685\n",
      "std: 0.011896298739520774\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.03103501593448792\n",
      "min: 0.011582469266407512\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32103931873067426\n",
      "std: 0.2940011261847574\n",
      "min: -0.7974335654434678\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.488273921725824\n",
      "std: 0.3616150511747035\n",
      "min: -0.3895482882391525\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261718787192852\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1995433683060304\n",
      "std: 0.1340221246448674\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.201730805245427\n",
      "std: 0.13623054876867505\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.031730197821696005\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33949634999898193\n",
      "std: 0.36464053934231894\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36371718740656406\n",
      "std: 0.3463893659187524\n",
      "min: -0.6747768124706292\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057004451097476296\n",
      "min: 0.07034332619054123\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077767189681691\n",
      "std: 0.004122585922942831\n",
      "min: 1.3717877071493065\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077947760822158\n",
      "std: 0.004167397593937901\n",
      "min: 1.3736210995459537\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.030699365959153537\n",
      "min: 0.01235641298930146\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3187005617120471\n",
      "std: 0.29427420504483515\n",
      "min: -0.7978768618452212\n",
      "max: 0.947109988485612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4895748987962353\n",
      "std: 0.36110037127182326\n",
      "min: -0.38879254994289514\n",
      "max: 0.947109988485612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257989787146295\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1973007017723585\n",
      "std: 0.146194874207465\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1995443810833128\n",
      "std: 0.14903726441800544\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.03210616120159646\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3399044277400638\n",
      "std: 0.3666785094609096\n",
      "min: -1.0775186071203195\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36321616270892226\n",
      "std: 0.3474312365661375\n",
      "min: -0.675379271976603\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05712401951245102\n",
      "min: 0.0703350309578788\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407433976600199\n",
      "std: 0.005939314122515022\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407457070856134\n",
      "std: 0.006008654817051702\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.030701016922752882\n",
      "min: 0.012165128597109063\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31797735358130663\n",
      "std: 0.29408999428090327\n",
      "min: -0.7971594015816316\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4895391208447176\n",
      "std: 0.3609128429086863\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06254792082291125\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1989308860632057\n",
      "std: 0.14266527512035967\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.201186508647738\n",
      "std: 0.1439587134881432\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.031641246837770004\n",
      "min: 0.0039152593942323064\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34063082675319545\n",
      "std: 0.3655186453634575\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36290277470193916\n",
      "std: 0.34735712492843124\n",
      "min: -0.675715937021514\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05710930096607119\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078876848274573\n",
      "std: 0.003664866145750997\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078998114796262\n",
      "std: 0.003826092321458875\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.030699066463281015\n",
      "min: 0.01238689634806131\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3188824753400196\n",
      "std: 0.2942387518194229\n",
      "min: -0.7978409502088328\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4891643454709105\n",
      "std: 0.3610611440333741\n",
      "min: -0.3890895033732395\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0625736957301979\n",
      "min: 0.08218608005805053\n",
      "max: 0.2997505107912778\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2173231854611315\n",
      "std: 0.07221996010053058\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2194471706758108\n",
      "std: 0.07593740737407086\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.031060386557215183\n",
      "min: 0.008628906921418262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3456172437561724\n",
      "std: 0.3629072510300991\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3585134766471727\n",
      "std: 0.3471876197838637\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05727064669230097\n",
      "min: 0.07043584963749591\n",
      "max: 0.32929995516261745\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082857604943606\n",
      "std: 0.0027946665975700884\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082871687301144\n",
      "std: 0.002992536135854415\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.030698838151254182\n",
      "min: 0.012427031987210334\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3198917322550277\n",
      "std: 0.29402073920190575\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48778136928188426\n",
      "std: 0.36105273619690775\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258128635887623\n",
      "min: 0.08224047526152706\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1910414476420847\n",
      "std: 0.18254459032022394\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1932715765066066\n",
      "std: 0.18508383225456665\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.032414555407207654\n",
      "min: 0.0025321524639696897\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3460937529633043\n",
      "std: 0.3638319830100625\n",
      "min: -1.0774167572242213\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.358370983386782\n",
      "std: 0.3477098035097684\n",
      "min: -0.6760788147460834\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05728469041155991\n",
      "min: 0.07035282456402318\n",
      "max: 0.3293850576520611\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064413310929758\n",
      "std: 0.011686018936116949\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4064494403093004\n",
      "std: 0.011829392614638036\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.030708285690635537\n",
      "min: 0.011502015720107681\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32099678573968865\n",
      "std: 0.2939867772338196\n",
      "min: -0.797433565443468\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4882939867223455\n",
      "std: 0.36160516204708226\n",
      "min: -0.38954828823915266\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261572009923247\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.19970470432893\n",
      "std: 0.1334906881448321\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2018692049434048\n",
      "std: 0.1356778472683246\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.03139641667227419\n",
      "min: 0.0037371563448466163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3398743210208854\n",
      "std: 0.3648458364272663\n",
      "min: -1.0775097237334763\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36288629290212954\n",
      "std: 0.34662098602446995\n",
      "min: -0.6747768124706293\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05702905875165899\n",
      "min: 0.07034332619054122\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078067151533173\n",
      "std: 0.0041036038508532385\n",
      "min: 1.3717877071493065\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078291526807316\n",
      "std: 0.004148630378004473\n",
      "min: 1.3736210995459537\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.030379984677405096\n",
      "min: 0.012212054896584019\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31864693696314506\n",
      "std: 0.2942762494658521\n",
      "min: -0.797876861845221\n",
      "max: 0.947109988485612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4895196087553641\n",
      "std: 0.36109121023459056\n",
      "min: -0.3887925499428949\n",
      "max: 0.947109988485612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0625797220118021\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1974880592365102\n",
      "std: 0.14564514174799867\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1997080045363027\n",
      "std: 0.14845970910855505\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.03176705552450157\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3402828677590332\n",
      "std: 0.3668574564148762\n",
      "min: -1.0775186071203195\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36238749276004856\n",
      "std: 0.3476507873151061\n",
      "min: -0.675379271976603\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05714753206402424\n",
      "min: 0.0703350309578788\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074685296938088\n",
      "std: 0.005908964764689394\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074959207153235\n",
      "std: 0.005978577024172097\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.030381612399931566\n",
      "min: 0.011982412191624995\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3179295390959066\n",
      "std: 0.29409235391755223\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.489483056239395\n",
      "std: 0.3609046366126258\n",
      "min: -0.3883083708185305\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06254797293633903\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1991002513081848\n",
      "std: 0.1420382232173137\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2013320032252386\n",
      "std: 0.14331981114809844\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.03130876083653357\n",
      "min: 0.003915259394232308\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34099794144046647\n",
      "std: 0.36571543684738117\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3620780156611347\n",
      "std: 0.34757765423353315\n",
      "min: -0.675715937021514\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05713289790352593\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079164431845148\n",
      "std: 0.0036502154511244837\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079330584581469\n",
      "std: 0.0038106483808674914\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.03037968943951949\n",
      "min: 0.012184944506530864\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31882593551591615\n",
      "std: 0.2942413871753483\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48911210320920895\n",
      "std: 0.36105147777473706\n",
      "min: -0.38908950337323966\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257345503843975\n",
      "min: 0.08218608005805053\n",
      "max: 0.2997505107912778\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2172895450076582\n",
      "std: 0.07205229695067525\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2193942476962356\n",
      "std: 0.07571532904430907\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691353\n",
      "std: 0.030735999452836064\n",
      "min: 0.008628906921418262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34592622109323357\n",
      "std: 0.36312259708669464\n",
      "min: -1.0767882755901546\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35773629586960204\n",
      "std: 0.3473984213101768\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05729200233455656\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083094921383421\n",
      "std: 0.0027827269022981786\n",
      "min: 1.3795947786130622\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083155394980886\n",
      "std: 0.002979387475977449\n",
      "min: 1.3795947786130622\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.030379464207540684\n",
      "min: 0.012249701042702846\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31982386286430997\n",
      "std: 0.2940253699283185\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4877437890158503\n",
      "std: 0.36104262316858243\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258088877074905\n",
      "min: 0.08224047526152706\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1913199439552624\n",
      "std: 0.1816825002534558\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1935253073124557\n",
      "std: 0.18420459036168538\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.032071120803361025\n",
      "min: 0.0025321524639696897\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34640690903242083\n",
      "std: 0.3640406557669053\n",
      "min: -1.0774167572242215\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3575964231287491\n",
      "std: 0.34791736669727535\n",
      "min: -0.6760788147460834\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05730670965250555\n",
      "min: 0.07035282456402318\n",
      "max: 0.3293850576520611\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064866420871167\n",
      "std: 0.01162552904691659\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4064990977983591\n",
      "std: 0.011769154780864415\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.03038877964523685\n",
      "min: 0.011301929423864598\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3209177455669367\n",
      "std: 0.29399070945519734\n",
      "min: -0.7974335654434678\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4882513985066592\n",
      "std: 0.36158923742184046\n",
      "min: -0.38954828823915255\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261500404683897\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2001141919689935\n",
      "std: 0.1327775710844073\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2020571621317646\n",
      "std: 0.13493030790474922\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.031069953238093504\n",
      "min: 0.0037371563448466154\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.339787170033707\n",
      "std: 0.36427796920035094\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3629603914007703\n",
      "std: 0.34644281890244116\n",
      "min: -0.674776812470629\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05702321473626233\n",
      "min: 0.07034332619054122\n",
      "max: 0.32939818075364125\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078186891254751\n",
      "std: 0.004080324830521776\n",
      "min: 1.3717877071493065\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078398203413864\n",
      "std: 0.004123255509595482\n",
      "min: 1.3736210995459537\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.030067581726849753\n",
      "min: 0.012032257327854175\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3186860411096665\n",
      "std: 0.2942751367563092\n",
      "min: -0.797876861845221\n",
      "max: 0.947109988485612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4894954852907054\n",
      "std: 0.3610832627102026\n",
      "min: -0.38879254994289497\n",
      "max: 0.947109988485612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258086483022762\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1979237493441526\n",
      "std: 0.144826683748352\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1999214686338535\n",
      "std: 0.14760096364135278\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.03143540040927718\n",
      "min: 0.004074749627124124\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34019712066299657\n",
      "std: 0.366268151947475\n",
      "min: -1.0775186071203198\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3624643094696912\n",
      "std: 0.34746304092758884\n",
      "min: -0.6753792719766031\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057140763306642875\n",
      "min: 0.0703350309578788\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407484036799629\n",
      "std: 0.0058713939743142\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075100558641014\n",
      "std: 0.005939606477550653\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.030069186718897592\n",
      "min: 0.011814878875742337\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3179745002125511\n",
      "std: 0.29409177221431815\n",
      "min: -0.7971594015816315\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4894582282482671\n",
      "std: 0.3608976780523026\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06254934959249396\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1995214461468855\n",
      "std: 0.14118023089070678\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2015307507356747\n",
      "std: 0.14243633798286728\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.030983546213828036\n",
      "min: 0.003915259394232308\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3409005979256747\n",
      "std: 0.36514060294483264\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3621588508972511\n",
      "std: 0.3473904918865709\n",
      "min: -0.6757159370215139\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057126153405259665\n",
      "min: 0.07033286141518683\n",
      "max: 0.3294534672190304\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079269998141521\n",
      "std: 0.0036283016366855415\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079424424748337\n",
      "std: 0.003785759452184356\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.03006729059082629\n",
      "min: 0.01207279988143075\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31886215145308394\n",
      "std: 0.29424080434482147\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48909130549125784\n",
      "std: 0.3610430554080289\n",
      "min: -0.38908950337323966\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257453458628313\n",
      "min: 0.08218608005805053\n",
      "max: 0.2997505107912778\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2174738511849814\n",
      "std: 0.07181170371240991\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2193597206320603\n",
      "std: 0.07542975069624475\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.030418720873809552\n",
      "min: 0.008137892369931255\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3457741951529124\n",
      "std: 0.3625686105851458\n",
      "min: -1.0767882755901539\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35785847461995834\n",
      "std: 0.34721234826587777\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05728319536643132\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408315160017071\n",
      "std: 0.002768194042703184\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083201719319243\n",
      "std: 0.0029609128857885163\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.030067068432162794\n",
      "min: 0.012094714417833285\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3198491759124078\n",
      "std: 0.2940262733476021\n",
      "min: -0.7976242858584907\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48773669336449754\n",
      "std: 0.3610339132269731\n",
      "min: -0.3896776675411588\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258182310185056\n",
      "min: 0.08224047526152706\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1918028143766477\n",
      "std: 0.18080016619218983\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1937852879538153\n",
      "std: 0.1832872503220659\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.031735300322529\n",
      "min: 0.00253215246396969\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34625961536684474\n",
      "std: 0.36348080555819046\n",
      "min: -1.0774167572242213\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3577236453892759\n",
      "std: 0.34773003724754425\n",
      "min: -0.6760788147460834\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05729865986376699\n",
      "min: 0.07035282456402321\n",
      "max: 0.32938505765206105\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065136952869475\n",
      "std: 0.011553830878848677\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065247971913697\n",
      "std: 0.011696927187405726\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.03007625472448496\n",
      "min: 0.011176736778511694\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.320932555004586\n",
      "std: 0.29399076559663484\n",
      "min: -0.797433565443468\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48823938802867856\n",
      "std: 0.36157486614208095\n",
      "min: -0.3895482882391525\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261563567888513\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2001039978378116\n",
      "std: 0.1322202031621501\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2019064046281471\n",
      "std: 0.1343605002773059\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.03075067619731378\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33958503283289243\n",
      "std: 0.36392956166078505\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.363039957237144\n",
      "std: 0.3465200351710118\n",
      "min: -0.6747768124706292\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05702925398480109\n",
      "min: 0.07034332619054123\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078127071078994\n",
      "std: 0.00407260274834309\n",
      "min: 1.3717877071493065\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078391218121313\n",
      "std: 0.004115607621583046\n",
      "min: 1.3736210995459537\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.02976192578446612\n",
      "min: 0.011857222216789781\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31868059097393237\n",
      "std: 0.294245342636491\n",
      "min: -0.797876861845221\n",
      "max: 0.947109988485612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4895199183791203\n",
      "std: 0.361079812284077\n",
      "min: -0.3887925499428951\n",
      "max: 0.947109988485612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258330054958848\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1979470118148803\n",
      "std: 0.14408027413015198\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1998031993418738\n",
      "std: 0.1468389489733883\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.031111044270008666\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3399957123744523\n",
      "std: 0.36589838093180693\n",
      "min: -1.0775186071203195\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3625482540446069\n",
      "std: 0.34753056023500556\n",
      "min: -0.6753792719766031\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05714589511262361\n",
      "min: 0.07033503095787877\n",
      "max: 0.32943950013225615\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074819140362482\n",
      "std: 0.005842526264252938\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075131451698475\n",
      "std: 0.005911214003696929\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.02976350857807638\n",
      "min: 0.01171077470279186\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31797448611393603\n",
      "std: 0.2940623993876927\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48948208727759035\n",
      "std: 0.3608950965445166\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06255199858037601\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1995159276011147\n",
      "std: 0.140587600007836\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2013835683118088\n",
      "std: 0.14184171287747288\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.030665505599800143\n",
      "min: 0.003915259394232307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3406896663636268\n",
      "std: 0.3647860869756973\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3622453756454249\n",
      "std: 0.34745991117738867\n",
      "min: -0.6757159370215142\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05713136411185844\n",
      "min: 0.07033286141518685\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407919361323688\n",
      "std: 0.0036251112122764133\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407940203514463\n",
      "std: 0.0037815691262410925\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.029761638663667943\n",
      "min: 0.011858594291858916\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31885400211645204\n",
      "std: 0.29421134995961495\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48911860342494856\n",
      "std: 0.3610392230108334\n",
      "min: -0.3890895033732396\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257691701658567\n",
      "min: 0.08218608005805053\n",
      "max: 0.2997505107912778\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2172602850021494\n",
      "std: 0.07168765254529534\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2190075138504692\n",
      "std: 0.0752956589723486\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.030108363280017335\n",
      "min: 0.008137892369931258\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34550933000010065\n",
      "std: 0.36223757989786726\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35798773656658084\n",
      "std: 0.347282241234517\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057286401580633695\n",
      "min: 0.07043584963749587\n",
      "max: 0.3292999551626174\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083028655197052\n",
      "std: 0.0027723231940811562\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408313403619865\n",
      "std: 0.002962730659919135\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.029761419419754444\n",
      "min: 0.011933128462823635\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31983039584939826\n",
      "std: 0.2939984687936691\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48777761578706363\n",
      "std: 0.36102995928468096\n",
      "min: -0.38967766754115857\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258405816600046\n",
      "min: 0.08224047526152706\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1918780518338286\n",
      "std: 0.17992811423718902\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1937185704101068\n",
      "std: 0.18240069052477048\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.031406880110274135\n",
      "min: 0.0025321524639696897\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34599773981033033\n",
      "std: 0.363141963955983\n",
      "min: -1.0774167572242213\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3578572702723856\n",
      "std: 0.34779723814171887\n",
      "min: -0.6760788147460836\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057302495964742725\n",
      "min: 0.07035282456402321\n",
      "max: 0.32938505765206105\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065204352740501\n",
      "std: 0.011500133665870724\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065368056418799\n",
      "std: 0.011643494227475924\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.029770480555902357\n",
      "min: 0.010952535421221994\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32090311617418826\n",
      "std: 0.29396221668420425\n",
      "min: -0.7974335654434677\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4882758651012583\n",
      "std: 0.36156519885662186\n",
      "min: -0.38954828823915255\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261756505215119\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2003542535777598\n",
      "std: 0.1315822497685386\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2020894980430883\n",
      "std: 0.13368943047654608\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.030438224342957454\n",
      "min: 0.0037371563448466163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3402343423143998\n",
      "std: 0.364061913214616\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.362833085998712\n",
      "std: 0.3468431415370764\n",
      "min: -0.674776812470629\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05707775691254164\n",
      "min: 0.07034332619054123\n",
      "max: 0.32939818075364125\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078141888809386\n",
      "std: 0.004049810584929283\n",
      "min: 1.3717877071493065\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078291911271137\n",
      "std: 0.004096784669779714\n",
      "min: 1.3736210995459537\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.02946279537543252\n",
      "min: 0.011844955801203485\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3188123390560675\n",
      "std: 0.2942416622968828\n",
      "min: -0.797876861845221\n",
      "max: 0.947109988485612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4894401654321948\n",
      "std: 0.36111284599156973\n",
      "min: -0.3887925499428951\n",
      "max: 0.947109988485612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0625892138382299\n",
      "min: 0.08217901980142098\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1982254085483186\n",
      "std: 0.1433394310083796\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2000135038843518\n",
      "std: 0.14606267231320522\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.03079365741011463\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3406447037159863\n",
      "std: 0.36600629579659183\n",
      "min: -1.0775186071203198\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36234431862266236\n",
      "std: 0.34784250732329236\n",
      "min: -0.6753792719766031\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057193301340718365\n",
      "min: 0.0703350309578788\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074877906581211\n",
      "std: 0.005806527971984009\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075075494164424\n",
      "std: 0.0058775866239219165\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.029464356614265552\n",
      "min: 0.01160958937360601\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3181115658385682\n",
      "std: 0.294059329890333\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48940161116019737\n",
      "std: 0.36092897619972375\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06255811689319582\n",
      "min: 0.08221431473943862\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1997793195334339\n",
      "std: 0.1397979477636546\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2015787494316696\n",
      "std: 0.14102895228175363\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.030354231072302566\n",
      "min: 0.003915259394232308\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3413283476102703\n",
      "std: 0.3649101841782459\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3620463651522251\n",
      "std: 0.3477735213584174\n",
      "min: -0.675715937021514\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057178928824165386\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079192761675525\n",
      "std: 0.0036070152383900008\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407928812961982\n",
      "std: 0.0037670728134931546\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.02946251219980177\n",
      "min: 0.01183907998060433\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31898277849402584\n",
      "std: 0.29420803517869637\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48904215639323634\n",
      "std: 0.3610717808233811\n",
      "min: -0.3890895033732396\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258276740207393\n",
      "min: 0.08218608005805053\n",
      "max: 0.2997505107912778\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2173124121295522\n",
      "std: 0.07141655828941496\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2189953055090335\n",
      "std: 0.07496495648946601\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.029804607739720292\n",
      "min: 0.008137892369931258\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3460952503282093\n",
      "std: 0.36237463194315817\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35782953475491436\n",
      "std: 0.34759344497072936\n",
      "min: -0.6755313865519568\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0573318174106431\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408297904210612\n",
      "std: 0.0027636780873119553\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408297284502954\n",
      "std: 0.0029588559131573503\n",
      "min: 1.3795947786130625\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.029462295888731307\n",
      "min: 0.01184174037467037\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3199485516299394\n",
      "std: 0.2939962855849794\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.487714626998922\n",
      "std: 0.3610620263886672\n",
      "min: -0.38967766754115857\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258976184776949\n",
      "min: 0.08224047526152706\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1922034490986402\n",
      "std: 0.1790991642125677\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1939756696691552\n",
      "std: 0.1815428781110453\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.03108553323021016\n",
      "min: 0.0023448767340452452\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34658666496360163\n",
      "std: 0.3632712704033258\n",
      "min: -1.077416757224221\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35770208074459947\n",
      "std: 0.3481049023085\n",
      "min: -0.6760788147460834\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05734843184000156\n",
      "min: 0.07035282456402321\n",
      "max: 0.3293850576520611\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065360494310368\n",
      "std: 0.01143928894400599\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406541004537075\n",
      "std: 0.01158316067679568\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.029471234823039857\n",
      "min: 0.01095253542122199\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3210111668556066\n",
      "std: 0.2939588717854718\n",
      "min: -0.7974335654434677\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48820775805340577\n",
      "std: 0.3615916445763205\n",
      "min: -0.38954828823915255\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06262295187283659\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2008999816302381\n",
      "std: 0.13108243302241318\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.202641935803733\n",
      "std: 0.13315281659324582\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.0301324458770979\n",
      "min: 0.0037371563448466154\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3402552246289059\n",
      "std: 0.36466964900698207\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36305340830953214\n",
      "std: 0.3469308008838391\n",
      "min: -0.6747768124706292\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05708444041791461\n",
      "min: 0.07034332619054122\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078198856775643\n",
      "std: 0.004035539397553217\n",
      "min: 1.3717877071493065\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078273709646463\n",
      "std: 0.00408633425305928\n",
      "min: 1.3736210995459537\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.029169979253127382\n",
      "min: 0.011627172899228662\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3187891320639887\n",
      "std: 0.294330739332781\n",
      "min: -0.797876861845221\n",
      "max: 0.947109988485612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4895461598608399\n",
      "std: 0.3610951325518424\n",
      "min: -0.3887925499428951\n",
      "max: 0.947109988485612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258509856965046\n",
      "min: 0.08217881850779869\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.198796432147819\n",
      "std: 0.14277039155439966\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2005902470635281\n",
      "std: 0.14545592299029197\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.030483081449610677\n",
      "min: 0.004074749627124124\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34066613725559824\n",
      "std: 0.36658768600332425\n",
      "min: -1.0775186071203198\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36256743910760975\n",
      "std: 0.34792025327225545\n",
      "min: -0.675379271976603\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05719901362354239\n",
      "min: 0.07033503095787877\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407497719580522\n",
      "std: 0.005777770528357002\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075099020511723\n",
      "std: 0.0058511425064094605\n",
      "min: 1.3490538869125936\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.029171519510753335\n",
      "min: 0.011415853237390694\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3180936212349231\n",
      "std: 0.2941487487853552\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48950698538145454\n",
      "std: 0.36091203495703084\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0625541980120421\n",
      "min: 0.08219586315638133\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2003291369223208\n",
      "std: 0.1392620076642028\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2021345989119843\n",
      "std: 0.14046059133393807\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.0300496234844618\n",
      "min: 0.003915259394232308\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3413392335451903\n",
      "std: 0.3655083056672086\n",
      "min: -1.0777584281638517\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3622727632847271\n",
      "std: 0.34785194887589527\n",
      "min: -0.6757159370215139\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057184665935564406\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407923487626001\n",
      "std: 0.003597381391743917\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079256313522828\n",
      "std: 0.0037605625424715567\n",
      "min: 1.3740240626115368\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.02916969990534019\n",
      "min: 0.011635685010827951\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31895678485092344\n",
      "std: 0.294297564282733\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4891512277860031\n",
      "std: 0.36105372626218957\n",
      "min: -0.3890895033732396\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257859094694691\n",
      "min: 0.08218381980724239\n",
      "max: 0.2997505107912778\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.217676211962887\n",
      "std: 0.07129883114057267\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2193687910164372\n",
      "std: 0.07476469446219537\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.029507298328217135\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34605574731407474\n",
      "std: 0.36299581196537534\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35809847735358613\n",
      "std: 0.3476750540062083\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057335635816708856\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082972230071666\n",
      "std: 0.002761132037628026\n",
      "min: 1.3795947786130622\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082893247999158\n",
      "std: 0.00296047066283663\n",
      "min: 1.3795947786130622\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.029169486393725984\n",
      "min: 0.011663140784243164\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3199124440458872\n",
      "std: 0.2940873547716894\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4878368389461313\n",
      "std: 0.36104418062693666\n",
      "min: -0.38967766754115857\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258546179890082\n",
      "min: 0.0822029702719914\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.192844152915301\n",
      "std: 0.1783395452198723\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1946213133356067\n",
      "std: 0.1807555896007587\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.03077107074437707\n",
      "min: 0.002187964823642007\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3465493487993884\n",
      "std: 0.36388490864497647\n",
      "min: -1.0774167572242215\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35797385532672193\n",
      "std: 0.34818356661463323\n",
      "min: -0.6760788147460834\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0573527074159622\n",
      "min: 0.0703528245640232\n",
      "max: 0.32938505765206105\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065558069071866\n",
      "std: 0.01138077090387525\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065532296523326\n",
      "std: 0.01152540103809698\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.02917830617826426\n",
      "min: 0.010782595340328606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32096477304471793\n",
      "std: 0.29404950277493935\n",
      "min: -0.7974335654434677\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48832541052387185\n",
      "std: 0.3615681419216262\n",
      "min: -0.38954828823915255\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261832519557638\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2013274115674868\n",
      "std: 0.13057752078087692\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2030364108808302\n",
      "std: 0.13260974677984586\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.029833111860289876\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3403807009357397\n",
      "std: 0.364674399467715\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3625218959063139\n",
      "std: 0.34689804897049065\n",
      "min: -0.674776812470629\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05707241544063922\n",
      "min: 0.07034332619054123\n",
      "max: 0.32939818075364125\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407815513097951\n",
      "std: 0.004033433253157274\n",
      "min: 1.3712008384186136\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078144412572886\n",
      "std: 0.004091229281970334\n",
      "min: 1.3712008384186136\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.028883275151922187\n",
      "min: 0.011396844657371155\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3188763030713581\n",
      "std: 0.2943490489920237\n",
      "min: -0.797876861845221\n",
      "max: 0.947109988485612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4894597262409062\n",
      "std: 0.36110049396707294\n",
      "min: -0.3887925499428951\n",
      "max: 0.947109988485612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258531848362653\n",
      "min: 0.0821788185077987\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1992462536460802\n",
      "std: 0.14229494685550145\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.201006117568226\n",
      "std: 0.14494140360123012\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.030179083621086733\n",
      "min: 0.00398037163533402\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34079170171193507\n",
      "std: 0.3665702073253606\n",
      "min: -1.0775186071203198\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36203805995950716\n",
      "std: 0.34787754859200826\n",
      "min: -0.6753792719766031\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05718605339918726\n",
      "min: 0.07033503095787877\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074967020266453\n",
      "std: 0.005770827254278439\n",
      "min: 1.3463385904221308\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075002800188552\n",
      "std: 0.005848688116704234\n",
      "min: 1.3463385904221308\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.02888479529197581\n",
      "min: 0.0111191631285002\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31818605601063293\n",
      "std: 0.294167653292473\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4894197582813044\n",
      "std: 0.3609182702459891\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06255462090853788\n",
      "min: 0.0821958631563813\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2007601425130159\n",
      "std: 0.1387455733014513\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2025319972666053\n",
      "std: 0.13990893184768316\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.02975142729021656\n",
      "min: 0.0037315043450326445\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34145505391392533\n",
      "std: 0.36550668742994286\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.361747353595078\n",
      "std: 0.34780993707978397\n",
      "min: -0.6757159370215139\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057171778628509175\n",
      "min: 0.07033286141518688\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079181201993327\n",
      "std: 0.003602090522021151\n",
      "min: 1.3707063783097035\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079117884268004\n",
      "std: 0.003771695040105765\n",
      "min: 1.3707063783097035\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.02888299955082793\n",
      "min: 0.011390680622083482\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31904133533506635\n",
      "std: 0.29431637236248087\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48906757164766146\n",
      "std: 0.3610586049971716\n",
      "min: -0.3890895033732396\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257874354337556\n",
      "min: 0.0821838198072424\n",
      "max: 0.2997505107912778\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2179352448762226\n",
      "std: 0.0711220640192588\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2195976985589507\n",
      "std: 0.07451170029533136\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.02921621132597779\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3461191092489074\n",
      "std: 0.3630117518627455\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35761533653972505\n",
      "std: 0.3476274147789085\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05732075670910376\n",
      "min: 0.07043584963749587\n",
      "max: 0.3292999551626174\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082889989799\n",
      "std: 0.0027675229157665673\n",
      "min: 1.3782071630156876\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082727679959446\n",
      "std: 0.0029749823033614477\n",
      "min: 1.3782071630156876\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.02888278865310237\n",
      "min: 0.011472730016815858\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3199865303493288\n",
      "std: 0.29410727483791227\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.487766347570348\n",
      "std: 0.36104845766070337\n",
      "min: -0.38967766754115857\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258546591108743\n",
      "min: 0.0822029702719914\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.193399373300734\n",
      "std: 0.17743730993341197\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1951416518912528\n",
      "std: 0.17982554785574648\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.03046324639087401\n",
      "min: 0.0021879648236420076\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3466158001259316\n",
      "std: 0.36389470060872664\n",
      "min: -1.0774167572242213\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3574925955265866\n",
      "std: 0.34813273122230093\n",
      "min: -0.6760788147460836\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05733834140046224\n",
      "min: 0.0703528245640232\n",
      "max: 0.32938505765206105\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065675185551791\n",
      "std: 0.011325822627721777\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065563703669275\n",
      "std: 0.011472752207775687\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.02889149231965649\n",
      "min: 0.010559750845757918\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.321029204469042\n",
      "std: 0.294068814884131\n",
      "min: -0.7974335654434677\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48825020432552385\n",
      "std: 0.3615673228126428\n",
      "min: -0.38954828823915255\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06261804087868568\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2010517026519256\n",
      "std: 0.12992032420808386\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2028880170041043\n",
      "std: 0.13192724992969032\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.02953997945373991\n",
      "min: 0.0037371563448466163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3397309805431993\n",
      "std: 0.36414405938320316\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36222387416916657\n",
      "std: 0.346447529139382\n",
      "min: -0.6747768124706293\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05701456068408112\n",
      "min: 0.07034332619054122\n",
      "max: 0.32939818075364125\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078111881316901\n",
      "std: 0.004016768217554443\n",
      "min: 1.371200838418614\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078145798148867\n",
      "std: 0.004071915334110878\n",
      "min: 1.371200838418614\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.028602489021560845\n",
      "min: 0.011368907360331939\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3187517574870101\n",
      "std: 0.29427528323454333\n",
      "min: -0.797876861845221\n",
      "max: 0.947109988485612\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4894654185939663\n",
      "std: 0.36103056594935845\n",
      "min: -0.3887925499428951\n",
      "max: 0.947109988485612\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257612888170995\n",
      "min: 0.0821788185077987\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.198997333837254\n",
      "std: 0.14146145394905668\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2008835952784545\n",
      "std: 0.14408445117945418\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.029881378011069135\n",
      "min: 0.00398037163533402\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3401417351525583\n",
      "std: 0.36602141477572303\n",
      "min: -1.0775186071203195\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36174246005944755\n",
      "std: 0.3474191381068446\n",
      "min: -0.6753792719766029\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057127426395528494\n",
      "min: 0.0703350309578788\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074958296232185\n",
      "std: 0.0057413725480299094\n",
      "min: 1.346338590422131\n",
      "max: 1.4139812651754065\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075038073836175\n",
      "std: 0.005817285079523009\n",
      "min: 1.346338590422131\n",
      "max: 1.4139812651754065\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.028603989223975154\n",
      "min: 0.011119163128500203\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3180665612743846\n",
      "std: 0.2940941555879446\n",
      "min: -0.7971594015816312\n",
      "max: 0.9800013732642877\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48942476897094495\n",
      "std: 0.3608491680310041\n",
      "min: -0.3883083708185303\n",
      "max: 0.9800013732642877\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06254562930396197\n",
      "min: 0.0821958631563813\n",
      "max: 0.29968399445139043\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2004863606078857\n",
      "std: 0.13807894581741537\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2023848241486739\n",
      "std: 0.1392237243905021\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.02945941298382476\n",
      "min: 0.0037315043450326453\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34079723035703036\n",
      "std: 0.3649723317982807\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3614551401726564\n",
      "std: 0.3473525262315224\n",
      "min: -0.675715937021514\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0571132642205335\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079126649376836\n",
      "std: 0.0035881796634894838\n",
      "min: 1.3707063783097035\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079108931252988\n",
      "std: 0.0037538217400671613\n",
      "min: 1.3707063783097035\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.02860221703315779\n",
      "min: 0.011390680622083482\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3189142546837649\n",
      "std: 0.2942431667927547\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4890760524706362\n",
      "std: 0.3609882730418449\n",
      "min: -0.3890895033732396\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256949964614858\n",
      "min: 0.08218381980724239\n",
      "max: 0.2997505107912778\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2174542850504386\n",
      "std: 0.07095969771339461\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2192479515923138\n",
      "std: 0.07426410704292287\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.028931155287139264\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34541156350674707\n",
      "std: 0.36250277979095524\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35736168644102256\n",
      "std: 0.3471662853750163\n",
      "min: -0.6755313865519568\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0572605327217604\n",
      "min: 0.07043584963749591\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408280724856165\n",
      "std: 0.002761306571361397\n",
      "min: 1.3782071630156878\n",
      "max: 1.4139807655137457\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082691446430688\n",
      "std: 0.002963357657294377\n",
      "min: 1.3782071630156878\n",
      "max: 1.4139807655137457\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.028602008830789963\n",
      "min: 0.011411702631957402\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3198496488659841\n",
      "std: 0.2940360495476652\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48778733733308405\n",
      "std: 0.3609779870525025\n",
      "min: -0.38967766754115857\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06257609860821652\n",
      "min: 0.0822029702719914\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.19320520524798\n",
      "std: 0.17645289192314623\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.195073432537629\n",
      "std: 0.17882759360613093\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.03016186206747891\n",
      "min: 0.0021879648236420076\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3459103951382695\n",
      "std: 0.3633796761007916\n",
      "min: -1.0774167572242215\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3572412995908456\n",
      "std: 0.3476702744836501\n",
      "min: -0.6760788147460834\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057278575182138754\n",
      "min: 0.0703528245640232\n",
      "max: 0.32938505765206105\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065782198484562\n",
      "std: 0.011260910762669898\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065714757134173\n",
      "std: 0.011407129478222089\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068201\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.028610598897746444\n",
      "min: 0.010559750845757918\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.320882380409563\n",
      "std: 0.2939972607966053\n",
      "min: -0.7974335654434677\n",
      "max: 0.944353750023872\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4882668951220628\n",
      "std: 0.36149177227419677\n",
      "min: -0.38954828823915255\n",
      "max: 0.944353750023872\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06260837754715329\n",
      "min: 0.08217236485510232\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2012246291205102\n",
      "std: 0.12918458936420352\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2029754551430434\n",
      "std: 0.13120459536003426\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.02925286878816549\n",
      "min: 0.0037371563448466154\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3388091597331242\n",
      "std: 0.36409711314301874\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3623374876851245\n",
      "std: 0.3461835488399425\n",
      "min: -0.6747768124706292\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05696975969330141\n",
      "min: 0.07034332619054122\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078324542555707\n",
      "std: 0.003995681048729522\n",
      "min: 1.3712008384186138\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078446672746014\n",
      "std: 0.0040469430939461155\n",
      "min: 1.3712008384186138\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.028327435365755414\n",
      "min: 0.011295359827797996\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31858164601067196\n",
      "std: 0.29430055014352374\n",
      "min: -0.7978768618452212\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4894974743600812\n",
      "std: 0.36096756828235027\n",
      "min: -0.38879254994289525\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256579704403792\n",
      "min: 0.0821788185077987\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1991901938429455\n",
      "std: 0.14066944784389077\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2009899020074233\n",
      "std: 0.14330016684597813\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.029589824631894683\n",
      "min: 0.00398037163533402\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33922000730101254\n",
      "std: 0.3659546261078711\n",
      "min: -1.07751860712032\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3618581694683235\n",
      "std: 0.3471471417890624\n",
      "min: -0.6753792719766029\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057081792799081245\n",
      "min: 0.07033503095787877\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407520356765978\n",
      "std: 0.0057097196645833626\n",
      "min: 1.3463385904221308\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075370752109106\n",
      "std: 0.005782953895634715\n",
      "min: 1.3463385904221308\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.028328916129791548\n",
      "min: 0.011064400263248396\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3179014178593566\n",
      "std: 0.2941195268418524\n",
      "min: -0.7971594015816316\n",
      "max: 0.9800013732642878\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48945616209044557\n",
      "std: 0.3607869409833642\n",
      "min: -0.38830837081853053\n",
      "max: 0.9800013732642878\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06253548664742341\n",
      "min: 0.08219586315638133\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2006579739135599\n",
      "std: 0.1374177286289589\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2024699932274374\n",
      "std: 0.13858001748159243\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.02917340320925405\n",
      "min: 0.0037315043450326453\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3398661441723267\n",
      "std: 0.3649215952994115\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3615745609287429\n",
      "std: 0.3470815854344108\n",
      "min: -0.6757159370215138\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057067671321391705\n",
      "min: 0.07033286141518683\n",
      "max: 0.3294534672190304\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079329789807622\n",
      "std: 0.003571433367296712\n",
      "min: 1.3707063783097035\n",
      "max: 1.4139800835404732\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407940133269957\n",
      "std: 0.0037318375877890345\n",
      "min: 1.3707063783097035\n",
      "max: 1.4139800835404732\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.028327166940140223\n",
      "min: 0.011313054835547431\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3187414840734993\n",
      "std: 0.29426895411186693\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4891108527333668\n",
      "std: 0.36092484154599336\n",
      "min: -0.38908950337323983\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06255910464135944\n",
      "min: 0.08218381980724238\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2174235053000297\n",
      "std: 0.07078578909781184\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2191336668464376\n",
      "std: 0.07411340693766388\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.028651936981443037\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3444337226682949\n",
      "std: 0.3624794600285143\n",
      "min: -1.076788275590154\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35751614301417944\n",
      "std: 0.34689501877710155\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05721314780429844\n",
      "min: 0.0704358496374959\n",
      "max: 0.32929995516261745\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082975859312288\n",
      "std: 0.0027514444461334644\n",
      "min: 1.3782071630156878\n",
      "max: 1.4139807655137453\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082949874069426\n",
      "std: 0.002946365603531392\n",
      "min: 1.3782071630156878\n",
      "max: 1.4139807655137453\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.028326961383544708\n",
      "min: 0.01133156305025304\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3196676879759315\n",
      "std: 0.2940637976282392\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48783410053939985\n",
      "std: 0.3609145531041158\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256559739871086\n",
      "min: 0.0822029702719914\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1934488893654014\n",
      "std: 0.17552036336801893\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1952298799397103\n",
      "std: 0.17790296327153443\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.029866724159499015\n",
      "min: 0.002187964823642007\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3449341164217563\n",
      "std: 0.36335261294688104\n",
      "min: -1.0774167572242215\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3574005364846893\n",
      "std: 0.3473984959680581\n",
      "min: -0.6760788147460836\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05723174175493996\n",
      "min: 0.07035282456402321\n",
      "max: 0.32938505765206105\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066137347782086\n",
      "std: 0.011195636218021426\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066157225195624\n",
      "std: 0.011340892412280746\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.02833544054019317\n",
      "min: 0.010509379981742924\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3206904404336208\n",
      "std: 0.2940250462183878\n",
      "min: -0.7974335654434678\n",
      "max: 0.9443537500238719\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4883095160218734\n",
      "std: 0.36142328787381456\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238719\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259758021111861\n",
      "min: 0.08217236485510232\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2013069030962527\n",
      "std: 0.12848864042382183\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.203118879726695\n",
      "std: 0.13050416621409686\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.02897161630058082\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3389694420247954\n",
      "std: 0.3644089511916158\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3624943113509181\n",
      "std: 0.34604328296593945\n",
      "min: -0.6747768124706292\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056967756797491255\n",
      "min: 0.07034332619054123\n",
      "max: 0.32939818075364125\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407840921090414\n",
      "std: 0.003972907430822904\n",
      "min: 1.371200838418614\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407854229138357\n",
      "std: 0.004022560737899991\n",
      "min: 1.371200838418614\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.02805793665556029\n",
      "min: 0.01114604502371505\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31856988584984147\n",
      "std: 0.29435394459971354\n",
      "min: -0.7978768618452212\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48947423871087453\n",
      "std: 0.36093624833423693\n",
      "min: -0.38879254994289525\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256043697858907\n",
      "min: 0.0821788185077987\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1992914588699572\n",
      "std: 0.1399384636492993\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2011514292115921\n",
      "std: 0.14256146435851377\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.02930424617372747\n",
      "min: 0.00398037163533402\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33938104372480904\n",
      "std: 0.3662438019533534\n",
      "min: -1.0775186071203195\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36201605546760746\n",
      "std: 0.3469984353078739\n",
      "min: -0.6753792719766031\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057078912319506826\n",
      "min: 0.0703350309578788\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075327867337153\n",
      "std: 0.005675132037723778\n",
      "min: 1.3463385904221308\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075505275372233\n",
      "std: 0.005747239798399169\n",
      "min: 1.3463385904221308\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.028059398409552988\n",
      "min: 0.010941099526254324\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3178947916624125\n",
      "std: 0.29417337399351406\n",
      "min: -0.7971594015816316\n",
      "max: 0.9800013732642878\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48943220112238084\n",
      "std: 0.36075648860734166\n",
      "min: -0.38830837081853053\n",
      "max: 0.9800013732642878\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0625303297167428\n",
      "min: 0.08219586315638133\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2007425787583876\n",
      "std: 0.13671767993414954\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2026151258215945\n",
      "std: 0.13787924698393966\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.028893212483617085\n",
      "min: 0.0037315043450326453\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3400185715328197\n",
      "std: 0.36522595198506397\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36173629404456564\n",
      "std: 0.34693419620953064\n",
      "min: -0.675715937021514\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05706493835045321\n",
      "min: 0.07033286141518687\n",
      "max: 0.3294534672190304\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407940369319368\n",
      "std: 0.003551459319737182\n",
      "min: 1.3707063783097035\n",
      "max: 1.4139800835404732\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079487104947115\n",
      "std: 0.0037092850583226806\n",
      "min: 1.3707063783097035\n",
      "max: 1.4139800835404732\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.028057671685420355\n",
      "min: 0.011186635813350271\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3187274269135482\n",
      "std: 0.2943228173687718\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4890902097403499\n",
      "std: 0.36089319751869947\n",
      "min: -0.38908950337323983\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06255370185484022\n",
      "min: 0.08218381980724239\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2173123101652659\n",
      "std: 0.07060020937394781\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2190866357173018\n",
      "std: 0.07389169912106817\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.028378381898962506\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3445399039133748\n",
      "std: 0.36280212426600295\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35771403762034193\n",
      "std: 0.346749843028639\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05720872069609304\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083004510042836\n",
      "std: 0.0027395240113253813\n",
      "min: 1.3782071630156878\n",
      "max: 1.4139807655137453\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082991445993485\n",
      "std: 0.002930922276054637\n",
      "min: 1.3782071630156878\n",
      "max: 1.4139807655137453\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.02805746873322231\n",
      "min: 0.011191485270440652\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31964435644761213\n",
      "std: 0.294119019604849\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48782545014521167\n",
      "std: 0.3608828341934002\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256009323312603\n",
      "min: 0.08220297027199142\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1936141231747783\n",
      "std: 0.17458385749734454\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.195454775824932\n",
      "std: 0.1769641150347072\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.02957763144633584\n",
      "min: 0.0021879648236420076\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34504325473693087\n",
      "std: 0.36366819790436683\n",
      "min: -1.0774167572242213\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3576009390502781\n",
      "std: 0.3472513997005595\n",
      "min: -0.6760788147460836\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05722773121253805\n",
      "min: 0.07035282456402321\n",
      "max: 0.32938505765206105\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066358233570837\n",
      "std: 0.011130225676953756\n",
      "min: 1.2899779509647342\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406638877298281\n",
      "std: 0.01127481247722732\n",
      "min: 1.2899779509647342\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.028065839664872444\n",
      "min: 0.010401746308364442\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32065779864940797\n",
      "std: 0.2940799680771502\n",
      "min: -0.7974335654434678\n",
      "max: 0.9443537500238719\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4882966339179518\n",
      "std: 0.3613865964369108\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238719\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259179154731342\n",
      "min: 0.08217236485510232\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.201530518357833\n",
      "std: 0.12795477766313468\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2032346773444038\n",
      "std: 0.1299661251630221\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.028696046005220084\n",
      "min: 0.0036524039405521997\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3401176465743096\n",
      "std: 0.3639860651508269\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36111834189910325\n",
      "std: 0.3465179394515393\n",
      "min: -0.6747768124706292\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05699573611709351\n",
      "min: 0.07034332619054123\n",
      "max: 0.32939818075364125\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078262356177873\n",
      "std: 0.003965216245378704\n",
      "min: 1.3712008384186136\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078364043938985\n",
      "std: 0.004012209650430351\n",
      "min: 1.3712008384186136\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.0277938226361958\n",
      "min: 0.010945481025282618\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3187585586858646\n",
      "std: 0.2942720558718566\n",
      "min: -0.7978768618452212\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48920382790597433\n",
      "std: 0.3609522801164892\n",
      "min: -0.38879254994289525\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256341988026914\n",
      "min: 0.0821788185077987\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.199536583797546\n",
      "std: 0.13940808242201833\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2012880583849257\n",
      "std: 0.14202061897595286\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.029024451071401315\n",
      "min: 0.0038270795679947282\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3405287530479852\n",
      "std: 0.3658028646672965\n",
      "min: -1.0775186071203195\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3606423274644399\n",
      "std: 0.34746252899675156\n",
      "min: -0.675379271976603\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05710596367849096\n",
      "min: 0.0703350309578788\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075216124136596\n",
      "std: 0.005664185226725859\n",
      "min: 1.3463385904221303\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075361551416592\n",
      "std: 0.005734139219806109\n",
      "min: 1.3463385904221303\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.02779526615376698\n",
      "min: 0.0106681698757419\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31808835474318736\n",
      "std: 0.2940921187913992\n",
      "min: -0.7971594015816316\n",
      "max: 0.9800013732642878\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48916102618915713\n",
      "std: 0.36077339104078326\n",
      "min: -0.38830837081853053\n",
      "max: 0.9800013732642878\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06253350008392457\n",
      "min: 0.08219586315638128\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2009747897368104\n",
      "std: 0.13610632214805893\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2027387854864826\n",
      "std: 0.1372686519684602\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.028618655583511485\n",
      "min: 0.003583987726740878\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3411573993728986\n",
      "std: 0.36479525489994286\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3603663950788446\n",
      "std: 0.3473981451160253\n",
      "min: -0.6757159370215139\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05709203729710322\n",
      "min: 0.07033286141518687\n",
      "max: 0.3294534672190304\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079249824627007\n",
      "std: 0.0035478116235417314\n",
      "min: 1.3707063783097035\n",
      "max: 1.4139800835404732\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407930268727869\n",
      "std: 0.0037016280447198873\n",
      "min: 1.3707063783097035\n",
      "max: 1.4139800835404732\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.027793561029486998\n",
      "min: 0.010960918151439816\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3189137212778521\n",
      "std: 0.2942411810585445\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48882239712854175\n",
      "std: 0.3609086828756918\n",
      "min: -0.38908950337323983\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06255662760552719\n",
      "min: 0.08218381980724239\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2173747452985915\n",
      "std: 0.07036855358081218\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2190432983122605\n",
      "std: 0.07365615855187767\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.028110289092995497\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34563025543775816\n",
      "std: 0.3623755636992067\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3563840591829425\n",
      "std: 0.3471995347056659\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05723404809199498\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40828184267582\n",
      "std: 0.002741538025559439\n",
      "min: 1.378207163015688\n",
      "max: 1.4139807655137453\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082775879078697\n",
      "std: 0.0029279595945577537\n",
      "min: 1.378207163015688\n",
      "max: 1.4139807655137453\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.027793360530576388\n",
      "min: 0.01107795331526123\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31982102891278835\n",
      "std: 0.2940382858157669\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4875700276512967\n",
      "std: 0.3608972205245284\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256288591912607\n",
      "min: 0.08220297027199142\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.193936754177869\n",
      "std: 0.1737519802887886\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.19566822183658\n",
      "std: 0.17612323357770943\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.029294388797392535\n",
      "min: 0.0021879648236420076\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3461359571482245\n",
      "std: 0.363235543507822\n",
      "min: -1.0774167572242213\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3562712015191537\n",
      "std: 0.3476976079595552\n",
      "min: -0.6760788147460834\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05725342454933555\n",
      "min: 0.07035282456402321\n",
      "max: 0.32938505765206105\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066353177091941\n",
      "std: 0.011080733484816929\n",
      "min: 1.2899779509647342\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066351814738574\n",
      "std: 0.011224314845501656\n",
      "min: 1.2899779509647342\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.02780162640819209\n",
      "min: 0.010155931699172489\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3208255481002162\n",
      "std: 0.29399803638452293\n",
      "min: -0.7974335654434678\n",
      "max: 0.9443537500238719\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4880365420165584\n",
      "std: 0.3613963956751488\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238719\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259431221219208\n",
      "min: 0.08217236485510232\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.201871268736955\n",
      "std: 0.12749350356993683\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2035401659977867\n",
      "std: 0.1294891324760069\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.02842596517823195\n",
      "min: 0.0036524039405521997\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3393726722021338\n",
      "std: 0.3641097385413173\n",
      "min: -1.077509723733476\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3613200103228405\n",
      "std: 0.34637998461175495\n",
      "min: -0.6747768124706292\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05697055776486237\n",
      "min: 0.07034332619054123\n",
      "max: 0.32939818075364125\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078335898459708\n",
      "std: 0.003955875140948283\n",
      "min: 1.3712008384186138\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407840583374057\n",
      "std: 0.004007344718276637\n",
      "min: 1.3712008384186138\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.027534929821857276\n",
      "min: 0.010788785408870667\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3186238114125702\n",
      "std: 0.29425643433397\n",
      "min: -0.7978768618452212\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4892384678717326\n",
      "std: 0.3609089735416963\n",
      "min: -0.38879254994289525\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0625576249674786\n",
      "min: 0.08217881850779869\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1999073475478208\n",
      "std: 0.138769024069874\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2016229323970335\n",
      "std: 0.14136364168163684\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.02875021561937691\n",
      "min: 0.0038270795679947282\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3397831126250044\n",
      "std: 0.3659065042462116\n",
      "min: -1.0775186071203195\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3608476792223803\n",
      "std: 0.3473162927193381\n",
      "min: -0.675379271976603\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057079947384380166\n",
      "min: 0.0703350309578788\n",
      "max: 0.3294395001322561\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075324820090331\n",
      "std: 0.005639022717058584\n",
      "min: 1.3463385904221308\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075438028719587\n",
      "std: 0.005712255984724471\n",
      "min: 1.3463385904221308\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.02753635521650095\n",
      "min: 0.01063369360184822\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3179581723936738\n",
      "std: 0.29407679162998934\n",
      "min: -0.7971594015816316\n",
      "max: 0.9800013732642878\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4891953730596244\n",
      "std: 0.36073085083405754\n",
      "min: -0.38830837081853053\n",
      "max: 0.9800013732642878\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06252788309237593\n",
      "min: 0.08219586315638132\n",
      "max: 0.2996839944513905\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.201325100873286\n",
      "std: 0.13552776883020595\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.203053224270657\n",
      "std: 0.13667991764075976\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.028349560911002453\n",
      "min: 0.003583987726740877\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3404036693169185\n",
      "std: 0.36491457588776266\n",
      "min: -1.0777584281638515\n",
      "max: 1.0584952565958234\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3605743544768376\n",
      "std: 0.34725329267533966\n",
      "min: -0.6757159370215139\n",
      "max: 1.0584952565958234\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05706612379088644\n",
      "min: 0.07033286141518687\n",
      "max: 0.3294534672190304\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407931227941116\n",
      "std: 0.0035412861582723313\n",
      "min: 1.3707063783097035\n",
      "max: 1.4139800835404732\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079334285223126\n",
      "std: 0.0036991066732275702\n",
      "min: 1.3707063783097035\n",
      "max: 1.4139800835404732\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.02753467148879312\n",
      "min: 0.010800992408967496\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31877647025332\n",
      "std: 0.2942260662553751\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48885976969768485\n",
      "std: 0.36086501156764894\n",
      "min: -0.38908950337323983\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06255077589946843\n",
      "min: 0.08218381980724238\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.217548749339785\n",
      "std: 0.07021448548961669\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2191844321219367\n",
      "std: 0.07346671775369487\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.027847500881966285\n",
      "min: 0.007579173812029776\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3448320345080351\n",
      "std: 0.36252156434474064\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.356628733252466\n",
      "std: 0.3470565756881864\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05720648981682973\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082842400899298\n",
      "std: 0.0027397271933847105\n",
      "min: 1.37804104011155\n",
      "max: 1.4139807655137453\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40827703907107\n",
      "std: 0.002930872195426384\n",
      "min: 1.37804104011155\n",
      "max: 1.4139807655137453\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.027534473392669383\n",
      "min: 0.010815396571138409\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3196748208566322\n",
      "std: 0.2940249722508785\n",
      "min: -0.7976242858584904\n",
      "max: 0.9425121760623354\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48761910992625823\n",
      "std: 0.36085349222023344\n",
      "min: -0.38967766754115873\n",
      "max: 0.9425121760623354\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06255691880789187\n",
      "min: 0.08220297027199139\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.194347599280329\n",
      "std: 0.17303926449219473\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1960430781529152\n",
      "std: 0.175395132828787\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.02901682342802481\n",
      "min: 0.0021879648236420076\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34533854599289715\n",
      "std: 0.36337487171792254\n",
      "min: -1.0774167572242213\n",
      "max: 1.0542347607461078\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35651888542754717\n",
      "std: 0.3475522776887578\n",
      "min: -0.6760788147460834\n",
      "max: 1.0542347607461078\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05722624076050783\n",
      "min: 0.07035282456402321\n",
      "max: 0.32938505765206105\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066545545836628\n",
      "std: 0.011026926848917902\n",
      "min: 1.2899779509647342\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406651268718904\n",
      "std: 0.011172164090368574\n",
      "min: 1.2899779509647342\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.027542636455773206\n",
      "min: 0.010051672886598698\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32066998781320794\n",
      "std: 0.29398457915957754\n",
      "min: -0.7974335654434678\n",
      "max: 0.9443537500238719\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48808167048345746\n",
      "std: 0.3613478505584478\n",
      "min: -0.38954828823915255\n",
      "max: 0.9443537500238719\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258806487990484\n",
      "min: 0.08217236485510232\n",
      "max: 0.2997094700213908\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.201985296265355\n",
      "std: 0.12671148567946336\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.203706086631875\n",
      "std: 0.12870099799972587\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.028161155768753218\n",
      "min: 0.0036524039405521997\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3392618066811545\n",
      "std: 0.3642859087387849\n",
      "min: -1.0775097237334763\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3618065167099745\n",
      "std: 0.3463042406250034\n",
      "min: -0.6747768124706292\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.056959409849831014\n",
      "min: 0.07034332619054123\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078170683838118\n",
      "std: 0.003945921238457317\n",
      "min: 1.3712008384186136\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078220738772824\n",
      "std: 0.0039938160973403206\n",
      "min: 1.3712008384186136\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.027281101221703415\n",
      "min: 0.010780118965705725\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3185544265396951\n",
      "std: 0.2943324976752976\n",
      "min: -0.7978768618452212\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4893406436143008\n",
      "std: 0.3609065043385229\n",
      "min: -0.38879254994289497\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0625541796578123\n",
      "min: 0.08217881850779872\n",
      "max: 0.29973801437421693\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2000435313882714\n",
      "std: 0.13787879740397058\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.201810190901938\n",
      "std: 0.1404662708705881\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.02848136485447108\n",
      "min: 0.0038270795679947282\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33967198844400426\n",
      "std: 0.3660624230851654\n",
      "min: -1.0775186071203195\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36133647493256393\n",
      "std: 0.3472326569454176\n",
      "min: -0.6753792719766031\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057067997392751056\n",
      "min: 0.07033503095787877\n",
      "max: 0.32943950013225615\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075191465571326\n",
      "std: 0.005612402046450112\n",
      "min: 1.3463385904221306\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075284285233374\n",
      "std: 0.005682952551144986\n",
      "min: 1.3463385904221306\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782605\n",
      "std: 0.027282508897189413\n",
      "min: 0.01057721126837686\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3178934035484821\n",
      "std: 0.29415324762162204\n",
      "min: -0.7971594015816316\n",
      "max: 0.9800013732642878\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4892971580652761\n",
      "std: 0.3607291753076428\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642878\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06252462703615587\n",
      "min: 0.0821958631563813\n",
      "max: 0.29968399445139055\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2014454841790587\n",
      "std: 0.13470595839203467\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2032248554941471\n",
      "std: 0.13585768763332673\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782605\n",
      "std: 0.028085729265157327\n",
      "min: 0.003583987726740877\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3402842312512478\n",
      "std: 0.365083804054159\n",
      "min: -1.0777584281638515\n",
      "max: 1.058495256595823\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3610669161155942\n",
      "std: 0.3471710923530876\n",
      "min: -0.6757159370215143\n",
      "max: 1.058495256595823\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057054229424292696\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079131899459738\n",
      "std: 0.0035348567296483438\n",
      "min: 1.3707063783097038\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079135092617243\n",
      "std: 0.0036878278317758954\n",
      "min: 1.3707063783097038\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782605\n",
      "std: 0.027280846090357247\n",
      "min: 0.010793378688236174\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3187045709525273\n",
      "std: 0.2943025959633557\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4889649239681303\n",
      "std: 0.36086227476249516\n",
      "min: -0.38908950337323966\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0625472793576916\n",
      "min: 0.0821838198072424\n",
      "max: 0.29975051079127785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2174573273122702\n",
      "std: 0.07002561712165087\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2191477446642605\n",
      "std: 0.07324046897845375\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.027589872638684964\n",
      "min: 0.007579173812029774\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3446695650834108\n",
      "std: 0.36270987326094006\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35715266554937053\n",
      "std: 0.3469786647638303\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0571930106413104\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082621887214724\n",
      "std: 0.0027475974306018103\n",
      "min: 1.37804104011155\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082532188241752\n",
      "std: 0.0029320209640803225\n",
      "min: 1.37804104011155\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782605\n",
      "std: 0.027280650435309594\n",
      "min: 0.010792209945560577\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31959432344974964\n",
      "std: 0.2941028208201073\n",
      "min: -0.7976242858584903\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4877350315040662\n",
      "std: 0.36085089445556223\n",
      "min: -0.3896776675411586\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06255331812183221\n",
      "min: 0.08220297027199142\n",
      "max: 0.2997211781190923\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1945393517586576\n",
      "std: 0.17194570596145847\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1962854237658063\n",
      "std: 0.17429893233386795\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.02874471005843638\n",
      "min: 0.002187964823642008\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3451780889017939\n",
      "std: 0.3635575755908765\n",
      "min: -1.0774167572242215\n",
      "max: 1.0542347607461076\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3570472171249217\n",
      "std: 0.3474728570144539\n",
      "min: -0.6760788147460834\n",
      "max: 1.0542347607461076\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05721319480957378\n",
      "min: 0.0703528245640232\n",
      "max: 0.32938505765206116\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066507939640176\n",
      "std: 0.010966498478492777\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066454990711825\n",
      "std: 0.011110488678727012\n",
      "min: 1.289977950964734\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02173913043478261\n",
      "std: 0.02728871270830922\n",
      "min: 0.009945388023415564\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3205804464632445\n",
      "std: 0.2940623216559881\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238719\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48819400342937086\n",
      "std: 0.3613405477437434\n",
      "min: -0.38954828823915266\n",
      "max: 0.9443537500238719\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06258419091833559\n",
      "min: 0.08217236485510235\n",
      "max: 0.29970947002139087\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2017239097265604\n",
      "std: 0.1262538883733394\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2034081939558008\n",
      "std: 0.12825140020712703\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.027901586381329085\n",
      "min: 0.0031024090435135517\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33967289591457467\n",
      "std: 0.3641891968303198\n",
      "min: -1.0775097237334763\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.36111414453396007\n",
      "std: 0.34626776046863866\n",
      "min: -0.6747768124706292\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05697225064957089\n",
      "min: 0.07034332619054123\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077927152231582\n",
      "std: 0.003955554271490013\n",
      "min: 1.3712008384186136\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077884722322525\n",
      "std: 0.004011816654980385\n",
      "min: 1.3712008384186136\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.027032186664795163\n",
      "min: 0.010608181876187929\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3186932647540334\n",
      "std: 0.2943461240279184\n",
      "min: -0.7978768618452212\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48926890419424346\n",
      "std: 0.360953534930921\n",
      "min: -0.38879254994289497\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256344164978184\n",
      "min: 0.08194887001764484\n",
      "max: 0.29983291706457527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1997992317837898\n",
      "std: 0.13746104567361153\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2015287295848622\n",
      "std: 0.14004911325514413\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.02821787499037879\n",
      "min: 0.0033692519883650423\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3400836344327661\n",
      "std: 0.3659471754204058\n",
      "min: -1.0775186071203195\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3606455670469308\n",
      "std: 0.3471880128300612\n",
      "min: -0.6753792719766031\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057080048768445864\n",
      "min: 0.07033503095787877\n",
      "max: 0.32943950013225615\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074974637210547\n",
      "std: 0.005613364581779064\n",
      "min: 1.346276914090381\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407497443742377\n",
      "std: 0.005689350969664893\n",
      "min: 1.346276914090381\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02150537634408602\n",
      "std: 0.027033577336519538\n",
      "min: 0.01029318391312836\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3180370523004832\n",
      "std: 0.2941675355064596\n",
      "min: -0.7971594015816316\n",
      "max: 0.9800013732642878\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4892245996526153\n",
      "std: 0.36077707498576167\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642878\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0625340826657287\n",
      "min: 0.08196441032013609\n",
      "max: 0.299808660983855\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2011862149462915\n",
      "std: 0.13421629390642906\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2029283594115243\n",
      "std: 0.13538114698495546\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02150537634408602\n",
      "std: 0.027827123550747\n",
      "min: 0.003583987726740878\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34068753848141575\n",
      "std: 0.36498000284720494\n",
      "min: -1.0777584281638515\n",
      "max: 1.058495256595823\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3603793407989117\n",
      "std: 0.3471263838147447\n",
      "min: -0.6757159370215143\n",
      "max: 1.058495256595823\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057066344344180425\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078878669304422\n",
      "std: 0.003552386777787419\n",
      "min: 1.3706621748903753\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078790033738564\n",
      "std: 0.003713198918105666\n",
      "min: 1.3706621748903753\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02150537634408602\n",
      "std: 0.027031934698612557\n",
      "min: 0.010544628445521934\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3188413025599715\n",
      "std: 0.2943164595183767\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48889543260617097\n",
      "std: 0.360908974604695\n",
      "min: -0.38908950337323966\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06255650356349081\n",
      "min: 0.08195439946638076\n",
      "max: 0.2998332572562752\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.217050374272406\n",
      "std: 0.06990326747364302\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.218706105915385\n",
      "std: 0.07312553473641943\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.02733727258442166\n",
      "min: 0.007249589589230065\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3450271470402355\n",
      "std: 0.36261837158513455\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.35650179527909404\n",
      "std: 0.34692746788332857\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05720337527528683\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082348011378647\n",
      "std: 0.002772841318536282\n",
      "min: 1.37804104011155\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082167720480931\n",
      "std: 0.0029665797546898328\n",
      "min: 1.37804104011155\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02150537634408602\n",
      "std: 0.027031741297143554\n",
      "min: 0.01065849854226213\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31972180675842893\n",
      "std: 0.2941175741077765\n",
      "min: -0.7976242858584903\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4876769864666888\n",
      "std: 0.36089702618701325\n",
      "min: -0.3896776675411586\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256239405604469\n",
      "min: 0.08197773171163376\n",
      "max: 0.2998164845483698\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1943860063345537\n",
      "std: 0.1710928922700785\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1960942429782997\n",
      "std: 0.17345054380849\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.028477992762434123\n",
      "min: 0.002187964823642008\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3455384304041832\n",
      "std: 0.3634611547677447\n",
      "min: -1.0774167572242215\n",
      "max: 1.0542347607461076\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3563985580105448\n",
      "std: 0.3474194154158909\n",
      "min: -0.6760788147460834\n",
      "max: 1.0542347607461076\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057224010751277754\n",
      "min: 0.0703528245640232\n",
      "max: 0.32938505765206116\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406639162164597\n",
      "std: 0.010929825635175203\n",
      "min: 1.2868910295901326\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066246252732877\n",
      "std: 0.011076018737842955\n",
      "min: 1.2868910295901326\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.027039705843636297\n",
      "min: 0.009705574157829265\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32069970095927275\n",
      "std: 0.2940761569016499\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238719\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4881318494281496\n",
      "std: 0.36138221944462434\n",
      "min: -0.38954828823915266\n",
      "max: 0.9443537500238719\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259302659436158\n",
      "min: 0.08195038030201648\n",
      "max: 0.29981300686606593\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2021895740611097\n",
      "std: 0.1257920411196776\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2038867290616129\n",
      "std: 0.1277779914580092\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.02764700702406542\n",
      "min: 0.0031024090435135534\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34006777077817085\n",
      "std: 0.364294787935122\n",
      "min: -1.0775097237334763\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3609975760805108\n",
      "std: 0.3462828184572842\n",
      "min: -0.6747768124706292\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05700093414903338\n",
      "min: 0.07034332619054123\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078013937234646\n",
      "std: 0.00394309056325899\n",
      "min: 1.3712008384186136\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077916540033373\n",
      "std: 0.004002735392289701\n",
      "min: 1.3712008384186136\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.02678804136602129\n",
      "min: 0.010524966672218444\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3187700765991026\n",
      "std: 0.2944254626083883\n",
      "min: -0.7978768618452212\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4892303072591473\n",
      "std: 0.36096854695163394\n",
      "min: -0.38879254994289497\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256460374394826\n",
      "min: 0.08194887001764481\n",
      "max: 0.29983291706457527\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2002871130272221\n",
      "std: 0.13692202265516243\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.202028724190952\n",
      "std: 0.1394972647718463\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.027959446387225348\n",
      "min: 0.0033692519883650423\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34047835735963483\n",
      "std: 0.366034112238678\n",
      "min: -1.0775186071203195\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3605317303456488\n",
      "std: 0.3471952410230753\n",
      "min: -0.6753792719766031\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05710790924739936\n",
      "min: 0.07033503095787877\n",
      "max: 0.32943950013225615\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075093214311103\n",
      "std: 0.005589825929228931\n",
      "min: 1.3462769140903812\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075037579502008\n",
      "std: 0.0056680884518722045\n",
      "min: 1.3462769140903812\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.026789415216816687\n",
      "min: 0.010293183913128362\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31811838399916315\n",
      "std: 0.29424746477236857\n",
      "min: -0.7971594015816316\n",
      "max: 0.9800013732642878\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48918554671124187\n",
      "std: 0.3607928101958661\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642878\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06253541933847676\n",
      "min: 0.08196441032013606\n",
      "max: 0.299808660983855\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2016667280966986\n",
      "std: 0.13356965061789666\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2034210472953066\n",
      "std: 0.1347309296795116\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021276595744680847\n",
      "std: 0.027573447760939365\n",
      "min: 0.003583987726740877\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34107329423329474\n",
      "std: 0.3650795402112573\n",
      "min: -1.0777584281638515\n",
      "max: 1.058495256595823\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3602697164535738\n",
      "std: 0.3471341211571255\n",
      "min: -0.6757159370215143\n",
      "max: 1.058495256595823\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0570942283041942\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407895626534326\n",
      "std: 0.0035416252956237924\n",
      "min: 1.3706621748903753\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078813448821508\n",
      "std: 0.0037053909310904875\n",
      "min: 1.3706621748903753\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.026787792441248678\n",
      "min: 0.010524074559868691\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31891582563832005\n",
      "std: 0.294396217988472\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.488859500809781\n",
      "std: 0.36092363201915095\n",
      "min: -0.38908950337323966\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06255761640934059\n",
      "min: 0.0819543994663808\n",
      "max: 0.2998332572562752\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2173683816860006\n",
      "std: 0.06970428247639002\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2190391693394955\n",
      "std: 0.07289638189941412\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.02708949159835908\n",
      "min: 0.00724958958923007\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3453701499116531\n",
      "std: 0.3627312011297077\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3564260166430812\n",
      "std: 0.3469346256234509\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0572296154501294\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082388618932944\n",
      "std: 0.002769724748534429\n",
      "min: 1.3780410401115495\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408215500146385\n",
      "std: 0.0029669166880781105\n",
      "min: 1.3780410401115495\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021276595744680854\n",
      "std: 0.02678760133753501\n",
      "min: 0.010522092009166654\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3197877159163651\n",
      "std: 0.2941983864624768\n",
      "min: -0.7976242858584903\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48765214742980084\n",
      "std: 0.3609114292332625\n",
      "min: -0.3896776675411586\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256339921556625\n",
      "min: 0.08197773171163376\n",
      "max: 0.2998164845483698\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1949252994918438\n",
      "std: 0.17042803686654737\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1966452383517714\n",
      "std: 0.17277832344323948\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021276595744680847\n",
      "std: 0.028216445128971607\n",
      "min: 0.002181503785771067\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3458835497096106\n",
      "std: 0.3635687270490585\n",
      "min: -1.0774167572242215\n",
      "max: 1.0542347607461076\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3563246116180846\n",
      "std: 0.34742498453498705\n",
      "min: -0.6760788147460834\n",
      "max: 1.0542347607461076\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05725065819665182\n",
      "min: 0.0703528245640232\n",
      "max: 0.32938505765206116\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066598963454386\n",
      "std: 0.010878836269529865\n",
      "min: 1.2868910295901321\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40663987822813\n",
      "std: 0.011025752872979754\n",
      "min: 1.2868910295901321\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.026795470038596576\n",
      "min: 0.00970557415782926\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32075718614169046\n",
      "std: 0.2941565122318966\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238719\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4881028468286561\n",
      "std: 0.36139215576217026\n",
      "min: -0.38954828823915266\n",
      "max: 0.9443537500238719\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259376829442158\n",
      "min: 0.08195038030201647\n",
      "max: 0.299813006866066\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.202849914166861\n",
      "std: 0.1252882495526344\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2046711006600632\n",
      "std: 0.12728448187758382\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.02739727450340936\n",
      "min: 0.0031024090435135534\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3403060917097966\n",
      "std: 0.36426372002021334\n",
      "min: -1.0775097237334763\n",
      "max: 1.058627484273601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3608395547045828\n",
      "std: 0.34638115833289357\n",
      "min: -0.6747768124706292\n",
      "max: 1.058627484273601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057012164910082666\n",
      "min: 0.07034332619054123\n",
      "max: 0.3293981807536413\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078142669990057\n",
      "std: 0.003925555347974457\n",
      "min: 1.3712008384186136\n",
      "max: 1.41398057698029\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078109672524626\n",
      "std: 0.003982028735252651\n",
      "min: 1.3712008384186136\n",
      "max: 1.41398057698029\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.026548526558477187\n",
      "min: 0.010405527663287987\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31875787279825096\n",
      "std: 0.2944213367288425\n",
      "min: -0.7978768618452212\n",
      "max: 0.9471099884856122\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48915883341895905\n",
      "std: 0.36094951126834146\n",
      "min: -0.38879254994289497\n",
      "max: 0.9471099884856122\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256313325275\n",
      "min: 0.08194887001764484\n",
      "max: 0.2998329170645753\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.200970011530044\n",
      "std: 0.13628876540741247\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2028349426168683\n",
      "std: 0.1388739238014173\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02105263157894737\n",
      "std: 0.027705943460914977\n",
      "min: 0.0033692519883650423\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34071614219815666\n",
      "std: 0.3659848569289077\n",
      "min: -1.0775186071203195\n",
      "max: 1.0577993898987512\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3603764814187232\n",
      "std: 0.3472851384606419\n",
      "min: -0.6753792719766031\n",
      "max: 1.0577993898987512\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05711831246660807\n",
      "min: 0.07033503095787877\n",
      "max: 0.32943950013225615\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075254664380412\n",
      "std: 0.005560204922164584\n",
      "min: 1.346276914090381\n",
      "max: 1.4139812651754067\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075262916686944\n",
      "std: 0.005636366713217486\n",
      "min: 1.346276914090381\n",
      "max: 1.4139812651754067\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02105263157894737\n",
      "std: 0.0265498839034873\n",
      "min: 0.0102501672211414\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31811058175543466\n",
      "std: 0.29424387403750285\n",
      "min: -0.7971594015816316\n",
      "max: 0.9800013732642878\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48911369517633957\n",
      "std: 0.3607745722285972\n",
      "min: -0.38830837081853037\n",
      "max: 0.9800013732642878\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06253412574050156\n",
      "min: 0.08196441032013607\n",
      "max: 0.299808660983855\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.202335071772173\n",
      "std: 0.13297838079240343\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2042128428072323\n",
      "std: 0.13415550794401668\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.027324615849575754\n",
      "min: 0.003583987726740877\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3413035910726691\n",
      "std: 0.36504210881833377\n",
      "min: -1.0777584281638515\n",
      "max: 1.058495256595823\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3601174081949732\n",
      "std: 0.3472251196720949\n",
      "min: -0.6757159370215143\n",
      "max: 1.058495256595823\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.05710471241944265\n",
      "min: 0.07033286141518684\n",
      "max: 0.32945346721903035\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407907534902825\n",
      "std: 0.0035255528672722054\n",
      "min: 1.3706621748903753\n",
      "max: 1.4139800835404734\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078997776494468\n",
      "std: 0.0036852281512247736\n",
      "min: 1.3706621748903753\n",
      "max: 1.4139800835404734\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947364\n",
      "std: 0.026548280613251048\n",
      "min: 0.010433131054295294\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31890151565184777\n",
      "std: 0.2943925031356649\n",
      "min: -0.797840950208833\n",
      "max: 0.946593770219205\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4887904775207586\n",
      "std: 0.3609043005294501\n",
      "min: -0.38908950337323966\n",
      "max: 0.946593770219205\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06255611038369335\n",
      "min: 0.0819543994663808\n",
      "max: 0.29983325725627513\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2178721935532837\n",
      "std: 0.06947804439334711\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2196698798826862\n",
      "std: 0.07266114722159575\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.026846412085085654\n",
      "min: 0.00724958958923007\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3455592670265103\n",
      "std: 0.36270964989722626\n",
      "min: -1.0767882755901543\n",
      "max: 1.046981690607396\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3563073968172685\n",
      "std: 0.3470253900501091\n",
      "min: -0.675531386551957\n",
      "max: 1.046981690607396\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.0572386442254642\n",
      "min: 0.0704358496374959\n",
      "max: 0.3292999551626175\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408246934538712\n",
      "std: 0.002760155602323966\n",
      "min: 1.3780410401115502\n",
      "max: 1.4139807655137455\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082301757251658\n",
      "std: 0.0029517051167017813\n",
      "min: 1.3780410401115502\n",
      "max: 1.4139807655137455\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.026548091767732877\n",
      "min: 0.010465679996833194\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3197651087050641\n",
      "std: 0.2941960927384646\n",
      "min: -0.7976242858584903\n",
      "max: 0.9425121760623357\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48759402821069725\n",
      "std: 0.36089180027867424\n",
      "min: -0.3896776675411586\n",
      "max: 0.9425121760623357\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06256178965642563\n",
      "min: 0.08197773171163378\n",
      "max: 0.29981648454836984\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1956529014307336\n",
      "std: 0.16966920169385843\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1974958304374124\n",
      "std: 0.17203288024164112\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947364\n",
      "std: 0.027959901891787653\n",
      "min: 0.0021815037857710667\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34607379594428234\n",
      "std: 0.3635394987675066\n",
      "min: -1.0774167572242215\n",
      "max: 1.0542347607461076\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.3562081802317936\n",
      "std: 0.34751227635097587\n",
      "min: -0.6760788147460834\n",
      "max: 1.0542347607461076\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.057259959715606774\n",
      "min: 0.0703528245640232\n",
      "max: 0.32938505765206116\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066838421633607\n",
      "std: 0.010826361524900971\n",
      "min: 1.2868910295901324\n",
      "max: 1.4139848306068206\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406670255214514\n",
      "std: 0.010972304292294087\n",
      "min: 1.2868910295901324\n",
      "max: 1.4139848306068206\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.02655586676907921\n",
      "min: 0.00965558706004401\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32072618851583046\n",
      "std: 0.2941536805445027\n",
      "min: -0.7974335654434677\n",
      "max: 0.9443537500238719\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4880408820357242\n",
      "std: 0.3613680982391775\n",
      "min: -0.38954828823915266\n",
      "max: 0.9443537500238719\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.06259190661665694\n",
      "min: 0.08195038030201647\n",
      "max: 0.299813006866066\n",
      "Test translation: il fait froid -> principal\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8870100157088149\n",
      "std: 0.3544227500738071\n",
      "min: -0.7506604629054356\n",
      "max: 1.413273325417982\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.8870100157088149\n",
      "std: 0.3544227500738071\n",
      "min: -0.7506604629054356\n",
      "max: 1.413273325417982\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.010526315789473682\n",
      "std: 0.002067154151643966\n",
      "min: 0.0018978000632500064\n",
      "max: 0.055013561116569985\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1559069748222803\n",
      "std: 0.46250046554994595\n",
      "min: -1.035003333502247\n",
      "max: 1.4139143566492707\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1559069748222803\n",
      "std: 0.46250046554994595\n",
      "min: -1.035003333502247\n",
      "max: 1.4139143566492707\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.010526315789473684\n",
      "std: 0.0024845495661750643\n",
      "min: 0.0010321050913558553\n",
      "max: 0.0764056462750567\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4113182340624673\n",
      "std: 0.0007336068564112406\n",
      "min: 1.4102557543740661\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4113182340624673\n",
      "std: 0.0007336068564112406\n",
      "min: 1.4102557543740661\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 1.0\n",
      "std: 0.0\n",
      "min: 1.0\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3167013567602568\n",
      "std: 0.32012624539516593\n",
      "min: -0.848807643738612\n",
      "max: 0.790598284608898\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5260279384434268\n",
      "std: 0.13495807052963443\n",
      "min: 0.2951615467181723\n",
      "max: 0.790598284608898\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.022323711808815982\n",
      "min: 0.20478580134988097\n",
      "max: 0.28416586652701487\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4137559858247082\n",
      "std: 0.00014198568868230516\n",
      "min: 1.413622624312541\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4137559858247082\n",
      "std: 0.00014198568868230516\n",
      "min: 1.413622624312541\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 1.0\n",
      "std: 0.0\n",
      "min: 1.0\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3144353481479013\n",
      "std: 0.2822375101163788\n",
      "min: -0.7495986709814553\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6612189514780034\n",
      "std: 0.10051683257463356\n",
      "min: 0.4512684392976412\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019190443387708585\n",
      "min: 0.20941466405035933\n",
      "max: 0.2765212664108828\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1963623061909985\n",
      "std: 0.22168255608041917\n",
      "min: 0.8476747683893139\n",
      "max: 1.4123025686197597\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2650026332042277\n",
      "std: 0.2093357704790612\n",
      "min: 0.9124721050936906\n",
      "max: 1.4123025686197597\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.2518618548026998\n",
      "min: 0.37769058979187176\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.324866200111124\n",
      "std: 0.34399131149921275\n",
      "min: -0.9168601834501579\n",
      "max: 0.790598284608898\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.526901835262204\n",
      "std: 0.123414653414368\n",
      "min: 0.29516154671817224\n",
      "max: 0.790598284608898\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.02013800184857577\n",
      "min: 0.204785801349881\n",
      "max: 0.2841658665270149\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4089953493709377\n",
      "std: 0.005652339898791366\n",
      "min: 1.39577158415802\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4102772295330752\n",
      "std: 0.005573554159126861\n",
      "min: 1.39577158415802\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.23571349666439265\n",
      "min: 0.49557304482380904\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3239181189489783\n",
      "std: 0.28683119786243055\n",
      "min: -0.7828910629665342\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6493016669564677\n",
      "std: 0.0969602714913278\n",
      "min: 0.4253942514857918\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019011292364019584\n",
      "min: 0.20941466405035936\n",
      "max: 0.2769695720700582\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9311392748460531\n",
      "std: 0.5200042157371114\n",
      "min: 0.06308843307539107\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.092094570120888\n",
      "std: 0.47992343647084595\n",
      "min: 0.0945946245166937\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.29976242841654843\n",
      "min: 0.2109675039341757\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.13778055403287343\n",
      "std: 0.3393747003539346\n",
      "min: -0.848807643738612\n",
      "max: 0.9599022535921014\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5516296456694681\n",
      "std: 0.17761688886698296\n",
      "min: 0.28094240958898664\n",
      "max: 0.9599022535921014\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.022470801886869934\n",
      "min: 0.204785801349881\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4009912677124423\n",
      "std: 0.013204436768408925\n",
      "min: 1.3810324042407565\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4048858556751291\n",
      "std: 0.012868702012389481\n",
      "min: 1.3810324042407565\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.23576673899538805\n",
      "min: 0.49186100090293583\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2951729794023745\n",
      "std: 0.28923065026327577\n",
      "min: -0.7495986709814553\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.67151890660905\n",
      "std: 0.09900652553575524\n",
      "min: 0.4512684392976412\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018499723570439004\n",
      "min: 0.20665074214840007\n",
      "max: 0.2765212664108828\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8806036235418093\n",
      "std: 0.5638278344719377\n",
      "min: -0.07777795867923404\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0577907928586716\n",
      "std: 0.5233245226550282\n",
      "min: -0.057988019018108516\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.3092163277732682\n",
      "min: 0.18673836015167006\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.23629727857092298\n",
      "std: 0.3007801946040131\n",
      "min: -0.848807643738612\n",
      "max: 0.790598284608898\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4550059567949847\n",
      "std: 0.17807953674164917\n",
      "min: 0.0952796377382266\n",
      "max: 0.790598284608898\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01997573370494964\n",
      "min: 0.204785801349881\n",
      "max: 0.2841658665270149\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3900620135094885\n",
      "std: 0.024203334562296126\n",
      "min: 1.3585877302405789\n",
      "max: 1.4139976643506524\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3979333173723703\n",
      "std: 0.02276404945562089\n",
      "min: 1.3598201713442386\n",
      "max: 1.4139976643506524\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.2359056570698679\n",
      "min: 0.48653383719267657\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31827724328815077\n",
      "std: 0.2906552177967662\n",
      "min: -0.7555124301791605\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6667133867804682\n",
      "std: 0.11299555135960908\n",
      "min: 0.4103171507964889\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01945792337996015\n",
      "min: 0.20941466405035936\n",
      "max: 0.27812874928404513\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9483295474094224\n",
      "std: 0.5109892073587207\n",
      "min: -0.02905747130271812\n",
      "max: 1.4137919023565602\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.102249871529562\n",
      "std: 0.4708734966189789\n",
      "min: -0.011290172094139345\n",
      "max: 1.4137919023565602\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.29673510939503395\n",
      "min: 0.19386611073883797\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.1937233596253531\n",
      "std: 0.29439735300336944\n",
      "min: -0.848807643738612\n",
      "max: 0.790598284608898\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4188525459781014\n",
      "std: 0.2146700089454464\n",
      "min: -0.044100218148607824\n",
      "max: 0.790598284608898\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.02024642150104455\n",
      "min: 0.204785801349881\n",
      "max: 0.28631071809454506\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4007178438139776\n",
      "std: 0.01405704067763445\n",
      "min: 1.3743032695719681\n",
      "max: 1.413985614881546\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4049017476481336\n",
      "std: 0.013431656438935758\n",
      "min: 1.3743032695719681\n",
      "max: 1.413985614881546\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.23577066070887806\n",
      "min: 0.4901682028765398\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3052152552246024\n",
      "std: 0.2835857416767019\n",
      "min: -0.7495986709814553\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.657189263476227\n",
      "std: 0.09213034241413146\n",
      "min: 0.4512684392976412\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.017689958892336464\n",
      "min: 0.20941466405035936\n",
      "max: 0.2765212664108828\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7506384432892446\n",
      "std: 0.66634164900538\n",
      "min: -0.09647691344892374\n",
      "max: 1.41412238185193\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9718514371427064\n",
      "std: 0.6265292132993461\n",
      "min: -0.09647691344892374\n",
      "max: 1.41412238185193\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.33393944927010755\n",
      "min: 0.18090931757814332\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.048954221525790674\n",
      "std: 0.3549374281263697\n",
      "min: -0.848807643738612\n",
      "max: 0.790598284608898\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.39008651173312325\n",
      "std: 0.20313085169465825\n",
      "min: -0.018586286534345905\n",
      "max: 0.790598284608898\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019244690953287652\n",
      "min: 0.204785801349881\n",
      "max: 0.2841658665270149\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3890037860395221\n",
      "std: 0.026622787255971295\n",
      "min: 1.350256527309577\n",
      "max: 1.4140366522400856\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3975137999818676\n",
      "std: 0.02438522088678136\n",
      "min: 1.3504446828290437\n",
      "max: 1.4140366522400856\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.6666666666666666\n",
      "std: 0.2359303329176569\n",
      "min: 0.4841073630236118\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2884659347083009\n",
      "std: 0.2815502599706249\n",
      "min: -0.7495986709814553\n",
      "max: 0.7919368816673965\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.64938242355614\n",
      "std: 0.10122826136152643\n",
      "min: 0.40024946760608077\n",
      "max: 0.7919368816673965\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018748595659495413\n",
      "min: 0.20456895864837715\n",
      "max: 0.2765212664108828\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1748716814975388\n",
      "std: 0.21585164020611053\n",
      "min: 0.805551952401327\n",
      "max: 1.4123025686197597\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2284351063099628\n",
      "std: 0.21669056828450103\n",
      "min: 0.8544662153487507\n",
      "max: 1.4123025686197597\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.24861177813466626\n",
      "min: 0.23443909030689963\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3450691667546365\n",
      "std: 0.35912157106734327\n",
      "min: -0.9688731920322019\n",
      "max: 0.790598284608898\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.52118306941115\n",
      "std: 0.12379212383992402\n",
      "min: 0.2947844500032407\n",
      "max: 0.790598284608898\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019449832861101288\n",
      "min: 0.204785801349881\n",
      "max: 0.2841658665270149\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407609909736922\n",
      "std: 0.00553278817606117\n",
      "min: 1.3952156321632014\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4087146284787855\n",
      "std: 0.0059763392570745845\n",
      "min: 1.3952156321632014\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.23571165521890974\n",
      "min: 0.3303373984733517\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33080605685909503\n",
      "std: 0.2905616467304273\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6432074850531082\n",
      "std: 0.09560523980522685\n",
      "min: 0.4235752283506134\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019049971918149233\n",
      "min: 0.20941466405035936\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8749350193827582\n",
      "std: 0.4497770940866647\n",
      "min: 0.06308843307539107\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0047956294937386\n",
      "std: 0.45550345480441856\n",
      "min: 0.0945946245166937\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.2850626518997712\n",
      "min: 0.17007493119185874\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.21688283696120306\n",
      "std: 0.38203594966890597\n",
      "min: -0.9886005288969593\n",
      "max: 0.9599022535921014\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5514741194340108\n",
      "std: 0.16161147099368914\n",
      "min: 0.28094240958898664\n",
      "max: 0.9599022535921014\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.02105368806219121\n",
      "min: 0.204785801349881\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3981653395845735\n",
      "std: 0.014588709913784503\n",
      "min: 1.3692798414406067\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4016188504222498\n",
      "std: 0.014538359594252506\n",
      "min: 1.3692798414406067\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.23575999364704472\n",
      "min: 0.32469865481285176\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3084013411843742\n",
      "std: 0.2933786857651206\n",
      "min: -0.7982799952322005\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6616224842546976\n",
      "std: 0.09807613173788451\n",
      "min: 0.4306916548061463\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018739122579366583\n",
      "min: 0.20665074214840007\n",
      "max: 0.2777292467892489\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9308050071691591\n",
      "std: 0.41965173401719086\n",
      "min: 0.1593609256324407\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0491273856700547\n",
      "std: 0.4186511356163475\n",
      "min: 0.1593609256324407\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.26706613930160994\n",
      "min: 0.1702328061857205\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.24508974414465012\n",
      "std: 0.34028940472340424\n",
      "min: -0.9168601834501579\n",
      "max: 0.8067518578042032\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5443496285414507\n",
      "std: 0.12945586340506526\n",
      "min: 0.29516154671817224\n",
      "max: 0.8067518578042032\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018741990573555176\n",
      "min: 0.204785801349881\n",
      "max: 0.2841658665270149\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.402822794081168\n",
      "std: 0.009269948611802605\n",
      "min: 1.386701371856955\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4049992698461302\n",
      "std: 0.009896118896448968\n",
      "min: 1.386701371856955\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.2357201313554568\n",
      "min: 0.3296743731636865\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31685793366531945\n",
      "std: 0.29057621127807476\n",
      "min: -0.7828910629665342\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6545085907538466\n",
      "std: 0.09489197674407145\n",
      "min: 0.4253942514857918\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018670667329497365\n",
      "min: 0.2078622763800807\n",
      "max: 0.2769695720700582\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8109572123003389\n",
      "std: 0.5252062043159589\n",
      "min: -0.2941077066191615\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9558382248241438\n",
      "std: 0.5260365563866248\n",
      "min: -0.2941077066191615\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.2939262426839983\n",
      "min: 0.10266640668548715\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.29333211524235425\n",
      "std: 0.3483838251302698\n",
      "min: -0.9888031364348414\n",
      "max: 0.790598284608898\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4817677630910633\n",
      "std: 0.1650798536131047\n",
      "min: 0.0952796377382266\n",
      "max: 0.790598284608898\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019489991997943285\n",
      "min: 0.204785801349881\n",
      "max: 0.2841658665270149\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3881157438800455\n",
      "std: 0.02549171809735779\n",
      "min: 1.331511798138747\n",
      "max: 1.4139976643506524\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3941091667538414\n",
      "std: 0.024961896386525705\n",
      "min: 1.331511798138747\n",
      "max: 1.4139976643506524\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.23588034508329406\n",
      "min: 0.3172445529396456\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3299971014774049\n",
      "std: 0.29360353089054486\n",
      "min: -0.8007488762610249\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6557492239271744\n",
      "std: 0.1096581915581393\n",
      "min: 0.40832565147486616\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019538904262985695\n",
      "min: 0.20941466405035936\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.7744623754352606\n",
      "std: 0.5495160597829207\n",
      "min: 0.023304721427690203\n",
      "max: 1.4131125437064043\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9319499297900787\n",
      "std: 0.549781204669337\n",
      "min: 0.023304721427690203\n",
      "max: 1.4131125437064043\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.28533765727765087\n",
      "min: 0.16508929563220068\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2944366935189806\n",
      "std: 0.32661003227429036\n",
      "min: -0.9168601834501579\n",
      "max: 0.790598284608898\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4782389031125765\n",
      "std: 0.15281427519862292\n",
      "min: 0.1576267745335413\n",
      "max: 0.790598284608898\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019066476242447263\n",
      "min: 0.204785801349881\n",
      "max: 0.2841658665270149\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3925956304389655\n",
      "std: 0.02148355175563298\n",
      "min: 1.3531953400323873\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3975525756834788\n",
      "std: 0.0209897784985073\n",
      "min: 1.3546755342765546\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.5\n",
      "std: 0.2357637579180155\n",
      "min: 0.32445198551804905\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32918307447617023\n",
      "std: 0.2930360623019472\n",
      "min: -0.7828910629665342\n",
      "max: 0.8094433785098477\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6523530365242084\n",
      "std: 0.10386266320679546\n",
      "min: 0.386882602990662\n",
      "max: 0.8094433785098477\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01920899074876493\n",
      "min: 0.20941466405035936\n",
      "max: 0.27853861580476513\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1708351085391293\n",
      "std: 0.1869859006572501\n",
      "min: 0.8055519524013274\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2127137458214494\n",
      "std: 0.19737938074259095\n",
      "min: 0.8544662153487502\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.22961736700686555\n",
      "min: 0.1853587758408729\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3603086340864447\n",
      "std: 0.36755422567228735\n",
      "min: -1.0388133449438242\n",
      "max: 0.8080487155260071\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5269934189875578\n",
      "std: 0.12777556864471779\n",
      "min: 0.29478445000324055\n",
      "max: 0.8080487155260071\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019893529300940387\n",
      "min: 0.204785801349881\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077952615747258\n",
      "std: 0.00475485864697284\n",
      "min: 1.3952156321632012\n",
      "max: 1.413977017938873\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408672228075005\n",
      "std: 0.0052876010096246946\n",
      "min: 1.3952156321632012\n",
      "max: 1.413977017938873\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.21985535590165037\n",
      "min: 0.24822687837295992\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3327148975767237\n",
      "std: 0.2921464811271137\n",
      "min: -0.8024797058014199\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6429029741350731\n",
      "std: 0.09536692984365493\n",
      "min: 0.41909625603315853\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019159057628073826\n",
      "min: 0.20941466405035936\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8891511669698786\n",
      "std: 0.44689857501812136\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9878465316708818\n",
      "std: 0.45428587844210516\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.2589986821600784\n",
      "min: 0.08616557489792928\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2624518652593087\n",
      "std: 0.3944533614957748\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5562198000620804\n",
      "std: 0.15567428617218937\n",
      "min: 0.2809424095889865\n",
      "max: 0.9599022535921016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.021121291990823368\n",
      "min: 0.2031681543061914\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3992050847700594\n",
      "std: 0.014096578028101086\n",
      "min: 1.3692798414406069\n",
      "max: 1.413977017938873\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40181282506173\n",
      "std: 0.013979700813617527\n",
      "min: 1.3692798414406069\n",
      "max: 1.413977017938873\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.2198948932664367\n",
      "min: 0.24338270254962846\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3142280245910241\n",
      "std: 0.2946055924927718\n",
      "min: -0.7982799952322004\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6585838736548972\n",
      "std: 0.0974237911032086\n",
      "min: 0.43054142846717464\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01893328661768967\n",
      "min: 0.2066507421484001\n",
      "max: 0.2777292467892489\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9316990458457172\n",
      "std: 0.4011981105887229\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0231731356213796\n",
      "std: 0.40751534668343553\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.24611845255094672\n",
      "min: 0.09769427941573716\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2808515786151308\n",
      "std: 0.3614227594958833\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5517648369017847\n",
      "std: 0.13160493345606591\n",
      "min: 0.29516154671817224\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019407954570359064\n",
      "min: 0.20350907135133764\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4031298859022499\n",
      "std: 0.008700041821199723\n",
      "min: 1.3867013718569547\n",
      "max: 1.413977017938873\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4049015646200051\n",
      "std: 0.009081221133358673\n",
      "min: 1.3867013718569547\n",
      "max: 1.413977017938873\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.21986314198057222\n",
      "min: 0.2466501646992438\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32045264172983073\n",
      "std: 0.29268977378299454\n",
      "min: -0.7949179104719662\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6539321355697434\n",
      "std: 0.09482090800348755\n",
      "min: 0.425394251485792\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01888148359341979\n",
      "min: 0.2078622763800807\n",
      "max: 0.2769695720700581\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.8443061490327828\n",
      "std: 0.5061438207953619\n",
      "min: -0.2941077066191617\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9511161467790437\n",
      "std: 0.5095685451728392\n",
      "min: -0.2941077066191617\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.2653662493820915\n",
      "min: 0.07293152928685523\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3244942863913245\n",
      "std: 0.36452182251888665\n",
      "min: -1.0458017076285246\n",
      "max: 0.8202929878414408\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5017849947657624\n",
      "std: 0.16126544376451588\n",
      "min: 0.0952796377382267\n",
      "max: 0.8202929878414408\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.020138509013933104\n",
      "min: 0.20340155096524204\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3904752465636598\n",
      "std: 0.025109911317539535\n",
      "min: 1.331511798138747\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3947497915841751\n",
      "std: 0.024587822115383743\n",
      "min: 1.331511798138747\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.2199941052079678\n",
      "min: 0.23665697752754114\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3336619939684268\n",
      "std: 0.2943931163822165\n",
      "min: -0.8007488762610249\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6530196700582074\n",
      "std: 0.1072136769505878\n",
      "min: 0.4083256514748659\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019621557480640688\n",
      "min: 0.20941466405035936\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9370663802514149\n",
      "std: 0.4076149624836101\n",
      "min: 0.1265687730872469\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.027778659738246\n",
      "std: 0.4117992096336931\n",
      "min: 0.14847232270936514\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.39999999999999997\n",
      "std: 0.2411076334826278\n",
      "min: 0.14764759365348262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2867543183936296\n",
      "std: 0.3602312150498112\n",
      "min: -0.9688731920322019\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.547747108454236\n",
      "std: 0.12814756246294395\n",
      "min: 0.29478445000324055\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.020233476323790772\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4042387146414588\n",
      "std: 0.0072528978416391806\n",
      "min: 1.3895975688112978\n",
      "max: 1.413977017938873\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4057966278067244\n",
      "std: 0.007693921750186683\n",
      "min: 1.3895975688112978\n",
      "max: 1.413977017938873\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.4\n",
      "std: 0.21985773327884678\n",
      "min: 0.24772234842294272\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3240023083716722\n",
      "std: 0.2922701233066471\n",
      "min: -0.8024797058014199\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6512772598197376\n",
      "std: 0.09606507220824496\n",
      "min: 0.4235752283506136\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018960636173454115\n",
      "min: 0.2071750899445349\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1822303510492187\n",
      "std: 0.170414813819749\n",
      "min: 0.8055519524013274\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2159428865332884\n",
      "std: 0.18092053697155946\n",
      "min: 0.8544662153487502\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333333\n",
      "std: 0.2104321660495947\n",
      "min: 0.14732430296998564\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35844617083321756\n",
      "std: 0.3664260929494285\n",
      "min: -1.0388133449438242\n",
      "max: 0.8080487155260071\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5099062788778721\n",
      "std: 0.13231255748653142\n",
      "min: 0.23333713872627473\n",
      "max: 0.8080487155260071\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019627104469258392\n",
      "min: 0.204785801349881\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081615087781143\n",
      "std: 0.0043410856968625\n",
      "min: 1.3952156321632014\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4088948138916848\n",
      "std: 0.004848198073584075\n",
      "min: 1.3952156321632014\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.33333333333333337\n",
      "std: 0.20276418128976964\n",
      "min: 0.19848988751020824\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3334751158188958\n",
      "std: 0.2921533053817284\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6391641326059773\n",
      "std: 0.09532755073648227\n",
      "min: 0.4079269375394852\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01913565162829127\n",
      "min: 0.20941466405035936\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.938532950715296\n",
      "std: 0.41779785903733235\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.012797618697749\n",
      "std: 0.42375298488144797\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333334\n",
      "std: 0.23391045961741766\n",
      "min: 0.0828389111440554\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2791133948107173\n",
      "std: 0.3915403381409078\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5363980657022092\n",
      "std: 0.1555677406015409\n",
      "min: 0.2532827857718811\n",
      "max: 0.9599022535921016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.02063360039628576\n",
      "min: 0.2031681543061914\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4007552176680398\n",
      "std: 0.013150074628001471\n",
      "min: 1.3692798414406067\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4027495663713412\n",
      "std: 0.013010807243735675\n",
      "min: 1.3692798414406067\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333333\n",
      "std: 0.20279584714176338\n",
      "min: 0.19506402939599934\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.317634650869915\n",
      "std: 0.2942901629809929\n",
      "min: -0.7982799952322005\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6527318639730462\n",
      "std: 0.09740861648138195\n",
      "min: 0.41711721873759283\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018955026803853615\n",
      "min: 0.2066507421484001\n",
      "max: 0.2777292467892489\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9724614645415912\n",
      "std: 0.37545323528005364\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0418796229379248\n",
      "std: 0.3803765951882272\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.33333333333333326\n",
      "std: 0.22414953339507948\n",
      "min: 0.08930966514056929\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.29250423655801344\n",
      "std: 0.3641957699557662\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5334013349482765\n",
      "std: 0.13588229212763883\n",
      "min: 0.25740735238140255\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019217907830177135\n",
      "min: 0.20350907135133764\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4041201247513622\n",
      "std: 0.008100628026155039\n",
      "min: 1.3867013718569547\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4055300332547191\n",
      "std: 0.008320678063477844\n",
      "min: 1.3867013718569547\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333333\n",
      "std: 0.20277062578052119\n",
      "min: 0.1976478418700112\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3226345687513386\n",
      "std: 0.29289628035564114\n",
      "min: -0.794917910471966\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6494267987713304\n",
      "std: 0.09503329550975759\n",
      "min: 0.41662651929257954\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018916750530939396\n",
      "min: 0.2078622763800807\n",
      "max: 0.277182359447076\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.884367729663889\n",
      "std: 0.4980022952919234\n",
      "min: -0.3220562513263309\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9667922364951866\n",
      "std: 0.4990224105295292\n",
      "min: -0.3220562513263309\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333333\n",
      "std: 0.23962375552540674\n",
      "min: 0.05101998228411438\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3317689971098315\n",
      "std: 0.3653086682522107\n",
      "min: -1.0458017076285246\n",
      "max: 0.8202929878414408\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49090108165533775\n",
      "std: 0.15599156038473633\n",
      "min: 0.0952796377382267\n",
      "max: 0.8202929878414408\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019889803348451425\n",
      "min: 0.20340155096524204\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3930891712131128\n",
      "std: 0.024166360198785392\n",
      "min: 1.3315117981387472\n",
      "max: 1.413997664350653\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3962421058273717\n",
      "std: 0.023654515666180785\n",
      "min: 1.3315117981387472\n",
      "max: 1.413997664350653\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333333\n",
      "std: 0.20287823385923082\n",
      "min: 0.1888908332385531\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33518831677115063\n",
      "std: 0.2938082942113401\n",
      "min: -0.8007488762610248\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6474087439086554\n",
      "std: 0.10584918407317641\n",
      "min: 0.4083256514748659\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01956060308367182\n",
      "min: 0.20941466405035936\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9748892280187182\n",
      "std: 0.3855939455922153\n",
      "min: 0.1265687730872469\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0443287192222501\n",
      "std: 0.38762518219120834\n",
      "min: 0.14847232270936514\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.3333333333333333\n",
      "std: 0.22058800650973923\n",
      "min: 0.08485825115146074\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.29791368273178037\n",
      "std: 0.36456827783172924\n",
      "min: -0.9688731920322019\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5299864586736952\n",
      "std: 0.1333023058017089\n",
      "min: 0.2596592351342368\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01993498126649337\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405023466456808\n",
      "std: 0.006637847020273672\n",
      "min: 1.3895975688112976\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4062625843215042\n",
      "std: 0.007038705427468143\n",
      "min: 1.3895975688112976\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.33333333333333337\n",
      "std: 0.202766323331482\n",
      "min: 0.19807756547355804\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3256202307442482\n",
      "std: 0.2925272797609478\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6471895016007206\n",
      "std: 0.09603546509437093\n",
      "min: 0.4155774594870263\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018983163730538002\n",
      "min: 0.2071750899445349\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1775929551477997\n",
      "std: 0.1675137080631079\n",
      "min: 0.7740393198270334\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2089957707392895\n",
      "std: 0.17770670871182323\n",
      "min: 0.8154559782521462\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.19362650070920634\n",
      "min: 0.1143876940702646\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34330604481256144\n",
      "std: 0.36799630425631646\n",
      "min: -1.0388133449438242\n",
      "max: 0.8080487155260071\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5043231549554151\n",
      "std: 0.1320319351946267\n",
      "min: 0.2333371387262748\n",
      "max: 0.8080487155260071\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01966539349296154\n",
      "min: 0.204785801349881\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077465204091604\n",
      "std: 0.004768996308751219\n",
      "min: 1.3903233075804848\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084856624920252\n",
      "std: 0.005225499138172639\n",
      "min: 1.3903233075804848\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.28571428571428575\n",
      "std: 0.18717855402664965\n",
      "min: 0.1642556189115263\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33249693708839384\n",
      "std: 0.29191602272354633\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6362247013965695\n",
      "std: 0.09491804182186828\n",
      "min: 0.4079269375394852\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019208236946026944\n",
      "min: 0.20941466405035936\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9672918345730364\n",
      "std: 0.38950443963982023\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0282432084662023\n",
      "std: 0.3965029523289134\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.21285884755912013\n",
      "min: 0.06927779248720833\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.27644136225922283\n",
      "std: 0.3895053489696352\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5294507819498978\n",
      "std: 0.15225848218333599\n",
      "min: 0.2532827857718808\n",
      "max: 0.9599022535921016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.020561455656875813\n",
      "min: 0.2031681543061914\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4012183451868359\n",
      "std: 0.01247732859315357\n",
      "min: 1.3692798414406067\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4029180799304892\n",
      "std: 0.012418311500349683\n",
      "min: 1.3692798414406067\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.28571428571428575\n",
      "std: 0.18720460640323291\n",
      "min: 0.16227823073856695\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3185944721442825\n",
      "std: 0.2937671597756837\n",
      "min: -0.7982799952322005\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.648315534889158\n",
      "std: 0.09697021774201366\n",
      "min: 0.41637502239763313\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01906699226304754\n",
      "min: 0.2066507421484001\n",
      "max: 0.2777292467892489\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9947071922746292\n",
      "std: 0.3574912189779483\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0522512647622226\n",
      "std: 0.3626660803825417\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.2051958611764854\n",
      "min: 0.06515184149231606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.28674004972235667\n",
      "std: 0.3664790887731828\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5269154759161183\n",
      "std: 0.1355768144429548\n",
      "min: 0.2574073523814025\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019352311202635204\n",
      "min: 0.20350907135133764\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.404168299934713\n",
      "std: 0.008062613246140216\n",
      "min: 1.3835241757985113\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4054358189700387\n",
      "std: 0.008227938690452744\n",
      "min: 1.3862551417725792\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2857142857142857\n",
      "std: 0.18718407633344084\n",
      "min: 0.1642314446455724\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32283647966111856\n",
      "std: 0.29273958747352447\n",
      "min: -0.794917910471966\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6458192658555358\n",
      "std: 0.09481330808297228\n",
      "min: 0.4166265192925797\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019038133915363003\n",
      "min: 0.2078622763800807\n",
      "max: 0.2773494896688313\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.994895729589764\n",
      "std: 0.3708894433486788\n",
      "min: 0.1265687730872469\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.052888254222003\n",
      "std: 0.37264820641403834\n",
      "min: 0.14847232270936514\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.28571428571428575\n",
      "std: 0.20253249812380433\n",
      "min: 0.07007452924393023\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2917900660094276\n",
      "std: 0.36785458706853685\n",
      "min: -0.9688731920322019\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5238351162182068\n",
      "std: 0.13357252559706445\n",
      "min: 0.25965923513423667\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019994068762930067\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4049921268666046\n",
      "std: 0.006664743431047444\n",
      "min: 1.3895975688112976\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406109724526854\n",
      "std: 0.007065794664466261\n",
      "min: 1.3895975688112976\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.28571428571428575\n",
      "std: 0.18718047523133113\n",
      "min: 0.16469519970953786\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3254114903474291\n",
      "std: 0.2924199464194203\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6438214366151339\n",
      "std: 0.09564270824326448\n",
      "min: 0.4155774594870266\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01909596550153231\n",
      "min: 0.2071750899445349\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9109373901171417\n",
      "std: 0.47964602217052527\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.9791344387046328\n",
      "std: 0.48144574185331346\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.28571428571428575\n",
      "std: 0.2178997417336621\n",
      "min: 0.03912628490824474\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32293420194974976\n",
      "std: 0.3672421111571898\n",
      "min: -1.0458017076285246\n",
      "max: 0.8202929878414408\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4897906602037079\n",
      "std: 0.15127433215169309\n",
      "min: 0.0952796377382267\n",
      "max: 0.8202929878414408\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019984612219275704\n",
      "min: 0.20340155096524204\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.39437360040853\n",
      "std: 0.023212174192107568\n",
      "min: 1.3315117981387472\n",
      "max: 1.413997664350653\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.39691947478032\n",
      "std: 0.022825848751237963\n",
      "min: 1.3315117981387472\n",
      "max: 1.413997664350653\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.28571428571428575\n",
      "std: 0.18727439564955384\n",
      "min: 0.1574081427535716\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33462653602990633\n",
      "std: 0.2931886102258759\n",
      "min: -0.8007488762610248\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6431760148214196\n",
      "std: 0.10442157107553175\n",
      "min: 0.4056270848534399\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019609633910263692\n",
      "min: 0.20941466405035936\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1857691004514663\n",
      "std: 0.15726815873594216\n",
      "min: 0.7740393198270334\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.211563814571216\n",
      "std: 0.167366920288674\n",
      "min: 0.8154559782521462\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.24999999999999997\n",
      "std: 0.17895142736543732\n",
      "min: 0.10568892954053766\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3415119630989902\n",
      "std: 0.3652296423921948\n",
      "min: -1.0388133449438242\n",
      "max: 0.8080487155260071\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49953569635389\n",
      "std: 0.12927850275853123\n",
      "min: 0.2333371387262748\n",
      "max: 0.8080487155260071\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01951669736049588\n",
      "min: 0.204785801349881\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076192174589988\n",
      "std: 0.004750271339932145\n",
      "min: 1.3875692253777165\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081283848701303\n",
      "std: 0.005275920948644486\n",
      "min: 1.3875692253777165\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.1735036153527794\n",
      "min: 0.14063074096235148\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33361975713131276\n",
      "std: 0.2918482764377205\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6334503374738178\n",
      "std: 0.09433798751202202\n",
      "min: 0.4019348670620286\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019273010458617405\n",
      "min: 0.20935011721497054\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9998140831592611\n",
      "std: 0.371022206197589\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.048257394480739\n",
      "std: 0.3765243218405848\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.19520345275767548\n",
      "min: 0.06139433050355361\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2836715458907186\n",
      "std: 0.3853121042366677\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.523019073950936\n",
      "std: 0.14741774536710084\n",
      "min: 0.2532827857718808\n",
      "max: 0.9599022535921016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.020313425255305734\n",
      "min: 0.2031681543061914\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4017476463069634\n",
      "std: 0.012066765051114807\n",
      "min: 1.3675591103550717\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4030153082926262\n",
      "std: 0.012045682595022637\n",
      "min: 1.3675591103550717\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.17352590353903657\n",
      "min: 0.13858147917460836\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32128052776439797\n",
      "std: 0.2935329952175721\n",
      "min: -0.7982799952322005\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6443149746978206\n",
      "std: 0.0963607618477051\n",
      "min: 0.40892178026260767\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019159828918027175\n",
      "min: 0.2066507421484001\n",
      "max: 0.2777292467892489\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0237946927910373\n",
      "std: 0.3382417485226483\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0695985230342904\n",
      "std: 0.3423140723771682\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.18882259930793827\n",
      "min: 0.05753863614276312\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2916652840435646\n",
      "std: 0.36500032095784973\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5211157384201341\n",
      "std: 0.13262267638413766\n",
      "min: 0.2574073523814025\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019258821305820503\n",
      "min: 0.20350907135133764\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4043757919966147\n",
      "std: 0.007816148828522045\n",
      "min: 1.3835241757985113\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4053116374777466\n",
      "std: 0.007997889823181415\n",
      "min: 1.3862551417725792\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.17350840274889526\n",
      "min: 0.14047522227678438\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3249192278847385\n",
      "std: 0.2927349755745339\n",
      "min: -0.794917910471966\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6424441904925426\n",
      "std: 0.0943726599716582\n",
      "min: 0.4087058109127857\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019137251544079303\n",
      "min: 0.2078622763800807\n",
      "max: 0.2773494896688313\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0223301577201815\n",
      "std: 0.3562925544439312\n",
      "min: 0.1265687730872469\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.068753911258899\n",
      "std: 0.35663853597960454\n",
      "min: 0.14847232270936514\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.18676679379100716\n",
      "min: 0.058706747353306395\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.29663475326623384\n",
      "std: 0.3668776972931633\n",
      "min: -0.9688731920322019\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5182819844148533\n",
      "std: 0.13081466418202517\n",
      "min: 0.25965923513423667\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019835658232606388\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405100025265892\n",
      "std: 0.006602876108447349\n",
      "min: 1.386461943659028\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4059062093932693\n",
      "std: 0.007029922010542277\n",
      "min: 1.386461943659028\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.1735054133041919\n",
      "min: 0.14086006502553966\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3272236113498208\n",
      "std: 0.2924474606972152\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6405782944197017\n",
      "std: 0.09507463225130283\n",
      "min: 0.4073921801424608\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019188403813776074\n",
      "min: 0.2071750899445349\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9454575061747871\n",
      "std: 0.46399200092280934\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.999880026684365\n",
      "std: 0.46464953834584066\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.19963942586551692\n",
      "min: 0.036934374599274934\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3254179222846738\n",
      "std: 0.36520560163830373\n",
      "min: -1.0458017076285246\n",
      "max: 0.8202929878414408\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48789757200825995\n",
      "std: 0.14556930603834614\n",
      "min: 0.0952796377382267\n",
      "max: 0.8202929878414408\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01986280431996125\n",
      "min: 0.20340155096524204\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.395572495627191\n",
      "std: 0.022585586773600518\n",
      "min: 1.3243916857138434\n",
      "max: 1.413997664350653\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3974791497733052\n",
      "std: 0.022274478343434004\n",
      "min: 1.3243916857138434\n",
      "max: 1.413997664350653\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.17358645240376042\n",
      "min: 0.13350427367048273\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3360071163924931\n",
      "std: 0.292817523785445\n",
      "min: -0.8007488762610248\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6394682957161085\n",
      "std: 0.10300451215806204\n",
      "min: 0.4050273726963621\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019651060174370766\n",
      "min: 0.2094068326190144\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1904032120524954\n",
      "std: 0.1493078517904957\n",
      "min: 0.7740393198270334\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.212460989600017\n",
      "std: 0.15971583933784203\n",
      "min: 0.8154559782521462\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.16630548608070012\n",
      "min: 0.09027777403900655\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34016569258148255\n",
      "std: 0.3669722261959332\n",
      "min: -1.0388133449438242\n",
      "max: 0.8080487155260071\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4982269658282499\n",
      "std: 0.12915327779904964\n",
      "min: 0.2333371387262748\n",
      "max: 0.8080487155260071\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.24999999999999997\n",
      "std: 0.01943470829192167\n",
      "min: 0.204785801349881\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077882093034815\n",
      "std: 0.0044711601622786585\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082415963287755\n",
      "std: 0.004979317752583393\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.16159980581802913\n",
      "min: 0.1233705985826124\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33267716400201114\n",
      "std: 0.2919866717332627\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.632850685079207\n",
      "std: 0.09372503273242165\n",
      "min: 0.4019348670620287\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01923066416722939\n",
      "min: 0.20935011721497054\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0206970173688812\n",
      "std: 0.3614403810697916\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0610213001680557\n",
      "std: 0.36595060293906373\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.180400955350615\n",
      "min: 0.04622834601720121\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.2892409199754301\n",
      "std: 0.38548437220605813\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5200566203429322\n",
      "std: 0.14522494531831676\n",
      "min: 0.25328278577188085\n",
      "max: 0.9599022535921016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.020138635733547346\n",
      "min: 0.2031681543061914\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4023836205252929\n",
      "std: 0.011706298872359694\n",
      "min: 1.3675591103550715\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4034640746762352\n",
      "std: 0.011665682100557939\n",
      "min: 1.3675591103550715\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.16161931648439623\n",
      "min: 0.12116172768825204\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3215156434120124\n",
      "std: 0.29345115043769965\n",
      "min: -0.7982799952322005\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6427522395843186\n",
      "std: 0.09557520540273239\n",
      "min: 0.40892178026260784\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019133367042847134\n",
      "min: 0.2066507421484001\n",
      "max: 0.2777292467892489\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0420540891617087\n",
      "std: 0.32690840671236776\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0802328733853956\n",
      "std: 0.3303916701750517\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.17493835491310208\n",
      "min: 0.04492634349452921\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.29559861001810084\n",
      "std: 0.36762860478906284\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5186143259610083\n",
      "std: 0.13215914177155233\n",
      "min: 0.2574073523814025\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019198286686706728\n",
      "min: 0.20350907135133764\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4047572611711656\n",
      "std: 0.0076099219102755715\n",
      "min: 1.3835241757985115\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4055759481822652\n",
      "std: 0.007724119580339706\n",
      "min: 1.3862551417725792\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.16160411127322794\n",
      "min: 0.12290725866634328\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32473571960196473\n",
      "std: 0.2928493897718801\n",
      "min: -0.794917910471966\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6413019909346809\n",
      "std: 0.09379678425998118\n",
      "min: 0.40870581091278585\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019116652508794095\n",
      "min: 0.2078622763800807\n",
      "max: 0.2773494896688313\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0405102258787786\n",
      "std: 0.3433820833404961\n",
      "min: 0.1265687730872469\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.079262016700038\n",
      "std: 0.3436314168863258\n",
      "min: 0.14847232270936514\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.1732437509327321\n",
      "min: 0.047702548032173234\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3002870340203397\n",
      "std: 0.36964554887321827\n",
      "min: -0.9688731920322019\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5160216210861435\n",
      "std: 0.13074206974254546\n",
      "min: 0.2596592351342367\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019724781167791854\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4054367470776459\n",
      "std: 0.006314396333838055\n",
      "min: 1.3864619436590282\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061397115715204\n",
      "std: 0.006711203660334298\n",
      "min: 1.3864619436590282\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.1616014583323789\n",
      "min: 0.12345785682306941\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3268021442169013\n",
      "std: 0.29259332550171113\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6395595726296264\n",
      "std: 0.09441789874556411\n",
      "min: 0.40739218014246087\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019161799426736924\n",
      "min: 0.2071750899445349\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.9732177791670495\n",
      "std: 0.44939514187407614\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0181000495196548\n",
      "std: 0.4495575540685571\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.18425166240813853\n",
      "min: 0.03076942045461365\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3269600444830529\n",
      "std: 0.3672492952011173\n",
      "min: -1.0458017076285246\n",
      "max: 0.8202929878414408\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4887717218440555\n",
      "std: 0.14315927579402749\n",
      "min: 0.0952796377382267\n",
      "max: 0.8202929878414408\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019759300941820757\n",
      "min: 0.20340155096524204\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3968298940957524\n",
      "std: 0.021921253353823125\n",
      "min: 1.3243916857138436\n",
      "max: 1.413997664350653\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.398394884752933\n",
      "std: 0.0216444312848822\n",
      "min: 1.3243916857138436\n",
      "max: 1.413997664350653\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2222222222222222\n",
      "std: 0.16167244613961346\n",
      "min: 0.11738202866756774\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33513308009116055\n",
      "std: 0.2927386530934557\n",
      "min: -0.8007488762610248\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6382326968295834\n",
      "std: 0.10162328937455574\n",
      "min: 0.405027372696362\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019585454737054062\n",
      "min: 0.20940683261901438\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1977718055010287\n",
      "std: 0.14013648985366703\n",
      "min: 0.7740393198270334\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2177496409257516\n",
      "std: 0.15017248666358232\n",
      "min: 0.8154559782521462\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.15532053838156537\n",
      "min: 0.08313808348406977\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3484841019787318\n",
      "std: 0.36824295998745316\n",
      "min: -1.0388133449438242\n",
      "max: 0.8080487155260071\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5057058319483015\n",
      "std: 0.13061039613940884\n",
      "min: 0.2333371387262748\n",
      "max: 0.8080487155260071\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019491617663560078\n",
      "min: 0.2035004553454793\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081323504216507\n",
      "std: 0.0041899191784535265\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084906601606229\n",
      "std: 0.004656093303830365\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.151218131503775\n",
      "min: 0.11018511082130066\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33324630562719826\n",
      "std: 0.29209538756548137\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6336709831005494\n",
      "std: 0.09326090730337715\n",
      "min: 0.4019348670620287\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01923585679240466\n",
      "min: 0.20935011721497054\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.043203733430588\n",
      "std: 0.34937877494876113\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0779680136437\n",
      "std: 0.3532737274687107\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.16770384843306657\n",
      "min: 0.041203480605189045\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3030111327996775\n",
      "std: 0.3863824716542643\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5261890581539012\n",
      "std: 0.14427057859102765\n",
      "min: 0.25328278577188085\n",
      "max: 0.9599022535921016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.02012626315125222\n",
      "min: 0.2022846769352537\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4032640879378495\n",
      "std: 0.011222962710069532\n",
      "min: 1.3675591103550715\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4041375777761074\n",
      "std: 0.011153958382435047\n",
      "min: 1.3675591103550715\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.15123527996414676\n",
      "min: 0.108075930752331\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3230583735090234\n",
      "std: 0.293429371122648\n",
      "min: -0.7982799952322005\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6427772465770533\n",
      "std: 0.09486820766657421\n",
      "min: 0.40892178026260784\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019151988478181697\n",
      "min: 0.2066507421484001\n",
      "max: 0.2777292467892489\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0624549937038035\n",
      "std: 0.31531670209048257\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0954389242414926\n",
      "std: 0.31817572589583193\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.16295359305994658\n",
      "min: 0.03969392280289475\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3082695071883724\n",
      "std: 0.37035800621442105\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.525227507160685\n",
      "std: 0.13289328361578745\n",
      "min: 0.2574073523814025\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019290046143676482\n",
      "min: 0.2023860661992064\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4054158076561314\n",
      "std: 0.007224692639446182\n",
      "min: 1.3835241757985115\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406077738713462\n",
      "std: 0.007287290497795912\n",
      "min: 1.3862551417725792\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.15122191749108574\n",
      "min: 0.10962173604587817\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.325953671460486\n",
      "std: 0.292955406724882\n",
      "min: -0.794917910471966\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6416363749040203\n",
      "std: 0.09329750688717027\n",
      "min: 0.40870581091278585\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019139668240270625\n",
      "min: 0.2078622763800807\n",
      "max: 0.2773494896688313\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0604496011440168\n",
      "std: 0.33378444874016505\n",
      "min: 0.029367885362486208\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0940207245282425\n",
      "std: 0.3334409920950127\n",
      "min: 0.030474529199092004\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.16153310686726052\n",
      "min: 0.03607247136422158\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31270700016907604\n",
      "std: 0.37231617909776304\n",
      "min: -1.023735588130894\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5227300236544781\n",
      "std: 0.13178946964204427\n",
      "min: 0.2596592351342367\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01977094593715019\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406029563463515\n",
      "std: 0.005984290495645009\n",
      "min: 1.3864619436590282\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406590053997357\n",
      "std: 0.0063241553695205215\n",
      "min: 1.3864619436590282\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.15121960092746173\n",
      "min: 0.10990394633105727\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3278375311299861\n",
      "std: 0.2927235608439235\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6400156183643572\n",
      "std: 0.09386691162677038\n",
      "min: 0.40739218014246087\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019179752116484938\n",
      "min: 0.2071750899445349\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0012609260388132\n",
      "std: 0.4322528294927507\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0395767942570076\n",
      "std: 0.43236562111042975\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.1710918061682626\n",
      "min: 0.028446366338657006\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33767026989264515\n",
      "std: 0.3690830768910005\n",
      "min: -1.0458017076285246\n",
      "max: 0.8202929878414408\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4978511470399172\n",
      "std: 0.14346132913645432\n",
      "min: 0.0952796377382267\n",
      "max: 0.8202929878414408\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019817686719226825\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3981927571539174\n",
      "std: 0.02117433416070406\n",
      "min: 1.3243916857138436\n",
      "max: 1.413997664350653\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.399446896293882\n",
      "std: 0.02091803882478792\n",
      "min: 1.3243916857138436\n",
      "max: 1.413997664350653\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.2\n",
      "std: 0.15128240612678867\n",
      "min: 0.10397165078229853\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.335757921312289\n",
      "std: 0.2926929839644825\n",
      "min: -0.8007488762610248\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6385678757872868\n",
      "std: 0.10045632651336729\n",
      "min: 0.405027372696362\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019571041309234344\n",
      "min: 0.20940683261901438\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.195861948758639\n",
      "std: 0.13714127305968538\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2132991211929303\n",
      "std: 0.1474409815550569\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.14578356822785954\n",
      "min: 0.06362103680521326\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35688514181492903\n",
      "std: 0.3632893349435951\n",
      "min: -1.0388133449438242\n",
      "max: 0.8080487155260071\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49280960746212604\n",
      "std: 0.1406983903142973\n",
      "min: 0.09390736161658192\n",
      "max: 0.8080487155260071\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019438239390248437\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407999142913735\n",
      "std: 0.004193699474816684\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083920310164848\n",
      "std: 0.004611112996795352\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.14211591488398306\n",
      "min: 0.09833766465454788\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33504419381398237\n",
      "std: 0.2916532037234623\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6321816144966578\n",
      "std: 0.09336332052921531\n",
      "min: 0.3959823812252252\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019266518316625635\n",
      "min: 0.20935011721497054\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0542488052190893\n",
      "std: 0.33909639900548655\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.083929455561233\n",
      "std: 0.34301031165521345\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.15680504233879938\n",
      "min: 0.033930323552858785\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31605459896960153\n",
      "std: 0.38145586602969767\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5119456019571613\n",
      "std: 0.1535737241767248\n",
      "min: 0.09681730243254442\n",
      "max: 0.9599022535921016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.020023815853997054\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4034232827865585\n",
      "std: 0.011050443051347747\n",
      "min: 1.3672550158502221\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4042621445375425\n",
      "std: 0.010980283567340368\n",
      "min: 1.3672550158502221\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.14213134019184345\n",
      "min: 0.09667993108017384\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32568316599685565\n",
      "std: 0.29290323232391985\n",
      "min: -0.7982799952322005\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6406151207816297\n",
      "std: 0.09494387494073359\n",
      "min: 0.39686843698963103\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019193734111787975\n",
      "min: 0.2066507421484001\n",
      "max: 0.2777292467892489\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0717435551213887\n",
      "std: 0.3040260478274845\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.099927789499865\n",
      "std: 0.3070978200959853\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.15260821368111557\n",
      "min: 0.03969392280289474\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3203800177405962\n",
      "std: 0.36655521442805766\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5112354624738977\n",
      "std: 0.1438170794534967\n",
      "min: 0.1003206465542351\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019268311571605617\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405444855954296\n",
      "std: 0.007109986518408535\n",
      "min: 1.3831978186333602\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40610408439784\n",
      "std: 0.007141152254993977\n",
      "min: 1.3862551417725792\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.1421193421177193\n",
      "min: 0.09825420478304543\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3283241722192378\n",
      "std: 0.29252493230630694\n",
      "min: -0.794917910471966\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6397088826554838\n",
      "std: 0.09349238971660909\n",
      "min: 0.3992909589056391\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019185346490750065\n",
      "min: 0.2078622763800807\n",
      "max: 0.2773494896688313\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0698168619401731\n",
      "std: 0.3215880100113002\n",
      "min: 0.02936788536248615\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0985369007875194\n",
      "std: 0.32168248740034117\n",
      "min: 0.03047452919909194\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.15137804118617462\n",
      "min: 0.03607247136422158\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32456324271292925\n",
      "std: 0.36853682963009504\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5089565886441972\n",
      "std: 0.14283319116855772\n",
      "min: 0.09334152177000896\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01970653558610289\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4060233371902253\n",
      "std: 0.005936931259848284\n",
      "min: 1.3856641532233454\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065912214950453\n",
      "std: 0.006242883464993176\n",
      "min: 1.386118542101816\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.14211727682153888\n",
      "min: 0.09830964535350459\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33005843202000185\n",
      "std: 0.29230888759252166\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.638172868255004\n",
      "std: 0.09400083424796184\n",
      "min: 0.39784973075130686\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019221259751644848\n",
      "min: 0.2071750899445349\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0168053395076109\n",
      "std: 0.41662118172918977\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0492905175101166\n",
      "std: 0.4172022502141292\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.18181818181818182\n",
      "std: 0.1598239176917562\n",
      "min: 0.028340512297233274\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3479567252247601\n",
      "std: 0.3647888283301877\n",
      "min: -1.0458017076285246\n",
      "max: 0.8202929878414408\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48603648214416567\n",
      "std: 0.1507271448873627\n",
      "min: 0.09087104107303264\n",
      "max: 0.8202929878414408\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019767969327608263\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3988176272585497\n",
      "std: 0.020561021915086526\n",
      "min: 1.3243916857138436\n",
      "max: 1.413997664350653\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3999529234478463\n",
      "std: 0.020357427863952334\n",
      "min: 1.3243916857138436\n",
      "max: 1.413997664350653\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1818181818181818\n",
      "std: 0.14217358888378603\n",
      "min: 0.09346772761224267\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3375749456814434\n",
      "std: 0.29213170467644084\n",
      "min: -0.8007488762610248\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6366405708269605\n",
      "std: 0.10006327529190766\n",
      "min: 0.3910971817698861\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019583883524451874\n",
      "min: 0.20940683261901438\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1973324341058826\n",
      "std: 0.13027951681792846\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2134321774315346\n",
      "std: 0.14042983500275633\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.1373727640104741\n",
      "min: 0.06362103680521326\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35496693267517854\n",
      "std: 0.362044332418957\n",
      "min: -1.0388133449438242\n",
      "max: 0.8080487155260071\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4908013379104979\n",
      "std: 0.14009193203070822\n",
      "min: 0.09390736161658192\n",
      "max: 0.8080487155260071\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01928105421048868\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407911593182598\n",
      "std: 0.00418027907211996\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082478963678238\n",
      "std: 0.004618246360550229\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.13408446222425074\n",
      "min: 0.08940612063873087\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33471014204892513\n",
      "std: 0.29125965254664504\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6314456547446271\n",
      "std: 0.0929205244256533\n",
      "min: 0.3959823812252252\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019237272909791842\n",
      "min: 0.20935011721497054\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0684464871580779\n",
      "std: 0.3233331884268305\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.094668329219953\n",
      "std: 0.3274177449021428\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.14725537939787184\n",
      "min: 0.033930323552858785\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3176206183580146\n",
      "std: 0.37903792691901134\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5089682640669598\n",
      "std: 0.15209646249294237\n",
      "min: 0.09681730243254442\n",
      "max: 0.9599022535921016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019819410459700697\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4036903443012723\n",
      "std: 0.010674295429255973\n",
      "min: 1.3672550158502221\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4044072320720782\n",
      "std: 0.01064131020437211\n",
      "min: 1.3672550158502221\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.1340983492254049\n",
      "min: 0.08836819518131893\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3259954896666163\n",
      "std: 0.2923881950122628\n",
      "min: -0.7982799952322005\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6393232952751913\n",
      "std: 0.09441328640245783\n",
      "min: 0.39686843698963103\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019172055661528995\n",
      "min: 0.2066507421484001\n",
      "max: 0.2777292467892489\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0841598208421552\n",
      "std: 0.29095666318679564\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.109130473916918\n",
      "std: 0.2940554754118304\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.1435173657520412\n",
      "min: 0.03969392280289474\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32121326758908403\n",
      "std: 0.36536754797305154\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.508401328019082\n",
      "std: 0.1431355370426619\n",
      "min: 0.1003206465542351\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0191201223727305\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4055508262193652\n",
      "std: 0.00689577912246705\n",
      "min: 1.3831978186333602\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061173834582918\n",
      "std: 0.006956389520380804\n",
      "min: 1.3862551417725792\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.13408755634850722\n",
      "min: 0.08956329600670529\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3284334293741081\n",
      "std: 0.2921023359775166\n",
      "min: -0.794917910471966\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6386018668330173\n",
      "std: 0.09307851101230144\n",
      "min: 0.3992909589056391\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019166604794617213\n",
      "min: 0.2078622763800807\n",
      "max: 0.2773494896688313\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0822026289760718\n",
      "std: 0.30831755697587726\n",
      "min: 0.02936788536248615\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1076732148579607\n",
      "std: 0.3086133610780753\n",
      "min: 0.03047452919909194\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.14244277757102822\n",
      "min: 0.03607247136422158\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32522476529992767\n",
      "std: 0.3673849975165769\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5062812738325988\n",
      "std: 0.14226582335519813\n",
      "min: 0.09334152177000896\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019529302652072755\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4060810238895118\n",
      "std: 0.005824991715099477\n",
      "min: 1.3856641532233454\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406567105731553\n",
      "std: 0.00615460350075929\n",
      "min: 1.386118542101816\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.1340857155883963\n",
      "min: 0.08953468612053596\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3300282963607188\n",
      "std: 0.29189941403475955\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6371402883961556\n",
      "std: 0.09353808457079768\n",
      "min: 0.39784973075130686\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019198912257987203\n",
      "min: 0.2071750899445349\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0321125730641103\n",
      "std: 0.4025862452958594\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0608108503544147\n",
      "std: 0.40345045860754286\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.15000618095516027\n",
      "min: 0.024747470962023538\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34735724626000275\n",
      "std: 0.3636069416738217\n",
      "min: -1.0458017076285246\n",
      "max: 0.8202929878414408\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48494284629347284\n",
      "std: 0.14908514559427125\n",
      "min: 0.09087104107303264\n",
      "max: 0.8202929878414408\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01960148326314498\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.399340872307613\n",
      "std: 0.02014127577555823\n",
      "min: 1.3224521511287406\n",
      "max: 1.413997664350653\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.400304025128969\n",
      "std: 0.019981969187130036\n",
      "min: 1.3224521511287406\n",
      "max: 1.413997664350653\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.16666666666666666\n",
      "std: 0.13413682368265142\n",
      "min: 0.08439464097451861\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33719282684274676\n",
      "std: 0.2916390127735006\n",
      "min: -0.8007488762610248\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.635536903028304\n",
      "std: 0.09918179134356622\n",
      "min: 0.3910971817698861\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019538278987951782\n",
      "min: 0.20940683261901438\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1999715101906454\n",
      "std: 0.12714295241342474\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2140432009987183\n",
      "std: 0.1371258863747304\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.12993926563171831\n",
      "min: 0.05473353682697026\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3510643668235539\n",
      "std: 0.3603759681099519\n",
      "min: -1.0388133449438242\n",
      "max: 0.8234650410689306\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49495088244214863\n",
      "std: 0.14587476031437352\n",
      "min: 0.09390736161658172\n",
      "max: 0.8234650410689306\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019390289751400957\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078821408555993\n",
      "std: 0.0040423359032742915\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081523991861404\n",
      "std: 0.004472874725857379\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.12695164969134756\n",
      "min: 0.08216446125274204\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3337614238025559\n",
      "std: 0.2910542052039348\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6322899839548127\n",
      "std: 0.09272401170981184\n",
      "min: 0.39598238122522517\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019267445684436457\n",
      "min: 0.20935011721497054\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.080897271076852\n",
      "std: 0.3133900829817476\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.103555280674754\n",
      "std: 0.3173085836350668\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.13889218441496348\n",
      "min: 0.03393032355285879\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31662337275789737\n",
      "std: 0.3761147572225174\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5122351726060922\n",
      "std: 0.15630205793032198\n",
      "min: 0.09681730243254436\n",
      "max: 0.9599022535921016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019882019245262797\n",
      "min: 0.20228467693525365\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4039689560855477\n",
      "std: 0.010381937807776473\n",
      "min: 1.3672550158502221\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4045669605113096\n",
      "std: 0.010343074665369541\n",
      "min: 1.3672550158502221\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.12696429762395434\n",
      "min: 0.08060111998346682\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3256100259824064\n",
      "std: 0.29206693954299173\n",
      "min: -0.7982799952322005\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.639684677888703\n",
      "std: 0.09407860728455358\n",
      "min: 0.396868436989631\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019209221963441443\n",
      "min: 0.2066507421484001\n",
      "max: 0.2777292467892489\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0953792184272748\n",
      "std: 0.2814619218958998\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1169457049617888\n",
      "std: 0.28446106677182154\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.1355200429650201\n",
      "min: 0.03298208696718896\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3196371565625534\n",
      "std: 0.3634898950070394\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5118006144798982\n",
      "std: 0.14842538320456472\n",
      "min: 0.1003206465542351\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019238290055370495\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405676174050959\n",
      "std: 0.006757206710856008\n",
      "min: 1.3831978186333602\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406147944664484\n",
      "std: 0.0067915654089887615\n",
      "min: 1.3862551417725792\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.12695450047616547\n",
      "min: 0.08185235468317643\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32788002615610473\n",
      "std: 0.2918519353013337\n",
      "min: -0.794917910471966\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.639105915672528\n",
      "std: 0.09285794549190056\n",
      "min: 0.39929095890563904\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019206215096733512\n",
      "min: 0.2078622763800807\n",
      "max: 0.27742069198642233\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0933686041775823\n",
      "std: 0.2987929692731875\n",
      "min: 0.02936788536248615\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1154033575522362\n",
      "std: 0.29912687619991085\n",
      "min: 0.03047452919909194\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.13457050936261164\n",
      "min: 0.034403236017276115\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32350284028899734\n",
      "std: 0.36553645139354496\n",
      "min: -1.0237355881308936\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5098041478002376\n",
      "std: 0.14773166495150067\n",
      "min: 0.093341521770009\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019622150598843348\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4061661125106488\n",
      "std: 0.005652628768397914\n",
      "min: 1.3856641532233454\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065656376917446\n",
      "std: 0.005968316452458582\n",
      "min: 1.3861185421018163\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.12695281236818945\n",
      "min: 0.08200728104757907\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32935142619766533\n",
      "std: 0.2916710031032421\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6377211209035875\n",
      "std: 0.09328952660289894\n",
      "min: 0.397849730751307\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019235799326103788\n",
      "min: 0.2071750899445349\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0473925987137664\n",
      "std: 0.38917507941306645\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0721087617838119\n",
      "std: 0.39017995244868325\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.1413947619017349\n",
      "min: 0.023115433230658088\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34447870008279896\n",
      "std: 0.3618900202784997\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4899597196555403\n",
      "std: 0.15396860536379228\n",
      "min: 0.09087104107303264\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019697554520949942\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3998483784463667\n",
      "std: 0.019747540080484745\n",
      "min: 1.322452151128741\n",
      "max: 1.413997664350653\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4006522196892643\n",
      "std: 0.01960619494820397\n",
      "min: 1.322452151128741\n",
      "max: 1.413997664350653\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.15384615384615385\n",
      "std: 0.1269995706891226\n",
      "min: 0.07721373639689977\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33618151344977265\n",
      "std: 0.29135779419581953\n",
      "min: -0.8007488762610248\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6361153811317397\n",
      "std: 0.09854944188732674\n",
      "min: 0.39109718176988606\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019554152151358334\n",
      "min: 0.20940683261901438\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1056221976763916\n",
      "std: 0.2747788494505487\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1246336027388548\n",
      "std: 0.277579112955338\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.1284190164667233\n",
      "min: 0.026478447798692538\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.320329311631458\n",
      "std: 0.3622204871677372\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5075746454146425\n",
      "std: 0.15077935702269576\n",
      "min: 0.1003206465542351\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01931421291009395\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4058841734191843\n",
      "std: 0.0066368082426445894\n",
      "min: 1.3831978186333602\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4063045247273795\n",
      "std: 0.0066657405814690525\n",
      "min: 1.3862551417725792\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12057996674003024\n",
      "min: 0.07548260717428015\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32778185785815867\n",
      "std: 0.29176536168688505\n",
      "min: -0.794917910471966\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6381032946963116\n",
      "std: 0.09283864528072236\n",
      "min: 0.39929095890563904\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019244790802951547\n",
      "min: 0.2078622763800807\n",
      "max: 0.2775025673756819\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.092227326991291\n",
      "std: 0.3057918759596843\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1122022278129127\n",
      "std: 0.3094872171983005\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.13148417257233316\n",
      "min: 0.027419760266060942\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3177573759885457\n",
      "std: 0.37397731150647273\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5079249135831991\n",
      "std: 0.1579504367139355\n",
      "min: 0.09681730243254436\n",
      "max: 0.9599022535921016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01991065964133943\n",
      "min: 0.20228467693525365\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4043048966095084\n",
      "std: 0.010130485095260803\n",
      "min: 1.3672550158502221\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.404832876964473\n",
      "std: 0.010102112428386045\n",
      "min: 1.3672550158502221\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12058892800663043\n",
      "min: 0.07440722378482911\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.325646239258883\n",
      "std: 0.2919213037640063\n",
      "min: -0.7982799952322005\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6385653522072955\n",
      "std: 0.09397117913788108\n",
      "min: 0.396868436989631\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01924550378225787\n",
      "min: 0.2066507421484001\n",
      "max: 0.2777292467892489\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2036019684170436\n",
      "std: 0.12194006283195523\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2161585681844094\n",
      "std: 0.13191118491567025\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12330161709519544\n",
      "min: 0.05473353682697026\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34965915171379164\n",
      "std: 0.35907820954925673\n",
      "min: -1.0388133449438242\n",
      "max: 0.8234650410689306\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49150824138947224\n",
      "std: 0.1482341204580003\n",
      "min: 0.09390736161658172\n",
      "max: 0.8234650410689306\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01945526584264229\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40796264629808\n",
      "std: 0.003920803063506928\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082025875845605\n",
      "std: 0.004348801275215245\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12057732467105084\n",
      "min: 0.07594241805794501\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33330777509681075\n",
      "std: 0.2909965979360018\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6316033900372061\n",
      "std: 0.09266989455571487\n",
      "min: 0.39598238122522517\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019297697739791102\n",
      "min: 0.20935011721497054\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1037030541728647\n",
      "std: 0.2914767502404046\n",
      "min: 0.02936788536248615\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1231472772744584\n",
      "std: 0.2917889893856169\n",
      "min: 0.03047452919909194\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12756624741726644\n",
      "min: 0.026715183547143192\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3240094860174059\n",
      "std: 0.3642955552014197\n",
      "min: -1.0237355881308936\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5056962686652623\n",
      "std: 0.1501920414936614\n",
      "min: 0.093341521770009\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01967324401856177\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4063351504171913\n",
      "std: 0.005561673601051579\n",
      "min: 1.3856641532233454\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066901736380621\n",
      "std: 0.005868190742279542\n",
      "min: 1.3861185421018163\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12057842006923639\n",
      "min: 0.0756353569529344\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3291462630648899\n",
      "std: 0.2915976106959582\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6367739085703202\n",
      "std: 0.09323134797756721\n",
      "min: 0.397849730751307\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01927168726096141\n",
      "min: 0.2071750899445349\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.060752334788989\n",
      "std: 0.37999278317991564\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.082491078713544\n",
      "std: 0.38100300238459844\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.13378056398255883\n",
      "min: 0.017954246835429514\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34396576490804054\n",
      "std: 0.36066191836435324\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48713044498988745\n",
      "std: 0.1552839892881848\n",
      "min: 0.09087104107303264\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25000000000000006\n",
      "std: 0.01975787981299092\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4004089898083918\n",
      "std: 0.01935694589931341\n",
      "min: 1.322452151128741\n",
      "max: 1.413997664350653\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4011088733059982\n",
      "std: 0.019237453553148712\n",
      "min: 1.322452151128741\n",
      "max: 1.413997664350653\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.14285714285714285\n",
      "std: 0.12062143011432494\n",
      "min: 0.07146433056937404\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33566379700941434\n",
      "std: 0.29123550763455397\n",
      "min: -0.8007488762610248\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6351746917538996\n",
      "std: 0.09816341332364487\n",
      "min: 0.39109718176988606\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019571726367847847\n",
      "min: 0.20940683261901438\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1152079841775198\n",
      "std: 0.26737838824009624\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1323003534152447\n",
      "std: 0.27004325970178006\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.12206577385010225\n",
      "min: 0.026227873314977022\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31907224775623444\n",
      "std: 0.3640988318381145\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5075378040529668\n",
      "std: 0.14901609700277652\n",
      "min: 0.1003206465542351\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01915169365826792\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4060246767805236\n",
      "std: 0.0064721493417162525\n",
      "min: 1.3831978186333602\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4064170599679122\n",
      "std: 0.00650414529085246\n",
      "min: 1.3862551417725792\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.11484994537079384\n",
      "min: 0.07038156049236259\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32736702787278266\n",
      "std: 0.29191433567207087\n",
      "min: -0.794917910471966\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6374954745267303\n",
      "std: 0.09286159591881825\n",
      "min: 0.39929095890563904\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01922078191866008\n",
      "min: 0.2078622763800807\n",
      "max: 0.2775025673756819\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1027282183298774\n",
      "std: 0.29670703178131175\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1206768690694429\n",
      "std: 0.3002999255677482\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.12487047515439215\n",
      "min: 0.02741976026606093\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.316825202435992\n",
      "std: 0.3749449785472383\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5077722412469854\n",
      "std: 0.15575725032327362\n",
      "min: 0.09681730243254436\n",
      "max: 0.9599022535921016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01971367441696151\n",
      "min: 0.20228467693525365\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4045424153796857\n",
      "std: 0.009848572873007567\n",
      "min: 1.3672550158502221\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405028998005089\n",
      "std: 0.009828407791447684\n",
      "min: 1.3672550158502221\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.1148581877510387\n",
      "min: 0.06924436039383307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3253475976631154\n",
      "std: 0.29202076532387217\n",
      "min: -0.7982799952322005\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6378652558841884\n",
      "std: 0.0939098535913366\n",
      "min: 0.396868436989631\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019219515549743254\n",
      "min: 0.2066507421484001\n",
      "max: 0.2777292467892489\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1137327492611302\n",
      "std: 0.28136618794680884\n",
      "min: 0.02936788536248615\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.131211514049171\n",
      "std: 0.28175742881617566\n",
      "min: 0.03047452919909194\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.1212836570030641\n",
      "min: 0.026715183547143175\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32254928123079807\n",
      "std: 0.3661734261772994\n",
      "min: -1.0237355881308936\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5057926113163288\n",
      "std: 0.14853729243603958\n",
      "min: 0.093341521770009\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019493346414088956\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064535870571448\n",
      "std: 0.0054333153631567245\n",
      "min: 1.3856641532233454\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067861008278069\n",
      "std: 0.0057349844786269075\n",
      "min: 1.3861185421018163\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.11484852206062345\n",
      "min: 0.07035163500498774\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3286299145386389\n",
      "std: 0.2917652707660586\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6362317389083787\n",
      "std: 0.0932205173496029\n",
      "min: 0.397849730751307\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019245292532044243\n",
      "min: 0.2071750899445349\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2063605038307645\n",
      "std: 0.11897493199435479\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2179154743874465\n",
      "std: 0.12847261734113635\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.11735329742864557\n",
      "min: 0.04964114403860137\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3466255098556623\n",
      "std: 0.36105251616762174\n",
      "min: -1.0388133449438242\n",
      "max: 0.8234650410689306\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49210849725701256\n",
      "std: 0.14660841278368886\n",
      "min: 0.09390736161658172\n",
      "max: 0.8234650410689306\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019284516514013833\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079739680756393\n",
      "std: 0.0038859087151576995\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408204439220647\n",
      "std: 0.004301386412049998\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.11484750749601852\n",
      "min: 0.07028918734758054\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3325836922545283\n",
      "std: 0.29117805922835255\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6312738605412063\n",
      "std: 0.0926770403087598\n",
      "min: 0.39598238122522517\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01926807272675492\n",
      "min: 0.20935011721497054\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0719392263524368\n",
      "std: 0.3725719552797353\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0914924966616801\n",
      "std: 0.3735511461682475\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.12700013474911007\n",
      "min: 0.015757041134209386\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3415568490479844\n",
      "std: 0.36257167316049915\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48823536792938615\n",
      "std: 0.15321662019770263\n",
      "min: 0.09087104107303264\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019575392798005874\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.400876465758525\n",
      "std: 0.018846233678335357\n",
      "min: 1.322452151128741\n",
      "max: 1.413997664350653\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4015059123705012\n",
      "std: 0.018756192334243846\n",
      "min: 1.322452151128741\n",
      "max: 1.413997664350653\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.13333333333333333\n",
      "std: 0.11488821949735556\n",
      "min: 0.06687549840794402\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3348687679194949\n",
      "std: 0.29136928590289607\n",
      "min: -0.8007488762610248\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.634632090652038\n",
      "std: 0.09786300403027512\n",
      "min: 0.39109718176988606\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019529596353027173\n",
      "min: 0.20940683261901438\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.124836866588275\n",
      "std: 0.2607258193888906\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1402854082370841\n",
      "std: 0.2632202368324842\n",
      "min: 0.07770279958335566\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.1163471071670282\n",
      "min: 0.023171579463964566\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32106869099201596\n",
      "std: 0.36165105995490576\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5063420284776613\n",
      "std: 0.14944170130019246\n",
      "min: 0.1003206465542351\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019059683577611192\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4062638430471144\n",
      "std: 0.0062999314007586415\n",
      "min: 1.3831978186333602\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406619293164636\n",
      "std: 0.0063186000613925574\n",
      "min: 1.3862551417725792\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.10967141062728011\n",
      "min: 0.0655049601364182\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32788448774236795\n",
      "std: 0.2918001699790987\n",
      "min: -0.794917910471966\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6371734286106067\n",
      "std: 0.09273336874250374\n",
      "min: 0.39929095890563904\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019215042542844552\n",
      "min: 0.2078622763800807\n",
      "max: 0.2775025673756819\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1130019420602433\n",
      "std: 0.2899977982655302\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.129222879074529\n",
      "std: 0.2933963880739951\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.11893582680332188\n",
      "min: 0.023517495753197924\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.31914347035290624\n",
      "std: 0.37188719599110764\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5064884148777551\n",
      "std: 0.15570316832592637\n",
      "min: 0.09681730243254436\n",
      "max: 0.9599022535921016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01958882692962218\n",
      "min: 0.20228467693525365\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4048648687706147\n",
      "std: 0.00959293501624508\n",
      "min: 1.3672550158502221\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4053034735731678\n",
      "std: 0.009570355852074715\n",
      "min: 1.3672550158502221\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.10967903987801178\n",
      "min: 0.06461495510922517\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32597184363929965\n",
      "std: 0.2918663837344685\n",
      "min: -0.7982799952322005\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6374576600488256\n",
      "std: 0.09370957311563646\n",
      "min: 0.396868436989631\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019212150076161047\n",
      "min: 0.2066507421484001\n",
      "max: 0.2777292467892489\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1229960326666169\n",
      "std: 0.27695757326730663\n",
      "min: 0.019312793458887326\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1388332385496842\n",
      "std: 0.27712542100515963\n",
      "min: 0.019312793458887326\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.11564292366491467\n",
      "min: 0.020662304654860537\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3244285248608725\n",
      "std: 0.3636577457280943\n",
      "min: -1.0237355881308936\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5046416497757729\n",
      "std: 0.14902603628516436\n",
      "min: 0.093341521770009\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019383492065707494\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066662798318985\n",
      "std: 0.005313432538453841\n",
      "min: 1.3856641532233454\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069672902691186\n",
      "std: 0.005591987641372911\n",
      "min: 1.3861185421018163\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.10967009919578004\n",
      "min: 0.0656471187655783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3290698525505727\n",
      "std: 0.2916560131910706\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6359504089330499\n",
      "std: 0.09306730304614234\n",
      "min: 0.397849730751307\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01923725088877422\n",
      "min: 0.2071750899445349\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2106234234851423\n",
      "std: 0.11603035629403743\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2212325006504832\n",
      "std: 0.1250406226079052\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.11198475095012063\n",
      "min: 0.04759232420676906\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34701875077081246\n",
      "std: 0.3585153721210307\n",
      "min: -1.0388133449438242\n",
      "max: 0.8234650410689306\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4915223753743494\n",
      "std: 0.14707381836101246\n",
      "min: 0.09390736161658172\n",
      "max: 0.8234650410689306\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01918491617483841\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081106595150952\n",
      "std: 0.0037622232232376847\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139770179388733\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083195277296865\n",
      "std: 0.004154869239204783\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139770179388733\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.1096691448502646\n",
      "min: 0.06591139609972743\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3328166602146\n",
      "std: 0.29107630964987474\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6312030935668526\n",
      "std: 0.09254793029863698\n",
      "min: 0.39598238122522517\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019256540493330216\n",
      "min: 0.20935011721497054\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0838460030121724\n",
      "std: 0.36432049737454575\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1014631239778574\n",
      "std: 0.36530844038657884\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.12091235984661657\n",
      "min: 0.015219574377605705\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3425821005782897\n",
      "std: 0.3600721260428473\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4880658711689991\n",
      "std: 0.1531645882101621\n",
      "min: 0.09087104107303264\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01946847425596526\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4014458832432224\n",
      "std: 0.018335591040624728\n",
      "min: 1.322452151128741\n",
      "max: 1.413997664350653\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4020005646212368\n",
      "std: 0.018266402454113956\n",
      "min: 1.322452151128741\n",
      "max: 1.413997664350653\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.125\n",
      "std: 0.10970688897152621\n",
      "min: 0.06192827848849346\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.335055664979189\n",
      "std: 0.2912225702073564\n",
      "min: -0.8007488762610248\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6343712007358673\n",
      "std: 0.09745517270784097\n",
      "min: 0.39109718176988606\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01950759027949666\n",
      "min: 0.20940683261901438\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1305373326431396\n",
      "std: 0.2564752120170327\n",
      "min: 0.057924141187968514\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.144386643854974\n",
      "std: 0.2588743155167232\n",
      "min: 0.057924141187968514\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.11118543081604296\n",
      "min: 0.020081627700605197\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.324710116287789\n",
      "std: 0.361301620269097\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5042930498393421\n",
      "std: 0.1493617237328264\n",
      "min: 0.100320646554235\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019101565055550277\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064173749283992\n",
      "std: 0.006225591946544145\n",
      "min: 1.3831978186333602\n",
      "max: 1.4139790623992685\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067486540309573\n",
      "std: 0.006239423103867806\n",
      "min: 1.3862551417725792\n",
      "max: 1.4139790623992685\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.10496802543788959\n",
      "min: 0.061246395183251055\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32818009385746566\n",
      "std: 0.2917165105913578\n",
      "min: -0.794917910471966\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6372109881397527\n",
      "std: 0.09258629616297864\n",
      "min: 0.399290958905639\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019212681346107957\n",
      "min: 0.2078622763800807\n",
      "max: 0.2775025673756819\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.119551180245686\n",
      "std: 0.2841725657805883\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.134093568683933\n",
      "std: 0.2875015800531937\n",
      "min: -0.03386190215710615\n",
      "max: 1.4138853464213648\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.11358201735446864\n",
      "min: 0.02281705614202005\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32303555382736\n",
      "std: 0.3709646081804373\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921016\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5043770221517296\n",
      "std: 0.1552173767491351\n",
      "min: 0.09681730243254426\n",
      "max: 0.9599022535921016\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019598202321244634\n",
      "min: 0.20228467693525365\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405088913286924\n",
      "std: 0.009488072786466267\n",
      "min: 1.3653977107015702\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4054943060615908\n",
      "std: 0.00946609415592058\n",
      "min: 1.3653977107015702\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.10497514538444691\n",
      "min: 0.0600179871094248\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.326355839004249\n",
      "std: 0.29174720711696106\n",
      "min: -0.7982799952322005\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6374282983821465\n",
      "std: 0.09349171498331174\n",
      "min: 0.39686843698963076\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019208334293382593\n",
      "min: 0.2066507421484001\n",
      "max: 0.2777292467892489\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.128900026795452\n",
      "std: 0.2709782450709404\n",
      "min: 0.019312793458887294\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.143104257395409\n",
      "std: 0.27124863331037113\n",
      "min: 0.019312793458887294\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.11053600120971575\n",
      "min: 0.02066230465486054\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3279418533391054\n",
      "std: 0.36327345481312545\n",
      "min: -1.0237355881308936\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5026755996032184\n",
      "std: 0.14900904088727812\n",
      "min: 0.093341521770009\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01940847489708743\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068034817200734\n",
      "std: 0.005263425925582356\n",
      "min: 1.3856641532233454\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070842053307593\n",
      "std: 0.005532340579511539\n",
      "min: 1.3861185421018163\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.1049668040382737\n",
      "min: 0.06142942027240274\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32929789264185194\n",
      "std: 0.29157857316147023\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6360266024476773\n",
      "std: 0.09290065269801151\n",
      "min: 0.397849730751307\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019233136034133454\n",
      "min: 0.2071750899445349\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2122237860506726\n",
      "std: 0.11357319680373577\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2217727128305405\n",
      "std: 0.12242934956205948\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1176470588235294\n",
      "std: 0.10711969797875424\n",
      "min: 0.041892149035940525\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34919517365983055\n",
      "std: 0.35799671218255424\n",
      "min: -1.0388133449438242\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4900261953196886\n",
      "std: 0.14701615890292583\n",
      "min: 0.09390736161658185\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0192179279919161\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408204290515276\n",
      "std: 0.0036900753099594415\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408399979242165\n",
      "std: 0.004074699931101805\n",
      "min: 1.3875692253777168\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.10496589696594459\n",
      "min: 0.061553340947360945\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.332857964254551\n",
      "std: 0.2910099168501972\n",
      "min: -0.8024797058014196\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6314664995097132\n",
      "std: 0.0924149942846554\n",
      "min: 0.39598238122522517\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019249511150033417\n",
      "min: 0.20935011721497054\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0933123904634945\n",
      "std: 0.3534957340981665\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1090047014973625\n",
      "std: 0.35467418213754076\n",
      "min: -0.37036468216519225\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.11541355265212909\n",
      "min: 0.01521957437760571\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3453152182283322\n",
      "std: 0.35964696441382743\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48696280052971863\n",
      "std: 0.15259309387500225\n",
      "min: 0.09087104107303254\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01949402268301439\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4018884781862249\n",
      "std: 0.017955336321791235\n",
      "min: 1.3224521511287408\n",
      "max: 1.413997664350653\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4023887510164403\n",
      "std: 0.017904347953900748\n",
      "min: 1.3224521511287408\n",
      "max: 1.413997664350653\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11764705882352941\n",
      "std: 0.10500110217087252\n",
      "min: 0.05800112954352057\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3350440565459024\n",
      "std: 0.2911233265492876\n",
      "min: -0.8007488762610248\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6344751191419874\n",
      "std: 0.09706708818088534\n",
      "min: 0.39109718176988606\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019491138961358734\n",
      "min: 0.20940683261901438\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1341856520638218\n",
      "std: 0.2489986801304884\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1473630594593875\n",
      "std: 0.251613357159496\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10648330732519647\n",
      "min: 0.020081627700605197\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3267819336464525\n",
      "std: 0.3605754028618305\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.498901483685477\n",
      "std: 0.15227698911745083\n",
      "min: 0.09107466027331775\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019201123048712836\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406488225663592\n",
      "std: 0.006055451895600045\n",
      "min: 1.38319781863336\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406789937754192\n",
      "std: 0.00607458000393474\n",
      "min: 1.386255141772579\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10067664451876696\n",
      "min: 0.058079781570476385\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3282473530629398\n",
      "std: 0.2916478487765935\n",
      "min: -0.794917910471966\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6366139890272031\n",
      "std: 0.09240979456657886\n",
      "min: 0.3992909589056391\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019192706382175278\n",
      "min: 0.2078622763800807\n",
      "max: 0.2775025673756819\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1237769512033906\n",
      "std: 0.2760986329940047\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1375824599893531\n",
      "std: 0.27963001832189804\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10871550712864182\n",
      "min: 0.022817056142020065\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.325357627517338\n",
      "std: 0.3697254638217813\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49891596988992726\n",
      "std: 0.157726283369999\n",
      "min: 0.0895414980270989\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019670470570223867\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4052365108627765\n",
      "std: 0.009217433289894583\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405604214285084\n",
      "std: 0.009204570023369302\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10068328690608665\n",
      "min: 0.05720381630444099\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32650413759529967\n",
      "std: 0.2916499389383804\n",
      "min: -0.7982799952322007\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6367734093793611\n",
      "std: 0.09326085455601917\n",
      "min: 0.39686843698963087\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019187120776966216\n",
      "min: 0.20665074214840007\n",
      "max: 0.2777292467892488\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1323116075404558\n",
      "std: 0.2650698823774724\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1458392259596124\n",
      "std: 0.2655308582716011\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10588906539592922\n",
      "min: 0.020662304654860547\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32994018584696855\n",
      "std: 0.36250692575275834\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4973115706652025\n",
      "std: 0.1519798853093557\n",
      "min: 0.08984119495485048\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01949470206588574\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406846088239611\n",
      "std: 0.005151707512030792\n",
      "min: 1.3856641532233454\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407102023183886\n",
      "std: 0.005412996079044769\n",
      "min: 1.3861185421018158\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10067550971638861\n",
      "min: 0.05805635439489491\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32930508091077826\n",
      "std: 0.2915163517879097\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6354680631120776\n",
      "std: 0.09270120088758695\n",
      "min: 0.3978497307513067\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0192114729087688\n",
      "min: 0.2071750899445349\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2109750542469322\n",
      "std: 0.11217969129862335\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2203856425721715\n",
      "std: 0.12073138148280763\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10268842014649807\n",
      "min: 0.039340330023840624\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35006424939836234\n",
      "std: 0.357219373027493\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4851371890688727\n",
      "std: 0.14983221430213106\n",
      "min: 0.0834566519683207\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01931230884507594\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408156420383935\n",
      "std: 0.0036828537775460165\n",
      "min: 1.3875692253777163\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083356821144122\n",
      "std: 0.004050290930133212\n",
      "min: 1.3875692253777163\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10067466154575584\n",
      "min: 0.05801453553469291\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3327064021098925\n",
      "std: 0.290963432553727\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6310831175240079\n",
      "std: 0.09222903070263544\n",
      "min: 0.3959823812252252\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019226057115817933\n",
      "min: 0.20935011721497054\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.097975554879491\n",
      "std: 0.34665573158257745\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1128386361691742\n",
      "std: 0.34807281322765676\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.11043537351216054\n",
      "min: 0.012930616370502825\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3466564618032058\n",
      "std: 0.35889843701247154\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.482337727128374\n",
      "std: 0.15478877884639156\n",
      "min: 0.08866259196286076\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019578810107726784\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4021431374657027\n",
      "std: 0.01765518207014025\n",
      "min: 1.319208275511956\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4025925768503582\n",
      "std: 0.017620034008653362\n",
      "min: 1.319208275511956\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1111111111111111\n",
      "std: 0.10070766077013936\n",
      "min: 0.05430993830747306\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33483492224114625\n",
      "std: 0.2910423792060204\n",
      "min: -0.8007488762610249\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6339353096057786\n",
      "std: 0.09666237493874194\n",
      "min: 0.39109718176988595\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019458249633688786\n",
      "min: 0.20940683261901438\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1394329393823623\n",
      "std: 0.2450910617927797\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.151906034105091\n",
      "std: 0.24766302223989042\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.10219331363843935\n",
      "min: 0.01812938846249621\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3283595123061271\n",
      "std: 0.3617202105603916\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49696092580855755\n",
      "std: 0.15426685488902012\n",
      "min: 0.09107466027331779\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019366800085435655\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065540414546076\n",
      "std: 0.006036748053165773\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4068849458375354\n",
      "std: 0.006023218683402221\n",
      "min: 1.3803219837213263\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.09674481027483996\n",
      "min: 0.0542120606745041\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3284816555248986\n",
      "std: 0.2917647620360126\n",
      "min: -0.794917910471966\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6361910645403955\n",
      "std: 0.09256151330707395\n",
      "min: 0.3992909589056391\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019221989577417477\n",
      "min: 0.2078622763800807\n",
      "max: 0.2775506330983326\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1296734791131855\n",
      "std: 0.27105196100122964\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1427158015342327\n",
      "std: 0.27457183206516295\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.10427839000880576\n",
      "min: 0.019485629443467257\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3271224041695223\n",
      "std: 0.3703835330183003\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49695690692029537\n",
      "std: 0.15933483271864604\n",
      "min: 0.08954149802709893\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01980934614046266\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4053660848391356\n",
      "std: 0.009073329721197062\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4057562109517918\n",
      "std: 0.009049745743450906\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.09675103624848154\n",
      "min: 0.053729375250526776\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32680758484677946\n",
      "std: 0.2917422647808902\n",
      "min: -0.7982799952322007\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6363062507471894\n",
      "std: 0.09336056291896805\n",
      "min: 0.39686843698963087\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01921537444084332\n",
      "min: 0.20665074214840007\n",
      "max: 0.2777292467892488\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1379065237026125\n",
      "std: 0.25876759389586257\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1506976846712962\n",
      "std: 0.2593635317066025\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.10163616481461589\n",
      "min: 0.01870139704624331\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33138478579501396\n",
      "std: 0.36366078776128724\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4954718023690811\n",
      "std: 0.15401984257271875\n",
      "min: 0.08984119495485048\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01964560440353784\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406899005182589\n",
      "std: 0.005112519455112331\n",
      "min: 1.3856641532233454\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071872316080576\n",
      "std: 0.005337329235187441\n",
      "min: 1.3861185421018158\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.0967437384462647\n",
      "min: 0.054581545510098306\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32948028259894874\n",
      "std: 0.29164377036517036\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6350834141919345\n",
      "std: 0.09283662855954501\n",
      "min: 0.3978497307513067\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019239570388180256\n",
      "min: 0.2071750899445349\n",
      "max: 0.2775499607472059\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.212714589856319\n",
      "std: 0.10898141249985056\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2218340738569669\n",
      "std: 0.11734025144553174\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.09862854640645044\n",
      "min: 0.039340330023840624\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3505055832553685\n",
      "std: 0.3583526508244623\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4837063679926977\n",
      "std: 0.15186915312320617\n",
      "min: 0.0834566519683208\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01947073900290121\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081543851759923\n",
      "std: 0.0036660898277363772\n",
      "min: 1.3875692253777163\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408371676619115\n",
      "std: 0.003979989854180216\n",
      "min: 1.3875692253777163\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.09674293332864678\n",
      "min: 0.05484259080657759\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3327371783295338\n",
      "std: 0.29109894614279763\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6308570853149902\n",
      "std: 0.09237711082370165\n",
      "min: 0.3959823812252252\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019251927991850045\n",
      "min: 0.20935011721497054\n",
      "max: 0.2775225559434859\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.105814754601201\n",
      "std: 0.33841671929375533\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1197559618368311\n",
      "std: 0.34003368394579236\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.10588867965644956\n",
      "min: 0.012930616370502822\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3474698468340949\n",
      "std: 0.36007514509605204\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48119636408655114\n",
      "std: 0.15638798820666203\n",
      "min: 0.08866259196286076\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01973054379346385\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4024407704632451\n",
      "std: 0.01728408524804152\n",
      "min: 1.319208275511956\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4028979765813099\n",
      "std: 0.01726165792006435\n",
      "min: 1.319208275511956\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10526315789473684\n",
      "std: 0.09677392808196257\n",
      "min: 0.05148146274504691\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3348100506465725\n",
      "std: 0.29115350344299956\n",
      "min: -0.8007488762610249\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6335868155312906\n",
      "std: 0.09659913818784355\n",
      "min: 0.39109718176988595\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019475800243564812\n",
      "min: 0.20940683261901438\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1422379450773068\n",
      "std: 0.2402399357649445\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1541732855912894\n",
      "std: 0.24283191153976796\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09825752208301565\n",
      "min: 0.01812938846249621\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3272676603164482\n",
      "std: 0.361993602918439\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49577244196889747\n",
      "std: 0.15394132020453696\n",
      "min: 0.09107466027331779\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019298888677131625\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065844186508292\n",
      "std: 0.0060340255891920104\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406889492846298\n",
      "std: 0.006058987243515467\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09312850016772754\n",
      "min: 0.05143317707365748\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32824552097509835\n",
      "std: 0.2917422030032659\n",
      "min: -0.794917910471966\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6358443371214172\n",
      "std: 0.09238690373372538\n",
      "min: 0.3992909589056391\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019219464256974076\n",
      "min: 0.2078622763800807\n",
      "max: 0.277986942580198\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1330672247097153\n",
      "std: 0.2651429145088307\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1455152172257346\n",
      "std: 0.26871192567498875\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.10021210652177409\n",
      "min: 0.018672845905404505\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3261961028953407\n",
      "std: 0.3702266019155923\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4957424431696216\n",
      "std: 0.15875005498182915\n",
      "min: 0.08954149802709893\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019721172279904716\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40545892928609\n",
      "std: 0.008950932436812043\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4058172899216488\n",
      "std: 0.008959967056723405\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09313435557111968\n",
      "min: 0.05084798522009307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32663486708613026\n",
      "std: 0.2916987843676209\n",
      "min: -0.7982799952322007\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6359179881825464\n",
      "std: 0.0931424613006928\n",
      "min: 0.39686843698963087\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019212089777011568\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1405956057283326\n",
      "std: 0.25502764486288887\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1528411664689229\n",
      "std: 0.25560714480567914\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09774013417505435\n",
      "min: 0.017583490189147243\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3302221118286861\n",
      "std: 0.36393498117478074\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4943429236513297\n",
      "std: 0.15370191247133747\n",
      "min: 0.08984119495485048\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01956833229366669\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069102980952648\n",
      "std: 0.005140117844586386\n",
      "min: 1.3787144478644813\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071755006646658\n",
      "std: 0.005402365926355389\n",
      "min: 1.3787144478644813\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09312749023287371\n",
      "min: 0.05147635383614575\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32919541302730077\n",
      "std: 0.2916315676148951\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.634765365728307\n",
      "std: 0.09264301950882221\n",
      "min: 0.3978497307513067\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019235788530560256\n",
      "min: 0.2071750899445349\n",
      "max: 0.2779915424877919\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2121575168054353\n",
      "std: 0.10670275539996893\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2210925121783627\n",
      "std: 0.11481357437251218\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09490068299975439\n",
      "min: 0.03864356974827985\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3484353474871321\n",
      "std: 0.35878068011341246\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48299963271881946\n",
      "std: 0.1515251708201113\n",
      "min: 0.0834566519683208\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01939967605348329\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408120445726569\n",
      "std: 0.0036887947614200065\n",
      "min: 1.3848743096167446\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083199309553713\n",
      "std: 0.004050323931817568\n",
      "min: 1.3848743096167446\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.0931267192734211\n",
      "min: 0.051734151543642345\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3323179475956405\n",
      "std: 0.291100072026766\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6306931318346509\n",
      "std: 0.09219185130609997\n",
      "min: 0.3959823812252252\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01924634184164322\n",
      "min: 0.20935011721497054\n",
      "max: 0.2779142175222817\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1101068134073115\n",
      "std: 0.3314849015679245\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1233593285208132\n",
      "std: 0.3332845433953961\n",
      "min: -0.3703646821651922\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.1017302200747945\n",
      "min: 0.012930616370502822\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3457124964187631\n",
      "std: 0.36046765224576616\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48069274470225204\n",
      "std: 0.15585330051011761\n",
      "min: 0.08866259196286076\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019651655072144066\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4026610711063576\n",
      "std: 0.01698931715292338\n",
      "min: 1.319208275511956\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4030761935253637\n",
      "std: 0.016996331653458575\n",
      "min: 1.319208275511956\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1\n",
      "std: 0.09315594677955681\n",
      "min: 0.04875810087959265\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33433270021519973\n",
      "std: 0.2911346704524019\n",
      "min: -0.8007488762610249\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6333062227893155\n",
      "std: 0.09625478178287966\n",
      "min: 0.39109718176988595\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019462771966122203\n",
      "min: 0.20940683261901438\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1468054846571816\n",
      "std: 0.23480438553223512\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1575071441788016\n",
      "std: 0.2373327577048103\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.09463063036400975\n",
      "min: 0.01812938846249621\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32698411442158265\n",
      "std: 0.3603021999184007\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49389719065420845\n",
      "std: 0.15616604813049048\n",
      "min: 0.09107466027331775\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019146077122198898\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066526717451424\n",
      "std: 0.00590886363484572\n",
      "min: 1.375663328776969\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069459437183203\n",
      "std: 0.005931418535461324\n",
      "min: 1.377784316792521\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.08979058422241509\n",
      "min: 0.04914813639714473\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3276246237559556\n",
      "std: 0.2913094500853045\n",
      "min: -0.794917910471966\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6355726687054991\n",
      "std: 0.09227892557442816\n",
      "min: 0.3992909589056391\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01918796125079364\n",
      "min: 0.2078622763800807\n",
      "max: 0.277986942580198\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1380938033808383\n",
      "std: 0.25891128912981887\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1492655497125346\n",
      "std: 0.26240884772492495\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.0964702229146673\n",
      "min: 0.01867284590540451\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32606134441536355\n",
      "std: 0.36817061254467703\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.49382502633579206\n",
      "std: 0.16067494031014326\n",
      "min: 0.08954149802709886\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01955161188073457\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405575461991109\n",
      "std: 0.00877302950180839\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405917165410929\n",
      "std: 0.00878435535351673\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.08979611140171283\n",
      "min: 0.048321817980401124\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32607198296391765\n",
      "std: 0.2912447692679602\n",
      "min: -0.7982799952322007\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.635607356575251\n",
      "std: 0.09299678805425537\n",
      "min: 0.39686843698963087\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019179792276998005\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1450910156677336\n",
      "std: 0.25029430873630615\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1560886799744972\n",
      "std: 0.2508441201275329\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.09414874377212358\n",
      "min: 0.017583490189147247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32985639811413914\n",
      "std: 0.36219965137997234\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4924975372099515\n",
      "std: 0.15596021403914848\n",
      "min: 0.08984119495485052\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01940617958221697\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069633930771297\n",
      "std: 0.005044826075341649\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072195792570585\n",
      "std: 0.005296098240753953\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.0897896322778768\n",
      "min: 0.049252620805885904\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32852776155991653\n",
      "std: 0.29120461688449983\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6345220797555765\n",
      "std: 0.09251943100386863\n",
      "min: 0.3978497307513067\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019203041578044946\n",
      "min: 0.2071750899445349\n",
      "max: 0.27799154248779195\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.213297432480516\n",
      "std: 0.10500779011451673\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2213043070694278\n",
      "std: 0.11291197162140194\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.09146344124859143\n",
      "min: 0.03251878823968577\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3472528454857418\n",
      "std: 0.35716498077958264\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4814985068827837\n",
      "std: 0.15372749390027304\n",
      "min: 0.0834566519683209\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019244142547601588\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081204947609622\n",
      "std: 0.0036306548047112743\n",
      "min: 1.3848743096167446\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083156090819622\n",
      "std: 0.00397692322175572\n",
      "min: 1.3848743096167446\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.0897889007651985\n",
      "min: 0.0492565734354906\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33153581004975446\n",
      "std: 0.2906937469518638\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6305830759731601\n",
      "std: 0.09207802945650508\n",
      "min: 0.3959823812252252\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019212410076356462\n",
      "min: 0.20935011721497054\n",
      "max: 0.27791421752228174\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1158138985226966\n",
      "std: 0.3253701236130728\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1277192177277187\n",
      "std: 0.3271331587150967\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.09790617131969744\n",
      "min: 0.010317216955760999\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3448217794517443\n",
      "std: 0.3588163390782531\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47940348254807236\n",
      "std: 0.1577630471636507\n",
      "min: 0.08866259196286072\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019488876509943902\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4028801559359088\n",
      "std: 0.016721191337027232\n",
      "min: 1.3192082755119565\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4032698563018056\n",
      "std: 0.016739776241765394\n",
      "min: 1.3192082755119565\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09523809523809523\n",
      "std: 0.08981655290092333\n",
      "min: 0.046128362214563\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33349243093254344\n",
      "std: 0.29070740269185075\n",
      "min: -0.8007488762610249\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6330908903424284\n",
      "std: 0.09598198700127591\n",
      "min: 0.39109718176988595\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019421601395806103\n",
      "min: 0.20940683261901438\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1482959783861464\n",
      "std: 0.22981324911421552\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1578363696813898\n",
      "std: 0.23244264459667674\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.09128113334821047\n",
      "min: 0.016328565126136847\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3297184748889601\n",
      "std: 0.3592653756668559\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4914951978215461\n",
      "std: 0.15688832837772004\n",
      "min: 0.09107466027331775\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019130187064712957\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066293213462455\n",
      "std: 0.005810697111830885\n",
      "min: 1.375663328776969\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4068457759888318\n",
      "std: 0.00585872348036936\n",
      "min: 1.377784316792521\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.08669956856697646\n",
      "min: 0.04676664090165034\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32826718234368896\n",
      "std: 0.291439297263898\n",
      "min: -0.7949507364187506\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6352887749194954\n",
      "std: 0.09210903622469228\n",
      "min: 0.3992909589056391\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01919593336555014\n",
      "min: 0.2078622763800807\n",
      "max: 0.277986942580198\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1399264752772207\n",
      "std: 0.2537823339208216\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1499063430189855\n",
      "std: 0.25732843841541064\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.09301959280408288\n",
      "min: 0.016619238648458257\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3289244950984529\n",
      "std: 0.36679540827214896\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4913732052874254\n",
      "std: 0.16116592179379216\n",
      "min: 0.08954149802709886\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019518748381296684\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405596679393149\n",
      "std: 0.008602794038199458\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405857623504016\n",
      "std: 0.008633030928921811\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.08670479858968971\n",
      "min: 0.04609898639837747\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32677047940600457\n",
      "std: 0.29136051902849774\n",
      "min: -0.7982799952322007\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6352887069818267\n",
      "std: 0.09278959832028315\n",
      "min: 0.39686843698963087\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019187031533821095\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.14646252803481\n",
      "std: 0.24611375115582756\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1562898492043965\n",
      "std: 0.24677386295209439\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.09083169186934739\n",
      "min: 0.016000796059946452\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33251611384972724\n",
      "std: 0.3610915114951519\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4901011993531541\n",
      "std: 0.15670575506808446\n",
      "min: 0.08984119495485052\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019381021407045316\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406924326982163\n",
      "std: 0.005014988238626903\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071059858159802\n",
      "std: 0.005285188274505517\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.0866986731486839\n",
      "min: 0.046622272881799286\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32913089195762746\n",
      "std: 0.29133687055914703\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6342602274711908\n",
      "std: 0.09233689738002905\n",
      "min: 0.3978497307513067\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019209883787409548\n",
      "min: 0.2071750899445349\n",
      "max: 0.27799154248779195\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2117936442122883\n",
      "std: 0.10391463612872892\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2188974708387619\n",
      "std: 0.11187037298994473\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.08828482308915656\n",
      "min: 0.03187752219177068\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.349142650360949\n",
      "std: 0.3560444149613833\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4794438908262296\n",
      "std: 0.15444684969945746\n",
      "min: 0.0834566519683209\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01922546794051551\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080383152718885\n",
      "std: 0.0036234325113633295\n",
      "min: 1.3842515967500917\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081635114886994\n",
      "std: 0.0039969858747405185\n",
      "min: 1.3842515967500917\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.08669797327930928\n",
      "min: 0.04670827223675134\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33202205721559896\n",
      "std: 0.2908302486039877\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6304468412290261\n",
      "std: 0.09190948816365507\n",
      "min: 0.3959823812252252\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019217837857356257\n",
      "min: 0.20935011721497054\n",
      "max: 0.27791421752228174\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1185269311439952\n",
      "std: 0.3191554215260823\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1291630660523841\n",
      "std: 0.32104592684629185\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.09438026594593599\n",
      "min: 0.010317216955760999\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3470069222547092\n",
      "std: 0.3577111356815645\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47752717579220744\n",
      "std: 0.15820015459164086\n",
      "min: 0.08866259196286072\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019464563173662977\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4030155913210716\n",
      "std: 0.016380513677273046\n",
      "min: 1.3192082755119565\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4033165878980887\n",
      "std: 0.016415606421914617\n",
      "min: 1.3192082755119565\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09090909090909091\n",
      "std: 0.08672416888419965\n",
      "min: 0.044064017735225045\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3339384104637642\n",
      "std: 0.29082465976747857\n",
      "min: -0.8007488762610249\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6328557938094862\n",
      "std: 0.09565773033371601\n",
      "min: 0.39109718176988595\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01942061957623484\n",
      "min: 0.20940683261901438\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1514099551067811\n",
      "std: 0.22598340783584805\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1602544549993137\n",
      "std: 0.22864735895372906\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08817844722402741\n",
      "min: 0.016328565126136844\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33559599008889934\n",
      "std: 0.3596712670999586\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48727476275926934\n",
      "std: 0.16097763060932896\n",
      "min: 0.04350261413105982\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01929920312438046\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406732302531447\n",
      "std: 0.005747287818343506\n",
      "min: 1.375663328776969\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069548913126542\n",
      "std: 0.0057812121918837936\n",
      "min: 1.377784316792521\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08382852900394216\n",
      "min: 0.04451154665033027\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.328804340768974\n",
      "std: 0.2915785206727116\n",
      "min: -0.7949507364187502\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6350302770912569\n",
      "std: 0.09222598784749601\n",
      "min: 0.3992909589056391\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019218596921854833\n",
      "min: 0.2078622763800807\n",
      "max: 0.277986942580198\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.143368891974862\n",
      "std: 0.2502645246169652\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1526228865022294\n",
      "std: 0.25380312998897425\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.0898256769653966\n",
      "min: 0.015691326148363275\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.334914150647658\n",
      "std: 0.36689850647550337\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4871267157418652\n",
      "std: 0.16496206765661384\n",
      "min: 0.04273000884392176\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019668476918550983\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4057388742020536\n",
      "std: 0.008509221598683236\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4060025940106786\n",
      "std: 0.00853247616974239\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08383349812199056\n",
      "min: 0.04380244643920145\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32735561835666604\n",
      "std: 0.29148713768468554\n",
      "min: -0.7982799952322007\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6350037239199622\n",
      "std: 0.09287063317389455\n",
      "min: 0.39686843698963087\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01920902639944765\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1496726851860568\n",
      "std: 0.2417057727875067\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1587883333000648\n",
      "std: 0.24247197121124434\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08775457950009836\n",
      "min: 0.016000796059946452\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3383059869563767\n",
      "std: 0.36143077108552263\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4859229773179972\n",
      "std: 0.1608123005752417\n",
      "min: 0.043673562950024704\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019539192646717288\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407017544331701\n",
      "std: 0.004959444931657104\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072075156910144\n",
      "std: 0.0052104887331037636\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.0838276783872941\n",
      "min: 0.04465300008384235\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32963024594192897\n",
      "std: 0.2914813738679302\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6340284142239759\n",
      "std: 0.09244308985705645\n",
      "min: 0.3978497307513067\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019231650034506085\n",
      "min: 0.2071750899445349\n",
      "max: 0.27799154248779195\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2124055266015503\n",
      "std: 0.10298400298092704\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2190339139602375\n",
      "std: 0.11081084400389159\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08533445083134386\n",
      "min: 0.028452937912743996\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3541996514149799\n",
      "std: 0.3562443351564913\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4755962112150857\n",
      "std: 0.15846323637660512\n",
      "min: 0.03941103347714442\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019388107087147426\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080967275340002\n",
      "std: 0.003584436020028895\n",
      "min: 1.3842515967500917\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082334786605186\n",
      "std: 0.0039322460573785155\n",
      "min: 1.3842515967500917\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08382700915171111\n",
      "min: 0.044751172172468344\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33241140395725005\n",
      "std: 0.29097976334736186\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6303348388384795\n",
      "std: 0.09202766433555397\n",
      "min: 0.3959823812252252\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019238169621547927\n",
      "min: 0.20928437944978717\n",
      "max: 0.27791421752228174\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1232220726529973\n",
      "std: 0.3132745386124027\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1330457719429445\n",
      "std: 0.31528564753405164\n",
      "min: -0.40344772751388114\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.09111582932757985\n",
      "min: 0.010317216955760999\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3523142004406892\n",
      "std: 0.3579798057927529\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4738371631403482\n",
      "std: 0.16186198748931505\n",
      "min: 0.043272530016648054\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019621029341655827\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4032676474330432\n",
      "std: 0.0161409322777291\n",
      "min: 1.3189138181182705\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4035638820775724\n",
      "std: 0.01618199986143127\n",
      "min: 1.3189138181182705\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08695652173913043\n",
      "std: 0.08385190984441784\n",
      "min: 0.041777242037039565\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33428285356862814\n",
      "std: 0.29096088489187205\n",
      "min: -0.8007488762610249\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6326545070768536\n",
      "std: 0.09562462267395176\n",
      "min: 0.39109718176988595\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019434674732306735\n",
      "min: 0.20930683824810611\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1515026389564034\n",
      "std: 0.22235509820301258\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1600122352181905\n",
      "std: 0.22513408176610572\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08529355296013909\n",
      "min: 0.016328565126136844\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3374290252124787\n",
      "std: 0.35882794067981205\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48347199304001576\n",
      "std: 0.16255906195419104\n",
      "min: 0.04350261413105982\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01925921808192953\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068108497252116\n",
      "std: 0.005643717926602891\n",
      "min: 1.375663328776969\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070232759892214\n",
      "std: 0.005684169872579165\n",
      "min: 1.377784316792521\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.081154330284721\n",
      "min: 0.042639596658292686\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3290371784571776\n",
      "std: 0.2914640239975468\n",
      "min: -0.7949507364187502\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6344895302233435\n",
      "std: 0.09212805377588532\n",
      "min: 0.3992909589056391\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019216562508874165\n",
      "min: 0.2078622763800807\n",
      "max: 0.277986942580198\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.143933813608003\n",
      "std: 0.2452786718918229\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1528181860666888\n",
      "std: 0.24895974024117712\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08685540387412556\n",
      "min: 0.015691326148363275\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3368503994469965\n",
      "std: 0.36577086766257405\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4833271325191502\n",
      "std: 0.16633098034281932\n",
      "min: 0.04273000884392176\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01961446303950269\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4058639013546896\n",
      "std: 0.008322847673412195\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406114044380336\n",
      "std: 0.008356192179897288\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08115904989351486\n",
      "min: 0.04206402568754786\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3276318975321792\n",
      "std: 0.2913620254675177\n",
      "min: -0.7982799952322007\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6344405140775679\n",
      "std: 0.09274233779545418\n",
      "min: 0.39686843698963087\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01920646011696595\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1499082816346937\n",
      "std: 0.23698394546065452\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1586725302066725\n",
      "std: 0.2379408246586984\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.084891648306264\n",
      "min: 0.016000796059946452\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34007657362488025\n",
      "std: 0.3605515219511664\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4821830994441236\n",
      "std: 0.16238335423899014\n",
      "min: 0.043673562950024704\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019491497530922584\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070782316471062\n",
      "std: 0.00486067469339657\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072602732471795\n",
      "std: 0.005115949826240101\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08115352061495146\n",
      "min: 0.04276793349929825\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32982761593805293\n",
      "std: 0.2913716166891\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6335138700514807\n",
      "std: 0.09233202668317661\n",
      "min: 0.3978497307513067\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019228713149409132\n",
      "min: 0.2071750899445349\n",
      "max: 0.27799154248779195\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2101131387557849\n",
      "std: 0.10148580649760916\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2166021437138976\n",
      "std: 0.10933254036945683\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08258699695789651\n",
      "min: 0.028452937912743996\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3553426236479411\n",
      "std: 0.35540590311133097\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4721839283812695\n",
      "std: 0.1599683701909713\n",
      "min: 0.03941103347714442\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01934370859653778\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408105808591564\n",
      "std: 0.0035210074237782287\n",
      "min: 1.3842515967500917\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082385484475077\n",
      "std: 0.0038706017687990413\n",
      "min: 1.3842515967500917\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08115288226958016\n",
      "min: 0.04286851149210697\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3325111023398153\n",
      "std: 0.29087941033666065\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6299389900525524\n",
      "std: 0.09191935958612402\n",
      "min: 0.3959823812252252\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019234170644475267\n",
      "min: 0.20928437944978717\n",
      "max: 0.27791421752228174\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1240970244366697\n",
      "std: 0.3089556565278314\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1335135147781585\n",
      "std: 0.3111109398635553\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08808543165642585\n",
      "min: 0.008725245544753972\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3536457973112382\n",
      "std: 0.3571027005772025\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4705289426212784\n",
      "std: 0.163107294314794\n",
      "min: 0.043272530016648054\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019572913593071777\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4034554233624585\n",
      "std: 0.015924583980010044\n",
      "min: 1.3178109892888872\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4037335742002666\n",
      "std: 0.015976673674333017\n",
      "min: 1.3178109892888872\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08333333333333333\n",
      "std: 0.08117661147670512\n",
      "min: 0.03995479174905277\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3343376614990311\n",
      "std: 0.2908426130135102\n",
      "min: -0.8007488762610249\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6321685257728378\n",
      "std: 0.09539283129729284\n",
      "min: 0.39109718176988595\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019424781573621444\n",
      "min: 0.20930683824810611\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1528225850991962\n",
      "std: 0.2183395719853991\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1608410602081987\n",
      "std: 0.22116870560613144\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.08260364834648468\n",
      "min: 0.016328565126136844\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33136728612672045\n",
      "std: 0.36283913625795944\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48581204010634194\n",
      "std: 0.16257552375353135\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019105534360077666\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406905125617604\n",
      "std: 0.005577400258081712\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070988999386065\n",
      "std: 0.005619984900181274\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.07865699953312194\n",
      "min: 0.040762031831898034\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3284746376305617\n",
      "std: 0.29177015831806635\n",
      "min: -0.7949507364187502\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6346950557685203\n",
      "std: 0.09210074749019956\n",
      "min: 0.3992909589056391\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019193650624933053\n",
      "min: 0.2078622763800807\n",
      "max: 0.277986942580198\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1455709838254988\n",
      "std: 0.2408433657556408\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1539362232398176\n",
      "std: 0.2445618891934316\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.08408948544995866\n",
      "min: 0.01569132614836328\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33088202986910137\n",
      "std: 0.3693916330022299\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4856590268986527\n",
      "std: 0.16617697744106522\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019449984645818992\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.405997798099841\n",
      "std: 0.008180275164255691\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4062266589929848\n",
      "std: 0.008218525184071856\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.07866149390780013\n",
      "min: 0.040333208093014807\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32710838633080025\n",
      "std: 0.29165458817989776\n",
      "min: -0.7982799952322007\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6346272892937964\n",
      "std: 0.09268191411182165\n",
      "min: 0.39686843698963087\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019183023833871462\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.151218551380381\n",
      "std: 0.23320040682691187\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1594805220256095\n",
      "std: 0.23423887605720123\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.08222373502343094\n",
      "min: 0.015651474057096063\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3339477601893025\n",
      "std: 0.36455209974714337\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.484560672711514\n",
      "std: 0.16242931651603962\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01933162367660172\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407159462534464\n",
      "std: 0.004815484476609729\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407324950146465\n",
      "std: 0.00506891405778115\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.07865622846622743\n",
      "min: 0.040873363695720075\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32922896315589173\n",
      "std: 0.291685054576334\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6337451103393105\n",
      "std: 0.0922962916167834\n",
      "min: 0.3978497307513067\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01920489991550989\n",
      "min: 0.2071750899445349\n",
      "max: 0.2779915424877919\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.208998343136975\n",
      "std: 0.10130205670105107\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2151757071253435\n",
      "std: 0.10893166852206827\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.08002464751370875\n",
      "min: 0.025832038177094833\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34868973336914655\n",
      "std: 0.3597129677627869\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47482677132407564\n",
      "std: 0.16016719316076505\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019189111038869073\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081492542910197\n",
      "std: 0.003486699823047721\n",
      "min: 1.3842515967500924\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082684229426436\n",
      "std: 0.0038334795410577232\n",
      "min: 1.3842515967500924\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.07865561583813784\n",
      "min: 0.04092655570316713\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3318279302630818\n",
      "std: 0.291204918499626\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6302732750595933\n",
      "std: 0.09190538776238381\n",
      "min: 0.3959823812252252\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019209624397957384\n",
      "min: 0.2092843794497872\n",
      "max: 0.2779142175222817\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.126275769363519\n",
      "std: 0.3041186210161017\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.135128820189108\n",
      "std: 0.30636022708107546\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.08526355011936756\n",
      "min: 0.008725245544753972\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3471237356806702\n",
      "std: 0.3613446135950381\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47331990748402974\n",
      "std: 0.1632085772264589\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019411019738634787\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4036713368033429\n",
      "std: 0.015671363133459907\n",
      "min: 1.3178109892888872\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4039232249719946\n",
      "std: 0.01573319997655505\n",
      "min: 1.3178109892888872\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08\n",
      "std: 0.07867825583993047\n",
      "min: 0.038451735095878806\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3336049336582659\n",
      "std: 0.29116173932885064\n",
      "min: -0.8007488762610249\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6324299231365688\n",
      "std: 0.09525122861455727\n",
      "min: 0.39109718176988595\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019394716707932073\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1544581590074072\n",
      "std: 0.214299833323294\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1619480636354893\n",
      "std: 0.21723064928593894\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.08008830612712703\n",
      "min: 0.01496309527221537\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3314262941752685\n",
      "std: 0.361015054424534\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4872535983890182\n",
      "std: 0.16231813339762974\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019059233254588602\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069062394430456\n",
      "std: 0.00548463770480615\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070416039586333\n",
      "std: 0.00554325029678738\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07631918413335259\n",
      "min: 0.039335347841818184\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32843514365513643\n",
      "std: 0.2915074432039929\n",
      "min: -0.7949507364187502\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6346800749159879\n",
      "std: 0.09188161739851289\n",
      "min: 0.3992909589056391\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01917299488217421\n",
      "min: 0.2078622763800807\n",
      "max: 0.277986942580198\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1474375067775886\n",
      "std: 0.2368205086449866\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.155252702376493\n",
      "std: 0.24060087106470793\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.08150558365090572\n",
      "min: 0.014998497372787259\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33102799196426747\n",
      "std: 0.3673525135105714\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4870653525070914\n",
      "std: 0.1657698900083958\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019391537292186033\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406028478256036\n",
      "std: 0.008064059616788456\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061965940919714\n",
      "std: 0.008111241019916456\n",
      "min: 1.3653977107015705\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07632347903486272\n",
      "min: 0.03855180229246647\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32710783883668626\n",
      "std: 0.2913817303323379\n",
      "min: -0.7982799952322007\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6345900113554084\n",
      "std: 0.09243658445848717\n",
      "min: 0.39686843698963087\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01916191997614241\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1528405701544568\n",
      "std: 0.2292464675703079\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.160563668082829\n",
      "std: 0.23041461755068632\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07972844969279828\n",
      "min: 0.015651474057096063\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3339516530387565\n",
      "std: 0.3627033035833423\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48602378158159615\n",
      "std: 0.16219186647950465\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01927866112134313\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407151471635348\n",
      "std: 0.004757239803316288\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072598649463959\n",
      "std: 0.005021385366455784\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07631844968564394\n",
      "min: 0.039347989079860826\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3291593433639291\n",
      "std: 0.2914248162798733\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6337477800622581\n",
      "std: 0.09206841375379757\n",
      "min: 0.3978497307513067\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019183445761764496\n",
      "min: 0.2071750899445349\n",
      "max: 0.2779915424877919\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2084088856305428\n",
      "std: 0.1003601295710616\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2142138719717885\n",
      "std: 0.10800551617686956\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07762637775664788\n",
      "min: 0.025832038177094833\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3481580090722091\n",
      "std: 0.35794879166190186\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4765219191424423\n",
      "std: 0.16005059082265172\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019141063271030417\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081118634676832\n",
      "std: 0.003459415681045249\n",
      "min: 1.3842515967500924\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081766353295924\n",
      "std: 0.0038206042219851334\n",
      "min: 1.3842515967500924\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07631786162226974\n",
      "min: 0.03935146608053647\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3316749853286851\n",
      "std: 0.2909552570021902\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6303712729446594\n",
      "std: 0.0916920126360456\n",
      "min: 0.3959823812252252\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01918738989715642\n",
      "min: 0.2092843794497872\n",
      "max: 0.2779142175222817\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.128785538969472\n",
      "std: 0.29916466891749427\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.137043086580984\n",
      "std: 0.3015196796313535\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.08262773871144748\n",
      "min: 0.008725245544753972\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34676150100382724\n",
      "std: 0.35956793854436\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4751414154531044\n",
      "std: 0.16297840653583384\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019358179452310408\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4037787112046278\n",
      "std: 0.015467558158017595\n",
      "min: 1.311685656470913\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4039654791647347\n",
      "std: 0.015539040654610002\n",
      "min: 1.311685656470913\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07692307692307693\n",
      "std: 0.07633951581723047\n",
      "min: 0.036605431985694194\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3334109706771027\n",
      "std: 0.2909004801715648\n",
      "min: -0.8007488762610249\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6324587394965161\n",
      "std: 0.09492756701591248\n",
      "min: 0.39109718176988595\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01936750505895184\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1565635573310584\n",
      "std: 0.21084297124979362\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1635395969494864\n",
      "std: 0.2137693839485271\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.077731779269\n",
      "min: 0.012953919620569458\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3356596799865\n",
      "std: 0.3612506844021559\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4858861198885375\n",
      "std: 0.16226953600157226\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019074100033428326\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406890973572323\n",
      "std: 0.005449007894891118\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069689639230998\n",
      "std: 0.005527991131733097\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.07412575199612957\n",
      "min: 0.03759282244961262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3291101860949986\n",
      "std: 0.291612924385023\n",
      "min: -0.7976532138861676\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6344004854978955\n",
      "std: 0.09198916767075575\n",
      "min: 0.3992909589056391\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019192691028334947\n",
      "min: 0.2078622763800807\n",
      "max: 0.2779914238559012\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1498256999510301\n",
      "std: 0.23258857381223028\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1571063069009042\n",
      "std: 0.2363731633238916\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.07908499908047198\n",
      "min: 0.01409781528698875\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33531156877036433\n",
      "std: 0.36735191461203437\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48566749715331414\n",
      "std: 0.1655950966125696\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019393468323324625\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4060466629449202\n",
      "std: 0.007997583304965057\n",
      "min: 1.3632262845475458\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406155189117187\n",
      "std: 0.008055676928511866\n",
      "min: 1.3632847653288143\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.0741298645578093\n",
      "min: 0.036852186197328954\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.327816570759153\n",
      "std: 0.29148087892935476\n",
      "min: -0.7982799952322007\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6342912267285723\n",
      "std: 0.0925187677610575\n",
      "min: 0.39686843698963087\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01918115394466544\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.155017512017319\n",
      "std: 0.22542432664548506\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1622164799212644\n",
      "std: 0.22662253085575945\n",
      "min: 0.019312793458887537\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.0773891069435158\n",
      "min: 0.013022107073856507\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33811227317333303\n",
      "std: 0.36287887859123935\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.484688291273596\n",
      "std: 0.16216532948605508\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0192865662639636\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071286940307683\n",
      "std: 0.004753755081570551\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071807974609611\n",
      "std: 0.005033704352965542\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.07412505045694315\n",
      "min: 0.03767775807166941\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32980566067604644\n",
      "std: 0.2915333815422862\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.633487868620498\n",
      "std: 0.09216638640309723\n",
      "min: 0.3978497307513067\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019202413728033958\n",
      "min: 0.2071750899445349\n",
      "max: 0.2779915424877919\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2085415991742836\n",
      "std: 0.09893750413337861\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2139679586878507\n",
      "std: 0.10648910905424047\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.0753768000335011\n",
      "min: 0.025832038177094833\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35180337711488957\n",
      "std: 0.35806459561967174\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47541627063127684\n",
      "std: 0.1600046282065378\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0191511777665565\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080637494094073\n",
      "std: 0.0034719961210984635\n",
      "min: 1.3842515967500924\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080747811811447\n",
      "std: 0.0038582797075637607\n",
      "min: 1.3842515967500924\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.07412448349415025\n",
      "min: 0.03778477866656482\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33223860180826087\n",
      "std: 0.29106522080261166\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6302015755588108\n",
      "std: 0.09179635543164977\n",
      "min: 0.3959823812252252\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019205382810117556\n",
      "min: 0.2092843794497872\n",
      "max: 0.27792103652706873\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1319218430677593\n",
      "std: 0.2935440209235757\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1396000386308112\n",
      "std: 0.29597046101729846\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.08015875516479014\n",
      "min: 0.008725245544753972\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3505660393778804\n",
      "std: 0.35969191154093766\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47412772739650566\n",
      "std: 0.16281165387617277\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019364519831465\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4038781992246985\n",
      "std: 0.015276346058130066\n",
      "min: 1.309713343496024\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4040015057048465\n",
      "std: 0.015358308748086394\n",
      "min: 1.309713343496024\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07407407407407407\n",
      "std: 0.07414522717777614\n",
      "min: 0.035182088792926405\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33393824850683884\n",
      "std: 0.29099973195254153\n",
      "min: -0.8007488762610249\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6322206299875687\n",
      "std: 0.09492743613490809\n",
      "min: 0.39109718176988595\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019380799460680664\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1596624058087734\n",
      "std: 0.20777262796063076\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.166704778785736\n",
      "std: 0.21068216047370908\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07551893946747394\n",
      "min: 0.012953919620569458\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3366319120225512\n",
      "std: 0.36139341415844567\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4842988848010761\n",
      "std: 0.16193395878796119\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019071993889844232\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406984792222682\n",
      "std: 0.00535920120808444\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070509573399983\n",
      "std: 0.005432871202048459\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07206342994404832\n",
      "min: 0.036343009397918534\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32958757107479014\n",
      "std: 0.2917579344096984\n",
      "min: -0.801440184307197\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6340998581899266\n",
      "std: 0.09207535261553797\n",
      "min: 0.3992909589056391\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01919626628907656\n",
      "min: 0.2078622763800807\n",
      "max: 0.2779914238559012\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1531055603658726\n",
      "std: 0.2297749435250652\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1604343655291638\n",
      "std: 0.23353599115793966\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.0768145590219702\n",
      "min: 0.012277480605241307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33635173458533424\n",
      "std: 0.3672728153511635\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48407001043390147\n",
      "std: 0.16513891813443435\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01938053545679937\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4061688356630369\n",
      "std: 0.007876691083870548\n",
      "min: 1.3632262845475458\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406263583312605\n",
      "std: 0.007931752314967132\n",
      "min: 1.3632847653288143\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07206737123519148\n",
      "min: 0.03566480475715026\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3283272113919248\n",
      "std: 0.291619307155587\n",
      "min: -0.8005417286013798\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6339753143593846\n",
      "std: 0.09258034274044248\n",
      "min: 0.39686843698963087\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01918437098435965\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1580618926375552\n",
      "std: 0.22321365023210674\n",
      "min: -0.05614650130534389\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1653220798107622\n",
      "std: 0.2243910896282456\n",
      "min: -0.05614650130534389\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07519334633471095\n",
      "min: 0.010485201568579247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3390284057477506\n",
      "std: 0.36298313787548864\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4831254788515938\n",
      "std: 0.16184560431753459\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019278522342509184\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072132763210525\n",
      "std: 0.004695425505417967\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072548372254179\n",
      "std: 0.004962848010394301\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07206275962325467\n",
      "min: 0.036289030332926\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3302576826244928\n",
      "std: 0.2916805137735148\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6332040708574966\n",
      "std: 0.09224373982455306\n",
      "min: 0.3978497307513067\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019205244804704966\n",
      "min: 0.2071750899445349\n",
      "max: 0.2779915424877919\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2099341868967088\n",
      "std: 0.09781297241237366\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2155538652122142\n",
      "std: 0.1050772853299988\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.073262409785151\n",
      "min: 0.02477128742990695\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35225162369956947\n",
      "std: 0.3582162981480458\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4740958986129004\n",
      "std: 0.15966747148261226\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01914578435207387\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081205956131202\n",
      "std: 0.0034209009839716005\n",
      "min: 1.3842515967500924\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408123002408877\n",
      "std: 0.003792742480348211\n",
      "min: 1.3842515967500924\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07206221350929519\n",
      "min: 0.03661293528781838\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33261324106063267\n",
      "std: 0.29121618290994944\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6300069603785032\n",
      "std: 0.09188005928415431\n",
      "min: 0.3959823812252252\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01920747248762748\n",
      "min: 0.2092843794497872\n",
      "max: 0.27792103652706873\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1359413318446028\n",
      "std: 0.2894693039530021\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1436252093184869\n",
      "std: 0.2919618780971457\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07784336400620516\n",
      "min: 0.007525264474855244\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35116187525307063\n",
      "std: 0.3598342137939913\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4729062521703607\n",
      "std: 0.1623514486005483\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0193545626565232\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4040834465149359\n",
      "std: 0.015000119035672057\n",
      "min: 1.309713343496024\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4041886579656524\n",
      "std: 0.015087131411661526\n",
      "min: 1.309713343496024\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07142857142857142\n",
      "std: 0.07208209442768702\n",
      "min: 0.034459546341943426\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.334280454007067\n",
      "std: 0.2911432758883745\n",
      "min: -0.8008078406008212\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6319630055903379\n",
      "std: 0.09491202039381903\n",
      "min: 0.39109718176988595\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019378475099343904\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1634110417449117\n",
      "std: 0.2050169071917968\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.170461964058004\n",
      "std: 0.20793380436115305\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07343643621865699\n",
      "min: 0.012243285406212305\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33662130616845753\n",
      "std: 0.36163599557942105\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4855058352176512\n",
      "std: 0.16057868162175243\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018997584097525208\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070648698066104\n",
      "std: 0.005287845230997246\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071421084762652\n",
      "std: 0.005352245914714768\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07012054831217092\n",
      "min: 0.03503158048278697\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.329434312335686\n",
      "std: 0.2918128684662904\n",
      "min: -0.801440184307197\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6340634416515113\n",
      "std: 0.09203883211737149\n",
      "min: 0.3992909589056391\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019181140890102352\n",
      "min: 0.2078622763800807\n",
      "max: 0.2779914238559012\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1571170968526703\n",
      "std: 0.22635575088804794\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1644370851871362\n",
      "std: 0.23013408578280703\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07467775669338882\n",
      "min: 0.012277480605241307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3363955058058644\n",
      "std: 0.3673115788058835\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4852675932409977\n",
      "std: 0.16369116958974497\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019296474650013253\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4062726774072063\n",
      "std: 0.007787319724624493\n",
      "min: 1.3632262845475458\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4063768367345084\n",
      "std: 0.007837317195184074\n",
      "min: 1.363284765328814\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.0701243334996011\n",
      "min: 0.03444538579145397\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32820424371441903\n",
      "std: 0.2916670251315461\n",
      "min: -0.8005417286013796\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6339255596819058\n",
      "std: 0.09252074486793112\n",
      "min: 0.39686843698963087\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01916897565089469\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1618860703985565\n",
      "std: 0.2200269261143127\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1691465542809765\n",
      "std: 0.22124746381816096\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137932\n",
      "std: 0.07312498301499394\n",
      "min: 0.010485201568579247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3389609438833883\n",
      "std: 0.36321079452083005\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4843727684909479\n",
      "std: 0.16051388181030385\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019199212412855916\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072878732459146\n",
      "std: 0.004631371465206801\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073417748501114\n",
      "std: 0.004884995922381637\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07011990495653163\n",
      "min: 0.03509849793288726\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33007846772342875\n",
      "std: 0.2917405011919378\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6331873799163102\n",
      "std: 0.09220039800681674\n",
      "min: 0.3978497307513067\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01918949655304177\n",
      "min: 0.2071750899445349\n",
      "max: 0.2779915424877919\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2120827631757418\n",
      "std: 0.09607097009199113\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2178267551364617\n",
      "std: 0.10320416152162208\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07127031986107514\n",
      "min: 0.024771287429906946\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35175289755855244\n",
      "std: 0.35851714250920735\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4755387407543367\n",
      "std: 0.15841974242075468\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01906899488240709\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408172601688278\n",
      "std: 0.0033780237918260877\n",
      "min: 1.3842515967500924\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081890006911058\n",
      "std: 0.00373007342036885\n",
      "min: 1.3842515967500924\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.0701193792453979\n",
      "min: 0.03525976373292429\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3323641797935317\n",
      "std: 0.2912844433750439\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6300702174505923\n",
      "std: 0.09184884505371191\n",
      "min: 0.3959823812252252\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01919110384650842\n",
      "min: 0.2092843794497872\n",
      "max: 0.27792103652706873\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1406974809866481\n",
      "std: 0.2846942354385943\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1483372069799707\n",
      "std: 0.2872644462052873\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07566483780388689\n",
      "min: 0.007525264474855244\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3507836123865037\n",
      "std: 0.360114325386405\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47444434768418225\n",
      "std: 0.1610403119419595\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019272902156836635\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4042677347668855\n",
      "std: 0.014765310372038107\n",
      "min: 1.309713343496024\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4043789792860102\n",
      "std: 0.01485662617526278\n",
      "min: 1.309713343496024\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06896551724137931\n",
      "std: 0.07013846850086464\n",
      "min: 0.03308245104065968\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33399606344467714\n",
      "std: 0.2912069088442687\n",
      "min: -0.8008078406008212\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6319704353424825\n",
      "std: 0.0947883499805158\n",
      "min: 0.39109718176988595\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019357944288152656\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1651666980007107\n",
      "std: 0.2013204643321795\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1719338844621765\n",
      "std: 0.2042574154012622\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.0714730727502398\n",
      "min: 0.012243285406212305\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33490534257679455\n",
      "std: 0.36002443951303587\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4836921159013904\n",
      "std: 0.1594023938936809\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018860943347284023\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407094844987755\n",
      "std: 0.005223091741961908\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071527925380611\n",
      "std: 0.005297719903955087\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.06828679089636666\n",
      "min: 0.03384785845565295\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32910777728416796\n",
      "std: 0.29173986113877665\n",
      "min: -0.801440184307197\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6336867679105673\n",
      "std: 0.0918820881614975\n",
      "min: 0.3992909589056391\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01914703108730332\n",
      "min: 0.2078622763800807\n",
      "max: 0.2779914238559012\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.159087885081485\n",
      "std: 0.22219335256546704\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1661070232206756\n",
      "std: 0.22599463466263547\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.07266456328913375\n",
      "min: 0.012277480605241307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33473182593694095\n",
      "std: 0.36553293727855996\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48344193922500817\n",
      "std: 0.16243430511712809\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019152266886927775\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406328710273983\n",
      "std: 0.0076798474803687925\n",
      "min: 1.3632262845475458\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4064119401203024\n",
      "std: 0.0077384582509679445\n",
      "min: 1.363284765328814\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.06829042863908416\n",
      "min: 0.03331332305001513\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3279060527868648\n",
      "std: 0.2915869987464199\n",
      "min: -0.8005417286013796\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6335353854043153\n",
      "std: 0.09234485399897753\n",
      "min: 0.39686843698963087\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019134573294486267\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.163588449564584\n",
      "std: 0.21687462626824588\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1705582712609557\n",
      "std: 0.21812670573061105\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.07117611979522989\n",
      "min: 0.010485201568579247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33719849875424757\n",
      "std: 0.3615801401373814\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48257482530877366\n",
      "std: 0.15933898388017317\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01905819749672329\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073103208910862\n",
      "std: 0.004599905323941749\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073461238419687\n",
      "std: 0.004859263605435955\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.06828617439920484\n",
      "min: 0.03373756554642071\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32972817036152885\n",
      "std: 0.29167078478194725\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.632824843841651\n",
      "std: 0.09203531737618272\n",
      "min: 0.3978497307513067\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01915476118064354\n",
      "min: 0.2071750899445349\n",
      "max: 0.2779915424877919\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2120921741944064\n",
      "std: 0.09484559352882398\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2176532502568582\n",
      "std: 0.10189624547524433\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.06939213619957917\n",
      "min: 0.02427694678421792\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3495882071389192\n",
      "std: 0.35701848198405844\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47395390084269257\n",
      "std: 0.1572290180974011\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01893130008674199\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081725919004136\n",
      "std: 0.003357120800785305\n",
      "min: 1.3842515967500924\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081725902345488\n",
      "std: 0.00371519011295826\n",
      "min: 1.3842515967500924\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666665\n",
      "std: 0.06828566626073873\n",
      "min: 0.033820463145873246\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3319500622314235\n",
      "std: 0.2912251956336669\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6297864302506104\n",
      "std: 0.09168671187667146\n",
      "min: 0.3959823812252252\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019156009553403068\n",
      "min: 0.2092843794497872\n",
      "max: 0.27792103652706873\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1430668772615553\n",
      "std: 0.2800858482323788\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1503813966159713\n",
      "std: 0.2827085906937287\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.07361413921440073\n",
      "min: 0.007525264474855244\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34871954936718086\n",
      "std: 0.3585868955287752\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4729274200998285\n",
      "std: 0.1597440075447685\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019130895573177133\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4043905701886399\n",
      "std: 0.01455127657980157\n",
      "min: 1.309713343496024\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4044780504358885\n",
      "std: 0.014651048493292842\n",
      "min: 1.309713343496024\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06666666666666667\n",
      "std: 0.0683040234389708\n",
      "min: 0.03191663223358927\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3335443614954883\n",
      "std: 0.29114169196153616\n",
      "min: -0.8008078406008212\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6316306740775907\n",
      "std: 0.09454880239479489\n",
      "min: 0.39109718176988595\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019318779600584226\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1660093184576692\n",
      "std: 0.19784924720139188\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1724721288403828\n",
      "std: 0.2008637839077574\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06961935940681127\n",
      "min: 0.012243285406212305\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3348743253369545\n",
      "std: 0.36092824880525476\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4822993554175525\n",
      "std: 0.15900112832159313\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018833019199984324\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071938093744094\n",
      "std: 0.005150579966089123\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407251275998441\n",
      "std: 0.005224845866794486\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06655300277868867\n",
      "min: 0.032702475902800614\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3288776615532137\n",
      "std: 0.29181463925501683\n",
      "min: -0.801440184307197\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6333400559519187\n",
      "std: 0.09184718132371546\n",
      "min: 0.3992909589056391\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019141359770357726\n",
      "min: 0.2078622763800807\n",
      "max: 0.2779914238559012\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1601240983036027\n",
      "std: 0.21848996470387322\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1668257088534872\n",
      "std: 0.2223535187016317\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.07076484907455269\n",
      "min: 0.012277480605241307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.334747052245672\n",
      "std: 0.3662400121028085\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4820344229009253\n",
      "std: 0.16193563480675385\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01911583958496823\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406452731175681\n",
      "std: 0.007571740959437419\n",
      "min: 1.3632262845475458\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065339875471505\n",
      "std: 0.007632351364295945\n",
      "min: 1.363284765328814\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06655650334305292\n",
      "min: 0.03227849132140671\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32770253582341163\n",
      "std: 0.2916553304498665\n",
      "min: -0.8005417286013796\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6331777256194682\n",
      "std: 0.09229085541363467\n",
      "min: 0.39686843698963087\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019128645384089617\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.164470357590451\n",
      "std: 0.2132921098525775\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1711279066591072\n",
      "std: 0.21465623468714098\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06933488350717894\n",
      "min: 0.010485201568579247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3371137913925044\n",
      "std: 0.3624611618847733\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.48119837584124564\n",
      "std: 0.15894450020628145\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01902535032670893\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407402588973617\n",
      "std: 0.004543796419985564\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074388738892956\n",
      "std: 0.004798961679876707\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06655241029891444\n",
      "min: 0.03275551332925335\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3294758114760162\n",
      "std: 0.2917497828988261\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6324931552894673\n",
      "std: 0.09199250833439286\n",
      "min: 0.3978497307513067\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01914858015309003\n",
      "min: 0.2071750899445349\n",
      "max: 0.2779915424877919\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.211319504368197\n",
      "std: 0.09407490375711496\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2166714140479755\n",
      "std: 0.10109060836168923\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06761745211456427\n",
      "min: 0.022280841443085894\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3491361869928949\n",
      "std: 0.3579595863388517\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47276707928370715\n",
      "std: 0.15683955293923865\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0189017382919902\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082376089930946\n",
      "std: 0.003319472068839809\n",
      "min: 1.3842515967500924\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082398654140367\n",
      "std: 0.0036693980807562814\n",
      "min: 1.3842515967500924\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06655192001666413\n",
      "min: 0.03281993696838979\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33163810784330194\n",
      "std: 0.291312021089337\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6295289030978908\n",
      "std: 0.09164706111900278\n",
      "min: 0.3959823812252252\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01914937600051369\n",
      "min: 0.2092843794497872\n",
      "max: 0.27792103652706873\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1447548148644233\n",
      "std: 0.2751081386253739\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1517219100142333\n",
      "std: 0.27782780469101787\n",
      "min: -0.4566026259993952\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.07167851306700457\n",
      "min: 0.007525264474855244\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3483685050652618\n",
      "std: 0.3595206770353799\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47182001598147116\n",
      "std: 0.1592309146493376\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01909734298455942\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4045811537752833\n",
      "std: 0.01432427937141409\n",
      "min: 1.309713343496024\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.404664034376723\n",
      "std: 0.014429533572038987\n",
      "min: 1.309713343496024\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06451612903225806\n",
      "std: 0.06656959002659817\n",
      "min: 0.03093403988159194\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.333197571280059\n",
      "std: 0.2912252454189266\n",
      "min: -0.8008078406008212\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6313227914674082\n",
      "std: 0.0944337135841295\n",
      "min: 0.39109718176988595\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01930832665929565\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1667219038093712\n",
      "std: 0.19543605916756498\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1728486273171959\n",
      "std: 0.19846312938132146\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.0678663780364848\n",
      "min: 0.01065291048590247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3360120923701393\n",
      "std: 0.36046365430256255\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4797816506851252\n",
      "std: 0.15922721031245302\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01882472839304743\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072240911539255\n",
      "std: 0.0050837493114301024\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072584200509737\n",
      "std: 0.005163132685257651\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06491104056654798\n",
      "min: 0.0317126945976494\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3289323656451212\n",
      "std: 0.29193679666383926\n",
      "min: -0.801440184307197\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6330430311891749\n",
      "std: 0.09194041057424245\n",
      "min: 0.3992909589056391\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019145618649906673\n",
      "min: 0.2078622763800807\n",
      "max: 0.2779914238559012\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1610304387775914\n",
      "std: 0.215731735435333\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.167383640790088\n",
      "std: 0.21959278812155855\n",
      "min: -0.03386190215710636\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.0689688893704885\n",
      "min: 0.011473070600501548\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33593057089121814\n",
      "std: 0.3656227254524861\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47950784627538945\n",
      "std: 0.1620710399219225\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019098781195164217\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065058371058723\n",
      "std: 0.007473557337615172\n",
      "min: 1.3632262845475458\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065625917304074\n",
      "std: 0.00753794510598097\n",
      "min: 1.363284765328814\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06491441401645301\n",
      "min: 0.0311561917913625\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3277832981499463\n",
      "std: 0.2917735103210983\n",
      "min: -0.8005417286013796\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6328700304346512\n",
      "std: 0.09236621844247815\n",
      "min: 0.39686843698963087\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019132715822930014\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1652546674235638\n",
      "std: 0.21042634328406415\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1715701351169325\n",
      "std: 0.211816385517823\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06759286114171822\n",
      "min: 0.010485201568579247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33820772428818185\n",
      "std: 0.361974260978173\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47871715464374215\n",
      "std: 0.15917865963955263\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019012631208418618\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074247140315062\n",
      "std: 0.004487447435180581\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074388195287346\n",
      "std: 0.004744226871490181\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06491046992578262\n",
      "min: 0.031791449806561546\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3295092414051313\n",
      "std: 0.29187546285342003\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6322126665315442\n",
      "std: 0.09207808315463142\n",
      "min: 0.3978497307513067\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019152343771447283\n",
      "min: 0.2071750899445349\n",
      "max: 0.2779915424877919\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2106612686777831\n",
      "std: 0.09314985731181781\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2157562428633526\n",
      "std: 0.10011788725691813\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06593725396035433\n",
      "min: 0.022280841443085894\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3498735057181432\n",
      "std: 0.3575050439043883\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47047500282756166\n",
      "std: 0.15701381024228306\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018890970108853846\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408231890336147\n",
      "std: 0.0032996893703938733\n",
      "min: 1.3842515967500924\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082137389722247\n",
      "std: 0.003650628780698127\n",
      "min: 1.3842515967500924\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06490999703124377\n",
      "min: 0.031856003775096\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3316130474723214\n",
      "std: 0.2914429640861666\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6293190027714529\n",
      "std: 0.0917358683352011\n",
      "min: 0.3959823812252252\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019152527569668315\n",
      "min: 0.2092843794497872\n",
      "max: 0.27792103652706873\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.145963554019295\n",
      "std: 0.2720914858314582\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1525590281601514\n",
      "std: 0.2748426317138535\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06985005560575314\n",
      "min: 0.006186380336109203\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.349204796714352\n",
      "std: 0.3590446498838214\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4695659573624637\n",
      "std: 0.15931531099616775\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01908296703406317\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.404680652608262\n",
      "std: 0.014165288848327384\n",
      "min: 1.309713343496024\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.404737227916542\n",
      "std: 0.014275620907278998\n",
      "min: 1.309713343496024\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0625\n",
      "std: 0.06492703935484977\n",
      "min: 0.02958868694967943\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3331409764768119\n",
      "std: 0.2913502550859547\n",
      "min: -0.8008078406008212\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6310610901036062\n",
      "std: 0.0944495633915931\n",
      "min: 0.39109718176988595\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019307852351877444\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.168915812570452\n",
      "std: 0.1938382198884879\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1747949632169299\n",
      "std: 0.19681455050222826\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06620561651138787\n",
      "min: 0.010119371837119922\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33695270805302685\n",
      "std: 0.3610463101554184\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4773761306000157\n",
      "std: 0.16050527766182082\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01879296465068209\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072050062473616\n",
      "std: 0.00508916273231672\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40723977323516\n",
      "std: 0.005175862897928279\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06335363417482419\n",
      "min: 0.030442467691774222\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3292588491563304\n",
      "std: 0.29204482020687395\n",
      "min: -0.8014401843071969\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.632493490722749\n",
      "std: 0.09214914112154854\n",
      "min: 0.3911669824056884\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01915295846900477\n",
      "min: 0.2078622763800807\n",
      "max: 0.2779914238559012\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.16340937557553\n",
      "std: 0.21412048855141863\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1695041467004479\n",
      "std: 0.21791539151913397\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06726817019599714\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3369075605957593\n",
      "std: 0.36604252476044524\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47709812496029147\n",
      "std: 0.1632378968788635\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01905875490595292\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406505768746274\n",
      "std: 0.007475429829002553\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406561904510352\n",
      "std: 0.007546114029719859\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06335689428882589\n",
      "min: 0.02979573761722687\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3281322328776902\n",
      "std: 0.2918772969393906\n",
      "min: -0.8005417286013797\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.632311215060865\n",
      "std: 0.09255835138685653\n",
      "min: 0.390614055347708\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019139816528866135\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1675358455072562\n",
      "std: 0.20801628052237728\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.173596395956649\n",
      "std: 0.20940329790537984\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06594214159982008\n",
      "min: 0.010485201568579247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3390933655333969\n",
      "std: 0.3625299061243421\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4763410587337018\n",
      "std: 0.1604604595851511\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018975921181411108\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40740345733388\n",
      "std: 0.004503691896414863\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074188376066288\n",
      "std: 0.004764788026401956\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06335308349577204\n",
      "min: 0.030505663020302276\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32981518938790144\n",
      "std: 0.29198575249117303\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.631677362406074\n",
      "std: 0.09227978879283961\n",
      "min: 0.390780840334538\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01915920496867393\n",
      "min: 0.2071750899445349\n",
      "max: 0.2779915424877919\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.211787201045519\n",
      "std: 0.09193615190639365\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2167023147493492\n",
      "std: 0.09879837560561405\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06434365086653013\n",
      "min: 0.0222808414430859\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3504155213305576\n",
      "std: 0.35810394891714387\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46829734461154027\n",
      "std: 0.15825311342839438\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018856565974043768\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081990350472682\n",
      "std: 0.0033072996791061343\n",
      "min: 1.3838602833854572\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081833160406512\n",
      "std: 0.0036632721250632445\n",
      "min: 1.3838602833854572\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06335262359096751\n",
      "min: 0.030624984419506725\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33185975022861397\n",
      "std: 0.2915564527882188\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6288537795874175\n",
      "std: 0.09193477452794172\n",
      "min: 0.39067148885145353\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019158828636318015\n",
      "min: 0.2092843794497872\n",
      "max: 0.27792103652706873\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1490136582869406\n",
      "std: 0.2688901848123671\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1553250003197033\n",
      "std: 0.271633987674884\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06811769468393278\n",
      "min: 0.006166630372460981\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34982983905634707\n",
      "std: 0.3596326614146823\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4674357437139618\n",
      "std: 0.16044421600497688\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01904470973092874\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4047391951163504\n",
      "std: 0.01404476742289726\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4047932325631103\n",
      "std: 0.01416334184189918\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.06060606060606061\n",
      "std: 0.06336908467475992\n",
      "min: 0.02853673668663731\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3333580227864583\n",
      "std: 0.29145913231286513\n",
      "min: -0.8008078406008211\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.630546368410958\n",
      "std: 0.09457598554831831\n",
      "min: 0.3889555089354744\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01931063850757989\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.171091526919481\n",
      "std: 0.19146190529573084\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1769468997790897\n",
      "std: 0.19438877265230017\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06462870655505434\n",
      "min: 0.010119371837119922\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3374071545626276\n",
      "std: 0.36118445379421954\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4788463583874342\n",
      "std: 0.15927701060866498\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018730011194777154\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072390695834638\n",
      "std: 0.0050393346224842\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072456732379488\n",
      "std: 0.0051370869850540755\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06187425463543663\n",
      "min: 0.02976432281028105\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3292645106343528\n",
      "std: 0.2921185609619276\n",
      "min: -0.8014401843071969\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6323776314541457\n",
      "std: 0.09213744356595456\n",
      "min: 0.3911669824056884\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019146155178447893\n",
      "min: 0.2078622763800807\n",
      "max: 0.2779914238559012\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.165770022551329\n",
      "std: 0.21109452508062762\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1718299467312454\n",
      "std: 0.21484833504810652\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06565365634808731\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.337392999638445\n",
      "std: 0.36603214874865986\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47856323851223953\n",
      "std: 0.16194200261711905\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01898915687436687\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065606511022093\n",
      "std: 0.007367048781331037\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065874872726292\n",
      "std: 0.007446109383195871\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.0618774009923154\n",
      "min: 0.02945836416384097\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32815959401840145\n",
      "std: 0.2919472751783073\n",
      "min: -0.8005417286013797\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6321882425830402\n",
      "std: 0.0925296151428721\n",
      "min: 0.390614055347708\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01913282781001483\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.169742947914815\n",
      "std: 0.205463016882291\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.175774293697292\n",
      "std: 0.20682627592416156\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06437511101894926\n",
      "min: 0.010213283256333729\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3395038652328112\n",
      "std: 0.3626429867444221\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47783289533999374\n",
      "std: 0.15924439713108798\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01890905049025057\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40743132486655\n",
      "std: 0.0044690540532731065\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407419329541711\n",
      "std: 0.004737858735044614\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06187372323059619\n",
      "min: 0.02976956157977919\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3298024989980004\n",
      "std: 0.2920623966323453\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6315757236351679\n",
      "std: 0.09226235555152705\n",
      "min: 0.390780840334538\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019151947847688772\n",
      "min: 0.2071750899445349\n",
      "max: 0.2779915424877919\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2127157057283837\n",
      "std: 0.0909631877241077\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2176778977145364\n",
      "std: 0.09759190391253098\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06283048989788019\n",
      "min: 0.021532927098359758\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3505121426303011\n",
      "std: 0.3582756582698541\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4699480291380392\n",
      "std: 0.15713171013722824\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018791991374132042\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082049516674784\n",
      "std: 0.0033024530070117453\n",
      "min: 1.3838602833854572\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081632476474937\n",
      "std: 0.003666833479744317\n",
      "min: 1.3838602833854572\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06187327819910152\n",
      "min: 0.02975874470003744\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3317947405390365\n",
      "std: 0.2916387875545138\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6288147920399838\n",
      "std: 0.09192567992358458\n",
      "min: 0.39067148885145353\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019151178410509635\n",
      "min: 0.2092843794497872\n",
      "max: 0.27792103652706873\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1516532674205808\n",
      "std: 0.2656292293797735\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.157915316681855\n",
      "std: 0.26837087591437725\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06647477434593503\n",
      "min: 0.006166630372460981\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3500072224895801\n",
      "std: 0.35978184190554247\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4691422276811926\n",
      "std: 0.15927927665258518\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018976988935841627\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4048524315667617\n",
      "std: 0.013818761910077497\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4048752814469843\n",
      "std: 0.01394459120907968\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.058823529411764705\n",
      "std: 0.06188917380617098\n",
      "min: 0.028201037453457846\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3332637282742637\n",
      "std: 0.2915381956978587\n",
      "min: -0.8008078406008211\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6304633368521211\n",
      "std: 0.09449931493571524\n",
      "min: 0.3889555089354744\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019299686230344917\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1721928683342804\n",
      "std: 0.18881196127060942\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1776020523649096\n",
      "std: 0.1917610689019523\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06313003076147403\n",
      "min: 0.010119371837119922\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3382267981699058\n",
      "std: 0.3613417874407611\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47867093599130495\n",
      "std: 0.15851205530189078\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01871053881445881\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072670765169448\n",
      "std: 0.004977544024098358\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072645875181211\n",
      "std: 0.0050728048718136935\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.060467047137647396\n",
      "min: 0.028910548954408057\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.329210459434569\n",
      "std: 0.2922517707641985\n",
      "min: -0.8014401843071969\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.632452819886273\n",
      "std: 0.09200033453623387\n",
      "min: 0.3911669824056884\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019135591319989907\n",
      "min: 0.2078622763800807\n",
      "max: 0.2779914238559012\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1670129707100976\n",
      "std: 0.2081468920677371\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.172618155429508\n",
      "std: 0.21190384644677276\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06412014390536155\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3382444786665635\n",
      "std: 0.3660506594992763\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4783752236143614\n",
      "std: 0.1611120173073052\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018962834724959108\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066060706086185\n",
      "std: 0.0072779816921296515\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406622825986394\n",
      "std: 0.007355926359529402\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06047008929871667\n",
      "min: 0.028398826672171015\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32812746607974935\n",
      "std: 0.2920773229389592\n",
      "min: -0.8005417286013797\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6322557962249644\n",
      "std: 0.09237747536429441\n",
      "min: 0.390614055347708\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019122069000169065\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.17079019015614\n",
      "std: 0.20343473430050027\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1763705564234812\n",
      "std: 0.2048293991545831\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06288644158429962\n",
      "min: 0.010002868444101837\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34028694148544913\n",
      "std: 0.36276446943278473\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4776658922174634\n",
      "std: 0.15848457541905683\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018885476927891755\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074521323553841\n",
      "std: 0.004422659388881643\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074318650575572\n",
      "std: 0.004685583498443804\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06046653405675136\n",
      "min: 0.028935063593044225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32973211984862844\n",
      "std: 0.29219757271733765\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6316629985443271\n",
      "std: 0.09212027935355838\n",
      "min: 0.390780840334538\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01914095449990594\n",
      "min: 0.2071750899445349\n",
      "max: 0.2779915424877919\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2126000147774323\n",
      "std: 0.09037101247786003\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.217173187962128\n",
      "std: 0.09699983928292402\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06139204248077031\n",
      "min: 0.019740216752738418\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3509937823357343\n",
      "std: 0.3584595789908352\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4699473420762273\n",
      "std: 0.15641177699261558\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01877113860871983\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082052057609498\n",
      "std: 0.0032780524470358797\n",
      "min: 1.3838602833854572\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408156366024821\n",
      "std: 0.0036336930957883416\n",
      "min: 1.3838602833854572\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06046610296403012\n",
      "min: 0.028920173768268477\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33167529133862467\n",
      "std: 0.2917817851587069\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.628962163245874\n",
      "std: 0.09179482558146684\n",
      "min: 0.39067148885145353\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019139896296646076\n",
      "min: 0.2092843794497872\n",
      "max: 0.27792103652706873\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1532156303344248\n",
      "std: 0.2622243276354653\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1590075812748764\n",
      "std: 0.2649829043119522\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06491444545559857\n",
      "min: 0.006166630372460981\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.350562233067118\n",
      "std: 0.35994409050761067\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46919148720965476\n",
      "std: 0.1584962364797802\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018951744724597326\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4049335091250414\n",
      "std: 0.013691148874594572\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4049452355346692\n",
      "std: 0.013817809776175348\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05714285714285714\n",
      "std: 0.06048148465006491\n",
      "min: 0.026817782197565348\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33311610347386844\n",
      "std: 0.29167705110226244\n",
      "min: -0.8008078406008211\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.630571013240138\n",
      "std: 0.09430414517222324\n",
      "min: 0.3889555089354744\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01928520188026908\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1718696418998795\n",
      "std: 0.18606933836203432\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1772592196910254\n",
      "std: 0.18903858599288156\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.061703745133410065\n",
      "min: 0.010119371837119922\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3400659773640238\n",
      "std: 0.3611566922235721\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4754809333071027\n",
      "std: 0.1595665117637808\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018697143972295074\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407270186582651\n",
      "std: 0.0049328549408784745\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072386346559098\n",
      "std: 0.005052120350720083\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.05912673294704278\n",
      "min: 0.028006929596058504\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3295166931917488\n",
      "std: 0.29233861305182707\n",
      "min: -0.8015765408922235\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6319908072185886\n",
      "std: 0.09191038162470998\n",
      "min: 0.3911669824056884\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019132251440001472\n",
      "min: 0.2078622763800807\n",
      "max: 0.2779914238559012\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1668252821629572\n",
      "std: 0.2054858796178428\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1724025369492677\n",
      "std: 0.2092528860395025\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.06266135901447199\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3401217865495134\n",
      "std: 0.36573903341388\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4751797536109858\n",
      "std: 0.16207507105687194\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01894273622142712\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066257804895537\n",
      "std: 0.007205573407809959\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066126919495785\n",
      "std: 0.007300423691599285\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.05912967768597081\n",
      "min: 0.027556500870309506\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3284550365785765\n",
      "std: 0.2921617003953735\n",
      "min: -0.8008303933291068\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6317862698294984\n",
      "std: 0.09227392317110159\n",
      "min: 0.390614055347708\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019118550262137938\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1705238701942344\n",
      "std: 0.2002927120769439\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1760787079639836\n",
      "std: 0.2017414893198439\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.06146857159874451\n",
      "min: 0.010002868444101837\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3420875192064338\n",
      "std: 0.3625492055165411\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47449746687041655\n",
      "std: 0.1595230410776513\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018868100618581487\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40745026864795\n",
      "std: 0.004402449379005701\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074016095288808\n",
      "std: 0.004686986021286284\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.05912623745104128\n",
      "min: 0.02800023548815181\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33002244427370275\n",
      "std: 0.29228617881450814\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6312128873069389\n",
      "std: 0.09202418789809867\n",
      "min: 0.390780840334538\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019137213275986137\n",
      "min: 0.2071750899445349\n",
      "max: 0.2779915424877919\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.211162944866511\n",
      "std: 0.08940570098067045\n",
      "min: 0.6875039894547316\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2157749787821899\n",
      "std: 0.09592489324465335\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.06002200812367253\n",
      "min: 0.019740216752738418\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35250700237188354\n",
      "std: 0.358258215729757\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46694076523839123\n",
      "std: 0.15740975041446173\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018756099855683744\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081843653182693\n",
      "std: 0.0032878366799900683\n",
      "min: 1.3818107108243127\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081083832481085\n",
      "std: 0.003667404400740927\n",
      "min: 1.3818107108243127\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.05912581943455051\n",
      "min: 0.027988933967001323\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3319171938846982\n",
      "std: 0.29187459461022885\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6285724889775273\n",
      "std: 0.09169884679876017\n",
      "min: 0.39067148885145353\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019135778263466456\n",
      "min: 0.2092843794497872\n",
      "max: 0.27792103652706873\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.153515556824762\n",
      "std: 0.2585467114033872\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1592613255291218\n",
      "std: 0.26135766708761643\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.0634298855542131\n",
      "min: 0.006166630372460981\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3521607742435878\n",
      "std: 0.35973883452004113\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46622107231656457\n",
      "std: 0.15938429865608242\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01893389619552649\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4049981361321906\n",
      "std: 0.01353996796695084\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4049787590642695\n",
      "std: 0.013676483547695042\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05555555555555555\n",
      "std: 0.0591407122143916\n",
      "min: 0.02626873095606681\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.333333817398741\n",
      "std: 0.2917655120165511\n",
      "min: -0.8010128100549136\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6301377499185625\n",
      "std: 0.09415144842437953\n",
      "min: 0.3889555089354744\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01927815534724764\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1720967243234948\n",
      "std: 0.18446705558713014\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1775616832438514\n",
      "std: 0.18736002551928116\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.060345412552073416\n",
      "min: 0.009317739624232905\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3410725959110077\n",
      "std: 0.36154578172040425\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47629862920536936\n",
      "std: 0.15998994225541735\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01870412695161122\n",
      "min: 0.20238606619920643\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073082677090725\n",
      "std: 0.004892326992173444\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072878414520102\n",
      "std: 0.005005087638081264\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.05784854025012126\n",
      "min: 0.027110471258217098\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3295688305202711\n",
      "std: 0.2923225971757939\n",
      "min: -0.8015765408922237\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6320329901971369\n",
      "std: 0.09183876939868718\n",
      "min: 0.3911669824056884\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019135674915967685\n",
      "min: 0.2078622763800807\n",
      "max: 0.2779914238559012\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1672261474239969\n",
      "std: 0.20329731180645655\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.172868752105229\n",
      "std: 0.20701245902468596\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.06127198089949303\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34115885449808575\n",
      "std: 0.36600088483951854\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47600064140805426\n",
      "std: 0.1624161830351374\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018943201311476383\n",
      "min: 0.20228467693525368\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066810416414322\n",
      "std: 0.007132838223443005\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406678265748429\n",
      "std: 0.007225872298741084\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.05785139275627657\n",
      "min: 0.02669894389996781\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3285260735023724\n",
      "std: 0.29214292260548164\n",
      "min: -0.8008303933291065\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6318234993825502\n",
      "std: 0.09218937148476623\n",
      "min: 0.390614055347708\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019121859797782564\n",
      "min: 0.20665074214840007\n",
      "max: 0.2780097060609751\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1708380160879313\n",
      "std: 0.1979996816018393\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1764620065928815\n",
      "std: 0.19942194113387907\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.06011780409527324\n",
      "min: 0.009430200681931684\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34305253342398007\n",
      "std: 0.36291619263853886\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4753428611990156\n",
      "std: 0.15995849953277352\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018871402006683538\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074836532747812\n",
      "std: 0.004362400852109842\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074467813189628\n",
      "std: 0.004638529390787272\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.05784806011730048\n",
      "min: 0.027198271730604396\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3300591526481053\n",
      "std: 0.2922729285279875\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6312679093200462\n",
      "std: 0.09194945087004743\n",
      "min: 0.390780840334538\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019140323299674352\n",
      "min: 0.2071750899445349\n",
      "max: 0.2779915424877919\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2103994112634346\n",
      "std: 0.08940739210304599\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2151401204473065\n",
      "std: 0.09559611137681341\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.05871625800223185\n",
      "min: 0.018961525349030825\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35321581742844055\n",
      "std: 0.35866300094681386\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4679302378059968\n",
      "std: 0.1579180417880518\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018761149346532432\n",
      "min: 0.20350045534547928\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408199880474217\n",
      "std: 0.003255218151571362\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081367777462606\n",
      "std: 0.003621704427659463\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.05784765400941354\n",
      "min: 0.027389756054427963\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33190930911594546\n",
      "std: 0.29186639501068673\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6286829412548004\n",
      "std: 0.09163392160217933\n",
      "min: 0.39067148885145353\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01913854941521251\n",
      "min: 0.2092843794497872\n",
      "max: 0.27792103652706873\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.154475693991284\n",
      "std: 0.25468850053994646\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.160266790933832\n",
      "std: 0.25751952400036554\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.062016007271664904\n",
      "min: 0.006166630372460981\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35292364878094334\n",
      "std: 0.36011978318031823\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46726244032117425\n",
      "std: 0.159826283351912\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018936050356067824\n",
      "min: 0.20245409658607497\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4051006648428692\n",
      "std: 0.01336781675895295\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4050902912122842\n",
      "std: 0.013507254166345732\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05405405405405406\n",
      "std: 0.057862083362304306\n",
      "min: 0.02564955077315746\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33329890622209796\n",
      "std: 0.2917537552496397\n",
      "min: -0.8010128100549134\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6302133212581373\n",
      "std: 0.094025198103254\n",
      "min: 0.3889555089354744\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01927806194174258\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1739888519841233\n",
      "std: 0.18250914576274518\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.179221682006701\n",
      "std: 0.18535838988322237\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05904893116680001\n",
      "min: 0.009304979576478311\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3411975908605924\n",
      "std: 0.36152049786004004\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4775149500312871\n",
      "std: 0.16129953420471077\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01875381820910875\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072744989998691\n",
      "std: 0.004873547553629229\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407241543972394\n",
      "std: 0.005000075239301278\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05662814671813371\n",
      "min: 0.02642968796689273\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32979483194276904\n",
      "std: 0.2923655555034184\n",
      "min: -0.8015765408922237\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6318426531764042\n",
      "std: 0.09200232963502734\n",
      "min: 0.38305640168109656\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019149319117895285\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1692362710177036\n",
      "std: 0.2012351797639728\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1746396112188686\n",
      "std: 0.20489497263144196\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05994656143111053\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3413038722135904\n",
      "std: 0.3658641739281186\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4772158897503543\n",
      "std: 0.16364137458991898\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018985888323857378\n",
      "min: 0.201862918460537\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406661006235382\n",
      "std: 0.007097326710189676\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406645049471117\n",
      "std: 0.007200733040552599\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05663091418609651\n",
      "min: 0.025838374162479364\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32877010516225913\n",
      "std: 0.29218399101027165\n",
      "min: -0.8008303933291065\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6316283205964971\n",
      "std: 0.09234096770775976\n",
      "min: 0.38256543125136727\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01913541597184898\n",
      "min: 0.20665074214840007\n",
      "max: 0.27827431333710057\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1727534068313696\n",
      "std: 0.19597235740865016\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1781403800580066\n",
      "std: 0.1973745797070376\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05882889295096384\n",
      "min: 0.008665723397299947\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3431342702459976\n",
      "std: 0.362876110044105\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47657901669425956\n",
      "std: 0.16128864078906557\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018916584315584423\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074470374991166\n",
      "std: 0.004375939285973356\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073980977991543\n",
      "std: 0.004661245347763874\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05662768249499207\n",
      "min: 0.026365012315795574\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33027040582917566\n",
      "std: 0.29231790319132156\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6310883266139256\n",
      "std: 0.09210856501680657\n",
      "min: 0.3826395672994968\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019153665874890993\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.211295472097498\n",
      "std: 0.08851621059388293\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.215850492330234\n",
      "std: 0.09460208688081696\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.057469493016496835\n",
      "min: 0.01833100890741517\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.353043006083318\n",
      "std: 0.3586811185496424\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46931124211589276\n",
      "std: 0.15933011292133456\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01880872045375281\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081502088944853\n",
      "std: 0.003269418103600075\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408076088918037\n",
      "std: 0.0036459143258649068\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05662728656902886\n",
      "min: 0.02646599513599428\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.332076355665541\n",
      "std: 0.29191529933154714\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6285572852124179\n",
      "std: 0.0917954575786211\n",
      "min: 0.3826233040490345\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019151509899506942\n",
      "min: 0.2092843794497872\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1567499852449405\n",
      "std: 0.2521870769345427\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1622914650934715\n",
      "std: 0.254992520686534\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.06066817947417005\n",
      "min: 0.005570598384979188\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3528032138902167\n",
      "std: 0.360126175415258\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4686795735924913\n",
      "std: 0.1611850941899416\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018980711989221258\n",
      "min: 0.2017041520919134\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4051248659163398\n",
      "std: 0.013232160922885816\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405100341267365\n",
      "std: 0.013379553031372641\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05263157894736842\n",
      "std: 0.05664128283516805\n",
      "min: 0.024816757670857753\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33344137609758\n",
      "std: 0.2917992900578651\n",
      "min: -0.8010128100549134\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6300515809371137\n",
      "std: 0.0941310064319465\n",
      "min: 0.38110284667940186\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019288308823502402\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1765729941411154\n",
      "std: 0.18025693167781254\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1814238027241384\n",
      "std: 0.18300086951055025\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.057810043134269115\n",
      "min: 0.009287357660340029\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34216273953817805\n",
      "std: 0.36166494725440557\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4787616282572958\n",
      "std: 0.16070750007550744\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018742904230337355\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073451772165657\n",
      "std: 0.004829325236746202\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073255239101712\n",
      "std: 0.004953604055806835\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.055461622115650006\n",
      "min: 0.025780883635195147\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32973071414538196\n",
      "std: 0.2924252258020079\n",
      "min: -0.8015765408922237\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6318201598127776\n",
      "std: 0.09193091239462649\n",
      "min: 0.3830564016810965\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01914762044362236\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1719386045788835\n",
      "std: 0.1985422121358312\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1769541115608275\n",
      "std: 0.20209976186532316\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05868026380919208\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3422837299111377\n",
      "std: 0.36589066036006146\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47845542938301966\n",
      "std: 0.16299227193496263\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01896938620191978\n",
      "min: 0.20186291846053703\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4067489789958791\n",
      "std: 0.007026354296147865\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406745654267497\n",
      "std: 0.007129050725916531\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.055464307379434225\n",
      "min: 0.02533100802499641\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32872225745826933\n",
      "std: 0.29224120779147345\n",
      "min: -0.8008303933291065\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6316019990976643\n",
      "std: 0.09225754414167919\n",
      "min: 0.38256543125136727\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01913360055321643\n",
      "min: 0.20665074214840007\n",
      "max: 0.2782743133371006\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.175405654045885\n",
      "std: 0.19320432398908813\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1804057154532046\n",
      "std: 0.1945304501887069\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05759681721971782\n",
      "min: 0.008665723397299947\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3440606104211679\n",
      "std: 0.3629956716446693\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4778479380778736\n",
      "std: 0.160709449622639\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018902443420357604\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075153227124737\n",
      "std: 0.004334622128329358\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074803527353303\n",
      "std: 0.004615205748277912\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.055461171674629064\n",
      "min: 0.025850610104763107\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3301910871564431\n",
      "std: 0.2923799104846241\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6310789344063159\n",
      "std: 0.09203287386488909\n",
      "min: 0.3826395672994968\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01915167328519251\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782653010781378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.212834551007623\n",
      "std: 0.08758232748769636\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.217051219865862\n",
      "std: 0.09347847530281106\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05627791277400411\n",
      "min: 0.018331008907415167\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3537320302357713\n",
      "std: 0.35884353025082694\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47069389829412317\n",
      "std: 0.15882380487771017\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018796237008720306\n",
      "min: 0.20182672427827303\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408202112773245\n",
      "std: 0.003242974045211157\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081426741229723\n",
      "std: 0.0036120173616300106\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.0554607869131521\n",
      "min: 0.02584005216169721\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3319575319476763\n",
      "std: 0.2919833168893473\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6285957828484378\n",
      "std: 0.09172758713470586\n",
      "min: 0.3826233040490345\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01914929594265144\n",
      "min: 0.2092843794497872\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1596082664266307\n",
      "std: 0.24950883221929285\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1647558699349558\n",
      "std: 0.25223199480413233\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05938099020050422\n",
      "min: 0.005402427103959512\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35354212971975757\n",
      "std: 0.36026564095761787\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47010470575288765\n",
      "std: 0.16063969316188323\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018965305158332047\n",
      "min: 0.2017041520919134\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40524843775386\n",
      "std: 0.01309787091713507\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4052356990743504\n",
      "std: 0.013246973093586403\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05128205128205128\n",
      "std: 0.05547437352272981\n",
      "min: 0.024329761685460482\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33329679571527343\n",
      "std: 0.29186495320071093\n",
      "min: -0.8010128100549134\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6300568175536048\n",
      "std: 0.09401056402708932\n",
      "min: 0.3811028466794017\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01928340540899299\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1765630325907366\n",
      "std: 0.17760056595562015\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1810553857849029\n",
      "std: 0.180364804757051\n",
      "min: 0.05792414118796837\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.056625685770372865\n",
      "min: 0.009287357660340029\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3406223369962822\n",
      "std: 0.3602316935845787\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4776727243457894\n",
      "std: 0.1599828375445374\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018667747097114155\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074068032169766\n",
      "std: 0.0047612335082071675\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073979403486694\n",
      "std: 0.004884473335556209\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05434539233104898\n",
      "min: 0.025212270783924608\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3294448307418897\n",
      "std: 0.2923272733819898\n",
      "min: -0.8015765408922237\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6316416820515437\n",
      "std: 0.09186699413927994\n",
      "min: 0.3830564016810965\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01914469671179327\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1720188825045323\n",
      "std: 0.19583509642697852\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1766700145400395\n",
      "std: 0.19939777535162634\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.0574702844416835\n",
      "min: 0.0086715765513606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34076338629417835\n",
      "std: 0.3643635503653445\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47735988307297234\n",
      "std: 0.16221883597167963\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018889750508837413\n",
      "min: 0.20186291846053703\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406825229684197\n",
      "std: 0.0069270283106421604\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4068319863027574\n",
      "std: 0.007030672311721506\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.054347998923244774\n",
      "min: 0.02484404512322207\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32845321195204996\n",
      "std: 0.292141245260806\n",
      "min: -0.8008303933291065\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6314185560036055\n",
      "std: 0.09218285435303947\n",
      "min: 0.38256543125136727\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019130590202016254\n",
      "min: 0.20665074214840007\n",
      "max: 0.2782743133371006\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1753751163702064\n",
      "std: 0.1908737289957967\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1800131488754908\n",
      "std: 0.19222262754519065\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05641949432949584\n",
      "min: 0.008665723397299947\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34248889345186856\n",
      "std: 0.36154610339418103\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47677086860656875\n",
      "std: 0.15998299990378392\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018824634038519715\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075709471558342\n",
      "std: 0.004274161653397031\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075474426583947\n",
      "std: 0.0045512834618891985\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05434495530016302\n",
      "min: 0.025264618833159006\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32989154444439\n",
      "std: 0.2922840908728858\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6309112314145657\n",
      "std: 0.09196402436000707\n",
      "min: 0.3826395672994968\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01914844292014681\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782653010781378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2117662328853656\n",
      "std: 0.08718525638528067\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2156642864649478\n",
      "std: 0.09307130760369146\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05513861126248383\n",
      "min: 0.018331008907415167\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35194032218316273\n",
      "std: 0.35748843436595057\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4697446554148307\n",
      "std: 0.15809136279060623\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018720172538582575\n",
      "min: 0.20182672427827303\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082386597924001\n",
      "std: 0.0031981074219506727\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081914972884737\n",
      "std: 0.003560703428428198\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.054344581408596625\n",
      "min: 0.0252911307883868\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33162048428750485\n",
      "std: 0.29189516497349205\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.628476184381382\n",
      "std: 0.09166217761902908\n",
      "min: 0.3826233040490345\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019145832160261438\n",
      "min: 0.2092843794497872\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1598957508668528\n",
      "std: 0.2464362766693032\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1646684855539124\n",
      "std: 0.24918052630692988\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05815105961415135\n",
      "min: 0.005402427103959512\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3517968720132307\n",
      "std: 0.3588808000734499\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4691899187695064\n",
      "std: 0.15986353521788424\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01888702372097681\n",
      "min: 0.2017041520919134\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4053578434127099\n",
      "std: 0.012937340246512708\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4053543372013424\n",
      "std: 0.013088831244823195\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.05\n",
      "std: 0.05435777701457896\n",
      "min: 0.023783387967826412\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3329351302030779\n",
      "std: 0.29177441784626484\n",
      "min: -0.8010128100549134\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6299038066322229\n",
      "std: 0.09389944408506914\n",
      "min: 0.3811028466794017\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01927742429015289\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1769416969407975\n",
      "std: 0.1762503452720106\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1815698114753348\n",
      "std: 0.17900838627675117\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05549253554092786\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3392165992685518\n",
      "std: 0.36154823482883797\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4777871601056999\n",
      "std: 0.1592874262192193\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018666195609362814\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074307904454946\n",
      "std: 0.004720342323617451\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074455792784317\n",
      "std: 0.004841706377748616\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.053276198234898986\n",
      "min: 0.0244979662136533\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32908091092639347\n",
      "std: 0.2925679647838844\n",
      "min: -0.8015765408922234\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6316327881562218\n",
      "std: 0.09172957294260871\n",
      "min: 0.38305640168109667\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019137023460274336\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1725320327744615\n",
      "std: 0.19392811135982535\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1773128881005908\n",
      "std: 0.19749197233055998\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05631261322375504\n",
      "min: 0.008105277866865783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3393752301282975\n",
      "std: 0.36556024119632924\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4774693051712912\n",
      "std: 0.16147456756824294\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0188829525375366\n",
      "min: 0.20186291846053703\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406862377250457\n",
      "std: 0.0068570358046015295\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4068921736072812\n",
      "std: 0.006961414789794141\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.053278731166081846\n",
      "min: 0.024131197615291786\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3281046909469264\n",
      "std: 0.2923797993031752\n",
      "min: -0.8008303933291065\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6314061872351338\n",
      "std: 0.09203460975203574\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019122831168469433\n",
      "min: 0.20665074214840007\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1758192039036341\n",
      "std: 0.18878300557917868\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1805894664657652\n",
      "std: 0.19015319476864834\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05529230103802724\n",
      "min: 0.008665723397299947\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3410468241759366\n",
      "std: 0.3628450850810045\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47689982113924645\n",
      "std: 0.15928997512270832\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018819989131085586\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075919902639544\n",
      "std: 0.004234501154122661\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407592661405937\n",
      "std: 0.004507559315785554\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05327577342836418\n",
      "min: 0.024493207307147314\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3295146969164856\n",
      "std: 0.2925280559977692\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6309122432727312\n",
      "std: 0.09182360128218153\n",
      "min: 0.3826395672994967\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01914055387756384\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.211385636260251\n",
      "std: 0.08632074672320827\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2154575460542372\n",
      "std: 0.09210387311473947\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05404717888868345\n",
      "min: 0.018331008907415163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3502900737849017\n",
      "std: 0.35888614547453573\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4700004455432795\n",
      "std: 0.15743932175640593\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018717226720806023\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082453245503772\n",
      "std: 0.003177230955369286\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082229921525933\n",
      "std: 0.0035307547141739865\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.053275409620596716\n",
      "min: 0.024482950855217414\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33120724275799623\n",
      "std: 0.2921455854422925\n",
      "min: -0.8024797058014196\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6285237387525608\n",
      "std: 0.09153011645305484\n",
      "min: 0.38262330404903433\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01913775272288425\n",
      "min: 0.2092843794497872\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1608020019583902\n",
      "std: 0.24363418482064095\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.165693293712616\n",
      "std: 0.24641550398475218\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.056974002961303866\n",
      "min: 0.005036729970517471\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3501832027250952\n",
      "std: 0.3602489591570117\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46947819683087993\n",
      "std: 0.15916465523737247\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01888070948400553\n",
      "min: 0.20170415209191342\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4054307148292762\n",
      "std: 0.012796383790986405\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4054495448234292\n",
      "std: 0.012950922784585282\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04878048780487805\n",
      "std: 0.05328823634318285\n",
      "min: 0.023063365366675026\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3324972311627196\n",
      "std: 0.29202490453843555\n",
      "min: -0.8010128100549134\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6299223428387736\n",
      "std: 0.09371799139718413\n",
      "min: 0.3811028466794016\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019266908530036545\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1766938238088294\n",
      "std: 0.17502178763405057\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1813523491401787\n",
      "std: 0.17770409032837137\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05440700931554552\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3401437166922908\n",
      "std: 0.3620288796049309\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4752638755115914\n",
      "std: 0.16014912809264417\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018678807690872042\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074204600671283\n",
      "std: 0.004684111911631892\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074252674186196\n",
      "std: 0.004808731238864867\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05225105589730246\n",
      "min: 0.02393739453267118\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.329377738638004\n",
      "std: 0.2926972314745466\n",
      "min: -0.8090169112147215\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6310963569248954\n",
      "std: 0.09181619017923313\n",
      "min: 0.38305640168109667\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019134479094602884\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1723903742645676\n",
      "std: 0.1926414420981804\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.177194557203235\n",
      "std: 0.1961323158000797\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05520412953513183\n",
      "min: 0.008105277866865783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3403202413886721\n",
      "std: 0.3659399626522992\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4749414409586901\n",
      "std: 0.16227127546224665\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018890209868135076\n",
      "min: 0.20186291846053703\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068645515656222\n",
      "std: 0.006806106391492759\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4068838354279156\n",
      "std: 0.006912890546155495\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05225352010603821\n",
      "min: 0.023458050195468514\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32841715467044846\n",
      "std: 0.2925081062241706\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6308657272376699\n",
      "std: 0.09211106628300739\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019120225567992533\n",
      "min: 0.20665074214840007\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1756110544989653\n",
      "std: 0.18719507796756463\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1804080766311529\n",
      "std: 0.18851304120404097\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05421256412037885\n",
      "min: 0.008210139074399584\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3419395113780162\n",
      "std: 0.3633054014244486\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4743913784179741\n",
      "std: 0.1601491509169794\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018829229637439576\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075795671814826\n",
      "std: 0.004211591784601602\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075707309785777\n",
      "std: 0.004484800247523193\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.0522506431734543\n",
      "min: 0.023969859489334333\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32979988922105347\n",
      "std: 0.292658766265887\n",
      "min: -0.809025623169343\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6303852749472727\n",
      "std: 0.09190527211239889\n",
      "min: 0.3826395672994967\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019137754511991775\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2103860042068464\n",
      "std: 0.08643127854678935\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.21452296467087\n",
      "std: 0.09193743922136875\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05300133010381332\n",
      "min: 0.01656583730500829\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35097382932829313\n",
      "std: 0.35937647531064115\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46762361249545753\n",
      "std: 0.15826220182321044\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018728248027716145\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082205166339499\n",
      "std: 0.0031769633735254793\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081893208851701\n",
      "std: 0.0035284101892571903\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.05225028883781235\n",
      "min: 0.023959637837989697\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3314549823256229\n",
      "std: 0.2922790844373942\n",
      "min: -0.8087437014825689\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6280435894442083\n",
      "std: 0.09160884832671978\n",
      "min: 0.38262330404903433\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019134743402625904\n",
      "min: 0.2092843794497872\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.161058612196397\n",
      "std: 0.24113495946988006\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1659609445865302\n",
      "std: 0.24389879536695436\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.0558471162262531\n",
      "min: 0.005036729970517471\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35090372184850266\n",
      "std: 0.3607260869366629\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46712229625956797\n",
      "std: 0.15990756218399604\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018888859025836726\n",
      "min: 0.20170415209191342\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4054717562573535\n",
      "std: 0.012664663400603812\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405479245149709\n",
      "std: 0.012821778811722563\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.047619047619047616\n",
      "std: 0.0522627659562224\n",
      "min: 0.022511416101651145\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3327239710489836\n",
      "std: 0.2921558241870526\n",
      "min: -0.8084344089842\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6294110074395881\n",
      "std: 0.0937524127239419\n",
      "min: 0.3811028466794016\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019261548166240924\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1793738001171032\n",
      "std: 0.17399983610105338\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1838159148388405\n",
      "std: 0.1765799723792145\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.053365459248199416\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3407492118348347\n",
      "std: 0.3623936757133642\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47603764218627564\n",
      "std: 0.16002152366396397\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01867451529105509\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074898649659433\n",
      "std: 0.004652017981667862\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075070057610266\n",
      "std: 0.0047758314995528985\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05126723248614242\n",
      "min: 0.02328948433413781\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.329437926324896\n",
      "std: 0.2926816636652527\n",
      "min: -0.8090169112147217\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6310964464993184\n",
      "std: 0.09177775466917734\n",
      "min: 0.38305640168109667\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019131510131777142\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1751840559993354\n",
      "std: 0.19126313453709087\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.179766450538659\n",
      "std: 0.1946535817755504\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05414063954561685\n",
      "min: 0.008105277866865783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34094183646566717\n",
      "std: 0.36621205434077597\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4757168781090299\n",
      "std: 0.16209168494461149\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018881199064082223\n",
      "min: 0.20186291846053703\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40694699438986\n",
      "std: 0.0067486444203956305\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40697807656658\n",
      "std: 0.006856655322894433\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05126963053468142\n",
      "min: 0.022898190350814775\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32849144934514213\n",
      "std: 0.29249095603169634\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6308633582026879\n",
      "std: 0.0920626586868618\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019117196173905972\n",
      "min: 0.20665074214840007\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1783132897622803\n",
      "std: 0.18600600945439055\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1828906503516152\n",
      "std: 0.18724460692546532\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05317659997005294\n",
      "min: 0.007350254367341712\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34251401446684193\n",
      "std: 0.3636503157614666\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4751824136584769\n",
      "std: 0.16003157444413874\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018821924717655553\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076461100876623\n",
      "std: 0.004182948876429194\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076501412182056\n",
      "std: 0.004453253286804919\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05126683087438173\n",
      "min: 0.023353209777159684\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32984880293910834\n",
      "std: 0.29264432615080616\n",
      "min: -0.8090256231693429\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6303952123565812\n",
      "std: 0.09186396828033792\n",
      "min: 0.3826395672994967\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01913454155604013\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2123756118207136\n",
      "std: 0.08602262817688983\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.21632510824597\n",
      "std: 0.09133311664764164\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05199735020562879\n",
      "min: 0.015962127648045187\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35134867922223745\n",
      "std: 0.35976553814399115\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4685341801157778\n",
      "std: 0.1582035534865711\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018722806267197224\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082749650063577\n",
      "std: 0.003153007902010704\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408257141779253\n",
      "std: 0.0034995362954251845\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.051266485266543656\n",
      "min: 0.02341565688899589\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33146935420508566\n",
      "std: 0.29226951290777203\n",
      "min: -0.8087437014825686\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6280971079491512\n",
      "std: 0.09157499785640444\n",
      "min: 0.38262330404903433\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019131384542722358\n",
      "min: 0.2092843794497872\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1640854078459149\n",
      "std: 0.23935342739957313\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1687584522469543\n",
      "std: 0.2420490480231712\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.05476648735394323\n",
      "min: 0.005036729970517471\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3513136988961525\n",
      "std: 0.36109746238346263\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46805966692499945\n",
      "std: 0.15980815313911714\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01888076713286976\n",
      "min: 0.20170415209191342\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4055866004435824\n",
      "std: 0.012544301482327852\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4056052955843803\n",
      "std: 0.012703820778521457\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.046511627906976744\n",
      "std: 0.051278631010445795\n",
      "min: 0.02194003180922903\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3327166030599079\n",
      "std: 0.29214434782277027\n",
      "min: -0.8084344089842\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.629437101454256\n",
      "std: 0.09367332103718824\n",
      "min: 0.3811028466794016\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019255945130243073\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.180609997006428\n",
      "std: 0.1716852578768217\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.184887217769129\n",
      "std: 0.1742688165575916\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05236496546793809\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34155585369842945\n",
      "std: 0.3618024173833929\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4766230244803389\n",
      "std: 0.16007978664997766\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018700577001875034\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075557827087486\n",
      "std: 0.0046089002741250915\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075648459241796\n",
      "std: 0.004726469209793012\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.050322219424406824\n",
      "min: 0.022779216211878128\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3294603184580145\n",
      "std: 0.29265533332905713\n",
      "min: -0.8090169112147217\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6312362054411121\n",
      "std: 0.09174519167742863\n",
      "min: 0.38305640168109667\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01913926439021153\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1765018198282946\n",
      "std: 0.18885818312726235\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1809142126663765\n",
      "std: 0.19225104577750404\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.053119425898490884\n",
      "min: 0.008105277866865783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3417620358781133\n",
      "std: 0.36554235305671096\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4762973749807222\n",
      "std: 0.1620977724103308\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018902313054038843\n",
      "min: 0.20186291846053703\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070253226681295\n",
      "std: 0.006682164889266772\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070478785610545\n",
      "std: 0.006786362578468763\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.050324554421688844\n",
      "min: 0.02243566782043013\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3285277095297734\n",
      "std: 0.2924636844510566\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6310010355473284\n",
      "std: 0.09202131331223526\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019124904640984583\n",
      "min: 0.20665074214840007\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1795658795918962\n",
      "std: 0.18364723124653928\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.183974396200863\n",
      "std: 0.1849079100697555\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.052181490338141644\n",
      "min: 0.007350254367341712\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3432932026186959\n",
      "std: 0.3630459325443668\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4757835606658902\n",
      "std: 0.1600975330199142\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018845053334559946\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077076243846351\n",
      "std: 0.00414149591456878\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40770404202562\n",
      "std: 0.004404448662298287\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05032182840398673\n",
      "min: 0.022800776376719838\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32986017818820884\n",
      "std: 0.29261966223920527\n",
      "min: -0.8090256231693429\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6305447167317308\n",
      "std: 0.09182917674118786\n",
      "min: 0.3826395672994967\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01914207692067233\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2127679827274327\n",
      "std: 0.08512954297177887\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2165832667615888\n",
      "std: 0.09040855838307299\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05103315128263795\n",
      "min: 0.015962127648045187\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3519373976035013\n",
      "std: 0.3591928537656417\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4692372506927437\n",
      "std: 0.15830744499179372\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01874739081423644\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083220310079334\n",
      "std: 0.0031194615221897763\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082974213421213\n",
      "std: 0.0034571497758398213\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.050321491383442114\n",
      "min: 0.022865196489926874\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.331447671201186\n",
      "std: 0.2922492841759466\n",
      "min: -0.8087437014825686\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6282867859842687\n",
      "std: 0.09154892431403296\n",
      "min: 0.38262330404903433\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0191387010618806\n",
      "min: 0.2092843794497872\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1656572385058346\n",
      "std: 0.2362782908161177\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1701508654147403\n",
      "std: 0.23899881437729223\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.053728932565740316\n",
      "min: 0.005036729970517471\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35194241432967477\n",
      "std: 0.36051442709105047\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46879112380687327\n",
      "std: 0.15988341800037134\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01890335293761386\n",
      "min: 0.20170415209191342\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4056915994249999\n",
      "std: 0.012422042671993505\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40570138887615\n",
      "std: 0.012580498666827393\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.045454545454545456\n",
      "std: 0.05033332180447868\n",
      "min: 0.021413350161729447\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33267433166518995\n",
      "std: 0.29212254901308937\n",
      "min: -0.8084344089842\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6296022022962373\n",
      "std: 0.09360346318294424\n",
      "min: 0.3811028466794016\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01926111648326722\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1805192098430863\n",
      "std: 0.1698971542060297\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.184675385698884\n",
      "std: 0.17250433363046028\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.05140424371635753\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3419043836640097\n",
      "std: 0.36113215553288425\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4750154452604944\n",
      "std: 0.16193433136814164\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018717152776102614\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075721763980702\n",
      "std: 0.004569500779310118\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075998106387901\n",
      "std: 0.004674694319287786\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.04941370993881798\n",
      "min: 0.02224320461488767\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.329378815891514\n",
      "std: 0.29258732790049025\n",
      "min: -0.8090169112147215\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6310838234151298\n",
      "std: 0.09167002217084164\n",
      "min: 0.38305640168109667\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019142071790555736\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1765049824186076\n",
      "std: 0.18685606327640808\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1807922197824274\n",
      "std: 0.1902648099553863\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.05213893880148369\n",
      "min: 0.008105277866865783\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3421271397631643\n",
      "std: 0.364793700900121\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4746875800679165\n",
      "std: 0.16388264164787747\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018914644913976916\n",
      "min: 0.20186291846053703\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070523341493173\n",
      "std: 0.006614905155034192\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070930166881703\n",
      "std: 0.006711842099051265\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.04941598478413617\n",
      "min: 0.0219333190455488\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3284597069218655\n",
      "std: 0.2923945743551358\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6308466796902986\n",
      "std: 0.09193835558086462\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019127658330885023\n",
      "min: 0.20665074214840007\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1794997016661053\n",
      "std: 0.18164517316685858\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1837839682941098\n",
      "std: 0.18294857347934715\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.051225781977055934\n",
      "min: 0.007350254367341714\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3436146621465227\n",
      "std: 0.3623571637110347\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47418493880770624\n",
      "std: 0.16195346924050746\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018858997234356623\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077211963809044\n",
      "std: 0.004106849550998745\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077366420468636\n",
      "std: 0.004354617826221442\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.04941332903203937\n",
      "min: 0.022264853510107208\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3297683298292665\n",
      "std: 0.292553004490211\n",
      "min: -0.809025623169343\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6304008159840871\n",
      "std: 0.09175094850553482\n",
      "min: 0.3826395672994967\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019144688953548816\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2119575770921778\n",
      "std: 0.08453475134319013\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.21568015606471\n",
      "std: 0.0897940496726094\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.05010667850334672\n",
      "min: 0.015720911602309328\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3520810954182762\n",
      "std: 0.35854642952009985\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4677515021928389\n",
      "std: 0.16015561699856715\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018763185748109826\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083226134758327\n",
      "std: 0.0030986114769550226\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408317567356289\n",
      "std: 0.003415070931021882\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.04941300022102748\n",
      "min: 0.02236246123041275\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33132402407095396\n",
      "std: 0.29218787334435636\n",
      "min: -0.8087437014825689\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6281828871167761\n",
      "std: 0.09147351969727947\n",
      "min: 0.38262330404903433\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019141130054005164\n",
      "min: 0.2092843794497872\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.165933759744005\n",
      "std: 0.23367595728903512\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1702945665289464\n",
      "std: 0.23642550464262793\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.05273279545638075\n",
      "min: 0.004900611357952902\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3521247722832995\n",
      "std: 0.3598514424434509\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4673324289849811\n",
      "std: 0.16166335512178998\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01891685544845024\n",
      "min: 0.20170415209191342\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4057446519410302\n",
      "std: 0.012300656235193698\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4057720398958373\n",
      "std: 0.012457141932443497\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.044444444444444446\n",
      "std: 0.04942453024850637\n",
      "min: 0.020865969109177287\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33253146848412607\n",
      "std: 0.29205954486442476\n",
      "min: -0.8084344089842\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6294736017046149\n",
      "std: 0.09348831383226422\n",
      "min: 0.3811028466794016\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019261472771553344\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1811351403408477\n",
      "std: 0.16825329601951497\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1851085827722072\n",
      "std: 0.17082055629659346\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.05048025432904138\n",
      "min: 0.0071507529317910035\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3419220505975438\n",
      "std: 0.36070834131893714\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4742840917482499\n",
      "std: 0.16156187342932762\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018698771585164572\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407558453686243\n",
      "std: 0.0045412172954170035\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075622291437098\n",
      "std: 0.0046548846179970595\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.04853957863676036\n",
      "min: 0.021805361669927182\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3294112526815558\n",
      "std: 0.2925847648526047\n",
      "min: -0.8090169112147215\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6308631571760333\n",
      "std: 0.09164529039272236\n",
      "min: 0.38305640168109667\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019137126475382453\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1772054897125084\n",
      "std: 0.18491622282826467\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.181306146196155\n",
      "std: 0.18827597855652053\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.05119615864500564\n",
      "min: 0.007471783927356017\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34216005250364806\n",
      "std: 0.36429474655639166\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4739557694101604\n",
      "std: 0.163470896659848\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01889263336929756\n",
      "min: 0.20186291846053703\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070487274882097\n",
      "std: 0.006549551344787411\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070650806375236\n",
      "std: 0.006652666764937617\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.04854179574318797\n",
      "min: 0.021528682137357875\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3285055934045113\n",
      "std: 0.29239095840023344\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6306234199110795\n",
      "std: 0.09190492602659599\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019122666340622537\n",
      "min: 0.20665074214840007\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1801400750377649\n",
      "std: 0.17977930054228325\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1842382899643806\n",
      "std: 0.18106666467241825\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.05030656293651893\n",
      "min: 0.007292912968699337\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3436068084602652\n",
      "std: 0.36191778774389893\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47346657175988266\n",
      "std: 0.16158587791436907\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018838318211279834\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077037095655032\n",
      "std: 0.00408750889561453\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076956292158864\n",
      "std: 0.004341835246039178\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.048539207429811486\n",
      "min: 0.02180190261571006\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3297912931371529\n",
      "std: 0.2925512212235531\n",
      "min: -0.809025623169343\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6301877433443628\n",
      "std: 0.091722259838172\n",
      "min: 0.3826395672994967\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019139511766621955\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2118562412770693\n",
      "std: 0.08396583984366361\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2154213369252953\n",
      "std: 0.08912357161540821\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.049215384252141024\n",
      "min: 0.015354345068632645\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3519073834115832\n",
      "std: 0.35815418174775104\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46713620856306803\n",
      "std: 0.1597889665967647\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018744196936629643\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4082906032317601\n",
      "std: 0.003104953675495474\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082626637559634\n",
      "std: 0.0034284931341580344\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.04853888660760261\n",
      "min: 0.021797127797445238\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33131782090058276\n",
      "std: 0.2921903477989669\n",
      "min: -0.8087437014825689\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6280076620073559\n",
      "std: 0.0914464099303694\n",
      "min: 0.38262330404903433\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019135848691966727\n",
      "min: 0.2092843794497872\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.166806509648464\n",
      "std: 0.23142025237441652\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.17097566103319\n",
      "std: 0.23414391026512588\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.051775342106333305\n",
      "min: 0.004900611357952902\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3519824695400528\n",
      "std: 0.35944430373391023\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46673864625012035\n",
      "std: 0.16126347314895292\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018895697696756916\n",
      "min: 0.20170415209191342\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4057661585910677\n",
      "std: 0.012175566994111547\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405768886857309\n",
      "std: 0.01233533033245278\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.043478260869565216\n",
      "std: 0.04855012891144664\n",
      "min: 0.020488789599653917\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3325060643218014\n",
      "std: 0.2920605646199939\n",
      "min: -0.8084344089842\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6292736084219381\n",
      "std: 0.09342600124487231\n",
      "min: 0.3811028466794016\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019254207195185967\n",
      "min: 0.20930683824810614\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1823281896208975\n",
      "std: 0.16688909391087303\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.186225592277248\n",
      "std: 0.16947152345731623\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.049591039727646676\n",
      "min: 0.007137886790462734\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3426424683515347\n",
      "std: 0.3615116947916011\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4752811904752371\n",
      "std: 0.1615369113431038\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01875206692308909\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075937576982103\n",
      "std: 0.004502752293675208\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076009885462692\n",
      "std: 0.00461111893805524\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.04769786347232294\n",
      "min: 0.02129955386741876\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32954453517212984\n",
      "std: 0.2926806357450173\n",
      "min: -0.8090169112147215\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6309688175156605\n",
      "std: 0.09162117822174462\n",
      "min: 0.38305640168109667\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019145278070481494\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1784831142219403\n",
      "std: 0.1834262583352426\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.18250397543275\n",
      "std: 0.18679145874831019\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.050289058776002545\n",
      "min: 0.007471783927356017\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34289289518960514\n",
      "std: 0.36501790080965535\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4749550714487779\n",
      "std: 0.16340336989255572\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01894140781011878\n",
      "min: 0.20186291846053703\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070947921525072\n",
      "std: 0.006482224839323941\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071142029596568\n",
      "std: 0.006582906145791859\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.047700025688088406\n",
      "min: 0.02102042383896787\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3286512405035058\n",
      "std: 0.2924864611021481\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6307277935491321\n",
      "std: 0.091872661704471\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019130796421151144\n",
      "min: 0.20665074214840007\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1813680269363878\n",
      "std: 0.17807459998860106\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1853870601429302\n",
      "std: 0.17940136105402696\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.04942179553070967\n",
      "min: 0.007292912968699337\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.344299596743389\n",
      "std: 0.3627072915779665\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47447971799732364\n",
      "std: 0.1615691498624721\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018888717427672903\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077355213816207\n",
      "std: 0.0040434577797525155\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077313002600012\n",
      "std: 0.004292015657070772\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.04769750111513904\n",
      "min: 0.02135171671373456\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3299152731220102\n",
      "std: 0.29264872529256425\n",
      "min: -0.809025623169343\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6303021052460482\n",
      "std: 0.09169631163430318\n",
      "min: 0.3826395672994967\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019147478037852172\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.212445654540894\n",
      "std: 0.08317509517991796\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2159569709392406\n",
      "std: 0.08834510618307463\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.048357129168932665\n",
      "min: 0.015354345068632648\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35243729175965066\n",
      "std: 0.35898348258749935\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.468251290390219\n",
      "std: 0.1598328996116666\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018796349877085432\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083102798711864\n",
      "std: 0.0030701203088065072\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082867664327696\n",
      "std: 0.0033858140314435136\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.047697187824720676\n",
      "min: 0.02145036044738511\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33141214865779\n",
      "std: 0.2922914259522763\n",
      "min: -0.8087437014825689\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6281583761990823\n",
      "std: 0.0914282194381824\n",
      "min: 0.38262330404903433\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01914365058168524\n",
      "min: 0.20919997721928477\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1683396977794978\n",
      "std: 0.2292783853617092\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1724230102277382\n",
      "std: 0.23202180132358088\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.05085402894289532\n",
      "min: 0.004900611357952902\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3525370246049453\n",
      "std: 0.3602618488595528\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.467879763114331\n",
      "std: 0.16127707894530485\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018945447860512842\n",
      "min: 0.20170415209191342\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4058383799389798\n",
      "std: 0.012047986295442226\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4058438640908897\n",
      "std: 0.012207051231973779\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0425531914893617\n",
      "std: 0.04770815568125342\n",
      "min: 0.020192523731334223\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3325820235798344\n",
      "std: 0.2921605543785421\n",
      "min: -0.8084344089842\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6294031984427546\n",
      "std: 0.0933684244709641\n",
      "min: 0.3811028466794016\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019260063358141625\n",
      "min: 0.20921255256223345\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1834968844976108\n",
      "std: 0.16559206866213558\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1870300307204185\n",
      "std: 0.16812309213831966\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04873467739599222\n",
      "min: 0.006749489675278262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3437180751837091\n",
      "std: 0.3605108171293547\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4747912005111064\n",
      "std: 0.1614029948957287\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018745778205945494\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076111743744166\n",
      "std: 0.00445949036268795\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407618369757828\n",
      "std: 0.004567463290700571\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.046886750851938774\n",
      "min: 0.02089468868382736\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32974352053179906\n",
      "std: 0.29264499608782174\n",
      "min: -0.8090169112147215\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6308384099064239\n",
      "std: 0.09154664528697974\n",
      "min: 0.38305640168109667\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019144155556898315\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1797377550226034\n",
      "std: 0.18189410876048034\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1833907858053745\n",
      "std: 0.18520065361425248\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04941561327657629\n",
      "min: 0.0074304841430578895\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34397935180816513\n",
      "std: 0.3639571745714317\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.474465577996563\n",
      "std: 0.16322911267255594\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018931238430287052\n",
      "min: 0.20186291846053703\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071231018378567\n",
      "std: 0.0064130235749613575\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071420309618197\n",
      "std: 0.00651424579871245\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04688886073594748\n",
      "min: 0.020613674861572666\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3288622846996266\n",
      "std: 0.29245048946341573\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6305952034629057\n",
      "std: 0.09179071273339683\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019129646744212175\n",
      "min: 0.20665074214840007\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1825623074662577\n",
      "std: 0.17655272528504423\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1862138751152902\n",
      "std: 0.1778514431754043\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.0485697250294887\n",
      "min: 0.007261371971477695\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34534975121236483\n",
      "std: 0.361691807651432\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47400290498912523\n",
      "std: 0.16143448770800384\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01887993636619021\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407749879257703\n",
      "std: 0.0040058548950609235\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077459576466198\n",
      "std: 0.004252310052965705\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04688639733345224\n",
      "min: 0.020911952757894644\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33010541903495855\n",
      "std: 0.29261373650858713\n",
      "min: -0.809025623169343\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6301792595550443\n",
      "std: 0.09161903722527241\n",
      "min: 0.3826395672994967\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0191461672813666\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.213020741796593\n",
      "std: 0.08254264074044255\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2161858410457804\n",
      "std: 0.08766245311903126\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04753036124055223\n",
      "min: 0.014964023336498619\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3533232545490374\n",
      "std: 0.3579906810221952\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4678706503720539\n",
      "std: 0.15971653609046668\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018789253815320414\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083132785655832\n",
      "std: 0.003045032038315262\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4082905265969572\n",
      "std: 0.0033570580761408428\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.046886091262117194\n",
      "min: 0.020947864960303687\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33157381051185425\n",
      "std: 0.29225996854621916\n",
      "min: -0.8087437014825689\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6280710238027735\n",
      "std: 0.09135451657287953\n",
      "min: 0.38262330404903433\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01914221845542528\n",
      "min: 0.20919997721928477\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.169753203277316\n",
      "std: 0.22752157608932913\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1734645412073141\n",
      "std: 0.2302175793761013\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.04996718811257991\n",
      "min: 0.004622232797715273\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3534530030455074\n",
      "std: 0.3592625009439438\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4675207135876195\n",
      "std: 0.16112257910279226\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018936301916671727\n",
      "min: 0.20170415209191342\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4058923136886345\n",
      "std: 0.011924572357920552\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4058969957273972\n",
      "std: 0.012084179830625371\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.041666666666666664\n",
      "std: 0.046896796944736495\n",
      "min: 0.019758082814805573\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3327263574304392\n",
      "std: 0.2921269823334273\n",
      "min: -0.8084344089842\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6292932560816524\n",
      "std: 0.09325960375260778\n",
      "min: 0.3811028466794016\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01925678954769101\n",
      "min: 0.20921255256223345\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1847986611626504\n",
      "std: 0.1640980282618453\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1881333531897287\n",
      "std: 0.1666003807653965\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.047909043749169246\n",
      "min: 0.006749489675278261\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3426247276165404\n",
      "std: 0.3608195497376386\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4752464904634805\n",
      "std: 0.16254821145365936\n",
      "min: 0.04350261413105978\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018733873357738337\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076337130655157\n",
      "std: 0.004426017253368884\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076475579669085\n",
      "std: 0.004531149394282521\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.04610456175225637\n",
      "min: 0.02047725005276969\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32942964700886557\n",
      "std: 0.2927058612457873\n",
      "min: -0.8090169112147215\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6310596616604532\n",
      "std: 0.09148648859060726\n",
      "min: 0.38305640168109667\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019132555542549383\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1811158327435758\n",
      "std: 0.18019127519414838\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.184567133478058\n",
      "std: 0.18346215848902067\n",
      "min: -0.08315292230984526\n",
      "max: 1.4138853464213643\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.048573681064362696\n",
      "min: 0.007430484143057889\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.342897485472538\n",
      "std: 0.364188589939676\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4749208856218318\n",
      "std: 0.16432210384476956\n",
      "min: 0.042730008843921675\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01891606414336952\n",
      "min: 0.20186291846053703\n",
      "max: 0.30255149342259957\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071566038111183\n",
      "std: 0.006350686821855714\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071818431177465\n",
      "std: 0.0064505917275546835\n",
      "min: 1.358128239843575\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.04610662151418067\n",
      "min: 0.02014454797448691\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32855971511737975\n",
      "std: 0.29251027537141444\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6308152227766227\n",
      "std: 0.09172321893183986\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019118005570741337\n",
      "min: 0.20665074214840007\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.18386839567449\n",
      "std: 0.1750523401598539\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.187319266692129\n",
      "std: 0.17633261894847896\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.04774829983749487\n",
      "min: 0.007209387012694378\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34423392875661973\n",
      "std: 0.36198471417076106\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4744683113752985\n",
      "std: 0.16258569957326863\n",
      "min: 0.04367356295002469\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018866006556741113\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077690699422882\n",
      "std: 0.003981773631994231\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407772249261475\n",
      "std: 0.004222734567260953\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.04610421678650496\n",
      "min: 0.020464647382890746\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32978231353641335\n",
      "std: 0.2926759498095138\n",
      "min: -0.809025623169343\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6304090990730393\n",
      "std: 0.09155759599848187\n",
      "min: 0.3826395672994967\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0191343966263357\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2137110356813707\n",
      "std: 0.08199176436468139\n",
      "min: 0.6681541528240924\n",
      "max: 1.4123025686197601\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2166975873450163\n",
      "std: 0.08703900505690605\n",
      "min: 0.7199851205004343\n",
      "max: 1.4123025686197601\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.04673314483929775\n",
      "min: 0.014489802841169812\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3520641511555972\n",
      "std: 0.3583550810949162\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46842989751459463\n",
      "std: 0.160917232701026\n",
      "min: 0.03941103347714461\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01877696275033927\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083198105329062\n",
      "std: 0.003033401601912169\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083045986291527\n",
      "std: 0.00333706672886616\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.046103917588686136\n",
      "min: 0.020477986503705425\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33122543814413324\n",
      "std: 0.2923277173764903\n",
      "min: -0.8087437014825689\n",
      "max: 0.7892345033522846\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6283337725345439\n",
      "std: 0.09130235139984616\n",
      "min: 0.38262330404903433\n",
      "max: 0.7892345033522846\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01913040161736073\n",
      "min: 0.20919997721928474\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1712909898868789\n",
      "std: 0.22552568051569907\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1747961418213015\n",
      "std: 0.22819998264810307\n",
      "min: -0.47406788551255225\n",
      "max: 1.4136302305115\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.0491124447727528\n",
      "min: 0.004622232797715271\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.352213118066029\n",
      "std: 0.3596053397197363\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4681032173767276\n",
      "std: 0.16227967454966932\n",
      "min: 0.04327253001664791\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018921561446107453\n",
      "min: 0.20170415209191342\n",
      "max: 0.29039844568107287\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4059447281999473\n",
      "std: 0.01181888044687466\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.405955584870036\n",
      "std: 0.011978094202071937\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04081632653061224\n",
      "std: 0.04611437362232583\n",
      "min: 0.019281206862398693\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33235911674499563\n",
      "std: 0.29219474665998585\n",
      "min: -0.8084344089842\n",
      "max: 0.850822432680428\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6295357500812944\n",
      "std: 0.093169855770005\n",
      "min: 0.3811028466794016\n",
      "max: 0.850822432680428\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01924316796602984\n",
      "min: 0.20921255256223342\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1856381426781566\n",
      "std: 0.16237687890933664\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1887882975237587\n",
      "std: 0.16486691905162223\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04711260887922426\n",
      "min: 0.006749489675278261\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34299349323579365\n",
      "std: 0.36037179771628086\n",
      "min: -1.0402221534507257\n",
      "max: 0.8380933254280943\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47395861979666914\n",
      "std: 0.16365644310881083\n",
      "min: 0.04350261413105972\n",
      "max: 0.8380933254280943\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01876987305924691\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076517170571063\n",
      "std: 0.004384370588492476\n",
      "min: 1.3756633287769693\n",
      "max: 1.4139790623992685\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076598896362031\n",
      "std: 0.0044812928451781545\n",
      "min: 1.3777843167925208\n",
      "max: 1.4139790623992685\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.045349739494808736\n",
      "min: 0.020015991035637063\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3295662512292389\n",
      "std: 0.2926435539041043\n",
      "min: -0.8090169112147217\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6307989122227667\n",
      "std: 0.09155255892633656\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019136095956442386\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1820200447955886\n",
      "std: 0.17841979107091185\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1852837591080492\n",
      "std: 0.18166628085751685\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.047761706782293946\n",
      "min: 0.007430484143057889\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34327513069465676\n",
      "std: 0.36367997043981987\n",
      "min: -1.04372230358105\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47363253552769863\n",
      "std: 0.16538193371267823\n",
      "min: 0.04273000884392158\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01894826322583141\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071834755197108\n",
      "std: 0.00629134582787996\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019793\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072027359527266\n",
      "std: 0.006385521114598257\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019793\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.045351751750263514\n",
      "min: 0.019675207659384165\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3287075006641643\n",
      "std: 0.2924476851147374\n",
      "min: -0.808344770486722\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6305529592517402\n",
      "std: 0.09178273598827481\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019121525838007834\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1847329852250952\n",
      "std: 0.17316503560550675\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1879964751160157\n",
      "std: 0.17444656866253863\n",
      "min: -0.05614650130534394\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04695575455677234\n",
      "min: 0.007209387012694378\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34457729594638054\n",
      "std: 0.36152846791642557\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4731948074168278\n",
      "std: 0.16369594746022276\n",
      "min: 0.043673562950024586\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01889956019575668\n",
      "min: 0.20092394836109737\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407784969326547\n",
      "std: 0.003945975324758999\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498367\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077827816833737\n",
      "std: 0.0041764415026975905\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498367\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04534940260941012\n",
      "min: 0.020057202388211202\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3299103158746822\n",
      "std: 0.29261462222788137\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6301557785322869\n",
      "std: 0.09162041935522071\n",
      "min: 0.3826395672994968\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01913775556416814\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.213941191130323\n",
      "std: 0.0812270257057268\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2167623523991355\n",
      "std: 0.0862397971980865\n",
      "min: 0.7199851205004337\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04596391863728755\n",
      "min: 0.014489802841169812\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3522625339012144\n",
      "std: 0.3579286835600872\n",
      "min: -1.038813344943824\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4672465224463418\n",
      "std: 0.16202256864753123\n",
      "min: 0.03941103347714462\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018811865951918628\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083263963438242\n",
      "std: 0.0030067438065019933\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083062923251608\n",
      "std: 0.0032978558953410822\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04534910999524479\n",
      "min: 0.020121011152075076\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3313265483834291\n",
      "std: 0.29226950901671356\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6281137236414005\n",
      "std: 0.09136499302675542\n",
      "min: 0.38262330404903455\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019133613618904477\n",
      "min: 0.20919997721928477\n",
      "max: 0.27820366470954305\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1723608887578016\n",
      "std: 0.22343149840400778\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1756744068774176\n",
      "std: 0.22609189390125617\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04828818729478291\n",
      "min: 0.004622232797715271\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35243552328441563\n",
      "std: 0.3591721826590237\n",
      "min: -1.0458017076285246\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46693397337980336\n",
      "std: 0.16333952347379313\n",
      "min: 0.043272530016648096\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018954729065817327\n",
      "min: 0.20170415209191345\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4059994087023804\n",
      "std: 0.011695365178283975\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4060039089571943\n",
      "std: 0.011852248489833435\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.04\n",
      "std: 0.04535932561030809\n",
      "min: 0.018821415862454206\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3324442181261416\n",
      "std: 0.29213534041169587\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6292944889489551\n",
      "std: 0.0932011093533435\n",
      "min: 0.38110284667940175\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019244662520098696\n",
      "min: 0.20921255256223345\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1868903929317247\n",
      "std: 0.16131284554613448\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1899595820223838\n",
      "std: 0.16380483642094415\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04634411817580324\n",
      "min: 0.006710811012526809\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3429456775093519\n",
      "std: 0.3610726809962853\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.473968329413035\n",
      "std: 0.16296241082084842\n",
      "min: 0.04350261413105981\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018776010378961663\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076772185850623\n",
      "std: 0.0043655817977281295\n",
      "min: 1.3756633287769688\n",
      "max: 1.4139790623992687\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076951100892294\n",
      "std: 0.004454600884549539\n",
      "min: 1.3777843167925208\n",
      "max: 1.4139790623992687\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04462083877444757\n",
      "min: 0.01957254017815681\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32949336456213085\n",
      "std: 0.29276072098163064\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6307958277421152\n",
      "std: 0.09151520259196148\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019131564186740804\n",
      "min: 0.20786227638008073\n",
      "max: 0.27826719929881266\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.183361479531304\n",
      "std: 0.17700352748877066\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1865413020099198\n",
      "std: 0.18024863077615774\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04697820681433993\n",
      "min: 0.00668439443831623\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34323497589917595\n",
      "std: 0.36431113895109185\n",
      "min: -1.0437223035810501\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47364446841620295\n",
      "std: 0.164659044572997\n",
      "min: 0.04273000884392159\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01895107087386726\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072185461229525\n",
      "std: 0.006249713483929614\n",
      "min: 1.3581282398435746\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072471803056814\n",
      "std: 0.006338899276599723\n",
      "min: 1.3581282398435746\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.0446228055853763\n",
      "min: 0.019287219912681928\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32864482950725316\n",
      "std: 0.2925643415290464\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6305494286988624\n",
      "std: 0.09173823477827446\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019116973845204714\n",
      "min: 0.2066507421484001\n",
      "max: 0.27827431333710057\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1860168874407933\n",
      "std: 0.17178511615422218\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1891968444727052\n",
      "std: 0.1730896967142505\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.046190925801724014\n",
      "min: 0.007209387012694376\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34450521434759207\n",
      "std: 0.3622178933097749\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4732180810673423\n",
      "std: 0.1630053216611812\n",
      "min: 0.04367356295002453\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01890377137804662\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078086198224813\n",
      "std: 0.0039249697367147\n",
      "min: 1.3787144478644813\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078165062068515\n",
      "std: 0.004146347470884389\n",
      "min: 1.3787144478644813\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04462050931399648\n",
      "min: 0.019607704086645413\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.329828981306787\n",
      "std: 0.29273319545290616\n",
      "min: -0.809025623169343\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6301602899310125\n",
      "std: 0.09158088710699847\n",
      "min: 0.3826395672994967\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019133079189919834\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2146979681007342\n",
      "std: 0.08065808195005038\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2174549373602648\n",
      "std: 0.08566240465523446\n",
      "min: 0.7199851205004337\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04522123795839489\n",
      "min: 0.013311520165241128\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35205224556455555\n",
      "std: 0.3586646839322293\n",
      "min: -1.0388133449438244\n",
      "max: 0.8234650410689309\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4673571515757661\n",
      "std: 0.16135315803699668\n",
      "min: 0.03941103347714462\n",
      "max: 0.8234650410689309\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01881741695834813\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083422322003363\n",
      "std: 0.0029918790496807094\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935544\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083324984855914\n",
      "std: 0.003271309272360384\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935544\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.039215686274509796\n",
      "std: 0.04462022283146094\n",
      "min: 0.019621575607252837\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33122011210272084\n",
      "std: 0.2923918008530235\n",
      "min: -0.808743701482569\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6281499050931092\n",
      "std: 0.09133059454667564\n",
      "min: 0.3826233040490345\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019128856881177183\n",
      "min: 0.20919997721928474\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1738689282279946\n",
      "std: 0.22172044836155058\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1770951180585836\n",
      "std: 0.22438489387634783\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.047492904721139144\n",
      "min: 0.004181555809506524\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3522449819453526\n",
      "std: 0.35989609087926894\n",
      "min: -1.0458017076285244\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46706169820779453\n",
      "std: 0.16264646140132988\n",
      "min: 0.043272530016647895\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018957981444437135\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4060583615122313\n",
      "std: 0.011598289515903444\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4060720019809492\n",
      "std: 0.011753043928031354\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0392156862745098\n",
      "std: 0.04463020996549929\n",
      "min: 0.01850932743658484\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33232107337344524\n",
      "std: 0.2922579044618659\n",
      "min: -0.8084344089842004\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6293114983472254\n",
      "std: 0.09313484071261949\n",
      "min: 0.3811028466794016\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019238226156274622\n",
      "min: 0.20921255256223342\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1870234798279626\n",
      "std: 0.16000976431560046\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1900389324231742\n",
      "std: 0.16247658717598273\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03846153846153846\n",
      "std: 0.045601986469845916\n",
      "min: 0.006710811012526809\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3411673224328431\n",
      "std: 0.3619200857711171\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47323424686292104\n",
      "std: 0.16245636454877876\n",
      "min: 0.04350261413105986\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01873975647007666\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076838243776244\n",
      "std: 0.004324615979766147\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407713867580813\n",
      "std: 0.004411066049072468\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.04391651357143752\n",
      "min: 0.01932514344604256\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3292227027858613\n",
      "std: 0.29285396334830793\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6307145394001527\n",
      "std: 0.09146854116368745\n",
      "min: 0.38305640168109645\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019117605829712055\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1835582072988857\n",
      "std: 0.17565702854934193\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1866804311920813\n",
      "std: 0.17887189221565472\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.046221867141682145\n",
      "min: 0.00668439443831623\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34146844842520363\n",
      "std: 0.36509067476309326\n",
      "min: -1.0437223035810501\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47290920370090456\n",
      "std: 0.1641256310756115\n",
      "min: 0.042730008843921585\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018911862938040508\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072341150994596\n",
      "std: 0.0061923156744788125\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019793\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4072745574573622\n",
      "std: 0.006280068118439506\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019793\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.04391843681321791\n",
      "min: 0.018991361163907913\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32838460017633464\n",
      "std: 0.2926567968527218\n",
      "min: -0.808344770486722\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6304667657552485\n",
      "std: 0.09168517494286546\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019103006014386928\n",
      "min: 0.2066507421484001\n",
      "max: 0.27827431333710057\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1861315496519427\n",
      "std: 0.17078731816467238\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1892557864689732\n",
      "std: 0.17207198539210186\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.045452552734782284\n",
      "min: 0.006410717386126359\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.342707376559837\n",
      "std: 0.36305873282156054\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4724928769680274\n",
      "std: 0.16250037638778925\n",
      "min: 0.043673562950024565\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018865681229478227\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078125927267862\n",
      "std: 0.003893522250211989\n",
      "min: 1.3787144478644813\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078329852202591\n",
      "std: 0.004109583838655289\n",
      "min: 1.3787144478644813\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.043916191633349345\n",
      "min: 0.01932269916222516\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3295504833599718\n",
      "std: 0.29282796142232953\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.630085908835157\n",
      "std: 0.09153188854896666\n",
      "min: 0.3826395672994968\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019118953790550196\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2143034494199965\n",
      "std: 0.08063600069749075\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2170226504336819\n",
      "std: 0.08552563080167652\n",
      "min: 0.7199851205004337\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.044504027257254886\n",
      "min: 0.012434515686955576\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3501234130496732\n",
      "std: 0.3595811577303622\n",
      "min: -1.0388133449438244\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46671862936686775\n",
      "std: 0.16084913984656904\n",
      "min: 0.039411033477144655\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01878071370686176\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083359071638084\n",
      "std: 0.002978078039641469\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935542\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083389081100939\n",
      "std: 0.0032487801630284143\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935542\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.043915911379664455\n",
      "min: 0.019317572834615413\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3309187262543698\n",
      "std: 0.2924915499258937\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6281069036342762\n",
      "std: 0.09128522425750722\n",
      "min: 0.38262330404903433\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019114705850279287\n",
      "min: 0.20919997721928474\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1742214434981921\n",
      "std: 0.2200720447849135\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1773854126898022\n",
      "std: 0.22272326739752576\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.04672528442452626\n",
      "min: 0.004181555809506524\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3503338220062553\n",
      "std: 0.3608029755201972\n",
      "min: -1.0458017076285244\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46643804175555814\n",
      "std: 0.16211773276956115\n",
      "min: 0.04327253001664796\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018919055159877206\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406094779219841\n",
      "std: 0.011494487887603278\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061200042745945\n",
      "std: 0.011649434007251202\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.038461538461538464\n",
      "std: 0.043925678809411464\n",
      "min: 0.018106916031009924\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33200255016708335\n",
      "std: 0.2923586917608362\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6292492206381974\n",
      "std: 0.09305963069332926\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0192224520381647\n",
      "min: 0.20921255256223342\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1874366689225022\n",
      "std: 0.15872855515688875\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1904394204902655\n",
      "std: 0.16119145906153348\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04488451941583117\n",
      "min: 0.006140696417090343\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3419232796402268\n",
      "std: 0.36203823302816734\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47324498104154517\n",
      "std: 0.1627718548177867\n",
      "min: 0.043502614131059734\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018760752511048695\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077101739359081\n",
      "std: 0.0042967489828101306\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077448728656827\n",
      "std: 0.004374057801297417\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04323551326530967\n",
      "min: 0.018835207206528235\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32922980045076394\n",
      "std: 0.2928078675500301\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6307949572965553\n",
      "std: 0.09137856992392779\n",
      "min: 0.38305640168109667\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01911902525879324\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.184033475198632\n",
      "std: 0.17427444834617428\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.187140469206794\n",
      "std: 0.1774798043915325\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.0454907790233211\n",
      "min: 0.006684394438316229\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.342233798625153\n",
      "std: 0.3651479760243167\n",
      "min: -1.0437223035810501\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4729184499183888\n",
      "std: 0.16440255477957613\n",
      "min: 0.04273000884392169\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018929598610350297\n",
      "min: 0.20186291846053703\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072688539851628\n",
      "std: 0.006147744501002105\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407313691362596\n",
      "std: 0.006229385685113253\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660378\n",
      "std: 0.04323739483425154\n",
      "min: 0.018533605398506143\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32840184954830304\n",
      "std: 0.29261019103909625\n",
      "min: -0.808344770486722\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6305460459334574\n",
      "std: 0.09158924205494852\n",
      "min: 0.3825654312513674\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910440898390798\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371006\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1865821097272162\n",
      "std: 0.16907252983693585\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1896913454486713\n",
      "std: 0.17037250152952196\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.0447384083941289\n",
      "min: 0.006410717386126359\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3434435544400069\n",
      "std: 0.363162490195503\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4725159125352271\n",
      "std: 0.1628160585781303\n",
      "min: 0.04367356295002459\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01888460217397535\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078363420930755\n",
      "std: 0.003859117485403746\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498367\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078617069989616\n",
      "std: 0.0040649684768023055\n",
      "min: 1.378714447864481\n",
      "max: 1.4139785360498367\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04323519804211234\n",
      "min: 0.018933184700355866\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.329550089178113\n",
      "std: 0.292782704565365\n",
      "min: -0.809025623169343\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6301736147050814\n",
      "std: 0.09144046256770828\n",
      "min: 0.38263956729949683\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019120224698670953\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782653010781378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.214217471339358\n",
      "std: 0.08005889221529625\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2169408419061234\n",
      "std: 0.08489321113091673\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04381040484071032\n",
      "min: 0.012434515686955574\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3507307773602518\n",
      "std: 0.3597118631228534\n",
      "min: -1.0388133449438244\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46681759369428905\n",
      "std: 0.1611954267878345\n",
      "min: 0.039411033477144565\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018800990885696853\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083511889620235\n",
      "std: 0.002955684840817834\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935542\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083594840178966\n",
      "std: 0.003212992696687004\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935542\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.043234923732790406\n",
      "min: 0.019016019510358046\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3308954984868581\n",
      "std: 0.29245017240620713\n",
      "min: -0.8087437014825686\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6282240187278421\n",
      "std: 0.09119994605572829\n",
      "min: 0.38262330404903444\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019115873940942777\n",
      "min: 0.20919997721928477\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.174937585073549\n",
      "std: 0.21793647279497513\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1780814543429088\n",
      "std: 0.22059733856043293\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04598321603469702\n",
      "min: 0.004181555809506525\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3509612919318211\n",
      "std: 0.3609205169672242\n",
      "min: -1.0458017076285244\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4665566102420845\n",
      "std: 0.16242811991098502\n",
      "min: 0.043272530016648054\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018937394235686432\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4061503933159585\n",
      "std: 0.011398091896043685\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061798242340726\n",
      "std: 0.01155039748395346\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03773584905660377\n",
      "std: 0.04324448089437652\n",
      "min: 0.017761770152753972\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3319640348987914\n",
      "std: 0.2923166100817013\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6293488567573331\n",
      "std: 0.0929433803828638\n",
      "min: 0.3811028466794016\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01922205709241231\n",
      "min: 0.20921255256223345\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.187453292706497\n",
      "std: 0.1574954819333942\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.190299910324214\n",
      "std: 0.1599491152719567\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.044190824255633525\n",
      "min: 0.006140696417090343\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3412426836921514\n",
      "std: 0.3613858522038325\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4717087770245023\n",
      "std: 0.16361731463433227\n",
      "min: 0.02893535078928436\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018765733710176723\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077062395359943\n",
      "std: 0.004265786911058236\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077323521214093\n",
      "std: 0.0043432299773167584\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04257667032849122\n",
      "min: 0.01843768274813723\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3292226078665689\n",
      "std: 0.29276132129352983\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.630630503415369\n",
      "std: 0.09136659180699314\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019115965466518097\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1841045414248639\n",
      "std: 0.17307698058718263\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1870524840693684\n",
      "std: 0.17626207729798757\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04478404934730151\n",
      "min: 0.006475206007519072\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34156009169009705\n",
      "std: 0.36444375325175676\n",
      "min: -1.0437223035810501\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47138132846197767\n",
      "std: 0.16520753915385716\n",
      "min: 0.028674009790096735\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018931570627409224\n",
      "min: 0.20186291846053703\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4072731742923255\n",
      "std: 0.0061097435458462865\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019797\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407309170839126\n",
      "std: 0.006191209705596896\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019797\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.042578512345137175\n",
      "min: 0.01806137024398357\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3284043488349904\n",
      "std: 0.29256309469270547\n",
      "min: -0.808344770486722\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.630380047943313\n",
      "std: 0.09157171391286094\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019101339564146586\n",
      "min: 0.2066507421484001\n",
      "max: 0.27827431333710057\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.186592932978359\n",
      "std: 0.16801233543569702\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.189544041533197\n",
      "std: 0.16930952718566433\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04404810319513837\n",
      "min: 0.005740098898050175\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34274197647126514\n",
      "std: 0.36250136478860373\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47098751755694035\n",
      "std: 0.16365842662308294\n",
      "min: 0.028870670051266478\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018887700188200244\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078306868995203\n",
      "std: 0.003839566605508168\n",
      "min: 1.3787144478644813\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078477039950585\n",
      "std: 0.0040434021520966605\n",
      "min: 1.3787144478644813\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.042576362067637874\n",
      "min: 0.018434485571349832\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32953594425187027\n",
      "std: 0.29273698186426145\n",
      "min: -0.8090256231693427\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6300149718933856\n",
      "std: 0.09142621509818392\n",
      "min: 0.3826395672994966\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01911703080511767\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2137554287020562\n",
      "std: 0.0797911599129889\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.216336126498826\n",
      "std: 0.0845844088728\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04313960889127231\n",
      "min: 0.012434515686955574\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3499030478809515\n",
      "std: 0.3590974627924611\n",
      "min: -1.0388133449438244\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4653719863265051\n",
      "std: 0.16202637155173039\n",
      "min: 0.027418415317775724\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01880552755994822\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408338884946659\n",
      "std: 0.002935733038871217\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408339173808817\n",
      "std: 0.0031915180576032364\n",
      "min: 1.381810710824313\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.042576093030413764\n",
      "min: 0.018505597376375815\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3308585308095268\n",
      "std: 0.2924079184285313\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6280951847907601\n",
      "std: 0.09118705006948012\n",
      "min: 0.38262330404903433\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019112601318136465\n",
      "min: 0.20919997721928474\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.175178875589161\n",
      "std: 0.21629617102893192\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1781597834738846\n",
      "std: 0.21895016965667813\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.045266053885944346\n",
      "min: 0.004181555809506525\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35015046494845314\n",
      "std: 0.3602963524929467\n",
      "min: -1.0458017076285244\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46512274914708324\n",
      "std: 0.163221729817873\n",
      "min: 0.02877950555986485\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018939631068651253\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4061771226992326\n",
      "std: 0.011303381670515441\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4061974989673975\n",
      "std: 0.011455962377935272\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.037037037037037035\n",
      "std: 0.04258544845311077\n",
      "min: 0.017313754523196417\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33191182153288057\n",
      "std: 0.2922740997239964\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6292013008152899\n",
      "std: 0.09290302456322683\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019217266501428337\n",
      "min: 0.20921255256223345\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1885795729657773\n",
      "std: 0.15631605763942558\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1915610088238189\n",
      "std: 0.15880271412613214\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04351941550602679\n",
      "min: 0.006140696417090343\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34170092873805685\n",
      "std: 0.3612328884383897\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4709001074975124\n",
      "std: 0.16450455090914456\n",
      "min: 0.028935350789284234\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018757719890007064\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077479759233875\n",
      "std: 0.004238164596997614\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077876357680321\n",
      "std: 0.004308775971974849\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04193889430793673\n",
      "min: 0.018172838928791422\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3291870475042472\n",
      "std: 0.29275276147157386\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6305879677017143\n",
      "std: 0.09133403816340833\n",
      "min: 0.38305640168109684\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01911257283046045\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.185298656727597\n",
      "std: 0.17164848403684052\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1883782284764355\n",
      "std: 0.17486468621514237\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04410002015723345\n",
      "min: 0.006475206007519074\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34202658852748286\n",
      "std: 0.3642374878535076\n",
      "min: -1.0437223035810501\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4705746230742051\n",
      "std: 0.1660529034425003\n",
      "min: 0.028674009790096627\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018920832845549553\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073227186859507\n",
      "std: 0.006057537088721318\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4073719964105504\n",
      "std: 0.006135165739881986\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.041940697474576495\n",
      "min: 0.01793752407504719\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.328378144713932\n",
      "std: 0.2925545433473369\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6303371150688856\n",
      "std: 0.0915337979851779\n",
      "min: 0.3825654312513674\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019097948850386598\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1877214553593165\n",
      "std: 0.1668800037393363\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1908054964246182\n",
      "std: 0.16821938503201375\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04337989999202745\n",
      "min: 0.005740098898050175\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34318294012648887\n",
      "std: 0.36233586508979454\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4701875226471469\n",
      "std: 0.164546722001743\n",
      "min: 0.028870670051266506\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01887797481023551\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078695306580689\n",
      "std: 0.003814027850505112\n",
      "min: 1.3787144478644813\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079004100641708\n",
      "std: 0.004008757606357291\n",
      "min: 1.3787144478644813\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04193859248282395\n",
      "min: 0.018224947444461726\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.329493788819655\n",
      "std: 0.2927293569868107\n",
      "min: -0.809025623169343\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6299789107847826\n",
      "std: 0.09139189297174916\n",
      "min: 0.38263956729949694\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019113502058444063\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782653010781378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2144156132249109\n",
      "std: 0.07929459284045888\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2171469286847258\n",
      "std: 0.08407670831752027\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.04249015979534089\n",
      "min: 0.012308134224543887\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35022206764602065\n",
      "std: 0.358963221435533\n",
      "min: -1.0388133449438244\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46465184217721534\n",
      "std: 0.16292060555361781\n",
      "min: 0.02741841531777583\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018797012754364566\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083680439790274\n",
      "std: 0.0029216884625219842\n",
      "min: 1.3818107108243132\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083825205338958\n",
      "std: 0.0031647816076796533\n",
      "min: 1.3818107108243132\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.041938328927759394\n",
      "min: 0.018228671059783923\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33079456396913187\n",
      "std: 0.29240399033567344\n",
      "min: -0.8087437014825688\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6280873110199771\n",
      "std: 0.09115638244409485\n",
      "min: 0.38262330404903433\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019109026026271098\n",
      "min: 0.20919997721928474\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1765217858552497\n",
      "std: 0.2146055059764856\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1796308110485167\n",
      "std: 0.21729762270328662\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.0445720249323198\n",
      "min: 0.004048918960777755\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35048897344434665\n",
      "std: 0.3601492602923545\n",
      "min: -1.0458017076285244\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46441482758692143\n",
      "std: 0.1640790857707958\n",
      "min: 0.02877950555986486\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018929386801718878\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406244332714858\n",
      "std: 0.011209426859161105\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4062778441285877\n",
      "std: 0.011361049537945436\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03636363636363636\n",
      "std: 0.041947489967978556\n",
      "min: 0.017067529270903194\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33183345745042125\n",
      "std: 0.29227001994702345\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6291767770569507\n",
      "std: 0.09284409260588793\n",
      "min: 0.38110284667940153\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019212209991273235\n",
      "min: 0.20921255256223345\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1888314089034666\n",
      "std: 0.15498566009682538\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1917608625016494\n",
      "std: 0.1574891036690799\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.042869362242986715\n",
      "min: 0.006140696417090343\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3418656988238032\n",
      "std: 0.36072389727396265\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.470530200641454\n",
      "std: 0.16487547829041166\n",
      "min: 0.02893535078928424\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018756151549350356\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077777982000026\n",
      "std: 0.004207223660148237\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078242367296805\n",
      "std: 0.004275291532553187\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04132116720876727\n",
      "min: 0.017773201121898636\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32923044339691954\n",
      "std: 0.2926990567385248\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.630446415304213\n",
      "std: 0.09133762134500394\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01911604635778892\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1856197084933369\n",
      "std: 0.170014124123151\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1886440837566818\n",
      "std: 0.17324495925772848\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04343779722370652\n",
      "min: 0.006475206007519074\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34219669125535446\n",
      "std: 0.3636823579877401\n",
      "min: -1.0437223035810501\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4702076488142661\n",
      "std: 0.16639300571756555\n",
      "min: 0.028674009790096648\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018916497061863907\n",
      "min: 0.20186291846053703\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407360153434795\n",
      "std: 0.006000258467991115\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074159828807506\n",
      "std: 0.006077060076438104\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04132293288889779\n",
      "min: 0.017553532916679104\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3284307226597245\n",
      "std: 0.29250105916244235\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6301953223129528\n",
      "std: 0.09153211112304332\n",
      "min: 0.38256543125136727\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019101444154191436\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.187983792789525\n",
      "std: 0.1655250922393762\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1910136656500456\n",
      "std: 0.16688897802558447\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04273288799903958\n",
      "min: 0.005740098898050175\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3433290259872139\n",
      "std: 0.36181902987167697\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.469828973474476\n",
      "std: 0.16492213460627322\n",
      "min: 0.028870670051266655\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01887463646560837\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078963913499878\n",
      "std: 0.0037852243397653875\n",
      "min: 1.3787144478644813\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079343166065919\n",
      "std: 0.003976240343728848\n",
      "min: 1.3787144478644813\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04132087159502688\n",
      "min: 0.01781073212593101\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32953058498513765\n",
      "std: 0.2926767008394872\n",
      "min: -0.809025623169343\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6298438613526433\n",
      "std: 0.09139292046963013\n",
      "min: 0.38263956729949683\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019116840561046903\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782653010781378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2141678039229817\n",
      "std: 0.07891787903554061\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2168609322784658\n",
      "std: 0.08369024990455114\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.0418612982553656\n",
      "min: 0.012308134224543887\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3502519621623191\n",
      "std: 0.35847657388451215\n",
      "min: -1.0388133449438244\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4643678610255719\n",
      "std: 0.16330058929866695\n",
      "min: 0.02741841531777597\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01879467061563349\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083855637283391\n",
      "std: 0.0028973442222662987\n",
      "min: 1.381810710824313\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084074589543238\n",
      "std: 0.003135548057298905\n",
      "min: 1.381810710824313\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.0413206131755835\n",
      "min: 0.017917125950029266\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3308099073040454\n",
      "std: 0.2923545847446966\n",
      "min: -0.8087437014825688\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6279800637245571\n",
      "std: 0.09115863307975121\n",
      "min: 0.38262330404903433\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01911227981699734\n",
      "min: 0.20919997721928474\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1769746243100403\n",
      "std: 0.2125714143968738\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1800246166160298\n",
      "std: 0.21529029442458697\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04390022251348277\n",
      "min: 0.004048918960777755\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35053420251338896\n",
      "std: 0.3596548532721853\n",
      "min: -1.0458017076285244\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46414331071386594\n",
      "std: 0.16444070669652008\n",
      "min: 0.02877950555986479\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01892586272092591\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406301002716689\n",
      "std: 0.01110442238281594\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4063409426934579\n",
      "std: 0.011256499685331364\n",
      "min: 1.3097133434960238\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03571428571428571\n",
      "std: 0.04132958647936996\n",
      "min: 0.016807999797272925\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.331834998663461\n",
      "std: 0.29221971588511386\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6290530192700039\n",
      "std: 0.09282207667248693\n",
      "min: 0.3811028466794016\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01921405459895338\n",
      "min: 0.20921255256223342\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1894471880731892\n",
      "std: 0.1537702754984167\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1922552631074175\n",
      "std: 0.15628319040742794\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04223965751642871\n",
      "min: 0.006140696417090344\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34196653008895156\n",
      "std: 0.36064139482260255\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47122582985497513\n",
      "std: 0.16548387565258318\n",
      "min: 0.028935350789284175\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018768602975592172\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077992054476707\n",
      "std: 0.004194834233809906\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078507620511318\n",
      "std: 0.004264452096829834\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04072253616329456\n",
      "min: 0.017393878716950112\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.329087556253558\n",
      "std: 0.292657997776744\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6304580125815941\n",
      "std: 0.09123216470805316\n",
      "min: 0.38305640168109645\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01911261541511185\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.186280618409345\n",
      "std: 0.16887786855275755\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.18918158345565\n",
      "std: 0.1721035960599215\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.042796533834094236\n",
      "min: 0.005991365314890132\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34230428333811797\n",
      "std: 0.36354842216657984\n",
      "min: -1.0437223035810501\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47090204100465033\n",
      "std: 0.1669668543124514\n",
      "min: 0.028674009790096783\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0189261641233581\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4073884046425915\n",
      "std: 0.005973869265844251\n",
      "min: 1.3581282398435746\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074491724893687\n",
      "std: 0.006052050350156943\n",
      "min: 1.3581282398435746\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04072426652458532\n",
      "min: 0.017148330797258478\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32829681380401815\n",
      "std: 0.2924597275018403\n",
      "min: -0.808344770486722\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6302067840303458\n",
      "std: 0.09142191343023849\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01909801190648444\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371006\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.188613635581076\n",
      "std: 0.16420559913754285\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1915199711371733\n",
      "std: 0.1655938844504339\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04210608729031442\n",
      "min: 0.005740098898050176\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34341154187537865\n",
      "std: 0.3617240334910166\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47053170072559725\n",
      "std: 0.16553056807278885\n",
      "min: 0.028870670051266565\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018885295136081157\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079162507707594\n",
      "std: 0.003778586777000946\n",
      "min: 1.3787144478644813\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407959557751545\n",
      "std: 0.003969980098287971\n",
      "min: 1.3787144478644813\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04072224656794252\n",
      "min: 0.017406916403717148\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32938120886269057\n",
      "std: 0.292636593343286\n",
      "min: -0.809025623169343\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6298616660393057\n",
      "std: 0.09128589305677819\n",
      "min: 0.3826395672994968\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019113286086729256\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2143174594517472\n",
      "std: 0.07871224856818508\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2169014365922037\n",
      "std: 0.08347068567713573\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04125197490097112\n",
      "min: 0.011660689369961615\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.350221856570562\n",
      "std: 0.3584190549051934\n",
      "min: -1.0388133449438244\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4651410434486442\n",
      "std: 0.16395571144371193\n",
      "min: 0.027418415317775873\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018806458585550738\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083987232341852\n",
      "std: 0.0028931570359108085\n",
      "min: 1.381810710824313\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084263078073898\n",
      "std: 0.003131225740808987\n",
      "min: 1.381810710824313\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04072199292081013\n",
      "min: 0.01745527252334767\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3306403497704357\n",
      "std: 0.2923185082078764\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6280243798081653\n",
      "std: 0.09105566687076289\n",
      "min: 0.38262330404903444\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910867512899082\n",
      "min: 0.20919997721928474\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.177750565812012\n",
      "std: 0.2111965641837511\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.180675050277988\n",
      "std: 0.213912997199566\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04324974894009373\n",
      "min: 0.003580235298510747\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3505177892715303\n",
      "std: 0.3595843280059836\n",
      "min: -1.0458017076285244\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4649322741716157\n",
      "std: 0.16507179733082955\n",
      "min: 0.028779505559864887\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018935963137982466\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4063451288058482\n",
      "std: 0.011043774508882711\n",
      "min: 1.3097133434960235\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4063899561880837\n",
      "std: 0.011197116485316827\n",
      "min: 1.3097133434960235\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03508771929824561\n",
      "std: 0.04073078845465617\n",
      "min: 0.016280555359289395\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.331651205065635\n",
      "std: 0.2921836790208472\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6290817832856387\n",
      "std: 0.09269348346442866\n",
      "min: 0.3811028466794016\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019209049876114454\n",
      "min: 0.20921255256223345\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1897720426502116\n",
      "std: 0.15269259460564902\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1924425994211834\n",
      "std: 0.15520097501128152\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.0416293634341582\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34245837478971186\n",
      "std: 0.3603296281609855\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4713294996836353\n",
      "std: 0.16546046818564317\n",
      "min: 0.028935350789284234\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018750171004594453\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078136379510382\n",
      "std: 0.004168598386460266\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078446932666926\n",
      "std: 0.004239392644920215\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.04014210736236145\n",
      "min: 0.017209567548456203\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3291658133061867\n",
      "std: 0.2926599925941123\n",
      "min: -0.8090169112147217\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6304100427692556\n",
      "std: 0.09116069227840884\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019113108582674072\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1866683752558482\n",
      "std: 0.16749698113658254\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.189429647574505\n",
      "std: 0.17071183738327494\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.042175031941662854\n",
      "min: 0.005991365314890132\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3428004098209829\n",
      "std: 0.36318570130855987\n",
      "min: -1.0437223035810501\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.471003437106132\n",
      "std: 0.1669175292159084\n",
      "min: 0.028674009790096686\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018905365709380173\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074104997177284\n",
      "std: 0.005924666224106062\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074505252062266\n",
      "std: 0.006003315050003949\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.040143803180894416\n",
      "min: 0.016934210881578603\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32838402053178956\n",
      "std: 0.29246194371536394\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6301579692166741\n",
      "std: 0.0913455374509414\n",
      "min: 0.3825654312513676\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019098505801347244\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1889726327531698\n",
      "std: 0.16275163033036488\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.191739145322494\n",
      "std: 0.1641568198128247\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.04149849138133396\n",
      "min: 0.005740098898050176\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3438842922524879\n",
      "std: 0.3613940826127189\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4706450677533458\n",
      "std: 0.16550506548669772\n",
      "min: 0.028870670051266714\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018865281654094367\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079281390903413\n",
      "std: 0.003753747713870114\n",
      "min: 1.3787144478644813\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079511652578927\n",
      "std: 0.003945372002694562\n",
      "min: 1.3787144478644813\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.04014182346547633\n",
      "min: 0.017229770574493868\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3294531154516221\n",
      "std: 0.2926391091196908\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6298200916534427\n",
      "std: 0.09121285886911189\n",
      "min: 0.3826395672994967\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01911365992468227\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782653010781378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.21420641976878\n",
      "std: 0.07829922892599636\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.216664309966002\n",
      "std: 0.0830376654703447\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.04066126178378382\n",
      "min: 0.01148856370921786\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35058837951149263\n",
      "std: 0.35811646799621294\n",
      "min: -1.0388133449438244\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46531475133115213\n",
      "std: 0.16395968059256014\n",
      "min: 0.02741841531777583\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018787526722161746\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408400763090399\n",
      "std: 0.0028848570734231276\n",
      "min: 1.381810710824313\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408408441010002\n",
      "std: 0.003123929572925786\n",
      "min: 1.381810710824313\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.04014157479953243\n",
      "min: 0.017227188966989767\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33069326721030323\n",
      "std: 0.29232385887695644\n",
      "min: -0.8087437014825686\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.628007797973245\n",
      "std: 0.0909861904782539\n",
      "min: 0.38262330404903444\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019108994455888706\n",
      "min: 0.20919997721928474\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1782670031866895\n",
      "std: 0.2094859751876419\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1810490356038108\n",
      "std: 0.21219971268643625\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03448275862068966\n",
      "std: 0.04261936317554902\n",
      "min: 0.003580235298510747\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3508987227611829\n",
      "std: 0.3592660956155638\n",
      "min: -1.0458017076285244\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46512036399095424\n",
      "std: 0.16505180973925293\n",
      "min: 0.02877950555986479\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018915543355313584\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406381303774389\n",
      "std: 0.010968354343007993\n",
      "min: 1.3094288397323328\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4064053892376582\n",
      "std: 0.01112148952743563\n",
      "min: 1.3094288397323328\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.034482758620689655\n",
      "std: 0.04015019803197252\n",
      "min: 0.015977024578527763\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3316911596577433\n",
      "std: 0.29218839408773406\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6290497051308604\n",
      "std: 0.09259852595777701\n",
      "min: 0.3811028466794016\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019208007886912574\n",
      "min: 0.20921255256223345\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1901622971998487\n",
      "std: 0.15183316497598956\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.192845007878766\n",
      "std: 0.15431700336357804\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.04103762633441271\n",
      "min: 0.0052508147561464\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34223504162802026\n",
      "std: 0.3606578293755954\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47016185498321134\n",
      "std: 0.16580630363106144\n",
      "min: 0.02893535078928432\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018723405299504177\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077981424148922\n",
      "std: 0.004163292082899286\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078238270515457\n",
      "std: 0.0042358194602861755\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.03957904431513354\n",
      "min: 0.016859022544965067\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32930616967523463\n",
      "std: 0.2927106773419703\n",
      "min: -0.8090169112147214\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.630347683232696\n",
      "std: 0.09117377195434036\n",
      "min: 0.38305640168109667\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019114191115494932\n",
      "min: 0.20786227638008073\n",
      "max: 0.27826719929881266\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1871128214368676\n",
      "std: 0.1665357079502117\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1898836829488968\n",
      "std: 0.16972268766193552\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.04157254783304485\n",
      "min: 0.005886533691104929\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34258269241334005\n",
      "std: 0.3634619703108049\n",
      "min: -1.0437223035810501\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46983503740173027\n",
      "std: 0.16723428553551015\n",
      "min: 0.028674009790096714\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01887632140769463\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074009765532027\n",
      "std: 0.005909250383428035\n",
      "min: 1.3581282398435746\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407435429386676\n",
      "std: 0.005988919916483989\n",
      "min: 1.3581282398435746\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.039580707638595315\n",
      "min: 0.016512261015755307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3285328917482998\n",
      "std: 0.29251283534677414\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.630094937533203\n",
      "std: 0.09135376200861585\n",
      "min: 0.38256543125136727\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019099590421581398\n",
      "min: 0.2066507421484001\n",
      "max: 0.27827431333710057\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1893551342404138\n",
      "std: 0.16204635905700815\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1921324321824183\n",
      "std: 0.16343055738434345\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.040909510731720236\n",
      "min: 0.005210908205748144\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34364418340382674\n",
      "std: 0.36170821717998447\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46948287711344566\n",
      "std: 0.16585126826895208\n",
      "min: 0.028870670051266537\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018837009536465717\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407911013658091\n",
      "std: 0.003760079836953926\n",
      "min: 1.3780322343743017\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079288950965574\n",
      "std: 0.003951327230177513\n",
      "min: 1.3780322343743017\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.03957876611077471\n",
      "min: 0.016804708067297378\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32958778279520695\n",
      "std: 0.29269020787286504\n",
      "min: -0.809025623169343\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6297630044501973\n",
      "std: 0.09122432144189059\n",
      "min: 0.3826395672994967\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01911461933566041\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2142281378743514\n",
      "std: 0.07801454963703817\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2167093073749806\n",
      "std: 0.08266365985110524\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.04008829684584135\n",
      "min: 0.011488563709217862\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35024151756973776\n",
      "std: 0.3584706154524912\n",
      "min: -1.0388133449438244\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46422529000723695\n",
      "std: 0.1642968505888827\n",
      "min: 0.027418415317775773\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018760321427206256\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083786266836127\n",
      "std: 0.0028953482419744486\n",
      "min: 1.381810710824313\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408381385351707\n",
      "std: 0.0031337852316684887\n",
      "min: 1.381810710824313\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.039578521795048706\n",
      "min: 0.016904030408033167\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3308084202586523\n",
      "std: 0.29237749948105957\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.627975803215951\n",
      "std: 0.09100027805816384\n",
      "min: 0.38262330404903444\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910988250862694\n",
      "min: 0.20919997721928474\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1788682812366282\n",
      "std: 0.2081095875830514\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.181656528827898\n",
      "std: 0.2108138570285094\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.04200825421814026\n",
      "min: 0.0035359243345667365\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3505654125379458\n",
      "std: 0.3596093065466633\n",
      "min: -1.0458017076285244\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46404118755889984\n",
      "std: 0.16536228371828204\n",
      "min: 0.028779505559864818\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01888658597057048\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4063886271130985\n",
      "std: 0.010908612405730449\n",
      "min: 1.3067256737265633\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406407085949252\n",
      "std: 0.011062409443890416\n",
      "min: 1.3067256737265633\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03389830508474576\n",
      "std: 0.039586979801801786\n",
      "min: 0.015667402264373093\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33179375626656926\n",
      "std: 0.2922417154416058\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6290028381648753\n",
      "std: 0.09258758192758822\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019207597091524066\n",
      "min: 0.20921255256223345\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1899541825824695\n",
      "std: 0.15086459511684625\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.192763380674907\n",
      "std: 0.1533204176442962\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.040463444077170535\n",
      "min: 0.0052508147561464\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3423773879181469\n",
      "std: 0.3600700416816339\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47033850703993524\n",
      "std: 0.16511567198632415\n",
      "min: 0.028935350789284282\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01868914820316479\n",
      "min: 0.2019131357857576\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077912177222438\n",
      "std: 0.004142462420789922\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078072659992225\n",
      "std: 0.004225029726078091\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.03903256017935892\n",
      "min: 0.016579291880905973\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32947488124316116\n",
      "std: 0.2926761376246252\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6302455971619728\n",
      "std: 0.09112627444228201\n",
      "min: 0.3830564016810965\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019107780608671226\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.186967491029898\n",
      "std: 0.16528930735177108\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1898619837065136\n",
      "std: 0.16845053257101217\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.04098794835816976\n",
      "min: 0.005886533691104929\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3427300739720301\n",
      "std: 0.3628340201090156\n",
      "min: -1.0437223035810501\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47001530233186045\n",
      "std: 0.16652607835064637\n",
      "min: 0.028674009790096756\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01883987599917251\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074002618466748\n",
      "std: 0.005871015417773455\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407424873800701\n",
      "std: 0.00595768904017566\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.03903419169637513\n",
      "min: 0.016370407324482694\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32870967348198343\n",
      "std: 0.29247861212435755\n",
      "min: -0.8083447704867218\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6299923783990402\n",
      "std: 0.09130161839529213\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01909319400905188\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.189163513095205\n",
      "std: 0.16094730448125044\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1920655112423775\n",
      "std: 0.1623136225084988\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.04033787923007226\n",
      "min: 0.005210908205748144\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34376998309936374\n",
      "std: 0.36111087588146984\n",
      "min: -1.0237355881308934\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46967204519285\n",
      "std: 0.16516169240853065\n",
      "min: 0.028870670051266603\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018801414768402303\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079022518643287\n",
      "std: 0.003744859321884741\n",
      "min: 1.3780322343743017\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079106900871647\n",
      "std: 0.0039450478945905\n",
      "min: 1.3780322343743017\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.03903228735055154\n",
      "min: 0.01657730466841972\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3297508371192221\n",
      "std: 0.292655944166149\n",
      "min: -0.809025623169343\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6296667451974859\n",
      "std: 0.09117491129591257\n",
      "min: 0.3826395672994967\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910809994624803\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782653010781378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2136310347642625\n",
      "std: 0.07781139540608734\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2162501528448355\n",
      "std: 0.08234263806185958\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.03953223393174502\n",
      "min: 0.011488563709217862\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3502644697059853\n",
      "std: 0.35790465815203376\n",
      "min: -1.0388133449438244\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4644772589292084\n",
      "std: 0.16362823873827076\n",
      "min: 0.027418415317775863\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018725770163108443\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408363339186489\n",
      "std: 0.002894400083429766\n",
      "min: 1.3817688628844547\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408356904821382\n",
      "std: 0.0031434371320645323\n",
      "min: 1.3817688628844547\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.039032047550298106\n",
      "min: 0.01657295443436659\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33095261299165185\n",
      "std: 0.2923458056755013\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6279037102418029\n",
      "std: 0.09095295833072305\n",
      "min: 0.3826233040490345\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019103324235478867\n",
      "min: 0.20919997721928474\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1788288410540002\n",
      "std: 0.2066574857113128\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1817389484931478\n",
      "std: 0.20935171506586714\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.04141542665349876\n",
      "min: 0.0035359243345667365\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3506030250417619\n",
      "std: 0.35903427479226036\n",
      "min: -1.0458017076285244\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46430516230043734\n",
      "std: 0.16468292451952632\n",
      "min: 0.02877950555986485\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01885048649706275\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064017895459968\n",
      "std: 0.010844483933250158\n",
      "min: 1.3067256737265638\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406410402658469\n",
      "std: 0.011002135243920368\n",
      "min: 1.3067256737265638\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03333333333333333\n",
      "std: 0.03904034609400304\n",
      "min: 0.015439482306237094\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3319260569521304\n",
      "std: 0.29220919236618215\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.628915011184093\n",
      "std: 0.09251810223723622\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019199795183245397\n",
      "min: 0.20921255256223342\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.191120828295267\n",
      "std: 0.1496876849643549\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1939767431539972\n",
      "std: 0.15214862675592392\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.03990592597157447\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3429963996940347\n",
      "std: 0.36066135024649165\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4715362189905268\n",
      "std: 0.16491921451066452\n",
      "min: 0.028935350789284185\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01868988495573871\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078211412511337\n",
      "std: 0.004116353512313273\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078401768893551\n",
      "std: 0.0041969784344220475\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.03850191599786018\n",
      "min: 0.01634418941006999\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32953725061624856\n",
      "std: 0.292774976270379\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.630340368525528\n",
      "std: 0.09108939707980614\n",
      "min: 0.3830564016810965\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910751439812036\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1881759991251497\n",
      "std: 0.16406092798504657\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1911147209845465\n",
      "std: 0.16722604043722428\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.040420458229562056\n",
      "min: 0.0058865336911049304\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3433535278277964\n",
      "std: 0.3633757636261522\n",
      "min: -1.0437223035810501\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47121296732515283\n",
      "std: 0.166306857499957\n",
      "min: 0.028674009790096804\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018838189064770916\n",
      "min: 0.20186291846053697\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4074363423935665\n",
      "std: 0.0058316759015599315\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407463775347334\n",
      "std: 0.005916908685832211\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.038503516866606156\n",
      "min: 0.016101693212698713\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32878017433937134\n",
      "std: 0.2925779230773954\n",
      "min: -0.8083447704867224\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6300871584124107\n",
      "std: 0.09126014293028512\n",
      "min: 0.38256543125136755\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019092933645309926\n",
      "min: 0.2066507421484001\n",
      "max: 0.27827431333710057\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1903416264409294\n",
      "std: 0.15973156692346663\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1932884984879526\n",
      "std: 0.16111483036404103\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.03978285764348662\n",
      "min: 0.005210908205748144\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3443724636894802\n",
      "std: 0.3616882299922057\n",
      "min: -1.0355454379731996\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47087907928679856\n",
      "std: 0.16496913557467335\n",
      "min: 0.028870670051266645\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018800670690005045\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079302279014454\n",
      "std: 0.003724589159650861\n",
      "min: 1.378032234374302\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079418748986925\n",
      "std: 0.003921583078255768\n",
      "min: 1.378032234374302\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.0385016484053706\n",
      "min: 0.01633812432083864\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3298077877078856\n",
      "std: 0.2927556938571541\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6297675139234676\n",
      "std: 0.09113719130134934\n",
      "min: 0.3826395672994968\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019107723309328212\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.214388902533023\n",
      "std: 0.07745638010541114\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2170649860843787\n",
      "std: 0.08195609841934505\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.038992299490917065\n",
      "min: 0.011488563709217864\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35076942252932725\n",
      "std: 0.3585095489753732\n",
      "min: -1.0388133449438244\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4657435823173498\n",
      "std: 0.16348543069688254\n",
      "min: 0.027418415317775852\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018725819074061432\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408383877323448\n",
      "std: 0.0028801406172952824\n",
      "min: 1.3817688628844547\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083809289194036\n",
      "std: 0.003124957157670579\n",
      "min: 1.3817688628844547\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.03850141290879353\n",
      "min: 0.016372532127746996\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33099162102515906\n",
      "std: 0.29244803543418874\n",
      "min: -0.8087437014825686\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6280274635881291\n",
      "std: 0.09092080572091982\n",
      "min: 0.3826233040490345\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019102904666656668\n",
      "min: 0.20909489195757852\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1801946126981073\n",
      "std: 0.20491698734110267\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1831459716832224\n",
      "std: 0.2076262175690681\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.040839916123982516\n",
      "min: 0.003535924334566736\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3511177573268902\n",
      "std: 0.35962574211940035\n",
      "min: -1.0458017076285244\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46558580515760856\n",
      "std: 0.16452320999998124\n",
      "min: 0.02877950555986492\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01884908036295162\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064536296328272\n",
      "std: 0.010768173599813389\n",
      "min: 1.3067256737265638\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4064650302984192\n",
      "std: 0.010925576234126398\n",
      "min: 1.3067256737265638\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03278688524590164\n",
      "std: 0.03850955668668993\n",
      "min: 0.01527401980495821\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.331952883541844\n",
      "std: 0.29231132675607857\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6290256493871654\n",
      "std: 0.09246091405165639\n",
      "min: 0.3811028466794016\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01919813705951617\n",
      "min: 0.20910318031483965\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1917331965804627\n",
      "std: 0.148368616736242\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.194528937064756\n",
      "std: 0.15082525255258986\n",
      "min: -0.06162828629403498\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.039364466799707364\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34286042738545147\n",
      "std: 0.3607788179270131\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4714636096873319\n",
      "std: 0.16435747987896843\n",
      "min: 0.028935350789284282\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018693018805243822\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078421793451306\n",
      "std: 0.004098821291906721\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078450372589448\n",
      "std: 0.004182314931946443\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612904\n",
      "std: 0.03798641710345365\n",
      "min: 0.01604784834258316\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3295650438458761\n",
      "std: 0.29279425511780327\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6302366937163402\n",
      "std: 0.0910408534888007\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019109259394107896\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.188824551439843\n",
      "std: 0.16269004200832404\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.191700956238744\n",
      "std: 0.16584535812237855\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.03986940145097745\n",
      "min: 0.0058865336911049304\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34322108994177775\n",
      "std: 0.3634496446505435\n",
      "min: -1.0437223035810501\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4711396447388324\n",
      "std: 0.16572636756379994\n",
      "min: 0.028674009790096756\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018838952540057838\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407463132576673\n",
      "std: 0.00580232317261142\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407474226825472\n",
      "std: 0.005889286649220605\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612904\n",
      "std: 0.03798798855061873\n",
      "min: 0.015756373103570163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3288157701930368\n",
      "std: 0.2925974558864471\n",
      "min: -0.808344770486722\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6299833025109747\n",
      "std: 0.0912074104430576\n",
      "min: 0.38256543125136755\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019094691209292754\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1909509110401728\n",
      "std: 0.1585056796180498\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1938359048648388\n",
      "std: 0.15989217881425194\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612904\n",
      "std: 0.039243873781754625\n",
      "min: 0.005210908205748144\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34421996141516176\n",
      "std: 0.36179515378063587\n",
      "min: -1.0355454379731999\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47081155875386993\n",
      "std: 0.1644083811170869\n",
      "min: 0.028870670051266586\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018802334801864478\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079496541097152\n",
      "std: 0.003714650080675366\n",
      "min: 1.3780322343743017\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079452829180257\n",
      "std: 0.00391345789316532\n",
      "min: 1.3780322343743017\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.03798615458400599\n",
      "min: 0.016005736955143034\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3298302318480908\n",
      "std: 0.29277566303182667\n",
      "min: -0.809025623169343\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6296689764550895\n",
      "std: 0.09108691323943485\n",
      "min: 0.3826395672994968\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910936226961773\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2145944220561817\n",
      "std: 0.07706339283111384\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2172194478638922\n",
      "std: 0.08152809822127854\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.038467862728211726\n",
      "min: 0.010583128182429364\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35051989768974884\n",
      "std: 0.3586501400547914\n",
      "min: -1.0388133449438244\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4657376651829871\n",
      "std: 0.16293888464310052\n",
      "min: 0.027418415317775814\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0187284220076904\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4083977009505488\n",
      "std: 0.0028758850708092607\n",
      "min: 1.3817688628844544\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4083790283140472\n",
      "std: 0.003123123327838523\n",
      "min: 1.3817688628844544\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.03798592316592126\n",
      "min: 0.01604877078698028\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.330996446049155\n",
      "std: 0.29247087685545\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.627951931227553\n",
      "std: 0.09087245075984132\n",
      "min: 0.38262330404903466\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019104492622106173\n",
      "min: 0.20909489195757847\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1809633972241422\n",
      "std: 0.20321611539686257\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1838503631481365\n",
      "std: 0.20592330670495163\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612903\n",
      "std: 0.04028116366209304\n",
      "min: 0.003535924334566737\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35087864985842887\n",
      "std: 0.3597585668206179\n",
      "min: -1.0458017076285244\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4655928608098471\n",
      "std: 0.16395972313093599\n",
      "min: 0.02877950555986486\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01885019573247142\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4064961680807215\n",
      "std: 0.010700361839892113\n",
      "min: 1.306725673726564\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406491190744982\n",
      "std: 0.010858328831254888\n",
      "min: 1.306725673726564\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03225806451612904\n",
      "std: 0.03799391783625013\n",
      "min: 0.014961046305423699\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3319459251240412\n",
      "std: 0.2923341473340583\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6289366968627169\n",
      "std: 0.09239101526795128\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01919852716147831\n",
      "min: 0.20910318031483968\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1931678203976637\n",
      "std: 0.1471733521523382\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1960207003191967\n",
      "std: 0.1496386590967127\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.03883833368548015\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3436767591189025\n",
      "std: 0.36107502574547157\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4714154231176869\n",
      "std: 0.16454310570276826\n",
      "min: 0.028935350789284213\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018731208832413405\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407866094042581\n",
      "std: 0.004067708654048985\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078628699446643\n",
      "std: 0.004150167706885645\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.037485408642689885\n",
      "min: 0.015824041524405485\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32948709041528557\n",
      "std: 0.29276408028142964\n",
      "min: -0.8090169112147214\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6301955499746366\n",
      "std: 0.09101283592866127\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910604398737108\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.190304018691259\n",
      "std: 0.16134014386540663\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1932358466119568\n",
      "std: 0.16449912443410233\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.03933395386590098\n",
      "min: 0.0058865336911049304\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3440394450498928\n",
      "std: 0.3637005161353158\n",
      "min: -1.0437223035810501\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47109092014713483\n",
      "std: 0.1658868435783477\n",
      "min: 0.028674009790096825\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01887466924359711\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407493335999189\n",
      "std: 0.005764652794476805\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4074981994040545\n",
      "std: 0.005850309478518547\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.03748695169293925\n",
      "min: 0.015547276337807767\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32874523291971125\n",
      "std: 0.29256728140266675\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6299424740470093\n",
      "std: 0.09117512382734447\n",
      "min: 0.38256543125136755\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0190914889298139\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1924050095935559\n",
      "std: 0.15716453864860108\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1953456653099999\n",
      "std: 0.1585713305760658\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.038720022587660566\n",
      "min: 0.005210908205748144\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3450182982546377\n",
      "std: 0.3620766931711166\n",
      "min: -1.0355454379732\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.470769437416249\n",
      "std: 0.164594972194838\n",
      "min: 0.028870670051266603\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01883883399826553\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079729217143684\n",
      "std: 0.0036883208682089333\n",
      "min: 1.378032234374302\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079626586374274\n",
      "std: 0.0038845648967061764\n",
      "min: 1.378032234374302\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.03748515097354793\n",
      "min: 0.015822128801721586\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3297467482768403\n",
      "std: 0.29274614590317527\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6296336159576094\n",
      "std: 0.09105737300606159\n",
      "min: 0.3826395672994968\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019106049695636652\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2156195162916725\n",
      "std: 0.0766987412812046\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2183125071103562\n",
      "std: 0.08112827211988279\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.037958128910553474\n",
      "min: 0.01058312818242936\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35122545882273126\n",
      "std: 0.3589537110007773\n",
      "min: -1.0388133449438244\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4657538772866725\n",
      "std: 0.1631454450686503\n",
      "min: 0.027418415317775852\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018766037259081308\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084146624825584\n",
      "std: 0.0028580901151312567\n",
      "min: 1.3817688628844547\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408390322378097\n",
      "std: 0.0031020788906257354\n",
      "min: 1.3817688628844547\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.03748492365151991\n",
      "min: 0.015818128863216412\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3308966784261119\n",
      "std: 0.29244480028785713\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6279384989150499\n",
      "std: 0.09084583843991578\n",
      "min: 0.38262330404903466\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019101161078019034\n",
      "min: 0.2090948919575785\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1825321992283402\n",
      "std: 0.2017222103073855\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1854728590675911\n",
      "std: 0.20443910185113176\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03174603174603175\n",
      "std: 0.039738331012480185\n",
      "min: 0.003535924334566737\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35159612540722346\n",
      "std: 0.36005318019634236\n",
      "min: -1.0458017076285244\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46561825096236614\n",
      "std: 0.16414500693127873\n",
      "min: 0.028779505559864887\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01888621993698785\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065414111261911\n",
      "std: 0.010629090265403708\n",
      "min: 1.3067256737265638\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065301959004943\n",
      "std: 0.010786284197701602\n",
      "min: 1.3067256737265638\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.031746031746031744\n",
      "std: 0.03749277429256493\n",
      "min: 0.01475764394262663\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33183439693883726\n",
      "std: 0.292308259214036\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6289097191641986\n",
      "std: 0.09234280620836824\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019194032047297537\n",
      "min: 0.20910318031483965\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1940342909477746\n",
      "std: 0.14631116174318334\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1968146899454986\n",
      "std: 0.14873938374685552\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03832710214809469\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34402169024041324\n",
      "std: 0.3607188124486912\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4703279204559692\n",
      "std: 0.1640475158425173\n",
      "min: 0.0289353507892843\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018711500146620565\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078910268407527\n",
      "std: 0.004044481425753026\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079019258338552\n",
      "std: 0.004124011356501779\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03699827396261706\n",
      "min: 0.015541467077456912\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3296250484246694\n",
      "std: 0.2927913049700528\n",
      "min: -0.8090169112147214\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6299284358384195\n",
      "std: 0.09103489265671136\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910889780649759\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1912131929042657\n",
      "std: 0.16040520828470906\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1940706545421245\n",
      "std: 0.1635250501117807\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03881375250226981\n",
      "min: 0.00537788043977454\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.344389049412644\n",
      "std: 0.36330767269273784\n",
      "min: -1.0437223035810501\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47000557111216634\n",
      "std: 0.16537274140416192\n",
      "min: 0.028674009790096714\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018853070980496843\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075240085725786\n",
      "std: 0.005731113103682878\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075428366436322\n",
      "std: 0.005815323145300258\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03699978953486525\n",
      "min: 0.01527485656326449\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32889046953717427\n",
      "std: 0.29259482995067265\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6296752597093535\n",
      "std: 0.0911928828391616\n",
      "min: 0.38256543125136755\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019094361715399553\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1932803629248858\n",
      "std: 0.15624620878606216\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1961470683661797\n",
      "std: 0.15762534768475722\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.0382110196363703\n",
      "min: 0.005080774480528211\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3453476825608809\n",
      "std: 0.36171176621514545\n",
      "min: -1.0355454379732\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46968938077135647\n",
      "std: 0.16409663767669244\n",
      "min: 0.028870670051266673\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01881785452090633\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079968575768191\n",
      "std: 0.0036679582918749416\n",
      "min: 1.378032234374302\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080009044538957\n",
      "std: 0.0038599468922656463\n",
      "min: 1.378032234374302\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03699802093009657\n",
      "min: 0.015561015520369407\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3298796636509029\n",
      "std: 0.29277389865456677\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6293710357059633\n",
      "std: 0.09107734357391965\n",
      "min: 0.3826395672994968\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019108800694066067\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2161654097974595\n",
      "std: 0.07634437151011327\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2187937281667809\n",
      "std: 0.08069696462187048\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.0374626289240835\n",
      "min: 0.01058312818242936\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35146328124164916\n",
      "std: 0.35861030831630275\n",
      "min: -1.0388133449438244\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46473483311540775\n",
      "std: 0.162639547853888\n",
      "min: 0.027418415317775852\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01874585973622711\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084326661678572\n",
      "std: 0.002841749790704687\n",
      "min: 1.3817688628844544\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408422808228806\n",
      "std: 0.003079731381192963\n",
      "min: 1.3817688628844544\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.0369977974555927\n",
      "min: 0.015643167674334487\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33101274439591105\n",
      "std: 0.2924747816085104\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6276983480042514\n",
      "std: 0.09086507366248749\n",
      "min: 0.38262330404903466\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019103868251863516\n",
      "min: 0.20909489195757847\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.183556757290942\n",
      "std: 0.2005045752834095\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1864207470840058\n",
      "std: 0.20319706715168132\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03921094211492515\n",
      "min: 0.003400302191169203\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35184667373149237\n",
      "std: 0.3597023495716567\n",
      "min: -1.0458017076285244\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.464607990692639\n",
      "std: 0.16362020747161482\n",
      "min: 0.028779505559864887\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018864842696159716\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065884286110177\n",
      "std: 0.010553019094821491\n",
      "min: 1.3067256737265638\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4065910759121136\n",
      "std: 0.01071065885894832\n",
      "min: 1.3067256737265638\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03125\n",
      "std: 0.03700550849533078\n",
      "min: 0.014570982369282923\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33193945687676796\n",
      "std: 0.2923377617898041\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6286557714702277\n",
      "std: 0.09234287080530762\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019195604502061914\n",
      "min: 0.20910318031483965\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1937236374052533\n",
      "std: 0.1453410697324657\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1965990584806527\n",
      "std: 0.14777543862006165\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.0378299811087451\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3435033515072605\n",
      "std: 0.36137568976166573\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4710689617546847\n",
      "std: 0.1633116207207401\n",
      "min: 0.02893535078928424\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01872682777767381\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078757735518992\n",
      "std: 0.004041044415658973\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078981166168298\n",
      "std: 0.004117028777473847\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.036524431417421295\n",
      "min: 0.015290887467932395\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32961344321406777\n",
      "std: 0.2929071644029388\n",
      "min: -0.8090169112147214\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6299139573937438\n",
      "std: 0.09105341313351982\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019111914524253343\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.190943491593333\n",
      "std: 0.15933181050398734\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1938944011476964\n",
      "std: 0.1624530529627842\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.038307955313561355\n",
      "min: 0.005377880439774539\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34387423939010897\n",
      "std: 0.3639209111170844\n",
      "min: -1.0437223035810501\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4707488075586397\n",
      "std: 0.1646220901370082\n",
      "min: 0.028674009790096724\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01886624199201423\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075136853923955\n",
      "std: 0.00571036873356165\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075438286701332\n",
      "std: 0.005792612871026573\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.03652592038566706\n",
      "min: 0.015004427936751618\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32888586204127085\n",
      "std: 0.2927108180650734\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6296611145208167\n",
      "std: 0.09120691398100926\n",
      "min: 0.38256543125136755\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01909740450736027\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.192986489201982\n",
      "std: 0.15511091951977857\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1959471130038541\n",
      "std: 0.15650497561921664\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.03771601337852091\n",
      "min: 0.00508077448052821\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3448143855991055\n",
      "std: 0.36236173124846777\n",
      "min: -1.0355454379731999\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47043859747700656\n",
      "std: 0.16336491069528375\n",
      "min: 0.028870670051266537\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018831827049118417\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079804827087519\n",
      "std: 0.0036702863958725388\n",
      "min: 1.378032234374302\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407996130604662\n",
      "std: 0.003856625380366593\n",
      "min: 1.378032234374302\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.036524182880633825\n",
      "min: 0.015298345820692191\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3298633315094281\n",
      "std: 0.2928906612689627\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6293613313986257\n",
      "std: 0.0910947704371645\n",
      "min: 0.3826395672994968\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01911174859363871\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2155150750415864\n",
      "std: 0.07606766833680595\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2182475149920933\n",
      "std: 0.08037325760453948\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.03698074106632064\n",
      "min: 0.01058312818242936\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35084378924841253\n",
      "std: 0.359298915965433\n",
      "min: -1.0388133449438244\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4655375580633039\n",
      "std: 0.16193825194667294\n",
      "min: 0.027418415317775755\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018760592525404126\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408410566237038\n",
      "std: 0.002854110881990027\n",
      "min: 1.3817688628844547\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084125234589684\n",
      "std: 0.0030834163340975685\n",
      "min: 1.3817688628844547\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.03652396311639269\n",
      "min: 0.015295702291557267\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33098047705357325\n",
      "std: 0.29259378402119623\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6277094075337795\n",
      "std: 0.09088615417764388\n",
      "min: 0.38262330404903466\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910675683034226\n",
      "min: 0.2090948919575785\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1834248040632456\n",
      "std: 0.19900678002480113\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.186380272380878\n",
      "std: 0.20171122161733152\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.038698159373637867\n",
      "min: 0.003400302191169203\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35123761475036364\n",
      "std: 0.36038243447447216\n",
      "min: -1.0458017076285244\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46542505803298395\n",
      "std: 0.16290976429050782\n",
      "min: 0.028779505559864898\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018878120299313687\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4065930790163983\n",
      "std: 0.010481400399060887\n",
      "min: 1.3067256737265638\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066070061293197\n",
      "std: 0.01063885082908714\n",
      "min: 1.3067256737265638\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.03076923076923077\n",
      "std: 0.03653153902297112\n",
      "min: 0.014355574924780654\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3318958799085159\n",
      "std: 0.29245757822054974\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6286546625389846\n",
      "std: 0.09234226544068104\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019197396003398887\n",
      "min: 0.20910318031483965\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1941995966075316\n",
      "std: 0.1443213338498276\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.196905283049398\n",
      "std: 0.14673346279964444\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.037346330485315646\n",
      "min: 0.005250814756146399\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3435374270357044\n",
      "std: 0.36104759379625245\n",
      "min: -1.0402221534507252\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47112152275642255\n",
      "std: 0.16271697722518585\n",
      "min: 0.02893535078928425\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01871001378379515\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079034078415946\n",
      "std: 0.0040101718943992915\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079167606644631\n",
      "std: 0.004085355755558313\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.036063330877755914\n",
      "min: 0.0151437424295673\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3296439550425647\n",
      "std: 0.29292876682676033\n",
      "min: -0.8090169112147214\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6298417455562193\n",
      "std: 0.09100878116549485\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910679401716955\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1914627741277453\n",
      "std: 0.15814456891718054\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1942419595442402\n",
      "std: 0.16123994322357676\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.0378159024097777\n",
      "min: 0.005377880439774539\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3439114443124076\n",
      "std: 0.3635587838357571\n",
      "min: -1.0437223035810501\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47080284130231653\n",
      "std: 0.16401212963390127\n",
      "min: 0.028674009790096714\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01884748539358034\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075468787408087\n",
      "std: 0.0056654597626330724\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4075678879692377\n",
      "std: 0.005746971891764118\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.03606479390599361\n",
      "min: 0.014874094932615371\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32892320622159554\n",
      "std: 0.29273283986097176\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6295890630404173\n",
      "std: 0.09115839346238698\n",
      "min: 0.38256543125136755\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01909230270925864\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1934687758477704\n",
      "std: 0.15406923858270238\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.196258237782928\n",
      "std: 0.15544624633304785\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.03723444634153234\n",
      "min: 0.00508077448052821\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34483500990820004\n",
      "std: 0.3620265280571593\n",
      "min: -1.0355454379731996\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47049913613918926\n",
      "std: 0.16277193178241323\n",
      "min: 0.028870670051266603\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018813829180039356\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080060979681237\n",
      "std: 0.003641626407666183\n",
      "min: 1.378032234374302\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080129368116907\n",
      "std: 0.003826204126672059\n",
      "min: 1.378032234374302\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.036063086682775976\n",
      "min: 0.01515212311149739\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3298891650721036\n",
      "std: 0.2929129014992204\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.629294252282959\n",
      "std: 0.09104858577892744\n",
      "min: 0.3826395672994968\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0191065375484129\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.215654066865227\n",
      "std: 0.0757017660146007\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2182226861112317\n",
      "std: 0.0799785610900046\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.03651185586812918\n",
      "min: 0.010055160744903945\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35077825510324034\n",
      "std: 0.35899234626251386\n",
      "min: -1.0388133449438244\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46565348122141165\n",
      "std: 0.1613627067693183\n",
      "min: 0.027418415317775773\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018743397497301684\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408429828884137\n",
      "std: 0.0028356272267209327\n",
      "min: 1.3817688628844544\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084231798166402\n",
      "std: 0.003062817762633842\n",
      "min: 1.3817688628844544\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.03606287070018672\n",
      "min: 0.015147974108096623\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3309906202586418\n",
      "std: 0.2926186679665786\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6276629380336352\n",
      "std: 0.09084231912699921\n",
      "min: 0.38262330404903466\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019101521164602498\n",
      "min: 0.2090948919575785\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.183982878541526\n",
      "std: 0.19790389160655644\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.186766149513744\n",
      "std: 0.20058189301634635\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.038199482058855275\n",
      "min: 0.003103809363328191\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.351179419423974\n",
      "std: 0.36006625485687027\n",
      "min: -1.0458017076285244\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4655492614391781\n",
      "std: 0.16231935609862938\n",
      "min: 0.02877950555986481\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01885947312346905\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4066387998543737\n",
      "std: 0.010408571706723834\n",
      "min: 1.3067256737265638\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066435953997822\n",
      "std: 0.010565273315456\n",
      "min: 1.3067256737265638\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.030303030303030304\n",
      "std: 0.03607031604102604\n",
      "min: 0.014155104762864208\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3318949122069041\n",
      "std: 0.29248217135296584\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6285957073470524\n",
      "std: 0.09227926018033221\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019191060481319612\n",
      "min: 0.20910318031483965\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1951201601327974\n",
      "std: 0.1434628656605842\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1978573732043367\n",
      "std: 0.1458644355850612\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03687561983294247\n",
      "min: 0.004997925647148765\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.343944801517819\n",
      "std: 0.3619754970402798\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47174015101493005\n",
      "std: 0.16241229676312224\n",
      "min: 0.028935350789284164\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01874393492917736\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407931109922929\n",
      "std: 0.003990748833334281\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407945828385934\n",
      "std: 0.004068603936042509\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03561445374383521\n",
      "min: 0.014832925252892228\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3296924772474543\n",
      "std: 0.2930562120087676\n",
      "min: -0.8090169112147214\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6298500335617598\n",
      "std: 0.09102692698055832\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019110053179853363\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1924268269582725\n",
      "std: 0.15713086422666647\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1952360271831977\n",
      "std: 0.1602126208587662\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03733706429426692\n",
      "min: 0.005377880439774539\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3443197445416521\n",
      "std: 0.3644413052325823\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47142301540676923\n",
      "std: 0.16368904241791798\n",
      "min: 0.028674009790096745\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01887917910073766\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407580319904971\n",
      "std: 0.0056278103063987246\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407602582563141\n",
      "std: 0.005711590494222655\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.035615891633824795\n",
      "min: 0.014671883232996648\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3289781603566091\n",
      "std: 0.29286073946228497\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6295978607170242\n",
      "std: 0.09117228577987892\n",
      "min: 0.38256543125136755\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019095576516226658\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.194408235431856\n",
      "std: 0.15301295478279694\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1972277744225421\n",
      "std: 0.1543932926100085\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03676570894716004\n",
      "min: 0.00508077448052821\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34522622847815854\n",
      "std: 0.3629402570510699\n",
      "min: -1.0772699643817993\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47112495482391076\n",
      "std: 0.1624692061064733\n",
      "min: 0.028870670051266645\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018846258610168455\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080320700487599\n",
      "std: 0.003623701874452006\n",
      "min: 1.378032234374302\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080404757249358\n",
      "std: 0.00381025282728235\n",
      "min: 1.378032234374302\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.0356142137153578\n",
      "min: 0.014861107148040493\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3299327784659743\n",
      "std: 0.2930408827628383\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6293078397146434\n",
      "std: 0.09106565970365448\n",
      "min: 0.3826395672994968\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910970975659434\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2162587506341045\n",
      "std: 0.07531467159451402\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2188664784630878\n",
      "std: 0.07954793406944063\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03605539109693043\n",
      "min: 0.010055160744903946\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3510882454121174\n",
      "std: 0.35993565790035054\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46633482543056065\n",
      "std: 0.16109292543530507\n",
      "min: 0.027418415317775863\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01877672618321546\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084490246468915\n",
      "std: 0.0028254396608092614\n",
      "min: 1.3817688628844547\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408444148160518\n",
      "std: 0.0030544251963730484\n",
      "min: 1.3817688628844547\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.03561400130895236\n",
      "min: 0.014859643737136203\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3310189922464735\n",
      "std: 0.2927491368369537\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6276962271802913\n",
      "std: 0.09086312932411074\n",
      "min: 0.38262330404903466\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910467007741824\n",
      "min: 0.20897601765193488\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1850335765340012\n",
      "std: 0.19675398434537236\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1878455587705685\n",
      "std: 0.19942594565414845\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.037714162524753826\n",
      "min: 0.0029581084628523247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35149520083654334\n",
      "std: 0.36099634000481645\n",
      "min: -1.076926362612901\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46623985227485587\n",
      "std: 0.16203411655005268\n",
      "min: 0.02877950555986487\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01889132351911977\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406683856925454\n",
      "std: 0.01034387650947624\n",
      "min: 1.3067256737265638\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4066899746309236\n",
      "std: 0.010501620169677829\n",
      "min: 1.3067256737265638\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029850746268656716\n",
      "std: 0.035621320519016904\n",
      "min: 0.01393333706227881\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33191267627492865\n",
      "std: 0.29261250333670535\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.628617212898641\n",
      "std: 0.09227931450951711\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019193130263022315\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1958360250473428\n",
      "std: 0.14261762379684179\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1986521767593545\n",
      "std: 0.14498593372980434\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03641733886265108\n",
      "min: 0.004997925647148765\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3442802415346407\n",
      "std: 0.362276145122967\n",
      "min: -1.0770239429008934\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47136424141405064\n",
      "std: 0.1619088440591654\n",
      "min: 0.028935350789284164\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01874588865887067\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079545042937394\n",
      "std: 0.003964919859981415\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407966361154971\n",
      "std: 0.004041165614282348\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.035177308794810534\n",
      "min: 0.014631465789523469\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32968509648909466\n",
      "std: 0.29310080195133653\n",
      "min: -0.8090169112147214\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6296905369277118\n",
      "std: 0.09103150973926619\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019109400870714107\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1931834658358098\n",
      "std: 0.15618796854532094\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1960697588481568\n",
      "std: 0.15924009239889056\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.0368709308318623\n",
      "min: 0.005377880439774539\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3446576358148965\n",
      "std: 0.3647040126574005\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.471047267607765\n",
      "std: 0.16317038931290156\n",
      "min: 0.028674009790096745\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01887921973241618\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076085776603025\n",
      "std: 0.005590262966758364\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076278538649378\n",
      "std: 0.005672817477580933\n",
      "min: 1.3581282398435748\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03517872247807883\n",
      "min: 0.014394482155293722\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3289774734291916\n",
      "std: 0.29290572274671317\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6294385986094901\n",
      "std: 0.09117317654860774\n",
      "min: 0.38256543125136755\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019094956974060464\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1951377378101136\n",
      "std: 0.15204899375777567\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1980351121908406\n",
      "std: 0.15340208970851826\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03630933953071557\n",
      "min: 0.00508077448052821\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3455469000320548\n",
      "std: 0.36323150313563823\n",
      "min: -1.0772699643817996\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47075557476308666\n",
      "std: 0.16196531626812616\n",
      "min: 0.028870670051266645\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01884701273404752\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080545284101236\n",
      "std: 0.0036011600916554297\n",
      "min: 1.378032234374302\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408060203192746\n",
      "std: 0.003784928593244629\n",
      "min: 1.378032234374302\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03517707284334154\n",
      "min: 0.014663274833903608\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32992092600025813\n",
      "std: 0.2930862970197064\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6291529409383023\n",
      "std: 0.09106854011160614\n",
      "min: 0.3826395672994968\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019108992460798578\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2166758675401808\n",
      "std: 0.0749801467084059\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2193706535396434\n",
      "std: 0.07911484688101353\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.03561089733971122\n",
      "min: 0.010055160744903946\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3513287627361474\n",
      "std: 0.36025143215340977\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46602056612858894\n",
      "std: 0.16059293365854893\n",
      "min: 0.027418415317775863\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01877822598798775\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084659279472125\n",
      "std: 0.0028092738129630685\n",
      "min: 1.3817688628844547\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084585179055873\n",
      "std: 0.003034631703268021\n",
      "min: 1.3817688628844547\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.035176863902783524\n",
      "min: 0.014661407319455927\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3309922789263585\n",
      "std: 0.29279705028277964\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6275611960877051\n",
      "std: 0.09086654537291855\n",
      "min: 0.38262330404903466\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910392167827581\n",
      "min: 0.20897601765193488\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1858906389167043\n",
      "std: 0.19554380420198922\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1887770824368982\n",
      "std: 0.1982055983138292\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.037241736366824596\n",
      "min: 0.0029581084628523247\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.351743737205637\n",
      "std: 0.3613020734745249\n",
      "min: -1.076926362612901\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4659313366528638\n",
      "std: 0.16152312838937072\n",
      "min: 0.02877950555986487\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018891504302980693\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4067261893981848\n",
      "std: 0.010269114397483745\n",
      "min: 1.3067256737265638\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067293035637274\n",
      "std: 0.010426312986470076\n",
      "min: 1.3067256737265638\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.029411764705882353\n",
      "std: 0.035184060442613956\n",
      "min: 0.013722742173828666\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33187559234949454\n",
      "std: 0.29266053115984497\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6284702476965117\n",
      "std: 0.09226545406168112\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01919135043560177\n",
      "min: 0.20898530379643304\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1960215750999377\n",
      "std: 0.1418169689437415\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1989092176489125\n",
      "std: 0.14416192788675103\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03597107175757497\n",
      "min: 0.004997925647148765\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3449215774698689\n",
      "std: 0.3623282412906733\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46961008282705274\n",
      "std: 0.16256773248623904\n",
      "min: 0.028935350789284164\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018761162527249915\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079336418749016\n",
      "std: 0.003966860839010755\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079357913010861\n",
      "std: 0.004044770768998027\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03475143184320917\n",
      "min: 0.01432805220676417\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3297681026209698\n",
      "std: 0.2930910591328169\n",
      "min: -0.8090169112147214\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6294140031456014\n",
      "std: 0.09103194760870108\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019110297542824374\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1934152307081576\n",
      "std: 0.15526014872638086\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1963711505785424\n",
      "std: 0.15829094468837673\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03641703647459984\n",
      "min: 0.005080353818882393\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3453020839852715\n",
      "std: 0.36472171730098746\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4692944032591868\n",
      "std: 0.16380390415093654\n",
      "min: 0.028674009790096745\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018892451001532685\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075922216355543\n",
      "std: 0.005581523284833386\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076016710087542\n",
      "std: 0.005665155175344714\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03475282238871605\n",
      "min: 0.01401702879050454\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32906712916319963\n",
      "std: 0.2928964939305745\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6291623017571375\n",
      "std: 0.09117022785237536\n",
      "min: 0.38256543125136755\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019095883374037774\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.195321153479546\n",
      "std: 0.151323054494365\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.19828881869075\n",
      "std: 0.15265882355292912\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03586497579342166\n",
      "min: 0.00508077448052821\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3461743496758343\n",
      "std: 0.36327268047216477\n",
      "min: -1.0772699643817991\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46900676166581134\n",
      "std: 0.16262022292822317\n",
      "min: 0.028870670051266645\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01886091642325898\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080330254661124\n",
      "std: 0.0036091497195770857\n",
      "min: 1.3776461719730801\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080291358337635\n",
      "std: 0.0037933072740630137\n",
      "min: 1.3776461719730801\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03475119985007096\n",
      "min: 0.014316564139794584\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32999975227214684\n",
      "std: 0.29307699151544503\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6288804926827417\n",
      "std: 0.09106721297614748\n",
      "min: 0.3826395672994968\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910980880899628\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2165838490541854\n",
      "std: 0.07472539939595534\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2193574437131258\n",
      "std: 0.07877769965296555\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03517796365195428\n",
      "min: 0.009392358214265827\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35187500801481864\n",
      "std: 0.3603129398972662\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46432971550003144\n",
      "std: 0.16122801124994915\n",
      "min: 0.027418415317775863\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01879297243553254\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084414461605657\n",
      "std: 0.0028210254203103113\n",
      "min: 1.3811898327437069\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084247039786923\n",
      "std: 0.0030465761039445895\n",
      "min: 1.3811898327437069\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.034750994071612376\n",
      "min: 0.014361103500647553\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33105613062360906\n",
      "std: 0.2927901046236156\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6273088081060624\n",
      "std: 0.09086403415780454\n",
      "min: 0.38262330404903466\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910468865363443\n",
      "min: 0.20897601765193485\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1862426285212522\n",
      "std: 0.19423461660779287\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1891964121505212\n",
      "std: 0.1968898047571223\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03678171632485782\n",
      "min: 0.002958108462852325\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3522999394408551\n",
      "std: 0.3613554079516584\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46424299755236575\n",
      "std: 0.16213579998435254\n",
      "min: 0.02877950555986487\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018904840988775772\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406724307782173\n",
      "std: 0.01022120447119255\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067176198543756\n",
      "std: 0.010378769068279049\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028985507246376812\n",
      "std: 0.03475807289577364\n",
      "min: 0.013317264724485653\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3319298423187543\n",
      "std: 0.29265349838097365\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6282055802395042\n",
      "std: 0.09224644255544384\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01919112154132858\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1960074521216575\n",
      "std: 0.14116101585431703\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1987862470482498\n",
      "std: 0.14355074046522218\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.03553628490706359\n",
      "min: 0.004580657668410551\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34389355525286147\n",
      "std: 0.36196617013449867\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46973489364437426\n",
      "std: 0.16203694067471522\n",
      "min: 0.028935350789284164\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018732141216348582\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407928678240415\n",
      "std: 0.003956872055020954\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079256118914356\n",
      "std: 0.004038442688577101\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.034336382009721306\n",
      "min: 0.01416365493175354\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3297286733926266\n",
      "std: 0.29311468962601817\n",
      "min: -0.8090169112147214\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6294418241809361\n",
      "std: 0.09095771741470901\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019106727919712584\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1934407960572644\n",
      "std: 0.15445906571809068\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1962866228925169\n",
      "std: 0.15752282587874314\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.03597488907933987\n",
      "min: 0.005080353818882393\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34427725924252\n",
      "std: 0.36432847301741883\n",
      "min: -1.0770316694735975\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46942140087691975\n",
      "std: 0.16325891371835402\n",
      "min: 0.028674009790096745\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01886188850761315\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075917308947816\n",
      "std: 0.0055584158395239275\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407595856328621\n",
      "std: 0.005644649623896486\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.03433774993518597\n",
      "min: 0.013935497055605456\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32903401918269154\n",
      "std: 0.29292022461903383\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6291906916474431\n",
      "std: 0.09109251485868788\n",
      "min: 0.38256543125136755\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019092335835522257\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1953173583682755\n",
      "std: 0.15053638761396373\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1981747640155647\n",
      "std: 0.15192576487016066\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.03543200050407013\n",
      "min: 0.00508077448052821\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34513345215281405\n",
      "std: 0.3629054809389849\n",
      "min: -1.0772699643817991\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4691380945237161\n",
      "std: 0.16208961860253335\n",
      "min: 0.028870670051266645\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018830874030781725\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080272522783428\n",
      "std: 0.0036023353945449665\n",
      "min: 1.3776461719730801\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080182944089599\n",
      "std: 0.0037894338027088946\n",
      "min: 1.3776461719730801\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.034336153818609466\n",
      "min: 0.014161821929617329\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3299561037653616\n",
      "std: 0.2931011012841774\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6289127858793097\n",
      "std: 0.0909921568989873\n",
      "min: 0.3826395672994968\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019106163705444212\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2162970091660992\n",
      "std: 0.074673610218756\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2189673882918324\n",
      "std: 0.07879905520297564\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.034756108797453486\n",
      "min: 0.009392358214265827\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.350758998685782\n",
      "std: 0.3599864696291578\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4645110635427097\n",
      "std: 0.16071557049569798\n",
      "min: 0.027418415317775863\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018763720236418494\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408431629777631\n",
      "std: 0.002820864480774872\n",
      "min: 1.3811898327437069\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084099699730377\n",
      "std: 0.003049507714090078\n",
      "min: 1.3811898327437069\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.03433595121383269\n",
      "min: 0.01415804041945003\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3309986861273485\n",
      "std: 0.2928168628900066\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6273596978355915\n",
      "std: 0.09079265467523001\n",
      "min: 0.38262330404903466\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019101029874938426\n",
      "min: 0.20897601765193485\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1863502314002012\n",
      "std: 0.19327155743049673\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1891928780487668\n",
      "std: 0.19595526998537016\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.036333674468751465\n",
      "min: 0.002958108462852325\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3511900830885154\n",
      "std: 0.3610207791084453\n",
      "min: -1.076926362612901\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46443319284649737\n",
      "std: 0.16161128618316037\n",
      "min: 0.02877950555986487\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01887431555588253\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406737488659784\n",
      "std: 0.010156488211031314\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067254937232745\n",
      "std: 0.010315126760222072\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02857142857142857\n",
      "std: 0.03434291510063471\n",
      "min: 0.013317264724485654\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33186224886727356\n",
      "std: 0.2926804730989295\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6282454582051494\n",
      "std: 0.09215693752404543\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01918648316413892\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.195817029516808\n",
      "std: 0.14015767135141408\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.198462111819546\n",
      "std: 0.14256445963175554\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03511241202277192\n",
      "min: 0.004580657668410551\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3435642046913139\n",
      "std: 0.36193810203550464\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47056611145239163\n",
      "std: 0.16225507373645134\n",
      "min: 0.028935350789284164\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018742842187530775\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079300793458926\n",
      "std: 0.003938865572098651\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079401641857971\n",
      "std: 0.004011896780810961\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03393174184242964\n",
      "min: 0.014027044461182685\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3296023227133457\n",
      "std: 0.29312564585328027\n",
      "min: -0.8090169112147214\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6295380527380815\n",
      "std: 0.09094011324453373\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019110555817507556\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.193273147145208\n",
      "std: 0.15351351167791888\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.195984132833084\n",
      "std: 0.15658374200921146\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03554392925460039\n",
      "min: 0.004951541197071224\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3439511051732854\n",
      "std: 0.36426708796566387\n",
      "min: -1.0770316694735975\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4702519099772595\n",
      "std: 0.16345717215374164\n",
      "min: 0.028674009790096745\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018870761805924077\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4075974491302203\n",
      "std: 0.005530033878985825\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076146128239935\n",
      "std: 0.005610577410591055\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03393308783846187\n",
      "min: 0.01378147842140074\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3289139159932471\n",
      "std: 0.29293130631458203\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6292871616704946\n",
      "std: 0.09107182466994185\n",
      "min: 0.38256543125136755\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01909619461233955\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1951338035039833\n",
      "std: 0.14949185172021606\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1978560421389208\n",
      "std: 0.1509100395355095\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03500989930371865\n",
      "min: 0.00508077448052821\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.344792916380858\n",
      "std: 0.3628714619675119\n",
      "min: -1.0772699643817993\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46997520627728157\n",
      "std: 0.16231200434163132\n",
      "min: 0.028870670051266645\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018840307880270822\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080270792254612\n",
      "std: 0.003587425921889714\n",
      "min: 1.3776461719730801\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080314295901193\n",
      "std: 0.0037642352182232558\n",
      "min: 1.3776461719730801\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03393151734801427\n",
      "min: 0.014064085488438238\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3298258638310229\n",
      "std: 0.2931127721526581\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6290133856429545\n",
      "std: 0.09097400838172455\n",
      "min: 0.3826395672994968\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910993284875398\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2157947021245312\n",
      "std: 0.07446892951885375\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2183364427140226\n",
      "std: 0.07861948864199285\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03434485647784458\n",
      "min: 0.009392358214265827\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35034794362731053\n",
      "std: 0.3599836584145537\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46539270835209023\n",
      "std: 0.1609719107125402\n",
      "min: 0.027418415317775863\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01877393272246888\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084257793466561\n",
      "std: 0.002816684292549484\n",
      "min: 1.3811898327437069\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084175682760554\n",
      "std: 0.003031287894011282\n",
      "min: 1.3811898327437069\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03393131794815574\n",
      "min: 0.014088570276243276\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33085542818132896\n",
      "std: 0.29283139917547174\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6274778319266339\n",
      "std: 0.09077870643647352\n",
      "min: 0.38262330404903466\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910476054222777\n",
      "min: 0.20897601765193488\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1862648831864953\n",
      "std: 0.19206970578033408\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1889712696674846\n",
      "std: 0.1947622995037352\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03589700254113138\n",
      "min: 0.002958108462852325\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3507844706135587\n",
      "std: 0.3610078431547808\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46532744824895156\n",
      "std: 0.16185454850570594\n",
      "min: 0.02877950555986487\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01888345375702581\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4067520683693608\n",
      "std: 0.010102341790303976\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406753158522374\n",
      "std: 0.010258052791178586\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.028169014084507043\n",
      "std: 0.03393817094941829\n",
      "min: 0.013086719542531839\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33170868512273954\n",
      "std: 0.29269526978202925\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6283534175454251\n",
      "std: 0.09212420517370065\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019189246843058904\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1961192743135434\n",
      "std: 0.13932430371644425\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.198533678885761\n",
      "std: 0.14170298683742938\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03469914568831481\n",
      "min: 0.00455777770589654\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.343957612005596\n",
      "std: 0.36147272987717016\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4711511993505048\n",
      "std: 0.16210215601102748\n",
      "min: 0.028935350789284164\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01873286662903732\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079442211806834\n",
      "std: 0.003909317011479779\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079572546604497\n",
      "std: 0.0039812772773881126\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.033537115722258315\n",
      "min: 0.01385161700487061\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32965318659602866\n",
      "std: 0.2930859284159285\n",
      "min: -0.8090169112147214\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6294455119609387\n",
      "std: 0.09092275259173353\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019108828159709493\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.193616795889403\n",
      "std: 0.15244512697736756\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1960958384077687\n",
      "std: 0.15548352437191898\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03512370942517325\n",
      "min: 0.004951541197071224\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3443449868060367\n",
      "std: 0.36377298591842244\n",
      "min: -1.0770316694735975\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47083868919276206\n",
      "std: 0.1632891811524276\n",
      "min: 0.028674009790096745\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018859149130343155\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407616360914865\n",
      "std: 0.005483007967735725\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076363303965116\n",
      "std: 0.005563230336478147\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.0335384401161603\n",
      "min: 0.013666363368555704\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32897070953739854\n",
      "std: 0.2928922047159226\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6291949407420144\n",
      "std: 0.09105131743682106\n",
      "min: 0.38256543125136755\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019094489859995078\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1954585861514535\n",
      "std: 0.14841774616716147\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.197948591121612\n",
      "std: 0.14982294157401985\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.034598288543877434\n",
      "min: 0.0050136528108701\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3451723963555096\n",
      "std: 0.36239728763711254\n",
      "min: -1.0772699643817993\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47056821869013166\n",
      "std: 0.16216255987634168\n",
      "min: 0.028870670051266645\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018829210449138795\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080397137579037\n",
      "std: 0.0035600199634879654\n",
      "min: 1.3776461719730801\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408047124047462\n",
      "std: 0.003734781667236385\n",
      "min: 1.3776461719730801\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03353689481412193\n",
      "min: 0.013912169974320546\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3298726251315263\n",
      "std: 0.29307344136264685\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6289252724369769\n",
      "std: 0.09095532764392829\n",
      "min: 0.3826395672994968\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0191081322128448\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2158073435717107\n",
      "std: 0.0741262333659157\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.218122153450356\n",
      "std: 0.07825682350122609\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.033943777890743106\n",
      "min: 0.009392358214265829\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35065654588148504\n",
      "std: 0.3595299940596957\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4660307140605813\n",
      "std: 0.1608495057043908\n",
      "min: 0.027418415317775863\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018763627374030086\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084318670191165\n",
      "std: 0.002799982428985539\n",
      "min: 1.3811898327437069\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084268901669834\n",
      "std: 0.003011469715960814\n",
      "min: 1.3811898327437069\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03353669857627694\n",
      "min: 0.013918166157528299\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33088921722672743\n",
      "std: 0.2927945793991876\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6274071161906347\n",
      "std: 0.09076155627645993\n",
      "min: 0.38262330404903466\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019102953111398254\n",
      "min: 0.20897601765193488\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1866595874540153\n",
      "std: 0.19092902023250247\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.189133234711454\n",
      "std: 0.19359448249860717\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.03547127933085239\n",
      "min: 0.002958108462852325\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3510983223966424\n",
      "std: 0.3605450073435892\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4659737687690086\n",
      "std: 0.16171972387003514\n",
      "min: 0.02877950555986487\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018872107604909687\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4067809543348433\n",
      "std: 0.010028453457394702\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4067849012307225\n",
      "std: 0.010183971959741854\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.027777777777777776\n",
      "std: 0.0335434430549271\n",
      "min: 0.013059122185481848\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3317331247635496\n",
      "std: 0.2926579374386025\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6282720828042128\n",
      "std: 0.09209070155466013\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019186502549151337\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1969337086730705\n",
      "std: 0.13844553765464734\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.19938376068817\n",
      "std: 0.14081242041422853\n",
      "min: -0.061628286294035085\n",
      "max: 1.4130914395500433\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03429603605662164\n",
      "min: 0.004557777705896541\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34346185703210236\n",
      "std: 0.36208115779361666\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280947\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47126158043981625\n",
      "std: 0.16230453212416018\n",
      "min: 0.028935350789284164\n",
      "max: 0.8380933254280947\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01871287503134379\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407966511206545\n",
      "std: 0.003892433908346898\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079747353164027\n",
      "std: 0.003966579473859517\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03315212816571674\n",
      "min: 0.01361518441488208\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32958471253238236\n",
      "std: 0.2931323209327052\n",
      "min: -0.8090169112147214\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6294277326404178\n",
      "std: 0.09091969890456841\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019106823838538994\n",
      "min: 0.20786227638008073\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1944634725872745\n",
      "std: 0.1515097581975116\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1969770174299124\n",
      "std: 0.15453186270408853\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.034713892496544003\n",
      "min: 0.0049515411970712225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34385106604276594\n",
      "std: 0.36434518969972224\n",
      "min: -1.0770316694735975\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47095059855169286\n",
      "std: 0.16347222936297923\n",
      "min: 0.028674009790096745\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018837648914594468\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076437394205865\n",
      "std: 0.005451615672323617\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076588235489003\n",
      "std: 0.005533149911993465\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03315343175928301\n",
      "min: 0.01344641325750779\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32890793935541207\n",
      "std: 0.29293888834566145\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6291779095434993\n",
      "std: 0.09104508160275525\n",
      "min: 0.38256543125136755\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019092510372822984\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1962756135436463\n",
      "std: 0.14755615812536768\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1988004255115141\n",
      "std: 0.14895441145941288\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.034196840430613426\n",
      "min: 0.0050136528108701\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34466414040498977\n",
      "std: 0.3629973826975394\n",
      "min: -1.0772699643817991\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4706833375979399\n",
      "std: 0.16236567809313815\n",
      "min: 0.028870670051266645\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018808252578976607\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080607783794958\n",
      "std: 0.0035481516576329644\n",
      "min: 1.3776461719730804\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080635189684663\n",
      "std: 0.0037242018554263494\n",
      "min: 1.3776461719730804\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03315191077447801\n",
      "min: 0.013595659614148709\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3298002319570355\n",
      "std: 0.2931204940107122\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6289119005240814\n",
      "std: 0.09095114182400785\n",
      "min: 0.3826395672994968\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910604985700285\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813785\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2163350907399249\n",
      "std: 0.07385663369568542\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2186914117251457\n",
      "std: 0.0779345629036471\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03355250991822466\n",
      "min: 0.009392358214265829\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.35008064015723794\n",
      "std: 0.36016481543678325\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46619586454143797\n",
      "std: 0.16106994769643457\n",
      "min: 0.027418415317775863\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018743329280440212\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408447418991093\n",
      "std: 0.0027926696122121983\n",
      "min: 1.381189832743707\n",
      "max: 1.413979212893554\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084380043762796\n",
      "std: 0.0030059874457382192\n",
      "min: 1.381189832743707\n",
      "max: 1.413979212893554\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03315171746817706\n",
      "min: 0.013632328553035606\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33080392669692754\n",
      "std: 0.2928441483907056\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6274110807593289\n",
      "std: 0.09075973947471268\n",
      "min: 0.38262330404903466\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910085726366633\n",
      "min: 0.20897601765193485\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1875868465010138\n",
      "std: 0.1898088156194753\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1900941289589226\n",
      "std: 0.19246376829980844\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.03505607784093914\n",
      "min: 0.002958108462852325\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.350525669505088\n",
      "std: 0.36117036697907295\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46614485490113033\n",
      "std: 0.1619243389266154\n",
      "min: 0.02877950555986487\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01885064026413545\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406819462069339\n",
      "std: 0.009965998587833829\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406818619670026\n",
      "std: 0.010121717457551999\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0273972602739726\n",
      "std: 0.033158356938595826\n",
      "min: 0.012880049082331152\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33163821390404014\n",
      "std: 0.29270792914030586\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6282659316091249\n",
      "std: 0.09207255670111157\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019183490039991515\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1972081261920626\n",
      "std: 0.13785564540242617\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1996528188637128\n",
      "std: 0.14021097266322674\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.0339027952995726\n",
      "min: 0.003956627346677075\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34276543751835986\n",
      "std: 0.36162674604521255\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47104221574900823\n",
      "std: 0.1624864023325837\n",
      "min: 0.028935350789284133\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018703412588633367\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079753019257866\n",
      "std: 0.0038810222021190546\n",
      "min: 1.3756633287769693\n",
      "max: 1.4139790623992685\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407979185457869\n",
      "std: 0.003952141305211938\n",
      "min: 1.3777843167925206\n",
      "max: 1.4139790623992685\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03277642204338519\n",
      "min: 0.013378805358110521\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3294878647032079\n",
      "std: 0.29307659172212136\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6294086577032201\n",
      "std: 0.09090231475168607\n",
      "min: 0.38305640168109667\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019108468011099018\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.194775167567141\n",
      "std: 0.15073776108704418\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1972822077926997\n",
      "std: 0.15374480578257882\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03431412360109364\n",
      "min: 0.004636582542056037\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3431555578874223\n",
      "std: 0.36386415614155276\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4707339799429851\n",
      "std: 0.16363585079305396\n",
      "min: 0.02867400979009659\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018826596085841876\n",
      "min: 0.20186291846053697\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076566671414075\n",
      "std: 0.005425983802230027\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019797\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076673182611483\n",
      "std: 0.005505395200420943\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019797\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03277770550588253\n",
      "min: 0.013169257456729628\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3288166335130062\n",
      "std: 0.29288347576827156\n",
      "min: -0.8083447704867224\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6291594270222118\n",
      "std: 0.09102499517699505\n",
      "min: 0.3825654312513674\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019094191920914657\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1965642112904564\n",
      "std: 0.1467725688098615\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1990829114587802\n",
      "std: 0.14816378197325908\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.033805169042140454\n",
      "min: 0.0045879183321635725\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3439549111295617\n",
      "std: 0.3625386679662813\n",
      "min: -1.0772699643817993\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47047159878320777\n",
      "std: 0.16254846159146488\n",
      "min: 0.028870670051266575\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01879772642435491\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40806806618473\n",
      "std: 0.00353642735808752\n",
      "min: 1.37764617197308\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080665932326395\n",
      "std: 0.0037085753880125084\n",
      "min: 1.37764617197308\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03277620796072557\n",
      "min: 0.013434719247580964\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3296993561955901\n",
      "std: 0.2930653236640513\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6288972732508108\n",
      "std: 0.09093276886166188\n",
      "min: 0.3826395672994966\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019107627961047213\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782653010781378\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2163554793481897\n",
      "std: 0.07366287273808042\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2187118017189518\n",
      "std: 0.0776978129255705\n",
      "min: 0.7199851205004337\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03317071825119197\n",
      "min: 0.009392358214265829\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34930442203094114\n",
      "std: 0.3597383078438352\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4660316243084143\n",
      "std: 0.1612629874096564\n",
      "min: 0.027418415317775714\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018733438663164344\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408449990605378\n",
      "std: 0.002786527364892159\n",
      "min: 1.3811898327437069\n",
      "max: 1.4139792128935542\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084365795761606\n",
      "std: 0.002995050420354231\n",
      "min: 1.3811898327437069\n",
      "max: 1.4139792128935542\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03277601751467429\n",
      "min: 0.013431166929385844\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33069044077443044\n",
      "std: 0.2927915948290449\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6274132197659108\n",
      "std: 0.09074345130295673\n",
      "min: 0.38262330404903444\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910240025506265\n",
      "min: 0.20897601765193485\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1879869099295137\n",
      "std: 0.18874327543302535\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1904865809856424\n",
      "std: 0.19139027802488745\n",
      "min: -0.47406788551255213\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.03465106464064914\n",
      "min: 0.00281082950672774\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34975365520396046\n",
      "std: 0.36073518721506065\n",
      "min: -1.0769263626129009\n",
      "max: 0.829131252860817\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4659859139665333\n",
      "std: 0.16210067404033246\n",
      "min: 0.0287795055598648\n",
      "max: 0.829131252860817\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018839835402918424\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068428904249133\n",
      "std: 0.009913541750359328\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4068376588284726\n",
      "std: 0.010067873531465727\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02702702702702703\n",
      "std: 0.032782555508443174\n",
      "min: 0.012511821437446892\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33151547051114333\n",
      "std: 0.2926555709847808\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6282580459364625\n",
      "std: 0.0920406232591813\n",
      "min: 0.3811028466794016\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019184144722638158\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1976137335127865\n",
      "std: 0.13716960701950437\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.199986323044619\n",
      "std: 0.13952771179304405\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.033518994607201875\n",
      "min: 0.0037371563448466163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3428788976472303\n",
      "std: 0.3615308343748376\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47050269432738195\n",
      "std: 0.16245939454177713\n",
      "min: 0.028935350789284234\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018720412844327298\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40797726646878\n",
      "std: 0.0038681355289197908\n",
      "min: 1.375663328776969\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4079869651165076\n",
      "std: 0.0039371453619060845\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.03240965796711024\n",
      "min: 0.013174675101749337\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3294797450162041\n",
      "std: 0.2931110388088448\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6293552258579513\n",
      "std: 0.09085462188059207\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019106622535450785\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1952118886255723\n",
      "std: 0.1499195974378414\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1976459775834853\n",
      "std: 0.152922474347783\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.033924007606714865\n",
      "min: 0.004510304502820164\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34326861621768656\n",
      "std: 0.3637384534138714\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4701933624562763\n",
      "std: 0.16359272893847637\n",
      "min: 0.028674009790096714\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018841863786175413\n",
      "min: 0.20186291846053697\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076634243598194\n",
      "std: 0.005404584565542806\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019797\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076797721140513\n",
      "std: 0.005482619432392796\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019797\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.032410922024528874\n",
      "min: 0.012957892775017585\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3288140877019336\n",
      "std: 0.29291834672675954\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6291062782340615\n",
      "std: 0.09097441146433896\n",
      "min: 0.38256543125136755\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019092366991637386\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1969731745665582\n",
      "std: 0.14603527992705545\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1994187057559582\n",
      "std: 0.1474385453215941\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.03342293821124141\n",
      "min: 0.004126493956970039\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34405577031716866\n",
      "std: 0.36243392143097924\n",
      "min: -1.0772699643817991\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46993555741652554\n",
      "std: 0.16252182052449524\n",
      "min: 0.028870670051266704\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01881350280284239\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080695879087786\n",
      "std: 0.0035275730672162512\n",
      "min: 1.37764617197308\n",
      "max: 1.4139785360498367\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080740457433434\n",
      "std: 0.0036966222979909267\n",
      "min: 1.37764617197308\n",
      "max: 1.4139785360498367\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.032409447181169504\n",
      "min: 0.013194235359008377\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3296876162781385\n",
      "std: 0.2931001902548411\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6288474603892165\n",
      "std: 0.09088408899228073\n",
      "min: 0.38263956729949655\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019105731165135486\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2165152259071983\n",
      "std: 0.07334252544827095\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.218804012815865\n",
      "std: 0.07737803894047834\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.032798059018792965\n",
      "min: 0.009343892882096238\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3493374476564983\n",
      "std: 0.35965690147445384\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46554277213237116\n",
      "std: 0.16123853588681908\n",
      "min: 0.027418415317775852\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018749981168209397\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408448170313004\n",
      "std: 0.002777262746231153\n",
      "min: 1.3811898327437069\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084408243030102\n",
      "std: 0.0029820846800809606\n",
      "min: 1.3811898327437069\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.03240925940519392\n",
      "min: 0.013190596683203042\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33066622889064545\n",
      "std: 0.29282873299870155\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6273800915282716\n",
      "std: 0.09069679438638151\n",
      "min: 0.38262330404903455\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019100500047216893\n",
      "min: 0.20897601765193488\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.188541947777195\n",
      "std: 0.18747904387763528\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1909672560161884\n",
      "std: 0.1901288433025459\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.03425582202642439\n",
      "min: 0.002810829506727741\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3497916186996594\n",
      "std: 0.3606465422419478\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4655018443567431\n",
      "std: 0.16206158070659119\n",
      "min: 0.0287795055598648\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018855203310662406\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.406861206951649\n",
      "std: 0.009861241621184375\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4068617302905368\n",
      "std: 0.010014665935968683\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02666666666666667\n",
      "std: 0.03241569883676576\n",
      "min: 0.012360571696481668\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33148237947230197\n",
      "std: 0.29269293924934514\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.628215300736671\n",
      "std: 0.0919785802469739\n",
      "min: 0.3811028466794014\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019181375152914258\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1972407773340854\n",
      "std: 0.13664403679367812\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1996057363523969\n",
      "std: 0.13897770636722653\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03314435786037688\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34247258643901785\n",
      "std: 0.3613328884711489\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4707157279712061\n",
      "std: 0.16242160449974258\n",
      "min: 0.028935350789284203\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018738263264974332\n",
      "min: 0.2019131357857576\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079820964322436\n",
      "std: 0.0038430948901754915\n",
      "min: 1.3756633287769693\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080017760391548\n",
      "std: 0.00391040361992426\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03205151277597848\n",
      "min: 0.013096293996121697\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3293707024845069\n",
      "std: 0.29315105360791494\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6293902557733216\n",
      "std: 0.09087855252338353\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910662184917339\n",
      "min: 0.2078622763800807\n",
      "max: 0.27826719929881266\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1948720315068002\n",
      "std: 0.14928980042190895\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1972973452089266\n",
      "std: 0.15226619931889387\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.033543229647245966\n",
      "min: 0.004074749627124123\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34286350760234136\n",
      "std: 0.363512881299536\n",
      "min: -1.0770316694735975\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4704081929452514\n",
      "std: 0.16353883931952326\n",
      "min: 0.028674009790096697\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01885814268843907\n",
      "min: 0.20186291846053697\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407672687211997\n",
      "std: 0.0053685105248438775\n",
      "min: 1.3561574302029646\n",
      "max: 1.4139796934019793\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4076989041067163\n",
      "std: 0.005445658928606857\n",
      "min: 1.3561574302029646\n",
      "max: 1.4139796934019793\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.032052757806671266\n",
      "min: 0.012847043506351824\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3287103024297246\n",
      "std: 0.2929586289263548\n",
      "min: -0.8083447704867218\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6291421128905912\n",
      "std: 0.09099531746638576\n",
      "min: 0.3825654312513674\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019092394643244946\n",
      "min: 0.2066507421484001\n",
      "max: 0.27827431333710057\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1966106698856553\n",
      "std: 0.14537998863358903\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1990475001820002\n",
      "std: 0.14676990003693882\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.033049789086993235\n",
      "min: 0.004064766270489547\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3436367794062501\n",
      "std: 0.36222957660060995\n",
      "min: -1.0772699643817991\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47015424836161\n",
      "std: 0.16248514337181147\n",
      "min: 0.028870670051266645\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01883025169252392\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080735035208853\n",
      "std: 0.003505130665624279\n",
      "min: 1.3776461719730806\n",
      "max: 1.4139785360498367\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080880948558077\n",
      "std: 0.0036714505162572693\n",
      "min: 1.3776461719730806\n",
      "max: 1.4139785360498367\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03205130518102329\n",
      "min: 0.013116583861123167\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32957476155982396\n",
      "std: 0.29314075024092723\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6288867127581828\n",
      "std: 0.09090735914273163\n",
      "min: 0.3826395672994967\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910567640294222\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2159279349350074\n",
      "std: 0.07321510937433336\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.218213324717104\n",
      "std: 0.07719057383447905\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03243420415360979\n",
      "min: 0.008628906921418267\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34885426164370564\n",
      "std: 0.35948087197559775\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4658048031113587\n",
      "std: 0.16122162592898867\n",
      "min: 0.02741841531777589\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018767452925063304\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084481047788995\n",
      "std: 0.0027603519912053616\n",
      "min: 1.381189832743707\n",
      "max: 1.4139792128935542\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084509710999389\n",
      "std: 0.002961078235677536\n",
      "min: 1.381189832743707\n",
      "max: 1.4139792128935542\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03205112014167143\n",
      "min: 0.013152235212685964\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33054156979167426\n",
      "std: 0.2928718471888015\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6274351470566281\n",
      "std: 0.09072318143155275\n",
      "min: 0.3826233040490345\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01910042954886492\n",
      "min: 0.20897601765193485\n",
      "max: 0.27820366470954305\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1883186028577455\n",
      "std: 0.18639242970400116\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.190733857084258\n",
      "std: 0.18902992854110087\n",
      "min: -0.4740678855125521\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03387005786586816\n",
      "min: 0.002810829506727741\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3493132532084305\n",
      "std: 0.36046324573393707\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46577307876113516\n",
      "std: 0.16203124978959493\n",
      "min: 0.028779505559864752\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01887158713066637\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4068826089755382\n",
      "std: 0.009788763164028\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406892992960148\n",
      "std: 0.009941918107531582\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02631578947368421\n",
      "std: 0.03205746289025883\n",
      "min: 0.012360571696481665\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33134888998872064\n",
      "std: 0.2927366557014967\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6282615170204207\n",
      "std: 0.09198875829947382\n",
      "min: 0.3811028466794016\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01918045999172063\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1974322332343923\n",
      "std: 0.13600715181601558\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1997900426102726\n",
      "std: 0.13833980970328247\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.03277844030689746\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34211626233318165\n",
      "std: 0.360974767574107\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.47077219986646596\n",
      "std: 0.16201283376644168\n",
      "min: 0.028935350789284185\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01870097107248614\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4079953748276348\n",
      "std: 0.003816675819864686\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080093990106217\n",
      "std: 0.003884052708145668\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.031701679483715224\n",
      "min: 0.012879848824763125\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3293217498250856\n",
      "std: 0.293108838179028\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6294036180367766\n",
      "std: 0.0908656978793466\n",
      "min: 0.3830564016810965\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019102297429519702\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1951006822335464\n",
      "std: 0.14846254465026149\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1975179446564514\n",
      "std: 0.1514328128518941\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.033171323435622416\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3425086578006328\n",
      "std: 0.3631280907854206\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4704673215704154\n",
      "std: 0.16311799376390831\n",
      "min: 0.028674009790096735\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01881962774853492\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4076894442254366\n",
      "std: 0.005330214196828196\n",
      "min: 1.3561574302029646\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407709910301675\n",
      "std: 0.005407375715129545\n",
      "min: 1.3561574302029646\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.031702905975234445\n",
      "min: 0.01270754043590663\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32866671183289714\n",
      "std: 0.2929167688785193\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6291561648917033\n",
      "std: 0.09097977828524423\n",
      "min: 0.38256543125136755\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01908810236528487\n",
      "min: 0.2066507421484001\n",
      "max: 0.27827431333710057\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1968082887825016\n",
      "std: 0.14470586498759605\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.199237062029265\n",
      "std: 0.14610104730861823\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.03268532703190057\n",
      "min: 0.004064766270489547\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34327065091338793\n",
      "std: 0.36186411871197\n",
      "min: -1.0772699643817996\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4702170472516269\n",
      "std: 0.16207768892897603\n",
      "min: 0.028870670051266596\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018792164122957155\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080853100115338\n",
      "std: 0.003481626968837654\n",
      "min: 1.3776461719730806\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408094341261901\n",
      "std: 0.0036472281659779785\n",
      "min: 1.3776461719730806\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.031701475001175906\n",
      "min: 0.01290420607512709\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3295225404204306\n",
      "std: 0.2930987699398038\n",
      "min: -0.8090256231693427\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6289039165597512\n",
      "std: 0.09089364137701988\n",
      "min: 0.3826395672994968\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019101286977358255\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2158884325836996\n",
      "std: 0.07298052169187648\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2181713707600084\n",
      "std: 0.0769370041370423\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.03207878080496278\n",
      "min: 0.008628906921418262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34842646590314996\n",
      "std: 0.35914444405398693\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46591180388402414\n",
      "std: 0.16082460728985742\n",
      "min: 0.027418415317775627\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018729958230480653\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084549662909507\n",
      "std: 0.002742576377564896\n",
      "min: 1.3811898327437069\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408452443103596\n",
      "std: 0.002942309737809088\n",
      "min: 1.3811898327437069\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.03170129264162678\n",
      "min: 0.012956273985142935\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33047787463856604\n",
      "std: 0.29283225927106155\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6274679623543339\n",
      "std: 0.09071195077253072\n",
      "min: 0.38262330404903433\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019096040540955508\n",
      "min: 0.20897601765193488\n",
      "max: 0.27820366470954316\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1886007885638459\n",
      "std: 0.18555232040089267\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1910073974672766\n",
      "std: 0.18818516238875596\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.033493372564695235\n",
      "min: 0.0025321524639696897\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3488900004365409\n",
      "std: 0.3601161622890785\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4658850072319596\n",
      "std: 0.1616262191071708\n",
      "min: 0.0287795055598648\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01883317005726886\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069080890184078\n",
      "std: 0.00972663936798649\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069128331499676\n",
      "std: 0.009879340516537001\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025974025974025976\n",
      "std: 0.031707541859187054\n",
      "min: 0.01211721838103297\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3312766351468343\n",
      "std: 0.292697157805003\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6282853881800478\n",
      "std: 0.09196273141776776\n",
      "min: 0.3811028466794016\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01917524824667212\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1979561312418276\n",
      "std: 0.13522271647040024\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.200342053610426\n",
      "std: 0.13754372989396216\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.032420941294565804\n",
      "min: 0.0037371563448466163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34177291464507703\n",
      "std: 0.3607561567326577\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4693878974738726\n",
      "std: 0.16239113256236887\n",
      "min: 0.02893535078928426\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018652874450241677\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080014669014083\n",
      "std: 0.0037984412147041412\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080138246368734\n",
      "std: 0.003867010735923857\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.031359865533678616\n",
      "min: 0.012718415457537532\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3293272699345802\n",
      "std: 0.2931084188969527\n",
      "min: -0.8090169112147214\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6292193191098776\n",
      "std: 0.09083314321790874\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019094055782958502\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782671992988126\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1956538205041254\n",
      "std: 0.14760001236789036\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.198097981479453\n",
      "std: 0.15055684436551964\n",
      "min: -0.08315292230984511\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.032808033107500564\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3421674200544631\n",
      "std: 0.3628842627034337\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4690846287706573\n",
      "std: 0.16347849772899348\n",
      "min: 0.028674009790096676\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018770392107479467\n",
      "min: 0.20186291846053703\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407698914442468\n",
      "std: 0.005303385018462149\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077176231136355\n",
      "std: 0.005381450852709638\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.031361074149970115\n",
      "min: 0.012497667810723789\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32867745817973254\n",
      "std: 0.29291662312352906\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6289722200067891\n",
      "std: 0.09094463693731905\n",
      "min: 0.38256543125136716\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019079883354279382\n",
      "min: 0.2066507421484001\n",
      "max: 0.27827431333710057\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1973331928385291\n",
      "std: 0.1439483568484915\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1997891845174498\n",
      "std: 0.145337362287082\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.03232926627275631\n",
      "min: 0.004064766270489547\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.342916458880029\n",
      "std: 0.36163914672828223\n",
      "min: -1.0772699643817991\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46883774371335346\n",
      "std: 0.16245239081285598\n",
      "min: 0.028870670051266662\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018743314214511045\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080905069376721\n",
      "std: 0.0034669424367838575\n",
      "min: 1.37764617197308\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080979945213026\n",
      "std: 0.0036331608848814037\n",
      "min: 1.37764617197308\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.03135966408037567\n",
      "min: 0.012695753281512415\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3295247387013171\n",
      "std: 0.29309866374652094\n",
      "min: -0.809025623169343\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6287232117547283\n",
      "std: 0.09085968064115037\n",
      "min: 0.3826395672994967\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019092980113291406\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2161717617259513\n",
      "std: 0.07268445658641819\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.218487439651347\n",
      "std: 0.07659784979606789\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.031731520337350896\n",
      "min: 0.008628906921418262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3480115778076968\n",
      "std: 0.35894445467529446\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4645770485056284\n",
      "std: 0.16118491502052634\n",
      "min: 0.027418415317775873\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018681730747599982\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084564393609569\n",
      "std: 0.002732030444404774\n",
      "min: 1.3811898327437069\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084525036812994\n",
      "std: 0.002932196631886545\n",
      "min: 1.3811898327437069\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.03135948427033219\n",
      "min: 0.012713897982849925\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3304686863589869\n",
      "std: 0.2928341754329721\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6273028056407991\n",
      "std: 0.09067781996696003\n",
      "min: 0.38262330404903455\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019087744438151606\n",
      "min: 0.20897601765193488\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1892189711699297\n",
      "std: 0.1845752999310395\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1916518112951142\n",
      "std: 0.18720013585918177\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.03312542345229125\n",
      "min: 0.0025321524639696897\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3484796352892655\n",
      "std: 0.35991036637496987\n",
      "min: -1.076926362612901\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4645531563520269\n",
      "std: 0.16197295322794053\n",
      "min: 0.02877950555986484\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018783933649836233\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069277149520425\n",
      "std: 0.009673442118036767\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.406930745004608\n",
      "std: 0.009826400571797688\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02564102564102564\n",
      "std: 0.031365642822949125\n",
      "min: 0.011925063707972746\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3312591272932288\n",
      "std: 0.29269923474610643\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6281108423066073\n",
      "std: 0.09191558097839718\n",
      "min: 0.38110284667940153\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019166137474537687\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.19847704747723\n",
      "std: 0.1345211460081383\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2008585428294256\n",
      "std: 0.1368231596084633\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.03207163157550212\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34191157394046084\n",
      "std: 0.36086347162865245\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.469285463011227\n",
      "std: 0.16286710876223276\n",
      "min: 0.028935350789284185\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018680521355669197\n",
      "min: 0.2019131357857576\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080183016124117\n",
      "std: 0.0037835784160558986\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080374865062835\n",
      "std: 0.003850594624840853\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.031025791877832488\n",
      "min: 0.012538022732439006\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3292547677883599\n",
      "std: 0.29304758299579736\n",
      "min: -0.8090169112147214\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.629231762126887\n",
      "std: 0.09075103122812798\n",
      "min: 0.38305640168109667\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019091878423853403\n",
      "min: 0.2078622763800807\n",
      "max: 0.27826719929881266\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1962070062840051\n",
      "std: 0.1467566961279903\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1986456715020943\n",
      "std: 0.14969281616680064\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.03245307369072965\n",
      "min: 0.004074749627124123\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3423068975726783\n",
      "std: 0.3629646959359792\n",
      "min: -1.0770316694735975\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46898322930434727\n",
      "std: 0.16393613879659086\n",
      "min: 0.028674009790096766\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018796480056376717\n",
      "min: 0.20186291846053703\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077197512281203\n",
      "std: 0.005275115000512306\n",
      "min: 1.3561574302029646\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077451845968385\n",
      "std: 0.00535242558858493\n",
      "min: 1.3561574302029646\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.031026982986392105\n",
      "min: 0.012350752365625814\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3286100200699507\n",
      "std: 0.29285614812524186\n",
      "min: -0.808344770486722\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6289852291853663\n",
      "std: 0.09086035043844037\n",
      "min: 0.3825654312513674\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019077739479547235\n",
      "min: 0.2066507421484001\n",
      "max: 0.2782743133371006\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1978607025654264\n",
      "std: 0.14316925908653036\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2003113268145162\n",
      "std: 0.14454753633310974\n",
      "min: -0.05614650130534398\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.031981334104613596\n",
      "min: 0.004064766270489547\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3430445517603603\n",
      "std: 0.3617387313230758\n",
      "min: -1.0772699643817991\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46873918759552896\n",
      "std: 0.16292802280161178\n",
      "min: 0.028870670051266714\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018769926670906455\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081061993887378\n",
      "std: 0.0034537899176581223\n",
      "min: 1.3776461719730804\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081206379798297\n",
      "std: 0.0036175489558473418\n",
      "min: 1.3776461719730804\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.0310255933367594\n",
      "min: 0.012533621144730767\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32944906308290445\n",
      "std: 0.29303822304026994\n",
      "min: -0.809025623169343\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6287392678929828\n",
      "std: 0.09077702271948361\n",
      "min: 0.38263956729949655\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019090759781243534\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826530107813774\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2164638175802986\n",
      "std: 0.07235833003428396\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2187793057939431\n",
      "std: 0.07622408907144418\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.03139215479241688\n",
      "min: 0.008628906921418267\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3480802661466532\n",
      "std: 0.359065696177446\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46452130063776265\n",
      "std: 0.1616749835350463\n",
      "min: 0.0274184153177759\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018709089518256086\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084677088092505\n",
      "std: 0.002723523911312784\n",
      "min: 1.3811898327437069\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408470859643436\n",
      "std: 0.0029201935695163795\n",
      "min: 1.3811898327437069\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.0310254160247795\n",
      "min: 0.012533442085157623\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33038211026994196\n",
      "std: 0.29277621954890776\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6273337694218497\n",
      "std: 0.09059766047469169\n",
      "min: 0.3826233040490345\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01908553160232317\n",
      "min: 0.20897601765193488\n",
      "max: 0.2782036647095431\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1898719177830457\n",
      "std: 0.18337635097056162\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1922982000218536\n",
      "std: 0.18598971405295037\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.03276589193104593\n",
      "min: 0.00253215246396969\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34855209096244\n",
      "std: 0.36002449275980775\n",
      "min: -1.076926362612901\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46450308717468003\n",
      "std: 0.1624475603645394\n",
      "min: 0.02877950555986485\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01881019119276274\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069568935619248\n",
      "std: 0.009622886657919263\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069667124617435\n",
      "std: 0.009775385322477953\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02531645569620253\n",
      "std: 0.031031486382814624\n",
      "min: 0.011736670639213308\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.331164299788218\n",
      "std: 0.2926415247653323\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6281335591107133\n",
      "std: 0.09182109502487419\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019163129811524716\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1995433683060304\n",
      "std: 0.1340221246448674\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.201730805245427\n",
      "std: 0.13623054876867505\n",
      "min: -0.06162828629403472\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.031730197821696005\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3427674655324598\n",
      "std: 0.36066991403509735\n",
      "min: -1.0770239429008934\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46888086945530333\n",
      "std: 0.16355146989844851\n",
      "min: 0.028935350789284185\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018709905025009903\n",
      "min: 0.20191313578575754\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080444331981645\n",
      "std: 0.0037657739302568954\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080555763979838\n",
      "std: 0.00383164517817523\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.030699192501655388\n",
      "min: 0.012391271545472126\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.329244582531825\n",
      "std: 0.2930330419397302\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6292424365480247\n",
      "std: 0.09078306525134973\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019096440116366742\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782702521050775\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1973007017723585\n",
      "std: 0.146194874207465\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1995443810833128\n",
      "std: 0.14903726441800544\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.03210616120159646\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3431635786008112\n",
      "std: 0.362746863499194\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4685803955463166\n",
      "std: 0.16460152213279455\n",
      "min: 0.028674009790096714\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018824277674596417\n",
      "min: 0.20186291846053697\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077496511590126\n",
      "std: 0.005244227799831073\n",
      "min: 1.3561574302029646\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077669560768644\n",
      "std: 0.005320727281053227\n",
      "min: 1.3561574302029646\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.030700366553502455\n",
      "min: 0.012230030169518971\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32860483441003036\n",
      "std: 0.29284212398405896\n",
      "min: -0.8083447704867218\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6289965651065915\n",
      "std: 0.09089002066630694\n",
      "min: 0.3825654312513674\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019082337270503968\n",
      "min: 0.2066507421484001\n",
      "max: 0.27827431333710057\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1989308860632057\n",
      "std: 0.14266527512035967\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.201186508647738\n",
      "std: 0.1439587134881432\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.031641246837770004\n",
      "min: 0.0039152593942323064\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34388977159042217\n",
      "std: 0.3615366774033492\n",
      "min: -1.0772699643817991\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4683403516395772\n",
      "std: 0.16361289711310228\n",
      "min: 0.028870670051266655\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018798247725344497\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081306049864726\n",
      "std: 0.0034367861711452957\n",
      "min: 1.3776461719730801\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081371020356361\n",
      "std: 0.003598930100852684\n",
      "min: 1.3776461719730801\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.030698996788749888\n",
      "min: 0.01241412093844876\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3294356762257915\n",
      "std: 0.29302405485520117\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6287537456248731\n",
      "std: 0.09080820000343988\n",
      "min: 0.3826395672994967\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01909527178751598\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782685958708604\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2173231854611315\n",
      "std: 0.07221996010053058\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2194471706758108\n",
      "std: 0.07593740737407086\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.031060386557215183\n",
      "min: 0.008628906921418262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34886590874934503\n",
      "std: 0.35887579295270755\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4641659874688198\n",
      "std: 0.16236449365399214\n",
      "min: 0.027418415317775734\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01873808821126339\n",
      "min: 0.20182672427827295\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084867880019678\n",
      "std: 0.002709803609066418\n",
      "min: 1.381189832743707\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084821631858278\n",
      "std: 0.002904996576079072\n",
      "min: 1.381189832743707\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.030698821915014555\n",
      "min: 0.012431152932783919\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.330357960842001\n",
      "std: 0.29276426427519275\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6273631137554363\n",
      "std: 0.09063080312862234\n",
      "min: 0.38262330404903444\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01909003286186846\n",
      "min: 0.20897601765193485\n",
      "max: 0.278232007365667\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1910414476420847\n",
      "std: 0.18254459032022394\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1932715765066066\n",
      "std: 0.18508383225456665\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.032414555407207654\n",
      "min: 0.0025321524639696897\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3493422340280418\n",
      "std: 0.35982743289210195\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46415020427957676\n",
      "std: 0.16312480481050912\n",
      "min: 0.028779505559864887\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018838215475314106\n",
      "min: 0.20170415209191336\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4069949871310612\n",
      "std: 0.009568760643609479\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4069967586376733\n",
      "std: 0.009720379763160333\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.025\n",
      "std: 0.03070480629625568\n",
      "min: 0.011646074687712697\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33113201566382733\n",
      "std: 0.2926296509095813\n",
      "min: -0.8084344089841998\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6281543633012698\n",
      "std: 0.09184074886676591\n",
      "min: 0.3811028466794016\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019166848488463735\n",
      "min: 0.2089853037964331\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.19970470432893\n",
      "std: 0.1334906881448321\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2018692049434048\n",
      "std: 0.1356778472683246\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.03139641667227419\n",
      "min: 0.0037371563448466163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3431453519945899\n",
      "std: 0.3608850885268065\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4680160395623673\n",
      "std: 0.1641543258815246\n",
      "min: 0.028935350789284234\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018727001750925114\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080728183659954\n",
      "std: 0.0037488634777517993\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080879636737549\n",
      "std: 0.003814728983383438\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.030379813641063267\n",
      "min: 0.01224609346239175\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3292056821695744\n",
      "std: 0.29304306937198166\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.629181348470149\n",
      "std: 0.09076466194341214\n",
      "min: 0.38305640168109656\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019095875536295423\n",
      "min: 0.2078622763800807\n",
      "max: 0.27827025210507744\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1974880592365102\n",
      "std: 0.14564514174799867\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1997080045363027\n",
      "std: 0.14845970910855505\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.03176705552450157\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3435420589617401\n",
      "std: 0.36293505820324806\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46771611254140655\n",
      "std: 0.1651859975708863\n",
      "min: 0.028674009790096745\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01883992455746426\n",
      "min: 0.20186291846053703\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077819634219368\n",
      "std: 0.005218541860557273\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078031813599383\n",
      "std: 0.005295167162584282\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.030380971190909035\n",
      "min: 0.012045259217641373\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3285708772828757\n",
      "std: 0.29285258715057627\n",
      "min: -0.8083447704867218\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6289361035168222\n",
      "std: 0.09086931619986684\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019081800697422272\n",
      "min: 0.2066507421484001\n",
      "max: 0.27827431333710057\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1991002513081848\n",
      "std: 0.1420382232173137\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2013320032252386\n",
      "std: 0.14331981114809844\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.03130876083653357\n",
      "min: 0.003915259394232308\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34425685244059356\n",
      "std: 0.3617435551956194\n",
      "min: -1.0772699643817991\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4674796746501144\n",
      "std: 0.16421442755014432\n",
      "min: 0.02887067005126673\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018814302082690172\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081580857430043\n",
      "std: 0.003423273671068045\n",
      "min: 1.37764617197308\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081686737483243\n",
      "std: 0.0035845511183446583\n",
      "min: 1.37764617197308\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.030379620716972602\n",
      "min: 0.012215242298792924\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32939376936830334\n",
      "std: 0.2930344625565127\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.628696071455349\n",
      "std: 0.09078889774348198\n",
      "min: 0.3826395672994966\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01909465901342394\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782685958708604\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2172895450076582\n",
      "std: 0.07205229695067525\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2193942476962356\n",
      "std: 0.07571532904430907\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691353\n",
      "std: 0.030735999452836064\n",
      "min: 0.008628906921418262\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3491750284886203\n",
      "std: 0.3591015809028013\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4633482332669563\n",
      "std: 0.16296310647798376\n",
      "min: 0.02741841531777592\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01875480749639469\n",
      "min: 0.20182672427827297\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4085097880815676\n",
      "std: 0.002698140372126249\n",
      "min: 1.3811898327437069\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408509400674889\n",
      "std: 0.0028921375546971757\n",
      "min: 1.3811898327437069\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.03037944819188356\n",
      "min: 0.012257726563651206\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.330305384479395\n",
      "std: 0.29277691890279617\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6273200566830688\n",
      "std: 0.09061279489310241\n",
      "min: 0.3826233040490345\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019089422578339996\n",
      "min: 0.20897601765193488\n",
      "max: 0.278232007365667\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1913199439552624\n",
      "std: 0.1816825002534558\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1935253073124557\n",
      "std: 0.18420459036168538\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.032071120803361025\n",
      "min: 0.0025321524639696897\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3496555522590721\n",
      "std: 0.36004619124227255\n",
      "min: -1.076926362612901\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46333584018352064\n",
      "std: 0.16370875203292248\n",
      "min: 0.02877950555986487\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01885397989256641\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40703530889519\n",
      "std: 0.009520575006926074\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070410812374856\n",
      "std: 0.009672209408873882\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024691358024691357\n",
      "std: 0.030385349062520547\n",
      "min: 0.011446793571058152\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33107155463965204\n",
      "std: 0.2926425298452774\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6281031338971695\n",
      "std: 0.09180951990772862\n",
      "min: 0.3811028466794016\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019165472521493473\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2001141919689935\n",
      "std: 0.1327775710844073\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2020571621317646\n",
      "std: 0.13493030790474922\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.031069953238093504\n",
      "min: 0.0037371563448466154\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3430606302272203\n",
      "std: 0.3603050155669928\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4679658599265466\n",
      "std: 0.16419356979942493\n",
      "min: 0.028935350789284046\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018688367093533474\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408082642672445\n",
      "std: 0.0037285550440132997\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408096590741417\n",
      "std: 0.0037919908750689104\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.03006741306579015\n",
      "min: 0.012059644867205854\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32925226639229926\n",
      "std: 0.29304047123715216\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6291340788966054\n",
      "std: 0.09071851408226998\n",
      "min: 0.38305640168109667\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01909248816725596\n",
      "min: 0.2078622763800807\n",
      "max: 0.27827025210507744\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1979237493441526\n",
      "std: 0.144826683748352\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1999214686338535\n",
      "std: 0.14760096364135278\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.03143540040927718\n",
      "min: 0.004074749627124124\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34345886743141524\n",
      "std: 0.36233316739483035\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.467667240427411\n",
      "std: 0.16521187676874308\n",
      "min: 0.028674009790096825\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01880028830639936\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077947097341958\n",
      "std: 0.005186496642455447\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078146599878283\n",
      "std: 0.005261432045157483\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.030068554466066676\n",
      "min: 0.011873578800299095\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32862247185762894\n",
      "std: 0.2928506047632807\n",
      "min: -0.808344770486722\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6288895154580862\n",
      "std: 0.09082092624291109\n",
      "min: 0.3825654312513674\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019078445484771826\n",
      "min: 0.2066507421484001\n",
      "max: 0.27827431333710057\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1995214461468855\n",
      "std: 0.14118023089070678\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2015307507356747\n",
      "std: 0.14243633798286728\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.030983546213828036\n",
      "min: 0.003915259394232308\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34416200979356254\n",
      "std: 0.3611567293593026\n",
      "min: -1.0772699643817993\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46743417137418625\n",
      "std: 0.1642533737161178\n",
      "min: 0.028870670051266742\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01877494906652393\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081668183191183\n",
      "std: 0.0034035212232105773\n",
      "min: 1.3776461719730801\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408176325221223\n",
      "std: 0.0035616806624469387\n",
      "min: 1.3776461719730801\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.030067222815586787\n",
      "min: 0.01209348866822412\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3294373713326955\n",
      "std: 0.29303218169131184\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.628652492939139\n",
      "std: 0.09074188061111992\n",
      "min: 0.3826395672994967\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019091223870891464\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782685958708604\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2174738511849814\n",
      "std: 0.07181170371240991\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2193597206320603\n",
      "std: 0.07542975069624475\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.030418720873809552\n",
      "min: 0.008137892369931255\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3490256407744364\n",
      "std: 0.35853573582035164\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46333963216263246\n",
      "std: 0.163014554080876\n",
      "min: 0.02741841531777589\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018716075255785145\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408514267718161\n",
      "std: 0.0026842903094269144\n",
      "min: 1.3811898327437069\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4085129300037986\n",
      "std: 0.0028743375073313833\n",
      "min: 1.3811898327437069\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.030067052634272586\n",
      "min: 0.012103317658508255\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3303387464383212\n",
      "std: 0.2927764255911151\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6272901743209197\n",
      "std: 0.0905673131966335\n",
      "min: 0.38262330404903455\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019085992399803225\n",
      "min: 0.20897601765193488\n",
      "max: 0.278232007365667\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1918028143766477\n",
      "std: 0.18080016619218983\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1937852879538153\n",
      "std: 0.1832872503220659\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.031735300322529\n",
      "min: 0.00253215246396969\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34951092325372457\n",
      "std: 0.35947417922880764\n",
      "min: -1.076926362612901\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4633333893882095\n",
      "std: 0.16374954343000783\n",
      "min: 0.02877950555986491\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01881440907100151\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070567668723435\n",
      "std: 0.009463209308365646\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070613268760361\n",
      "std: 0.009613923614530829\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024390243902439025\n",
      "std: 0.030072871854401804\n",
      "min: 0.011315973406225826\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33109761959457235\n",
      "std: 0.2926421702584909\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6280651914059037\n",
      "std: 0.09175117828301514\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019161300686590298\n",
      "min: 0.20898530379643304\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2001039978378116\n",
      "std: 0.1322202031621501\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2019064046281471\n",
      "std: 0.1343605002773059\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.03075067619731378\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3428570453047253\n",
      "std: 0.35995220464884486\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46807981672171795\n",
      "std: 0.16442121194729586\n",
      "min: 0.028935350789284154\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018666337086716275\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080743892782195\n",
      "std: 0.003724695966631578\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408093975550551\n",
      "std: 0.0037880432650986783\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.02976175941135348\n",
      "min: 0.011894462793923965\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.329247676765408\n",
      "std: 0.293004889883174\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6291554707152693\n",
      "std: 0.09065047104898684\n",
      "min: 0.38305640168109667\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019087503017939763\n",
      "min: 0.2078622763800807\n",
      "max: 0.27827025210507744\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1979470118148803\n",
      "std: 0.14408027413015198\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1998031993418738\n",
      "std: 0.1468389489733883\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.031111044270008666\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3432561425869684\n",
      "std: 0.36195853828167984\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4677844034047383\n",
      "std: 0.16542513647422774\n",
      "min: 0.028674009790096655\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018777125107570486\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077895991362617\n",
      "std: 0.005164006803416253\n",
      "min: 1.3561574302029646\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078151120527338\n",
      "std: 0.0052393467039027536\n",
      "min: 1.3561574302029646\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.029762885025560844\n",
      "min: 0.011773970566626771\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32862250010808397\n",
      "std: 0.2928155231337836\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.628911681445755\n",
      "std: 0.09075073019361532\n",
      "min: 0.3825654312513674\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019073488691870383\n",
      "min: 0.2066507421484001\n",
      "max: 0.27827431333710057\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1995159276011147\n",
      "std: 0.140587600007836\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2013835683118088\n",
      "std: 0.14184171287747288\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.030665505599800143\n",
      "min: 0.003915259394232307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.343949699780255\n",
      "std: 0.3607979883449807\n",
      "min: -1.0772699643817991\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4675534889584612\n",
      "std: 0.164482680601537\n",
      "min: 0.028870670051266655\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018752111513603398\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081571654375042\n",
      "std: 0.003403144502283055\n",
      "min: 1.3776461719730801\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081724119793917\n",
      "std: 0.0035602303002946808\n",
      "min: 1.3776461719730801\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.02976157178546246\n",
      "min: 0.011891796401031994\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32943000470657385\n",
      "std: 0.29299673941844534\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6286771203897142\n",
      "std: 0.09067328130515927\n",
      "min: 0.3826395672994967\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019086187100401667\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782685958708604\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2172602850021494\n",
      "std: 0.07168765254529534\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2190075138504692\n",
      "std: 0.0752956589723486\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.030108363280017335\n",
      "min: 0.008137892369931258\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3487595594999748\n",
      "std: 0.3582007527661458\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46349713710947227\n",
      "std: 0.16325893716630657\n",
      "min: 0.027418415317775793\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018693820136782616\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4085004788468305\n",
      "std: 0.002690638118121364\n",
      "min: 1.3811898327437069\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4085050005589732\n",
      "std: 0.0028783766673063796\n",
      "min: 1.3811898327437069\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.029761403831638826\n",
      "min: 0.011942857312056802\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3303214141437182\n",
      "std: 0.2927429573351091\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6273283701598878\n",
      "std: 0.09050116273454355\n",
      "min: 0.38262330404903455\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019080967795261933\n",
      "min: 0.20897601765193488\n",
      "max: 0.27823200736566706\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1918780518338286\n",
      "std: 0.17992811423718902\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1937185704101068\n",
      "std: 0.18240069052477048\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.031406880110274135\n",
      "min: 0.0025321524639696897\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.349247842836861\n",
      "std: 0.35913104416024727\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4634962157594742\n",
      "std: 0.1639811549174678\n",
      "min: 0.028779505559864693\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018791379029815838\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070578590475344\n",
      "std: 0.009422890352903732\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070680722661546\n",
      "std: 0.009573716984844003\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.024096385542168676\n",
      "std: 0.029767143955670858\n",
      "min: 0.01110159365710973\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3310727586808003\n",
      "std: 0.2926088639260744\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.628095889534082\n",
      "std: 0.09167204469578633\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01915555372911201\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2003542535777598\n",
      "std: 0.1315822497685386\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2020894980430883\n",
      "std: 0.13368943047654608\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.030438224342957454\n",
      "min: 0.0037371563448466163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3435029991153504\n",
      "std: 0.3600853070368197\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4680269645507641\n",
      "std: 0.16459267965045693\n",
      "min: 0.02893535078928431\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01866868973675386\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080766428142055\n",
      "std: 0.0037044222874702227\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080850833289822\n",
      "std: 0.003771767820578104\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.029462631246643504\n",
      "min: 0.011843924105265094\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32937501228292\n",
      "std: 0.2929996829501456\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6290851953653309\n",
      "std: 0.09062033928764975\n",
      "min: 0.38305640168109667\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019087328932309924\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782702521050775\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1982254085483186\n",
      "std: 0.1433394310083796\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2000135038843518\n",
      "std: 0.14606267231320522\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.03079365741011463\n",
      "min: 0.0040747496271241225\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.343901899888648\n",
      "std: 0.3620666899805679\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4677329681630302\n",
      "std: 0.16558217672262102\n",
      "min: 0.028674009790096815\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01877815241891379\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4077956241131038\n",
      "std: 0.005132703889553937\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078099225414251\n",
      "std: 0.005210590922875193\n",
      "min: 1.3561574302029649\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.029463741537193923\n",
      "min: 0.011672783157960822\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32875435684820836\n",
      "std: 0.29281095649789174\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6288419896595302\n",
      "std: 0.09071833577285443\n",
      "min: 0.3825654312513674\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019073341565642624\n",
      "min: 0.2066507421484001\n",
      "max: 0.27827431333710057\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1997793195334339\n",
      "std: 0.1397979477636546\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2015787494316696\n",
      "std: 0.14102895228175363\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.030354231072302566\n",
      "min: 0.003915259394232308\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34458509331144177\n",
      "std: 0.36092304384024704\n",
      "min: -1.0772699643817991\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4675067468493193\n",
      "std: 0.16465406667252758\n",
      "min: 0.028870670051266655\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018753612020414933\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081581850544527\n",
      "std: 0.0033865829229937296\n",
      "min: 1.37764617197308\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081623746417513\n",
      "std: 0.0035472534193959045\n",
      "min: 1.37764617197308\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.029462446205673804\n",
      "min: 0.011843018696997692\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3295542970818337\n",
      "std: 0.29299171760394216\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6286105194629039\n",
      "std: 0.09064224964115132\n",
      "min: 0.3826395672994967\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01908595952130558\n",
      "min: 0.2071750899445349\n",
      "max: 0.27826859587086034\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2173124121295522\n",
      "std: 0.07141655828941496\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2189953055090335\n",
      "std: 0.07496495648946601\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.029804607739720292\n",
      "min: 0.008137892369931258\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3493423481577698\n",
      "std: 0.3583390177993021\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4634866293510683\n",
      "std: 0.16344196045981982\n",
      "min: 0.02741841531777591\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018695777070063126\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084971184546122\n",
      "std: 0.0026822440051383414\n",
      "min: 1.3811898327437067\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084907252856433\n",
      "std: 0.002874553037316664\n",
      "min: 1.3811898327437067\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.029462280500551774\n",
      "min: 0.011840920548232005\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33043576206989733\n",
      "std: 0.29273941015394145\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6272751044560516\n",
      "std: 0.09047141673964117\n",
      "min: 0.38262330404903455\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019080744469369765\n",
      "min: 0.20897601765193488\n",
      "max: 0.278232007365667\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1922034490986402\n",
      "std: 0.1790991642125677\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1939756696691552\n",
      "std: 0.1815428781110453\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.03108553323021016\n",
      "min: 0.0023448767340452452\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34983363642846543\n",
      "std: 0.3592612520534772\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4634894930520875\n",
      "std: 0.16415214980058773\n",
      "min: 0.02877950555986487\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018792556291302137\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070712712121127\n",
      "std: 0.00937217448307573\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070703556304842\n",
      "std: 0.009523648159944904\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023809523809523808\n",
      "std: 0.029467943258793382\n",
      "min: 0.011101593657109735\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33118005561312064\n",
      "std: 0.29260518581439726\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6280345765234702\n",
      "std: 0.09162995746729598\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019154615644459822\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2008999816302381\n",
      "std: 0.13108243302241318\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.202641935803733\n",
      "std: 0.13315281659324582\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.0301324458770979\n",
      "min: 0.0037371563448466154\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34352288636050454\n",
      "std: 0.3607083107190591\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46827355226826173\n",
      "std: 0.16477607637567407\n",
      "min: 0.028935350789284175\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01870072118992107\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080794884506647\n",
      "std: 0.0036933887029194784\n",
      "min: 1.3756633287769688\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408079455882925\n",
      "std: 0.0037652248432066804\n",
      "min: 1.3777843167925208\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.029169817312144786\n",
      "min: 0.011658491960354764\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32935242947985377\n",
      "std: 0.29309386952744465\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6291942213433281\n",
      "std: 0.09060327357191654\n",
      "min: 0.38305640168109667\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019087339369486218\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782702521050775\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.198796432147819\n",
      "std: 0.14277039155439966\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2005902470635281\n",
      "std: 0.14545592299029197\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.030483081449610677\n",
      "min: 0.004074749627124124\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3439224589899196\n",
      "std: 0.3626626812672167\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46798097779882136\n",
      "std: 0.16575223790059387\n",
      "min: 0.028674009790096676\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018808839868279043\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078021950271933\n",
      "std: 0.0051089803288952495\n",
      "min: 1.3561574302029646\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078079530048342\n",
      "std: 0.005189774007019548\n",
      "min: 1.3561574302029646\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.029170912686020744\n",
      "min: 0.01148578661139075\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3287362392828149\n",
      "std: 0.29290559046788583\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.62895168120929\n",
      "std: 0.09069914190354632\n",
      "min: 0.3825654312513674\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019073381076196865\n",
      "min: 0.2066507421484001\n",
      "max: 0.27827431333710057\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2003291369223208\n",
      "std: 0.1392620076642028\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2021345989119843\n",
      "std: 0.14046059133393807\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.0300496234844618\n",
      "min: 0.003915259394232308\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34459504904220634\n",
      "std: 0.36153659007993005\n",
      "min: -1.0772699643817991\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4677574255099442\n",
      "std: 0.16483705491755585\n",
      "min: 0.02887067005126673\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018784774324988207\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081598552706884\n",
      "std: 0.003379295153661172\n",
      "min: 1.37764617197308\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081556782817553\n",
      "std: 0.003543813723047697\n",
      "min: 1.37764617197308\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.0291696347773631\n",
      "min: 0.01166477637185332\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3295288151399275\n",
      "std: 0.2930861850791259\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6287229928750767\n",
      "std: 0.09062491199801348\n",
      "min: 0.3826395672994967\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01908593638495421\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782685958708604\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.217676211962887\n",
      "std: 0.07129883114057267\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2193687910164372\n",
      "std: 0.07476469446219537\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.029507298328217135\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34930208092554854\n",
      "std: 0.3589760989368784\n",
      "min: -1.0762984934293214\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46377610922405177\n",
      "std: 0.16364422883435933\n",
      "min: 0.027418415317775762\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018727581906873375\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084943908393415\n",
      "std: 0.002681424525033933\n",
      "min: 1.381189832743707\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084797439863936\n",
      "std: 0.0028787255048912724\n",
      "min: 1.381189832743707\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.029169471211815314\n",
      "min: 0.011667521445130098\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3304008241129169\n",
      "std: 0.29283572736194396\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6274006275112459\n",
      "std: 0.0904575101669863\n",
      "min: 0.38262330404903455\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01908072219426899\n",
      "min: 0.20897601765193485\n",
      "max: 0.27823200736566694\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.192844152915301\n",
      "std: 0.1783395452198723\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1946213133356067\n",
      "std: 0.1807555896007587\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.03077107074437707\n",
      "min: 0.002187964823642007\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34979555912955795\n",
      "std: 0.35989042730833015\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4637822721264947\n",
      "std: 0.1643439714607304\n",
      "min: 0.02877950555986485\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01882322589458672\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070851376296567\n",
      "std: 0.009325582919785677\n",
      "min: 1.3042538351919855\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407075759762448\n",
      "std: 0.009478123617593537\n",
      "min: 1.3042538351919855\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023529411764705882\n",
      "std: 0.029175058589057917\n",
      "min: 0.010928663442022701\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3311378369971375\n",
      "std: 0.29270199316037393\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6281526524662912\n",
      "std: 0.09160265581058837\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01915388707563591\n",
      "min: 0.20898530379643304\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2013274115674868\n",
      "std: 0.13057752078087692\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2030364108808302\n",
      "std: 0.13260974677984586\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.029833111860289876\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34364551629203227\n",
      "std: 0.36071108117700396\n",
      "min: -1.0770239429008934\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4676319771008254\n",
      "std: 0.16488040429534648\n",
      "min: 0.028935350789284175\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018677932706523268\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080751565028142\n",
      "std: 0.0036934221972078963\n",
      "min: 1.3748137697226976\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080661288708651\n",
      "std: 0.003772201055301449\n",
      "min: 1.3748137697226976\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.028883115316239577\n",
      "min: 0.011434140342064228\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3294426029933989\n",
      "std: 0.2931151527412938\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6291023799469049\n",
      "std: 0.09059606916364468\n",
      "min: 0.38305640168109667\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019086114630853152\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782702521050775\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1992462536460802\n",
      "std: 0.14229494685550145\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.201006117568226\n",
      "std: 0.14494140360123012\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.030179083621086733\n",
      "min: 0.00398037163533402\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3440452901567243\n",
      "std: 0.3626427702171656\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4673401023943228\n",
      "std: 0.1658431412425034\n",
      "min: 0.028674009790096648\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018784960164656736\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078008796732127\n",
      "std: 0.005105055175843753\n",
      "min: 1.3537567072185879\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407797584550302\n",
      "std: 0.005190508668260346\n",
      "min: 1.3537567072185879\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.028884196413346882\n",
      "min: 0.011197619754272286\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32883090213910854\n",
      "std: 0.29292753094420654\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6288602951198955\n",
      "std: 0.09068982955032023\n",
      "min: 0.3825654312513674\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019072188502883464\n",
      "min: 0.2066507421484001\n",
      "max: 0.27827431333710057\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2007601425130159\n",
      "std: 0.1387455733014513\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2025319972666053\n",
      "std: 0.13990893184768316\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.02975142729021656\n",
      "min: 0.0037315043450326445\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34470808788350976\n",
      "std: 0.36153319631577846\n",
      "min: -1.077269964381799\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4671200319022159\n",
      "std: 0.16493943914783\n",
      "min: 0.02887067005126673\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01876127535261183\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081548314804702\n",
      "std: 0.0033842998738424024\n",
      "min: 1.374514752990217\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081417244964183\n",
      "std: 0.0035552119352128307\n",
      "min: 1.374514752990217\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.028882935231738672\n",
      "min: 0.011430243685865418\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3296162894259837\n",
      "std: 0.2931077917043961\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6286342459084775\n",
      "std: 0.09061688726733025\n",
      "min: 0.3826395672994967\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019084663255447484\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782685958708604\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2179352448762226\n",
      "std: 0.0711220640192588\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2195976985589507\n",
      "std: 0.07451170029533136\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.02921621132597779\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3493628152114318\n",
      "std: 0.3589905768948681\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46317697174897554\n",
      "std: 0.16374764223894037\n",
      "min: 0.027418415317775793\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018704587271847782\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084868828000947\n",
      "std: 0.0026875405524985282\n",
      "min: 1.3798059119284078\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084634474131243\n",
      "std: 0.0028927620395016594\n",
      "min: 1.3798059119284078\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.028882773655077854\n",
      "min: 0.01148762663120629\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3304784476612231\n",
      "std: 0.29285874680551377\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6273250252929947\n",
      "std: 0.0904503044971076\n",
      "min: 0.38262330404903455\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019079443582663457\n",
      "min: 0.20897601765193485\n",
      "max: 0.278232007365667\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.193399373300734\n",
      "std: 0.17743730993341197\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1951416518912528\n",
      "std: 0.17982554785574648\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.03046324639087401\n",
      "min: 0.0021879648236420076\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3498593884447104\n",
      "std: 0.3598984658799796\n",
      "min: -1.0769263626129006\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4631855192921021\n",
      "std: 0.16443470412383993\n",
      "min: 0.02877950555986486\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01879934504258459\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4070936759231834\n",
      "std: 0.009284484908715807\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070753129760605\n",
      "std: 0.009439493713168438\n",
      "min: 1.3042538351919857\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.023255813953488372\n",
      "std: 0.028888287659202594\n",
      "min: 0.010700877716747017\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3312087561966991\n",
      "std: 0.2927253402565112\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6280695027936423\n",
      "std: 0.09158366192232176\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01915192856734079\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2010517026519256\n",
      "std: 0.12992032420808386\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2028880170041043\n",
      "std: 0.13192724992969032\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.02953997945373991\n",
      "min: 0.0037371563448466163\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34300001216592474\n",
      "std: 0.36017153543757446\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4670471403132669\n",
      "std: 0.16481037231929282\n",
      "min: 0.028935350789284175\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018635387345671512\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080746970563578\n",
      "std: 0.003678380799032394\n",
      "min: 1.3748137697226976\n",
      "max: 1.413979062399269\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080705591717968\n",
      "std: 0.0037540906602538727\n",
      "min: 1.3748137697226976\n",
      "max: 1.413979062399269\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.028602331250758704\n",
      "min: 0.011395196900450603\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32932110287621974\n",
      "std: 0.2930408466302446\n",
      "min: -0.8090169112147215\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6290806415319428\n",
      "std: 0.09053143123382017\n",
      "min: 0.38305640168109667\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01907630974431389\n",
      "min: 0.2078622763800807\n",
      "max: 0.27827025210507744\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.198997333837254\n",
      "std: 0.14146145394905668\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2008835952784545\n",
      "std: 0.14408445117945418\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.029881378011069135\n",
      "min: 0.00398037163533402\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3433996461782035\n",
      "std: 0.3620844255424414\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4667563193050003\n",
      "std: 0.1657621873863927\n",
      "min: 0.028674009790096648\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018741498132589463\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078033626253894\n",
      "std: 0.005079623606002478\n",
      "min: 1.353756707218588\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078048874732025\n",
      "std: 0.005162813455541811\n",
      "min: 1.353756707218588\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.028603398177616295\n",
      "min: 0.011197619754272286\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3287136780262799\n",
      "std: 0.2928536016519432\n",
      "min: -0.8083447704867222\n",
      "max: 0.7949273189635108\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6288391481366256\n",
      "std: 0.09062327475611998\n",
      "min: 0.3825654312513674\n",
      "max: 0.7949273189635108\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019062414232514837\n",
      "min: 0.2066507421484001\n",
      "max: 0.27827431333710057\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2004863606078857\n",
      "std: 0.13807894581741537\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2023848241486739\n",
      "std: 0.1392237243905021\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.02945941298382476\n",
      "min: 0.0037315043450326453\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34405454337314395\n",
      "std: 0.3609898085815202\n",
      "min: -1.0772699643817991\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46653936321513556\n",
      "std: 0.16486910993626214\n",
      "min: 0.02887067005126673\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01871809414422909\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408153456561313\n",
      "std: 0.003370716347386002\n",
      "min: 1.3745147529902175\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081453226925866\n",
      "std: 0.0035375218103728236\n",
      "min: 1.3745147529902175\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.0286021535204277\n",
      "min: 0.011418358983251307\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32949217930380886\n",
      "std: 0.29303386642419643\n",
      "min: -0.8090256231693429\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6286156468678336\n",
      "std: 0.09055144028608443\n",
      "min: 0.3826395672994967\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01907481080979433\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782685958708604\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2174542850504386\n",
      "std: 0.07095969771339461\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2192479515923138\n",
      "std: 0.07426410704292287\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.028931155287139264\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34865966298421464\n",
      "std: 0.3584727889934016\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46263114147049916\n",
      "std: 0.16367494235179147\n",
      "min: 0.027418415317775793\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018661836258912747\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408483082089043\n",
      "std: 0.0026799197114609286\n",
      "min: 1.3798059119284076\n",
      "max: 1.4139792128935547\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408464706830666\n",
      "std: 0.002879808321407601\n",
      "min: 1.3798059119284076\n",
      "max: 1.4139792128935547\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.028601994003951442\n",
      "min: 0.011427176060194106\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3303451387741907\n",
      "std: 0.2927870672005166\n",
      "min: -0.8087437014825689\n",
      "max: 0.789234503352285\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6273189720155775\n",
      "std: 0.09038642457684756\n",
      "min: 0.38262330404903455\n",
      "max: 0.789234503352285\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01906960761460863\n",
      "min: 0.20897601765193488\n",
      "max: 0.278232007365667\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.19320520524798\n",
      "std: 0.17645289192314623\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.195073432537629\n",
      "std: 0.17882759360613093\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.03016186206747891\n",
      "min: 0.0021879648236420076\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3491583987699266\n",
      "std: 0.35937434191492684\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4626422346116932\n",
      "std: 0.1643543805373556\n",
      "min: 0.02877950555986486\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01875587946010098\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071050026184633\n",
      "std: 0.00923251372822472\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4070914975715731\n",
      "std: 0.009386422093325013\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506527\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022988505747126436\n",
      "std: 0.028607436154856655\n",
      "min: 0.010700877716747019\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3310683358205773\n",
      "std: 0.29265404421850555\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804282\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6280562969926922\n",
      "std: 0.09150880543763115\n",
      "min: 0.3811028466794017\n",
      "max: 0.8508224326804282\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019141429953825003\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2012246291205102\n",
      "std: 0.12918458936420352\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2029754551430434\n",
      "std: 0.13120459536003426\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.02925286878816549\n",
      "min: 0.0037371563448466154\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3420776996901245\n",
      "std: 0.36012680250673346\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4669984143814309\n",
      "std: 0.16474997675674127\n",
      "min: 0.028935350789284175\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0186073604332781\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080957759249062\n",
      "std: 0.0036600863089302446\n",
      "min: 1.3748137697226979\n",
      "max: 1.4139790623992687\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408100477751116\n",
      "std: 0.0037316194137682035\n",
      "min: 1.3748137697226979\n",
      "max: 1.4139790623992687\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.028327279635473688\n",
      "min: 0.01131785318154724\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32914723970470816\n",
      "std: 0.2930678076259401\n",
      "min: -0.8090169112147215\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6290918121939054\n",
      "std: 0.09050307758771696\n",
      "min: 0.38305640168109667\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01907004172388451\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782702521050775\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1991901938429455\n",
      "std: 0.14066944784389077\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2009899020074233\n",
      "std: 0.14330016684597813\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.029589824631894683\n",
      "min: 0.00398037163533402\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34247752779943874\n",
      "std: 0.3620193963978129\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46670838438614587\n",
      "std: 0.1656912239034407\n",
      "min: 0.028674009790096648\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018712470403001908\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078272480831977\n",
      "std: 0.005052765548454637\n",
      "min: 1.3537567072185879\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078375273186645\n",
      "std: 0.005132979359264111\n",
      "min: 1.3537567072185879\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.028328332751712246\n",
      "min: 0.011122862333294674\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3285440274370095\n",
      "std: 0.292880792805974\n",
      "min: -0.808344770486722\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6288508924263575\n",
      "std: 0.09059299515414297\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019056175821396168\n",
      "min: 0.20665074214840012\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2006579739135599\n",
      "std: 0.1374177286289589\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2024699932274374\n",
      "std: 0.13858001748159243\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.02917340320925405\n",
      "min: 0.0037315043450326453\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34312302401373\n",
      "std: 0.3609414754758425\n",
      "min: -1.0772699643817996\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46649471588635416\n",
      "std: 0.16480959593647393\n",
      "min: 0.02887067005126673\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01868938741623678\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081738388361944\n",
      "std: 0.00335560096735896\n",
      "min: 1.3745147529902175\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081746365669443\n",
      "std: 0.003517152517484097\n",
      "min: 1.3745147529902175\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.028327104235116404\n",
      "min: 0.011330893511203068\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32931556968767245\n",
      "std: 0.2930611910962743\n",
      "min: -0.8090256231693429\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6286298967301545\n",
      "std: 0.09052242336890697\n",
      "min: 0.3826395672994966\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019068500678632663\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782685958708604\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2174235053000297\n",
      "std: 0.07078578909781184\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2191336668464376\n",
      "std: 0.07411340693766388\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.028651936981443037\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3476814975816625\n",
      "std: 0.35845230202054745\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46261762788742444\n",
      "std: 0.16362434325722439\n",
      "min: 0.027418415317775793\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018633644439863907\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4085004477093361\n",
      "std: 0.002670431325874607\n",
      "min: 1.3798059119284078\n",
      "max: 1.4139792128935542\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408491055587684\n",
      "std: 0.002863467650457367\n",
      "min: 1.3798059119284078\n",
      "max: 1.4139792128935542\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.028326946741574415\n",
      "min: 0.011340787354927188\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3301599587098397\n",
      "std: 0.29281662258450303\n",
      "min: -0.8087437014825689\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6273451803074834\n",
      "std: 0.09035933983422208\n",
      "min: 0.38262330404903455\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01906331611398706\n",
      "min: 0.20897601765193485\n",
      "max: 0.278232007365667\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1934488893654014\n",
      "std: 0.17552036336801893\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1952298799397103\n",
      "std: 0.17790296327153443\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.029866724159499015\n",
      "min: 0.002187964823642007\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3481818137765367\n",
      "std: 0.35934981493396695\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4626341330461644\n",
      "std: 0.16429594182481258\n",
      "min: 0.02877950555986486\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01872690159677323\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071372317111048\n",
      "std: 0.009180447152721793\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071325070919016\n",
      "std: 0.00933291271478879\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022727272727272728\n",
      "std: 0.028332318734722122\n",
      "min: 0.0106246705001549\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3308759732702155\n",
      "std: 0.29268434640442953\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6280755958152047\n",
      "std: 0.09147037789588623\n",
      "min: 0.3811028466794016\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019134486486323384\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2013069030962527\n",
      "std: 0.12848864042382183\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.203118879726695\n",
      "std: 0.13050416621409686\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.02897161630058082\n",
      "min: 0.003737156344846616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34223910704953675\n",
      "std: 0.36044651416087004\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4672205006173826\n",
      "std: 0.16428804836439018\n",
      "min: 0.028935350789284175\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0186242472807006\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081037751727192\n",
      "std: 0.003639293531031967\n",
      "min: 1.3748137697226976\n",
      "max: 1.4139790623992687\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081094549867688\n",
      "std: 0.0037089792082097644\n",
      "min: 1.3748137697226976\n",
      "max: 1.4139790623992687\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.02805778290786404\n",
      "min: 0.011174706698049484\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32913586059143646\n",
      "std: 0.29312491327850754\n",
      "min: -0.8090169112147215\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6290630254578219\n",
      "std: 0.09046258909399568\n",
      "min: 0.38305640168109667\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01907000027226073\n",
      "min: 0.2078622763800807\n",
      "max: 0.27827025210507744\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1992914588699572\n",
      "std: 0.1399384636492993\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2011514292115921\n",
      "std: 0.14256146435851377\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.02930424617372747\n",
      "min: 0.00398037163533402\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3426397852576295\n",
      "std: 0.3623159301961657\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.466930187292786\n",
      "std: 0.1652211197910504\n",
      "min: 0.028674009790096648\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01872813765902109\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078386625016883\n",
      "std: 0.005022051232489615\n",
      "min: 1.3537567072185877\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40784984177251\n",
      "std: 0.005100932364422421\n",
      "min: 1.3537567072185877\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.028058822504764446\n",
      "min: 0.011005245519470939\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3285370527420396\n",
      "std: 0.2929384371213864\n",
      "min: -0.808344770486722\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.628822596010614\n",
      "std: 0.0905504792984881\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019056169705000396\n",
      "min: 0.20665074214840012\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2007425787583876\n",
      "std: 0.13671767993414954\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2026151258215945\n",
      "std: 0.13787924698393966\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.028893212483617085\n",
      "min: 0.0037315043450326453\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34327662590779334\n",
      "std: 0.3612538631291747\n",
      "min: -1.077269964381799\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46672012435491533\n",
      "std: 0.16434812147099864\n",
      "min: 0.02887067005126673\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01870548525053143\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081809925520128\n",
      "std: 0.003337004385916472\n",
      "min: 1.3745147529902175\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408182847225898\n",
      "std: 0.0034958681767147787\n",
      "min: 1.3745147529902175\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.028057609769269402\n",
      "min: 0.011197280185985854\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3293018130173252\n",
      "std: 0.2931186046895581\n",
      "min: -0.8090256231693429\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6286040365184432\n",
      "std: 0.09048129547428678\n",
      "min: 0.3826395672994966\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019068422400838902\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782685958708604\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2173123101652659\n",
      "std: 0.07060020937394781\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2190866357173018\n",
      "std: 0.07389169912106817\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.028378381898962506\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3477889826611613\n",
      "std: 0.35878331782314055\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46287539023387064\n",
      "std: 0.1631756447628476\n",
      "min: 0.027418415317775793\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01865027269873707\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4085034936573781\n",
      "std: 0.002658811905416889\n",
      "min: 1.379805911928408\n",
      "max: 1.4139792128935542\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084952605969863\n",
      "std: 0.0028483203219767748\n",
      "min: 1.379805911928408\n",
      "max: 1.4139792128935542\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.02805745427281093\n",
      "min: 0.01119582026947374\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33013754125914474\n",
      "std: 0.29287567371806905\n",
      "min: -0.8087437014825689\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.627331261451424\n",
      "std: 0.09032001324569801\n",
      "min: 0.38262330404903455\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019063243015568054\n",
      "min: 0.20897601765193488\n",
      "max: 0.278232007365667\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1936141231747783\n",
      "std: 0.17458385749734454\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.195454775824932\n",
      "std: 0.1769641150347072\n",
      "min: -0.48405425797278834\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.02957763144633584\n",
      "min: 0.0021879648236420076\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3482922674771218\n",
      "std: 0.3596734537633705\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46289501792926413\n",
      "std: 0.16384157669060204\n",
      "min: 0.02877950555986486\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018742667569030612\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071559754185565\n",
      "std: 0.00912556675052527\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071522238615948\n",
      "std: 0.009277071392307394\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02247191011235955\n",
      "std: 0.0280627577150338\n",
      "min: 0.010533872651567768\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33084699146882135\n",
      "std: 0.29274393322309106\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6280548064836166\n",
      "std: 0.0914197751110438\n",
      "min: 0.3811028466794016\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019133773927577695\n",
      "min: 0.2089853037964331\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.201530518357833\n",
      "std: 0.12795477766313468\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2032346773444038\n",
      "std: 0.1299661251630221\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.028696046005220084\n",
      "min: 0.0036524039405521997\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3433817775654961\n",
      "std: 0.360017634584409\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4659152870911394\n",
      "std: 0.1651689243774669\n",
      "min: 0.028935350789284175\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018602590618068196\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408087888456181\n",
      "std: 0.0036341875409388346\n",
      "min: 1.3748137697226976\n",
      "max: 1.4139790623992687\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080912955224372\n",
      "std: 0.0037006351957263074\n",
      "min: 1.3748137697226976\n",
      "max: 1.4139790623992687\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.02779367081828255\n",
      "min: 0.01097048287804762\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32931356324120215\n",
      "std: 0.293037797004588\n",
      "min: -0.8090169112147215\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6287841339648661\n",
      "std: 0.09049316197835695\n",
      "min: 0.38305640168109667\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019070931288294457\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782702521050775\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.199536583797546\n",
      "std: 0.13940808242201833\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2012880583849257\n",
      "std: 0.14202061897595286\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.029024451071401315\n",
      "min: 0.0038270795679947282\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3437820610473146\n",
      "std: 0.36186869170820724\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4656258414851987\n",
      "std: 0.16608565355524338\n",
      "min: 0.028674009790096648\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018705441628216114\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407825910277831\n",
      "std: 0.005014423657118115\n",
      "min: 1.353756707218588\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078347487608402\n",
      "std: 0.0050907372124802215\n",
      "min: 1.353756707218588\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.02779469747585975\n",
      "min: 0.010735359175968236\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3287189565205405\n",
      "std: 0.2928519620098429\n",
      "min: -0.808344770486722\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6285440980102216\n",
      "std: 0.09057915461537094\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019057137157534237\n",
      "min: 0.20665074214840012\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2009747897368104\n",
      "std: 0.13610632214805893\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2027387854864826\n",
      "std: 0.1372686519684602\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.028618655583511485\n",
      "min: 0.003583987726740878\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34440998319124494\n",
      "std: 0.3608173521064157\n",
      "min: -1.077269964381799\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46541915197642786\n",
      "std: 0.16522653519940625\n",
      "min: 0.02887067005126673\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018683135076775912\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081647062427805\n",
      "std: 0.003334790155350431\n",
      "min: 1.3745147529902175\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081643567755\n",
      "std: 0.003489288764165776\n",
      "min: 1.3745147529902175\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.02779349987694854\n",
      "min: 0.01097778531794992\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32947708061053504\n",
      "std: 0.2930315897899836\n",
      "min: -0.8090256231693429\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6283280526120514\n",
      "std: 0.09051052474060162\n",
      "min: 0.3826395672994966\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019069305299662918\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782685958708604\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2173747452985915\n",
      "std: 0.07036855358081218\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2190432983122605\n",
      "std: 0.07365615855187767\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.028110289092995497\n",
      "min: 0.007615040730570852\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3488740048731426\n",
      "std: 0.3583510626253125\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4616106689513397\n",
      "std: 0.16404365388514547\n",
      "min: 0.027418415317775793\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018628325165900267\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084844816675404\n",
      "std: 0.002660738492260939\n",
      "min: 1.379805911928408\n",
      "max: 1.4139792128935542\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084741469326645\n",
      "std: 0.0028449610171270828\n",
      "min: 1.379805911928408\n",
      "max: 1.4139792128935542\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.02779334624524629\n",
      "min: 0.01107727020841815\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3303037787113148\n",
      "std: 0.2927898982355299\n",
      "min: -0.8087437014825689\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6270676632906513\n",
      "std: 0.09034763442215055\n",
      "min: 0.38262330404903455\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01906412307344946\n",
      "min: 0.20897601765193488\n",
      "max: 0.27823200736566706\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.193936754177869\n",
      "std: 0.1737519802887886\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.19566822183658\n",
      "std: 0.17612323357770943\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.029294388797392535\n",
      "min: 0.0021879648236420076\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34937963013735196\n",
      "std: 0.35923489259299124\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4616309187892829\n",
      "std: 0.1646964677364191\n",
      "min: 0.02877950555986486\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018720030158847985\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071516361215433\n",
      "std: 0.009086844495246207\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071455802579544\n",
      "std: 0.009236922532526276\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.022222222222222223\n",
      "std: 0.027798583257839633\n",
      "min: 0.010289676950998417\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33100702476271415\n",
      "std: 0.29265790114969\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6277838922756149\n",
      "std: 0.09143757524019898\n",
      "min: 0.3811028466794016\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.0191340183999299\n",
      "min: 0.2089853037964331\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.201871268736955\n",
      "std: 0.12749350356993683\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2035401659977867\n",
      "std: 0.1294891324760069\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.02842596517823195\n",
      "min: 0.0036524039405521997\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3426256744070388\n",
      "std: 0.36015632675240655\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280948\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4660957051665691\n",
      "std: 0.16526549250824069\n",
      "min: 0.028935350789284175\n",
      "max: 0.8380933254280948\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01856967358712314\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080961669028813\n",
      "std: 0.0036262540424514705\n",
      "min: 1.3748137697226976\n",
      "max: 1.4139790623992687\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080957803993102\n",
      "std: 0.003696960711567362\n",
      "min: 1.3748137697226976\n",
      "max: 1.4139790623992687\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.02753477986733528\n",
      "min: 0.010826095011785794\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3291878306612635\n",
      "std: 0.2930301046641476\n",
      "min: -0.8090169112147215\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6288123536412589\n",
      "std: 0.09044379401234616\n",
      "min: 0.38305640168109667\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019062957600242045\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782702521050775\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1999073475478208\n",
      "std: 0.138769024069874\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2016229323970335\n",
      "std: 0.14136364168163684\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.02875021561937691\n",
      "min: 0.0038270795679947282\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34302540247310054\n",
      "std: 0.3619868265786674\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4658086919741425\n",
      "std: 0.1661709187490091\n",
      "min: 0.028674009790096648\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01867165477567082\n",
      "min: 0.201862918460537\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.407837184635386\n",
      "std: 0.004993363792684688\n",
      "min: 1.3537567072185879\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.40784217667365\n",
      "std: 0.0050729229137047634\n",
      "min: 1.3537567072185879\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.02753579364218308\n",
      "min: 0.01069546272483596\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3285970748051518\n",
      "std: 0.29284467734607283\n",
      "min: -0.808344770486722\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6285732273514248\n",
      "std: 0.09052807092382396\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019049194708723575\n",
      "min: 0.20665074214840012\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.201325100873286\n",
      "std: 0.13552776883020595\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.203053224270657\n",
      "std: 0.13667991764075976\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.028349560911002453\n",
      "min: 0.003583987726740877\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34364519052343495\n",
      "std: 0.360951851528349\n",
      "min: -1.077269964381799\n",
      "max: 0.842480639827969\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46560417233896817\n",
      "std: 0.16532350245987892\n",
      "min: 0.02887067005126673\n",
      "max: 0.842480639827969\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018649628403705862\n",
      "min: 0.2009239483610974\n",
      "max: 0.29559290650963493\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081721143975106\n",
      "std: 0.0033286007961999217\n",
      "min: 1.374514752990218\n",
      "max: 1.4139785360498363\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408168046256578\n",
      "std: 0.0034869155266578967\n",
      "min: 1.374514752990218\n",
      "max: 1.4139785360498363\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.027534611061816736\n",
      "min: 0.010832463802137596\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32934876358659726\n",
      "std: 0.29302424254992127\n",
      "min: -0.8090256231693429\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6283593317956927\n",
      "std: 0.09046065432196145\n",
      "min: 0.3826395672994966\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019061291711451153\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782685958708604\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.217548749339785\n",
      "std: 0.07021448548961669\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2191844321219367\n",
      "std: 0.07346671775369487\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.027847500881966285\n",
      "min: 0.007579173812029776\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3480648733213547\n",
      "std: 0.3585128065788083\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689308\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46182895917635813\n",
      "std: 0.16415451905990275\n",
      "min: 0.027418415317775793\n",
      "max: 0.8234650410689308\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018595292041711488\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084884426859967\n",
      "std: 0.0026584103251039966\n",
      "min: 1.3798059119284076\n",
      "max: 1.4139792128935542\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084745266305223\n",
      "std: 0.0028471050568318586\n",
      "min: 1.3798059119284076\n",
      "max: 1.4139792128935542\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.027534459266972407\n",
      "min: 0.010830901158003892\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33016706329067447\n",
      "std: 0.2927845645540462\n",
      "min: -0.8087437014825689\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6271106310276643\n",
      "std: 0.0902998235274787\n",
      "min: 0.38262330404903455\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019056127911443566\n",
      "min: 0.20897601765193488\n",
      "max: 0.27823200736566706\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.194347599280329\n",
      "std: 0.17303926449219473\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1960430781529152\n",
      "std: 0.175395132828787\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.02901682342802481\n",
      "min: 0.0021879648236420076\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34857129748598165\n",
      "std: 0.3593896641496\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608173\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4618526600538718\n",
      "std: 0.1647987939015952\n",
      "min: 0.02877950555986486\n",
      "max: 0.8291312528608173\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018686205468398033\n",
      "min: 0.20170415209191342\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071689100348561\n",
      "std: 0.009045170766073089\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071591062628448\n",
      "std: 0.009196898678242964\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02197802197802198\n",
      "std: 0.0275396312777639\n",
      "min: 0.010174845875765223\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3308636129758095\n",
      "std: 0.2926530975220284\n",
      "min: -0.8084344089842002\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6278203561195249\n",
      "std: 0.09137899886064214\n",
      "min: 0.3811028466794016\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019125405061467482\n",
      "min: 0.2089853037964331\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.201985296265355\n",
      "std: 0.12671148567946336\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.203706086631875\n",
      "std: 0.12870099799972587\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.028161155768753218\n",
      "min: 0.0036524039405521997\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3425161491370741\n",
      "std: 0.3603393035855138\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280944\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46665208942428055\n",
      "std: 0.1650557272686885\n",
      "min: 0.028935350789284175\n",
      "max: 0.8380933254280944\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01856315618713364\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080802118848974\n",
      "std: 0.0036190289292210203\n",
      "min: 1.3748137697226976\n",
      "max: 1.4139790623992687\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080782652226302\n",
      "std: 0.003685285450712974\n",
      "min: 1.3748137697226976\n",
      "max: 1.4139790623992687\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.027280953109737563\n",
      "min: 0.010804600604479178\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3291212612653074\n",
      "std: 0.2931057477186154\n",
      "min: -0.8090169112147217\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6289243609915741\n",
      "std: 0.09044659988642957\n",
      "min: 0.38305640168109667\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019057467265449612\n",
      "min: 0.2078622763800807\n",
      "max: 0.27827025210507744\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2000435313882714\n",
      "std: 0.13787879740397058\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.201810190901938\n",
      "std: 0.1404662708705881\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.02848136485447108\n",
      "min: 0.0038270795679947282\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3429157170979211\n",
      "std: 0.3621490803644353\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46636605171839296\n",
      "std: 0.16595218027718123\n",
      "min: 0.028674009790096714\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018664110509911923\n",
      "min: 0.20186291846053703\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078239100816625\n",
      "std: 0.0049715326041172726\n",
      "min: 1.353756707218588\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078272850318814\n",
      "std: 0.005047746916341608\n",
      "min: 1.353756707218588\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.027281954279837373\n",
      "min: 0.01063661263449616\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32853443728430004\n",
      "std: 0.29292082164974775\n",
      "min: -0.8083447704867218\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6286860574762431\n",
      "std: 0.09052905951078084\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01904373381175533\n",
      "min: 0.20665074214840012\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2014454841790587\n",
      "std: 0.13470595839203467\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2032248554941471\n",
      "std: 0.13585768763332673\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782605\n",
      "std: 0.028085729265157327\n",
      "min: 0.003583987726740877\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34352716485375606\n",
      "std: 0.3611280054987521\n",
      "min: -1.0772699643817991\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4661648177109943\n",
      "std: 0.16511537277360988\n",
      "min: 0.028870670051266586\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018642379697500214\n",
      "min: 0.20092394836109737\n",
      "max: 0.2955929065096349\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.40815486375247\n",
      "std: 0.003323896682864846\n",
      "min: 1.374514752990217\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081493298872352\n",
      "std: 0.0034766610380573483\n",
      "min: 1.374514752990217\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.0272807863944432\n",
      "min: 0.010804333228776764\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32927960632225056\n",
      "std: 0.29310018424237516\n",
      "min: -0.809025623169343\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6284746842920446\n",
      "std: 0.0904631972914094\n",
      "min: 0.3826395672994968\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019055751053964985\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782685958708604\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2174573273122702\n",
      "std: 0.07002561712165087\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2191477446642605\n",
      "std: 0.07324046897845375\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.027589872638684964\n",
      "min: 0.007579173812029774\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34790391765306933\n",
      "std: 0.3587083557334503\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689306\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46241724712089305\n",
      "std: 0.16396462857268843\n",
      "min: 0.027418415317775724\n",
      "max: 0.8234650410689306\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018588514025189455\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084675299764449\n",
      "std: 0.00266620768302188\n",
      "min: 1.3798059119284083\n",
      "max: 1.4139792128935542\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084522557631152\n",
      "std: 0.002847560706849632\n",
      "min: 1.3798059119284083\n",
      "max: 1.4139792128935542\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782605\n",
      "std: 0.02728063647154778\n",
      "min: 0.010803507217854006\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33008990091084084\n",
      "std: 0.2928620878594939\n",
      "min: -0.8087437014825689\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6272366511541227\n",
      "std: 0.09030541885393181\n",
      "min: 0.38262330404903455\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01905059416384263\n",
      "min: 0.20897601765193488\n",
      "max: 0.278232007365667\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1945393517586576\n",
      "std: 0.17194570596145847\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1962854237658063\n",
      "std: 0.17429893233386795\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021739130434782608\n",
      "std: 0.02874471005843638\n",
      "min: 0.002187964823642008\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.348412362082394\n",
      "std: 0.3595793315408719\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46244621432472216\n",
      "std: 0.16460179328281643\n",
      "min: 0.02877950555986479\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018678609529717078\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071626955637873\n",
      "std: 0.008998452413150252\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071513325252685\n",
      "std: 0.00914830087496739\n",
      "min: 1.304253835191986\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02173913043478261\n",
      "std: 0.027285744721401772\n",
      "min: 0.010066456039472442\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33078001551635805\n",
      "std: 0.2927312791387857\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6279403381876641\n",
      "std: 0.09137314990281689\n",
      "min: 0.3811028466794014\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01911926320733833\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2017239097265604\n",
      "std: 0.1262538883733394\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2034081939558008\n",
      "std: 0.12825140020712703\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.027901586381329085\n",
      "min: 0.0031024090435135517\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3429303929737113\n",
      "std: 0.36024313022997306\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280944\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4659431502108154\n",
      "std: 0.16496318093591775\n",
      "min: 0.028935350789284175\n",
      "max: 0.8380933254280944\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018591091593124706\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080548614560446\n",
      "std: 0.0036309830124881108\n",
      "min: 1.3748137697226976\n",
      "max: 1.4139790623992687\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080438384959268\n",
      "std: 0.003706065578532587\n",
      "min: 1.3748137697226976\n",
      "max: 1.4139790623992687\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.02703204033005294\n",
      "min: 0.01064039104582204\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32926077966726397\n",
      "std: 0.29311349949231513\n",
      "min: -0.8090169112147217\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6288629903201115\n",
      "std: 0.09041859109554314\n",
      "min: 0.38305640168109667\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019061451357303874\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782702521050775\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1997992317837898\n",
      "std: 0.13746104567361153\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2015287295848622\n",
      "std: 0.14004911325514413\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.02821787499037879\n",
      "min: 0.0033692519883650423\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34333060918156516\n",
      "std: 0.3620339834071513\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4656573903729157\n",
      "std: 0.16584976438090615\n",
      "min: 0.028674009790096714\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01869079099403122\n",
      "min: 0.20186291846053703\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078008445368615\n",
      "std: 0.004975450233020859\n",
      "min: 1.353756707218588\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4077950815396816\n",
      "std: 0.00505778608819545\n",
      "min: 1.353756707218588\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.027033029420391177\n",
      "min: 0.010367325851951862\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3286780945782866\n",
      "std: 0.2929292667389576\n",
      "min: -0.8083447704867218\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6286249979459619\n",
      "std: 0.09049931545489413\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019047746197615296\n",
      "min: 0.20665074214840012\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2011862149462915\n",
      "std: 0.13421629390642906\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2029283594115243\n",
      "std: 0.13538114698495546\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02150537634408602\n",
      "std: 0.027827123550747\n",
      "min: 0.003583987726740878\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3439336743690175\n",
      "std: 0.36102487972402847\n",
      "min: -1.0772699643817991\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4654591617399225\n",
      "std: 0.16502093976860122\n",
      "min: 0.028870670051266586\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018669474764847763\n",
      "min: 0.20092394836109737\n",
      "max: 0.2955929065096349\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081287784712786\n",
      "std: 0.0033421779550858693\n",
      "min: 1.374369216836909\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081142215907152\n",
      "std: 0.0035032208515650832\n",
      "min: 1.374369216836909\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02150537634408602\n",
      "std: 0.027031875691364036\n",
      "min: 0.010580233455292286\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32941694645295416\n",
      "std: 0.2931079938992798\n",
      "min: -0.809025623169343\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6284158763098655\n",
      "std: 0.0904344624959644\n",
      "min: 0.3826395672994968\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01905969563680687\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782685958708604\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.217050374272406\n",
      "std: 0.06990326747364302\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.218706105915385\n",
      "std: 0.07312553473641943\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.02733727258442166\n",
      "min: 0.007249589589230065\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3482648240477829\n",
      "std: 0.35861769233910046\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689306\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4617447196891717\n",
      "std: 0.1638670227746813\n",
      "min: 0.027418415317775724\n",
      "max: 0.8234650410689306\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018616062405397888\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084396620276087\n",
      "std: 0.0026914838910353173\n",
      "min: 1.379805911928408\n",
      "max: 1.4139792128935542\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084154862441425\n",
      "std: 0.0028823733755087132\n",
      "min: 1.379805911928408\n",
      "max: 1.4139792128935542\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02150537634408602\n",
      "std: 0.02703172749267342\n",
      "min: 0.010667612832055575\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.330218534991299\n",
      "std: 0.2928710783686287\n",
      "min: -0.8087437014825689\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6271892283860445\n",
      "std: 0.09027757229797582\n",
      "min: 0.38262330404903455\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01905451435193068\n",
      "min: 0.20897601765193488\n",
      "max: 0.278232007365667\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1943860063345537\n",
      "std: 0.1710928922700785\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1960942429782997\n",
      "std: 0.17345054380849\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.028477992762434123\n",
      "min: 0.002187964823642008\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3487760462257123\n",
      "std: 0.3594835248803825\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4617764399655548\n",
      "std: 0.16449654365507788\n",
      "min: 0.02877950555986479\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018705385177142004\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071473658114968\n",
      "std: 0.008972780538773319\n",
      "min: 1.3016304881552285\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071269469712517\n",
      "std: 0.00912541918519395\n",
      "min: 1.3016304881552285\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021505376344086023\n",
      "std: 0.027036773954414603\n",
      "min: 0.009845431012808128\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3309030096609317\n",
      "std: 0.2927402461108994\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6278863846623751\n",
      "std: 0.09133542126605548\n",
      "min: 0.3811028466794014\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019122592005884707\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2021895740611097\n",
      "std: 0.1257920411196776\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2038867290616129\n",
      "std: 0.1277779914580092\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.02764700702406542\n",
      "min: 0.0031024090435135534\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34332646735798594\n",
      "std: 0.3603457998110536\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280944\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4658795668168365\n",
      "std: 0.164614341553172\n",
      "min: 0.028935350789284175\n",
      "max: 0.8380933254280944\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018586394716203443\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080612198591187\n",
      "std: 0.003622028200270362\n",
      "min: 1.374813769722698\n",
      "max: 1.4139790623992687\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.408044670010114\n",
      "std: 0.003700844207459879\n",
      "min: 1.374813769722698\n",
      "max: 1.4139790623992687\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021276595744680847\n",
      "std: 0.02678789680140508\n",
      "min: 0.010528421542458633\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3293377012453102\n",
      "std: 0.2931926093367214\n",
      "min: -0.8090169112147217\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6288203615691841\n",
      "std: 0.09040634557129439\n",
      "min: 0.38305640168109667\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01906163262712103\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782702521050775\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2002871130272221\n",
      "std: 0.13692202265516243\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.202028724190952\n",
      "std: 0.1394972647718463\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.027959446387225348\n",
      "min: 0.0033692519883650423\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3437266314634068\n",
      "std: 0.362117616147675\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4655953196262016\n",
      "std: 0.16549304823869412\n",
      "min: 0.028674009790096714\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018685128174729893\n",
      "min: 0.20186291846053703\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078099400210984\n",
      "std: 0.0049572292517156965\n",
      "min: 1.353756707218588\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.407798595879782\n",
      "std: 0.0050422053148502085\n",
      "min: 1.353756707218588\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.026788873945634527\n",
      "min: 0.010367325851951862\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3287588829919876\n",
      "std: 0.29300902288980474\n",
      "min: -0.8083447704867218\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6285830357384119\n",
      "std: 0.09048515389208779\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019047961355674617\n",
      "min: 0.20665074214840012\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2016667280966986\n",
      "std: 0.13356965061789666\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2034210472953066\n",
      "std: 0.1347309296795116\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021276595744680847\n",
      "std: 0.027573447760939365\n",
      "min: 0.003583987726740877\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3443206976504985\n",
      "std: 0.3611216621923821\n",
      "min: -1.0772699643817991\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.465400939479294\n",
      "std: 0.16467177616660061\n",
      "min: 0.028870670051266586\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018664094605999302\n",
      "min: 0.20092394836109737\n",
      "max: 0.2955929065096349\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4081345116486097\n",
      "std: 0.003334293147259787\n",
      "min: 1.3743692168369086\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081144933076335\n",
      "std: 0.003498658130712774\n",
      "min: 1.3743692168369086\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.026787734146338303\n",
      "min: 0.010527470519363598\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3294914969966509\n",
      "std: 0.2931873627484292\n",
      "min: -0.809025623169343\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6283762407354068\n",
      "std: 0.09042157480402252\n",
      "min: 0.3826395672994968\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019059850544526115\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782685958708604\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2173683816860006\n",
      "std: 0.06970428247639002\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2190391693394955\n",
      "std: 0.07289638189941412\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.02708949159835908\n",
      "min: 0.00724958958923007\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3486092035723475\n",
      "std: 0.35872799360122365\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689306\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46171706734134976\n",
      "std: 0.16352633584451234\n",
      "min: 0.027418415317775724\n",
      "max: 0.8234650410689306\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01861121147573141\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4084421897809762\n",
      "std: 0.002690061918574797\n",
      "min: 1.3798059119284078\n",
      "max: 1.4139792128935542\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084126353512103\n",
      "std: 0.002884723021492415\n",
      "min: 1.3798059119284078\n",
      "max: 1.4139792128935542\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.026787587700985122\n",
      "min: 0.010525691308502526\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3302850350989094\n",
      "std: 0.29295178042640485\n",
      "min: -0.8087437014825689\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.627160639324341\n",
      "std: 0.09026601896309969\n",
      "min: 0.38262330404903455\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019054679597056763\n",
      "min: 0.20897601765193488\n",
      "max: 0.278232007365667\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1949252994918438\n",
      "std: 0.17042803686654737\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1966452383517714\n",
      "std: 0.17277832344323948\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021276595744680847\n",
      "std: 0.028216445128971607\n",
      "min: 0.002181503785771067\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34912255271177534\n",
      "std: 0.3595883100023236\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46175094967918784\n",
      "std: 0.1641496075663811\n",
      "min: 0.02877950555986479\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018699757158472947\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071633118349396\n",
      "std: 0.008933082782811196\n",
      "min: 1.3016304881552285\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071373941665115\n",
      "std: 0.009086693854730044\n",
      "min: 1.3016304881552285\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02127659574468085\n",
      "std: 0.026792573536989328\n",
      "min: 0.00984543101280813\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3309636169132315\n",
      "std: 0.29282132175837894\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6278512042874494\n",
      "std: 0.09131377368194461\n",
      "min: 0.3811028466794014\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019122162742962148\n",
      "min: 0.20898530379643307\n",
      "max: 0.27862366722969123\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.202849914166861\n",
      "std: 0.1252882495526344\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2046711006600632\n",
      "std: 0.12728448187758382\n",
      "min: -0.061628286294034766\n",
      "max: 1.4130914395500438\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.02739727450340936\n",
      "min: 0.0031024090435135534\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.343562184421371\n",
      "std: 0.3603168141380439\n",
      "min: -1.0770239429008936\n",
      "max: 0.8380933254280944\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4658056138955766\n",
      "std: 0.16475271859325405\n",
      "min: 0.028935350789284175\n",
      "max: 0.8380933254280944\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01859298268007961\n",
      "min: 0.20191313578575756\n",
      "max: 0.2904831519832517\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4080725252075998\n",
      "std: 0.0036061543040498785\n",
      "min: 1.374813769722698\n",
      "max: 1.4139790623992687\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4080623507962373\n",
      "std: 0.0036816212687043946\n",
      "min: 1.374813769722698\n",
      "max: 1.4139790623992687\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.026548383716499074\n",
      "min: 0.010434099840312785\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.32932690498860095\n",
      "std: 0.2931899427387282\n",
      "min: -0.8090169112147217\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6287440469565085\n",
      "std: 0.0903755713783633\n",
      "min: 0.38305640168109667\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01906028563683475\n",
      "min: 0.2078622763800807\n",
      "max: 0.2782702521050775\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.200970011530044\n",
      "std: 0.13628876540741247\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2028349426168683\n",
      "std: 0.1388739238014173\n",
      "min: -0.0831529223098451\n",
      "max: 1.413885346421365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.02105263157894737\n",
      "std: 0.027705943460914977\n",
      "min: 0.0033692519883650423\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.34396190854859815\n",
      "std: 0.3620700625445826\n",
      "min: -1.0770316694735973\n",
      "max: 0.9599022535921017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.46552296172664476\n",
      "std: 0.16562066376930307\n",
      "min: 0.028674009790096714\n",
      "max: 0.9599022535921017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018690721327804905\n",
      "min: 0.20186291846053703\n",
      "max: 0.3025514934225995\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4078240372036144\n",
      "std: 0.004931454145112034\n",
      "min: 1.353756707218588\n",
      "max: 1.4139796934019795\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4078190126400798\n",
      "std: 0.005014136009723746\n",
      "min: 1.353756707218588\n",
      "max: 1.4139796934019795\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.026549349126856813\n",
      "min: 0.010301882203521214\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3287518355202627\n",
      "std: 0.2930069556798362\n",
      "min: -0.8083447704867218\n",
      "max: 0.7949273189635107\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.628507465615713\n",
      "std: 0.09045274201941107\n",
      "min: 0.38256543125136744\n",
      "max: 0.7949273189635107\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01904665026936435\n",
      "min: 0.20665074214840012\n",
      "max: 0.2782743133371007\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.202335071772173\n",
      "std: 0.13297838079240343\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2042128428072323\n",
      "std: 0.13415550794401668\n",
      "min: -0.056146501305344036\n",
      "max: 1.4123449151074563\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.027324615849575754\n",
      "min: 0.003583987726740877\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3445484517902127\n",
      "std: 0.361086452403254\n",
      "min: -1.0772699643817991\n",
      "max: 0.8424806398279688\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4653311637165579\n",
      "std: 0.16481027268667378\n",
      "min: 0.028870670051266586\n",
      "max: 0.8424806398279688\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018669994953342244\n",
      "min: 0.20092394836109737\n",
      "max: 0.2955929065096349\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408145081927754\n",
      "std: 0.003319480832753768\n",
      "min: 1.374369216836909\n",
      "max: 1.4139785360498365\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4081315120246563\n",
      "std: 0.0034797572104615935\n",
      "min: 1.374369216836909\n",
      "max: 1.4139785360498365\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.026548223009177647\n",
      "min: 0.01045345289757125\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3294785204054291\n",
      "std: 0.29318494525993344\n",
      "min: -0.809025623169343\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6283027064596158\n",
      "std: 0.09039016954609988\n",
      "min: 0.3826395672994968\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.019058474430711795\n",
      "min: 0.2071750899445349\n",
      "max: 0.2782685958708604\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.2178721935532837\n",
      "std: 0.06947804439334711\n",
      "min: 0.6681541528240925\n",
      "max: 1.41230256861976\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.2196698798826862\n",
      "std: 0.07266114722159575\n",
      "min: 0.7199851205004341\n",
      "max: 1.41230256861976\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947368\n",
      "std: 0.026846412085085654\n",
      "min: 0.00724958958923007\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.3487958950748467\n",
      "std: 0.3587089527493181\n",
      "min: -1.0762984934293212\n",
      "max: 0.8234650410689306\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4616778960917772\n",
      "std: 0.16367556006435122\n",
      "min: 0.027418415317775724\n",
      "max: 0.8234650410689306\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018617606539567486\n",
      "min: 0.201826724278273\n",
      "max: 0.2889277285576929\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.408449412379868\n",
      "std: 0.0026805493654048934\n",
      "min: 1.3798059119284078\n",
      "max: 1.4139792128935542\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4084263807588029\n",
      "std: 0.002869784992592419\n",
      "min: 1.3798059119284078\n",
      "max: 1.4139792128935542\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947364\n",
      "std: 0.026548078290588983\n",
      "min: 0.010470783584308738\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33026431026864933\n",
      "std: 0.29295103250597737\n",
      "min: -0.8087437014825689\n",
      "max: 0.7892345033522847\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6270979684007234\n",
      "std: 0.0902355003292242\n",
      "min: 0.38262330404903455\n",
      "max: 0.7892345033522847\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01905331747143653\n",
      "min: 0.20878467500555511\n",
      "max: 0.278232007365667\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1956529014307336\n",
      "std: 0.16966920169385843\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.1974958304374124\n",
      "std: 0.17203288024164112\n",
      "min: -0.4840542579727882\n",
      "max: 1.4136302305114998\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947364\n",
      "std: 0.027959901891787653\n",
      "min: 0.0021815037857710667\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.349310377715692\n",
      "std: 0.35956131398747687\n",
      "min: -1.0769263626129009\n",
      "max: 0.8291312528608171\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4617142380082608\n",
      "std: 0.16428876841951573\n",
      "min: 0.02877950555986479\n",
      "max: 0.8291312528608171\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.018705352300671864\n",
      "min: 0.2017041520919134\n",
      "max: 0.2903984456810728\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.4071833448946158\n",
      "std: 0.008889619263590645\n",
      "min: 1.3016304881552285\n",
      "max: 1.4139976643506529\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.4071638097045887\n",
      "std: 0.009041947299637174\n",
      "min: 1.3016304881552285\n",
      "max: 1.4139976643506529\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.021052631578947364\n",
      "std: 0.02655300480807776\n",
      "min: 0.009786932415502164\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: -0.33093693811873465\n",
      "std: 0.29282077098163073\n",
      "min: -0.8084344089842\n",
      "max: 0.8508224326804283\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6277823271590066\n",
      "std: 0.0912733235524426\n",
      "min: 0.3811028466794014\n",
      "max: 0.8508224326804283\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.25\n",
      "std: 0.01912021604207421\n",
      "min: 0.20879115237028215\n",
      "max: 0.27862366722969123\n",
      "Test translation: merci beaucoup -> principal\n",
      "\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.6967096089113266\n",
      "std: 0.4439132925068381\n",
      "min: -0.9934327623675032\n",
      "max: 1.4140559778530943\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.03429940561324306\n",
      "std: 0.3497731180964939\n",
      "min: -0.9932295227458549\n",
      "max: 1.4140559778530943\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0896358543417367\n",
      "std: 0.043541049230224546\n",
      "min: 0.012845476454035089\n",
      "max: 0.4952455090356398\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1490879873564919\n",
      "std: 0.34411892538214367\n",
      "min: -1.0307203956335869\n",
      "max: 1.4137070403566083\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.04195788945295\n",
      "std: 0.47069463849727455\n",
      "min: -0.9493890640054435\n",
      "max: 1.41352267460937\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0896358543417367\n",
      "std: 0.034752676797208455\n",
      "min: 0.02571941044596643\n",
      "max: 0.2185696386871784\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0219942459999642\n",
      "std: 0.3466987798827854\n",
      "min: -0.8433668032924263\n",
      "max: 1.4141817499918388\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.44972848334530857\n",
      "std: 0.42709534952099526\n",
      "min: -0.8433668032924263\n",
      "max: 1.4141817499918388\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10709881979918971\n",
      "std: 0.07380023248057763\n",
      "min: 0.012586879607348701\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.537558363697276\n",
      "std: 0.26924931517370165\n",
      "min: -0.6432445120176503\n",
      "max: 1.2496728128366121\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5541472880700511\n",
      "std: 0.281398624259205\n",
      "min: -0.5878871067222406\n",
      "max: 1.2314318555020818\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0896358543417367\n",
      "std: 0.03506586756011054\n",
      "min: 0.02615660641065944\n",
      "max: 0.21229359306077117\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.360367736376207\n",
      "std: 0.02646820554757788\n",
      "min: 1.1128253086100124\n",
      "max: 1.4141208069784856\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3551555672205275\n",
      "std: 0.02844059984133278\n",
      "min: 1.1128253086100124\n",
      "max: 1.4141208069784856\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1070988197991897\n",
      "std: 0.054584302049265704\n",
      "min: 0.03480991951657152\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.5586255674949389\n",
      "std: 0.17282970368766915\n",
      "min: -0.2962811908814582\n",
      "max: 1.0608345262920764\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5910068661099663\n",
      "std: 0.1598193866089712\n",
      "min: -0.07913726294859973\n",
      "max: 1.0318304258601965\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08963585434173671\n",
      "std: 0.03506694052948537\n",
      "min: 0.028711986515221347\n",
      "max: 0.20531150215541147\n",
      "[=-----------------------------] 4% Epoch 2/50 - loss: 0.0087 - bleu: 0.0 - 2.13s=== Attention Logits (before mask) ===\n",
      "mean: 0.6843809845340416\n",
      "std: 0.44147681242008247\n",
      "min: -1.005875534778541\n",
      "max: 1.414174186970232\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.03227691239674476\n",
      "std: 0.35064409081421016\n",
      "min: -1.005875534778541\n",
      "max: 1.414174186970232\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08963585434173672\n",
      "std: 0.044895518364132275\n",
      "min: 0.012309646729548106\n",
      "max: 0.4367644021567972\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1407979426939487\n",
      "std: 0.35903169799761186\n",
      "min: -1.0008487578775787\n",
      "max: 1.4137019208835935\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0410797584209586\n",
      "std: 0.47954106301747296\n",
      "min: -0.8993164779535024\n",
      "max: 1.4133454107513952\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0896358543417367\n",
      "std: 0.036080137586395326\n",
      "min: 0.02380280442490547\n",
      "max: 0.23884498730266612\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0350531926031852\n",
      "std: 0.34019403353034305\n",
      "min: -0.9319921810073689\n",
      "max: 1.4141648447720023\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.4738920547289049\n",
      "std: 0.4296470679469271\n",
      "min: -0.9319921810073689\n",
      "max: 1.4141648447720023\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.10822356710573158\n",
      "std: 0.07293791263617563\n",
      "min: 0.015066440009220085\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.5461989899019916\n",
      "std: 0.2733457931104308\n",
      "min: -0.7034812071840661\n",
      "max: 1.277849447462527\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5642703433144463\n",
      "std: 0.28300991934733616\n",
      "min: -0.638904071182857\n",
      "max: 1.2344933660937776\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08963585434173668\n",
      "std: 0.03634981551109775\n",
      "min: 0.02926663025221056\n",
      "max: 0.21531383864475082\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3615037145504754\n",
      "std: 0.026641935990712004\n",
      "min: 1.0624007291375872\n",
      "max: 1.414110478645288\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.356877327978437\n",
      "std: 0.02844023720647341\n",
      "min: 1.0624007291375872\n",
      "max: 1.414110478645288\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.1082235671057316\n",
      "std: 0.053150151489685875\n",
      "min: 0.050173007937546456\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.5704334615076696\n",
      "std: 0.1821370563064772\n",
      "min: -0.34378696125087477\n",
      "max: 1.07343760209111\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6029733506448256\n",
      "std: 0.1660451955925875\n",
      "min: -0.10808007091894876\n",
      "max: 1.0641855336719148\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.08963585434173668\n",
      "std: 0.03638733756043701\n",
      "min: 0.03192174267988146\n",
      "max: 0.2040716883822324\n",
      "[==----------------------------] 8% Epoch 2/50 - loss: 0.0086 - bleu: 0.0 - 4.31s=== Attention Logits (before mask) ===\n",
      "mean: 0.684598611102259\n",
      "std: 0.43604926946427486\n",
      "min: -1.0355877525806472\n",
      "max: 1.4140493784773347\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.017946166012765937\n",
      "std: 0.3575688962951048\n",
      "min: -1.0355877525806472\n",
      "max: 1.4140493784773347\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0975609756097561\n",
      "std: 0.04957813462466552\n",
      "min: 0.016222909879138082\n",
      "max: 0.5432072298819716\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.133680115770894\n",
      "std: 0.37048227024929603\n",
      "min: -0.9723813800757246\n",
      "max: 1.4137128777087151\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.0620261206949102\n",
      "std: 0.4586446622582321\n",
      "min: -0.8458273578575534\n",
      "max: 1.4133239604267696\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09756097560975611\n",
      "std: 0.0405547167001246\n",
      "min: 0.031355162374053294\n",
      "max: 0.26338003108287644\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0585664404388488\n",
      "std: 0.3174869081452536\n",
      "min: -0.92572309168948\n",
      "max: 1.4141873301735792\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5222604005581047\n",
      "std: 0.42631704571021584\n",
      "min: -0.9118666516860644\n",
      "max: 1.4141873301735792\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11549713156794955\n",
      "std: 0.08003068116764973\n",
      "min: 0.015334189124855143\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.5668932242827092\n",
      "std: 0.2760770188073695\n",
      "min: -0.6341963487018372\n",
      "max: 1.2681868397625646\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5777036772416064\n",
      "std: 0.2873093674024841\n",
      "min: -0.5675041831411366\n",
      "max: 1.2203837728449545\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09756097560975611\n",
      "std: 0.04083478579634968\n",
      "min: 0.03728260841190068\n",
      "max: 0.26326768474346\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3617899725733744\n",
      "std: 0.027063870345657236\n",
      "min: 1.107188316741664\n",
      "max: 1.414113575484916\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3579816599206502\n",
      "std: 0.028737922409791627\n",
      "min: 1.1216293332022553\n",
      "max: 1.414113575484916\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.11549713156794955\n",
      "std: 0.060938028407226695\n",
      "min: 0.04976328831529948\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.5924013143327178\n",
      "std: 0.18260053975095822\n",
      "min: -0.3111169563639992\n",
      "max: 1.0886735470780196\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6179971758775469\n",
      "std: 0.16912712567160745\n",
      "min: -0.11441031570143484\n",
      "max: 1.0688755581531915\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.0975609756097561\n",
      "std: 0.040826412702034395\n",
      "min: 0.03828576281666444\n",
      "max: 0.25326552070511255\n",
      "[===---------------------------] 12% Epoch 2/50 - loss: 0.0100 - bleu: 0.0 - 6.47s=== Attention Logits (before mask) ===\n",
      "mean: 0.6259665284536922\n",
      "std: 0.4686621911474757\n",
      "min: -1.0282487465401209\n",
      "max: 1.4141837124283017\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.0006488852112410006\n",
      "std: 0.3559892818475497\n",
      "min: -1.0282487465401209\n",
      "max: 1.4141837124283017\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07547169811320756\n",
      "std: 0.034310965776182284\n",
      "min: 0.01297382308855041\n",
      "max: 0.4473360795714634\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.1051218295608554\n",
      "std: 0.406754388007952\n",
      "min: -1.0872343023157431\n",
      "max: 1.4138178353809678\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.008498621477699\n",
      "std: 0.5222460514460509\n",
      "min: -0.9921244617978066\n",
      "max: 1.4133102216082754\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07547169811320754\n",
      "std: 0.025385298571263773\n",
      "min: 0.023650313053310244\n",
      "max: 0.23341010986117952\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.0204181226689613\n",
      "std: 0.36764189857652635\n",
      "min: -0.9255582289953878\n",
      "max: 1.4141855631926807\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.475518024505335\n",
      "std: 0.4325196231928043\n",
      "min: -0.917967424258722\n",
      "max: 1.4141855631926807\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09146158011914074\n",
      "std: 0.06503276006820007\n",
      "min: 0.013670319639694674\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.5570721817083003\n",
      "std: 0.29409817462992227\n",
      "min: -0.6285147948574932\n",
      "max: 1.257322964570558\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.5746071398166817\n",
      "std: 0.30195601809464834\n",
      "min: -0.5699003032444838\n",
      "max: 1.2361466084357562\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07547169811320753\n",
      "std: 0.02558509952163204\n",
      "min: 0.028971460190432532\n",
      "max: 0.20656269711457476\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 1.3619814204644733\n",
      "std: 0.02737716579337246\n",
      "min: 1.0998764259850695\n",
      "max: 1.4141146595616116\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 1.3583198178366203\n",
      "std: 0.028846634762132402\n",
      "min: 1.1069900266435269\n",
      "max: 1.4141146595616116\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.09146158011914075\n",
      "std: 0.04783607276602158\n",
      "min: 0.04544745118616842\n",
      "max: 1.0\n",
      "=== Attention Logits (before mask) ===\n",
      "mean: 0.6043514727207735\n",
      "std: 0.1862774387998896\n",
      "min: -0.36678950387967946\n",
      "max: 1.0922299733642433\n",
      "=== Attention Logits (after mask, valid positions only) ===\n",
      "mean: 0.6350381249636522\n",
      "std: 0.1707517954704943\n",
      "min: -0.10575683715044092\n",
      "max: 1.073635753995944\n",
      "=== Attention Weights (non-zero only) ===\n",
      "mean: 0.07547169811320756\n",
      "std: 0.025605066215062606\n",
      "min: 0.028624490116658272\n",
      "max: 0.2176061813035111\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mLearningRateScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschedule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwarmup_cosine\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_learning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mDebugCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfr_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43men_tokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbleu_score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\marcp\\documents\\programming\\python\\neuralnetlib\\neuralnetlib\\models.py:1755\u001b[0m, in \u001b[0;36mTransformer.fit\u001b[1;34m(self, x_train, y_train, epochs, batch_size, verbose, metrics, random_state, validation_data, callbacks)\u001b[0m\n\u001b[0;32m   1752\u001b[0m dec_batch \u001b[38;5;241m=\u001b[39m decoder_input_shuffled[j:j \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m   1753\u001b[0m target_batch \u001b[38;5;241m=\u001b[39m decoder_target_shuffled[j:j \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m-> 1755\u001b[0m error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1756\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43menc_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_batch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_batch\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1759\u001b[0m predictions_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictions)\n\u001b[0;32m   1760\u001b[0m y_true_list\u001b[38;5;241m.\u001b[39mappend(target_batch)\n",
      "File \u001b[1;32mc:\\users\\marcp\\documents\\programming\\python\\neuralnetlib\\neuralnetlib\\models.py:1513\u001b[0m, in \u001b[0;36mTransformer.train_on_batch\u001b[1;34m(self, x_batch, y_batch, print_logging)\u001b[0m\n\u001b[0;32m   1511\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function(decoder_target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictions)\n\u001b[0;32m   1512\u001b[0m error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function\u001b[38;5;241m.\u001b[39mderivative(decoder_target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictions)\n\u001b[1;32m-> 1513\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_with_monitoring\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m, layer_idx: \u001b[38;5;28mint\u001b[39m, weights: np\u001b[38;5;241m.\u001b[39mndarray, \n\u001b[0;32m   1516\u001b[0m                          d_weights: np\u001b[38;5;241m.\u001b[39mndarray, bias: np\u001b[38;5;241m.\u001b[39mndarray, d_bias: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1517\u001b[0m     weight_norm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(d_weights)\n",
      "File \u001b[1;32mc:\\users\\marcp\\documents\\programming\\python\\neuralnetlib\\neuralnetlib\\models.py:1441\u001b[0m, in \u001b[0;36mTransformer.backward_pass\u001b[1;34m(self, error)\u001b[0m\n\u001b[0;32m   1438\u001b[0m d_enc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1440\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_layers):\n\u001b[1;32m-> 1441\u001b[0m     dx, d_enc \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1442\u001b[0m     d_enc_output \u001b[38;5;241m=\u001b[39m d_enc \u001b[38;5;28;01mif\u001b[39;00m d_enc_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m d_enc_output \u001b[38;5;241m+\u001b[39m d_enc\n\u001b[0;32m   1444\u001b[0m dx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_dropout\u001b[38;5;241m.\u001b[39mbackward_pass(dx)\n",
      "File \u001b[1;32mc:\\users\\marcp\\documents\\programming\\python\\neuralnetlib\\neuralnetlib\\layers.py:3367\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.backward_pass\u001b[1;34m(self, output_error)\u001b[0m\n\u001b[0;32m   3365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward_pass\u001b[39m(\u001b[38;5;28mself\u001b[39m, output_error: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m   3366\u001b[0m     d_norm3, d_residual3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3\u001b[38;5;241m.\u001b[39mbackward_pass(output_error)\n\u001b[1;32m-> 3367\u001b[0m     d_ffn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_norm3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3369\u001b[0m     d_ffn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn\u001b[38;5;241m.\u001b[39mbackward_pass(d_ffn)\n\u001b[0;32m   3371\u001b[0m     d_out2 \u001b[38;5;241m=\u001b[39m d_residual3 \u001b[38;5;241m+\u001b[39m d_ffn\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=True,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='loss', patience=20),\n",
    "        LearningRateScheduler(schedule=\"warmup_cosine\", initial_learning_rate=0.0001, verbose=True),\n",
    "        DebugCallback(model, fr_tokenizer, en_tokenizer)\n",
    "    ],\n",
    "    validation_data=(x_test, y_test),\n",
    "    metrics=['bleu_score']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc335b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary sizes:\n",
      "French vocab size: 1946\n",
      "English vocab size: 1671\n",
      "\n",
      "==================================================\n",
      "Testing: je vais bien\n",
      "Translation: <SOS> bin\n",
      "\n",
      "==================================================\n",
      "Testing: comment allez-vous ?\n",
      "Translation: <SOS> bin\n",
      "\n",
      "==================================================\n",
      "Testing: bonjour\n",
      "Translation: <SOS> bin\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary sizes:\")\n",
    "print(f\"French vocab size: {len(fr_tokenizer.word_index)}\")\n",
    "print(f\"English vocab size: {len(en_tokenizer.word_index)}\")\n",
    "\n",
    "for sent in test_sentences:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Testing: {sent}\")\n",
    "    translation = translate(sent, model, fr_tokenizer, en_tokenizer, temperature=1.2)\n",
    "    print(f\"Translation: {translation}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
