{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple diabete regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T19:03:42.300332700Z",
     "start_time": "2024-11-14T19:03:41.572444700Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "from neuralnetlib.preprocessing import MinMaxScaler, StandardScaler\n",
    "from neuralnetlib.activations import Linear, LeakyReLU\n",
    "from neuralnetlib.layers import Input, Dense, Activation\n",
    "from neuralnetlib.losses import MeanSquaredError, MeanAbsoluteError\n",
    "from neuralnetlib.models import Sequential\n",
    "from neuralnetlib.optimizers import Adam\n",
    "from neuralnetlib.utils import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading a dataset (in this case, the diabetes dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T19:03:42.333243200Z",
     "start_time": "2024-11-14T19:03:42.301332800Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y = load_diabetes(return_X_y=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T19:03:42.347365300Z",
     "start_time": "2024-11-14T19:03:42.333243200Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler_x = MinMaxScaler()\n",
    "x_train = scaler_x.fit_transform(x_train)\n",
    "x_test = scaler_x.transform(x_test)\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_test = scaler_y.transform(y_test.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T19:03:42.365577900Z",
     "start_time": "2024-11-14T19:03:42.349869300Z"
    }
   },
   "outputs": [],
   "source": [
    "input_neurons = x_train.shape[1:][0]\n",
    "num_hidden_layers = 2\n",
    "hidden_neurons = 2\n",
    "output_neurons = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(input_neurons))\n",
    "model.add(Dense(hidden_neurons, weights_init='he_normal', random_state=42))\n",
    "model.add(Activation(LeakyReLU()))\n",
    "\n",
    "for _ in range(num_hidden_layers - 1):\n",
    "    model.add(Dense(hidden_neurons, weights_init='he_normal', random_state=42))\n",
    "    model.add(Activation(LeakyReLU()))\n",
    "\n",
    "model.add(Dense(output_neurons, random_state=42))\n",
    "model.add(Activation(Linear()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T19:03:42.379141Z",
     "start_time": "2024-11-14T19:03:42.364577700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(gradient_clip_threshold=5.0, enable_padding=False, padding_size=32, random_state=1733786806176717100)\n",
      "-------------------------------------------------\n",
      "Layer 1: Input(input_shape=(10,))\n",
      "Layer 2: Dense(units=2)\n",
      "Layer 3: Activation(LeakyReLU)\n",
      "Layer 4: Dense(units=2)\n",
      "Layer 5: Activation(LeakyReLU)\n",
      "Layer 6: Dense(units=1)\n",
      "Layer 7: Activation(Linear)\n",
      "-------------------------------------------------\n",
      "Loss function: MeanSquaredError\n",
      "Optimizer: Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, clip_norm=None, clip_value=None)\n",
      "-------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss_function=MeanSquaredError(), optimizer=Adam(learning_rate=0.001))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T19:03:42.516565900Z",
     "start_time": "2024-11-14T19:03:42.380146700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================] 100% Epoch 1/100 - 0.01s - loss: 1.2543        \n",
      "[==============================] 100% Epoch 2/100 - 0.01s - loss: 1.2482        \n",
      "[==============================] 100% Epoch 3/100 - 0.01s - loss: 1.2422        \n",
      "[==============================] 100% Epoch 4/100 - 0.01s - loss: 1.2366        \n",
      "[==============================] 100% Epoch 5/100 - 0.01s - loss: 1.2320        \n",
      "[==============================] 100% Epoch 6/100 - 0.01s - loss: 1.2275        \n",
      "[==============================] 100% Epoch 7/100 - 0.01s - loss: 1.2231        \n",
      "[==============================] 100% Epoch 8/100 - 0.01s - loss: 1.2183        \n",
      "[==============================] 100% Epoch 9/100 - 0.01s - loss: 1.2134        \n",
      "[==============================] 100% Epoch 10/100 - 0.01s - loss: 1.2083       \n",
      "[==============================] 100% Epoch 11/100 - 0.01s - loss: 1.2029       \n",
      "[==============================] 100% Epoch 12/100 - 0.01s - loss: 1.1975       \n",
      "[==============================] 100% Epoch 13/100 - 0.01s - loss: 1.1921       \n",
      "[==============================] 100% Epoch 14/100 - 0.01s - loss: 1.1864       \n",
      "[==============================] 100% Epoch 15/100 - 0.01s - loss: 1.1806       \n",
      "[==============================] 100% Epoch 16/100 - 0.01s - loss: 1.1746       \n",
      "[==============================] 100% Epoch 17/100 - 0.01s - loss: 1.1685       \n",
      "[==============================] 100% Epoch 18/100 - 0.01s - loss: 1.1622       \n",
      "[==============================] 100% Epoch 19/100 - 0.01s - loss: 1.1555       \n",
      "[==============================] 100% Epoch 20/100 - 0.01s - loss: 1.1489       \n",
      "[==============================] 100% Epoch 21/100 - 0.01s - loss: 1.1421       \n",
      "[==============================] 100% Epoch 22/100 - 0.01s - loss: 1.1353       \n",
      "[==============================] 100% Epoch 23/100 - 0.01s - loss: 1.1284       \n",
      "[==============================] 100% Epoch 24/100 - 0.01s - loss: 1.1213       \n",
      "[==============================] 100% Epoch 25/100 - 0.01s - loss: 1.1141       \n",
      "[==============================] 100% Epoch 26/100 - 0.01s - loss: 1.1068       \n",
      "[==============================] 100% Epoch 27/100 - 0.01s - loss: 1.0994       \n",
      "[==============================] 100% Epoch 28/100 - 0.01s - loss: 1.0919       \n",
      "[==============================] 100% Epoch 29/100 - 0.01s - loss: 1.0841       \n",
      "[==============================] 100% Epoch 30/100 - 0.01s - loss: 1.0761       \n",
      "[==============================] 100% Epoch 31/100 - 0.01s - loss: 1.0679       \n",
      "[==============================] 100% Epoch 32/100 - 0.01s - loss: 1.0597       \n",
      "[==============================] 100% Epoch 33/100 - 0.01s - loss: 1.0514       \n",
      "[==============================] 100% Epoch 34/100 - 0.01s - loss: 1.0429       \n",
      "[==============================] 100% Epoch 35/100 - 0.01s - loss: 1.0344       \n",
      "[==============================] 100% Epoch 36/100 - 0.01s - loss: 1.0259       \n",
      "[==============================] 100% Epoch 37/100 - 0.01s - loss: 1.0174       \n",
      "[==============================] 100% Epoch 38/100 - 0.01s - loss: 1.0090       \n",
      "[==============================] 100% Epoch 39/100 - 0.01s - loss: 1.0003       \n",
      "[==============================] 100% Epoch 40/100 - 0.01s - loss: 0.9914       \n",
      "[==============================] 100% Epoch 41/100 - 0.01s - loss: 0.9822       \n",
      "[==============================] 100% Epoch 42/100 - 0.01s - loss: 0.9729       \n",
      "[==============================] 100% Epoch 43/100 - 0.01s - loss: 0.9633       \n",
      "[==============================] 100% Epoch 44/100 - 0.01s - loss: 0.9534       \n",
      "[==============================] 100% Epoch 45/100 - 0.01s - loss: 0.9430       \n",
      "[==============================] 100% Epoch 46/100 - 0.01s - loss: 0.9322       \n",
      "[==============================] 100% Epoch 47/100 - 0.01s - loss: 0.9199       \n",
      "[==============================] 100% Epoch 48/100 - 0.01s - loss: 0.9069       \n",
      "[==============================] 100% Epoch 49/100 - 0.01s - loss: 0.8932       \n",
      "[==============================] 100% Epoch 50/100 - 0.01s - loss: 0.8791       \n",
      "[==============================] 100% Epoch 51/100 - 0.01s - loss: 0.8643       \n",
      "[==============================] 100% Epoch 52/100 - 0.01s - loss: 0.8502       \n",
      "[==============================] 100% Epoch 53/100 - 0.01s - loss: 0.8348       \n",
      "[==============================] 100% Epoch 54/100 - 0.01s - loss: 0.8178       \n",
      "[==============================] 100% Epoch 55/100 - 0.01s - loss: 0.7999       \n",
      "[==============================] 100% Epoch 56/100 - 0.01s - loss: 0.7825       \n",
      "[==============================] 100% Epoch 57/100 - 0.01s - loss: 0.7658       \n",
      "[==============================] 100% Epoch 58/100 - 0.01s - loss: 0.7502       \n",
      "[==============================] 100% Epoch 59/100 - 0.01s - loss: 0.7364       \n",
      "[==============================] 100% Epoch 60/100 - 0.01s - loss: 0.7243       \n",
      "[==============================] 100% Epoch 61/100 - 0.01s - loss: 0.7132       \n",
      "[==============================] 100% Epoch 62/100 - 0.01s - loss: 0.7031       \n",
      "[==============================] 100% Epoch 63/100 - 0.01s - loss: 0.6937       \n",
      "[==============================] 100% Epoch 64/100 - 0.01s - loss: 0.6846       \n",
      "[==============================] 100% Epoch 65/100 - 0.01s - loss: 0.6761       \n",
      "[==============================] 100% Epoch 66/100 - 0.01s - loss: 0.6674       \n",
      "[==============================] 100% Epoch 67/100 - 0.01s - loss: 0.6587       \n",
      "[==============================] 100% Epoch 68/100 - 0.01s - loss: 0.6508       \n",
      "[==============================] 100% Epoch 69/100 - 0.01s - loss: 0.6434       \n",
      "[==============================] 100% Epoch 70/100 - 0.01s - loss: 0.6365       \n",
      "[==============================] 100% Epoch 71/100 - 0.01s - loss: 0.6300       \n",
      "[==============================] 100% Epoch 72/100 - 0.01s - loss: 0.6237       \n",
      "[==============================] 100% Epoch 73/100 - 0.01s - loss: 0.6175       \n",
      "[==============================] 100% Epoch 74/100 - 0.01s - loss: 0.6110       \n",
      "[==============================] 100% Epoch 75/100 - 0.01s - loss: 0.6031       \n",
      "[==============================] 100% Epoch 76/100 - 0.01s - loss: 0.5917       \n",
      "[==============================] 100% Epoch 77/100 - 0.01s - loss: 0.5811       \n",
      "[==============================] 100% Epoch 78/100 - 0.01s - loss: 0.5711       \n",
      "[==============================] 100% Epoch 79/100 - 0.01s - loss: 0.5631       \n",
      "[==============================] 100% Epoch 80/100 - 0.01s - loss: 0.5569       \n",
      "[==============================] 100% Epoch 81/100 - 0.01s - loss: 0.5516       \n",
      "[==============================] 100% Epoch 82/100 - 0.01s - loss: 0.5470       \n",
      "[==============================] 100% Epoch 83/100 - 0.01s - loss: 0.5427       \n",
      "[==============================] 100% Epoch 84/100 - 0.01s - loss: 0.5384       \n",
      "[==============================] 100% Epoch 85/100 - 0.01s - loss: 0.5347       \n",
      "[==============================] 100% Epoch 86/100 - 0.01s - loss: 0.5312       \n",
      "[==============================] 100% Epoch 87/100 - 0.01s - loss: 0.5280       \n",
      "[==============================] 100% Epoch 88/100 - 0.01s - loss: 0.5252       \n",
      "[==============================] 100% Epoch 89/100 - 0.01s - loss: 0.5226       \n",
      "[==============================] 100% Epoch 90/100 - 0.01s - loss: 0.5202       \n",
      "[==============================] 100% Epoch 91/100 - 0.01s - loss: 0.5178       \n",
      "[==============================] 100% Epoch 92/100 - 0.01s - loss: 0.5156       \n",
      "[==============================] 100% Epoch 93/100 - 0.01s - loss: 0.5134       \n",
      "[==============================] 100% Epoch 94/100 - 0.01s - loss: 0.5112       \n",
      "[==============================] 100% Epoch 95/100 - 0.01s - loss: 0.5093       \n",
      "[==============================] 100% Epoch 96/100 - 0.01s - loss: 0.5075       \n",
      "[==============================] 100% Epoch 97/100 - 0.01s - loss: 0.5058       \n",
      "[==============================] 100% Epoch 98/100 - 0.01s - loss: 0.5041       \n",
      "[==============================] 100% Epoch 99/100 - 0.01s - loss: 0.5026       \n",
      "[==============================] 100% Epoch 100/100 - 0.01s - loss: 0.5011      \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100, batch_size=32, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T19:03:42.518566Z",
     "start_time": "2024-11-14T19:03:42.497221300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.7401693358245864 function=MeanSquaredError\n"
     ]
    }
   ],
   "source": [
    "loss, _ = model.evaluate(x_test, y_test)\n",
    "print(f'Test loss: {loss}', \"function=\" + str(model.loss_function))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T19:03:42.519566900Z",
     "start_time": "2024-11-14T19:03:42.503423800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  1.0799955616547592\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(\"MAE: \", MeanAbsoluteError()(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
