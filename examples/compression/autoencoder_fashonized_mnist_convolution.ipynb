{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37514bc3",
   "metadata": {},
   "source": [
    "# Autoencoders on Fashionized MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00856f2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4977326d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:48:18.472890200Z",
     "start_time": "2024-11-16T21:48:17.775974Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from neuralnetlib.models import Autoencoder\n",
    "from neuralnetlib.layers import Input, Conv2D, Conv2DTranspose, BatchNormalization, Flatten, Reshape, Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39acfc09",
   "metadata": {},
   "source": [
    "## Load Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f039b23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:48:28.070769900Z",
     "start_time": "2024-11-16T21:48:18.474889700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Fashion MNIST...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcp\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shapes:\n",
      "Training data: (56000, 28, 28, 1)\n",
      "Test data: (14000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Fashion MNIST...\")\n",
    "X, y = fetch_openml('Fashion-MNIST', version=1, return_X_y=True, as_frame=False)\n",
    "X = X.astype('float32') / 255.\n",
    "\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "print(\"Dataset shapes:\")\n",
    "print(f\"Training data: {X_train.shape}\")\n",
    "print(f\"Test data: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d66641",
   "metadata": {},
   "source": [
    "## Create Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ba5635b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:48:28.101015600Z",
     "start_time": "2024-11-16T21:48:28.070769900Z"
    }
   },
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(random_state=42, skip_connections=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543d43d3",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c9a7a05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:48:28.106015800Z",
     "start_time": "2024-11-16T21:48:28.087834900Z"
    }
   },
   "outputs": [],
   "source": [
    "autoencoder.add_encoder_layer(Input((28, 28, 1)))\n",
    "autoencoder.add_encoder_layer(Conv2D(32, kernel_size=(3, 3), strides=(2, 2), activation='relu', padding='same'))\n",
    "autoencoder.add_encoder_layer(BatchNormalization())\n",
    "\n",
    "autoencoder.add_encoder_layer(Conv2D(64, kernel_size=(3, 3), strides=(2, 2), activation='relu', padding='same'))\n",
    "autoencoder.add_encoder_layer(BatchNormalization())\n",
    "\n",
    "autoencoder.add_encoder_layer(Flatten())\n",
    "autoencoder.add_encoder_layer(Dense(128, activation='relu'))  # Bottleneck\n",
    "autoencoder.add_encoder_layer(BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a47ffcf",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c65ea32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:48:28.118598500Z",
     "start_time": "2024-11-16T21:48:28.104016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing Conv2DTranspose:\n",
      "- Filters: 32\n",
      "- Kernel size: (3, 3)\n",
      "- Strides: (2, 2)\n",
      "- Padding: same\n",
      "- Weights init: default\n",
      "- Bias init: default\n",
      "- Additional parameter: activation = relu\n",
      "\n",
      "Initializing Conv2DTranspose:\n",
      "- Filters: 16\n",
      "- Kernel size: (3, 3)\n",
      "- Strides: (2, 2)\n",
      "- Padding: same\n",
      "- Weights init: default\n",
      "- Bias init: default\n",
      "- Additional parameter: activation = relu\n",
      "\n",
      "Initializing Conv2DTranspose:\n",
      "- Filters: 1\n",
      "- Kernel size: (3, 3)\n",
      "- Strides: (1, 1)\n",
      "- Padding: same\n",
      "- Weights init: default\n",
      "- Bias init: default\n",
      "- Additional parameter: activation = sigmoid\n"
     ]
    }
   ],
   "source": [
    "autoencoder.add_decoder_layer(Dense(7 * 7 * 64, activation='relu'))\n",
    "autoencoder.add_decoder_layer(Reshape((7, 7, 64)))\n",
    "\n",
    "autoencoder.add_decoder_layer(Conv2DTranspose(32, kernel_size=(3, 3), strides=(2, 2), activation='relu', padding='same'))  # Output: 14x14x32\n",
    "autoencoder.add_decoder_layer(BatchNormalization())\n",
    "\n",
    "autoencoder.add_decoder_layer(Conv2DTranspose(16, kernel_size=(3, 3), strides=(2, 2), activation='relu', padding='same'))  # Output: 28x28x16\n",
    "autoencoder.add_decoder_layer(BatchNormalization())\n",
    "\n",
    "autoencoder.add_decoder_layer(Conv2DTranspose(1, kernel_size=(3, 3), strides=(1, 1), activation='sigmoid', padding='same'))  # Output: 28x28x1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23e41ad",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9926e67e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:48:28.163110Z",
     "start_time": "2024-11-16T21:48:28.118598500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder(temperature=1.0, gradient_clip_threshold=5.0, enable_padding=False, padding_size=32, random_state=42, skip_connections=True, l1_reg=0.0, l2_reg=0.0)\n",
      "-------------------------------------------------\n",
      "Encoder:\n",
      "Layer 1: Input(input_shape=(28, 28, 1))\n",
      "Layer 2: Conv2D(num_filters=32, kernel_size=(3, 3), strides=(2, 2), padding=same)\n",
      "Layer 3: Activation(ReLU)\n",
      "Layer 4: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "Layer 5: Conv2D(num_filters=64, kernel_size=(3, 3), strides=(2, 2), padding=same)\n",
      "Layer 6: Activation(ReLU)\n",
      "Layer 7: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "Layer 8: Flatten\n",
      "Layer 9: Dense(units=128)\n",
      "Layer 10: Activation(ReLU)\n",
      "Layer 11: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "-------------------------------------------------\n",
      "Decoder:\n",
      "Layer 1: Dense(units=3136)\n",
      "Layer 2: Activation(ReLU)\n",
      "Layer 3: Reshape(target_shape=(7, 7, 64))\n",
      "Layer 4: <neuralnetlib.layers.Conv2DTranspose object at 0x0000015A01A8CAF0>\n",
      "Layer 5: Activation(ReLU)\n",
      "Layer 6: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "Layer 7: <neuralnetlib.layers.Conv2DTranspose object at 0x0000015A6224F730>\n",
      "Layer 8: Activation(ReLU)\n",
      "Layer 9: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "Layer 10: <neuralnetlib.layers.Conv2DTranspose object at 0x0000015A62340DF0>\n",
      "Layer 11: Activation(Sigmoid)\n",
      "-------------------------------------------------\n",
      "Encoder loss function: MeanSquaredError\n",
      "Decoder loss function: MeanSquaredError\n",
      "Encoder optimizer: Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, clip_norm=None, clip_value=None)\n",
      "Decoder optimizer: Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, clip_norm=None, clip_value=None)\n",
      "-------------------------------------------------\n",
      "\n",
      "Autoencoder(temperature=1.0, gradient_clip_threshold=5.0, enable_padding=False, padding_size=32, random_state=42, skip_connections=True, l1_reg=0.0, l2_reg=0.0)\n",
      "-------------------------------------------------\n",
      "Encoder:\n",
      "Layer 1: Input(input_shape=(28, 28, 1))\n",
      "Layer 2: Conv2D(num_filters=32, kernel_size=(3, 3), strides=(2, 2), padding=same)\n",
      "Layer 3: Activation(ReLU)\n",
      "Layer 4: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "Layer 5: Conv2D(num_filters=64, kernel_size=(3, 3), strides=(2, 2), padding=same)\n",
      "Layer 6: Activation(ReLU)\n",
      "Layer 7: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "Layer 8: Flatten\n",
      "Layer 9: Dense(units=128)\n",
      "Layer 10: Activation(ReLU)\n",
      "Layer 11: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "-------------------------------------------------\n",
      "Decoder:\n",
      "Layer 1: Dense(units=3136)\n",
      "Layer 2: Activation(ReLU)\n",
      "Layer 3: Reshape(target_shape=(7, 7, 64))\n",
      "Layer 4: <neuralnetlib.layers.Conv2DTranspose object at 0x0000015A01A8CAF0>\n",
      "Layer 5: Activation(ReLU)\n",
      "Layer 6: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "Layer 7: <neuralnetlib.layers.Conv2DTranspose object at 0x0000015A6224F730>\n",
      "Layer 8: Activation(ReLU)\n",
      "Layer 9: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "Layer 10: <neuralnetlib.layers.Conv2DTranspose object at 0x0000015A62340DF0>\n",
      "Layer 11: Activation(Sigmoid)\n",
      "-------------------------------------------------\n",
      "Encoder loss function: MeanSquaredError\n",
      "Decoder loss function: MeanSquaredError\n",
      "Encoder optimizer: Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, clip_norm=None, clip_value=None)\n",
      "Decoder optimizer: Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, clip_norm=None, clip_value=None)\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(\n",
    "    encoder_loss='mse',\n",
    "    decoder_loss='mse',\n",
    "    encoder_optimizer='adam',\n",
    "    decoder_optimizer='adam',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a849c7b4",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b203201",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:48:28.614944200Z",
     "start_time": "2024-11-16T21:48:28.132919800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing weights:\n",
      "Input shape: 448\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mautoencoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Programming\\Python\\neuralnetlib\\neuralnetlib\\models.py:1197\u001B[0m, in \u001B[0;36mAutoencoder.fit\u001B[1;34m(self, x_train, epochs, batch_size, verbose, metrics, random_state, validation_data, callbacks)\u001B[0m\n\u001B[0;32m   1194\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, x_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], batch_size):\n\u001B[0;32m   1195\u001B[0m     x_batch \u001B[38;5;241m=\u001B[39m x_train_shuffled[j:j \u001B[38;5;241m+\u001B[39m batch_size]\n\u001B[1;32m-> 1197\u001B[0m     error \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_on_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1198\u001B[0m     predictions_list\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictions)\n\u001B[0;32m   1199\u001B[0m     inputs_list\u001B[38;5;241m.\u001B[39mappend(x_batch)\n",
      "File \u001B[1;32m~\\Documents\\Programming\\Python\\neuralnetlib\\neuralnetlib\\models.py:958\u001B[0m, in \u001B[0;36mAutoencoder.train_on_batch\u001B[1;34m(self, x_batch, y_batch)\u001B[0m\n\u001B[0;32m    955\u001B[0m     y_batch \u001B[38;5;241m=\u001B[39m x_batch\n\u001B[0;32m    957\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_true \u001B[38;5;241m=\u001B[39m y_batch\n\u001B[1;32m--> 958\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_pass\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    960\u001B[0m reconstruction_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder_loss(y_batch, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictions)\n\u001B[0;32m    961\u001B[0m regularization_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_calculate_regularization()\n",
      "File \u001B[1;32m~\\Documents\\Programming\\Python\\neuralnetlib\\neuralnetlib\\models.py:838\u001B[0m, in \u001B[0;36mAutoencoder.forward_pass\u001B[1;34m(self, X, training)\u001B[0m\n\u001B[0;32m    836\u001B[0m     encoded \u001B[38;5;241m=\u001B[39m layer\u001B[38;5;241m.\u001B[39mforward_pass(encoded, training)\n\u001B[0;32m    837\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 838\u001B[0m     encoded \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_pass\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoded\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    839\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder_activations\u001B[38;5;241m.\u001B[39mappend(encoded)\n\u001B[0;32m    841\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip_connections \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(layer, Dense):\n",
      "File \u001B[1;32m~\\Documents\\Programming\\Python\\neuralnetlib\\neuralnetlib\\layers.py:157\u001B[0m, in \u001B[0;36mDense.forward_pass\u001B[1;34m(self, input_data)\u001B[0m\n\u001B[0;32m    154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\u001B[38;5;241m.\u001B[39mreshape(batch_size, timesteps, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munits)\n\u001B[0;32m    156\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 157\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minitialize_weights\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mdot(input_data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\n",
      "File \u001B[1;32m~\\Documents\\Programming\\Python\\neuralnetlib\\neuralnetlib\\layers.py:88\u001B[0m, in \u001B[0;36mDense.initialize_weights\u001B[1;34m(self, input_shape)\u001B[0m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minput_shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     87\u001B[0m \u001B[38;5;66;03m# Determine input channel dimension\u001B[39;00m\n\u001B[1;32m---> 88\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43minput_shape\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m4\u001B[39m:  \u001B[38;5;66;03m# NHWC or NCHW format\u001B[39;00m\n\u001B[0;32m     89\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m input_shape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m<\u001B[39m input_shape[\u001B[38;5;241m2\u001B[39m]:  \u001B[38;5;66;03m# NCHW format\u001B[39;00m\n\u001B[0;32m     90\u001B[0m         channels \u001B[38;5;241m=\u001B[39m input_shape[\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[1;31mTypeError\u001B[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(\n",
    "    X_train,\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_test,),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba39b2d",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f3c0ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:48:28.619944300Z",
     "start_time": "2024-11-16T21:48:28.615944Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0a8a1",
   "metadata": {},
   "source": [
    "## Visualize Original vs Reconstructed Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97193fec",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-16T21:48:28.616944100Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 10  # Number of images to display\n",
    "decoded_imgs = autoencoder.predict(X_test[:n])\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Original\n",
    "    plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    if i == 0:\n",
    "        plt.title('Original')\n",
    "\n",
    "    # Reconstructed\n",
    "    plt.subplot(2, n, i + n + 1)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    if i == 0:\n",
    "        plt.title('Reconstructed')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6ddde2",
   "metadata": {},
   "source": [
    "## Visualize Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898dc2d3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-16T21:48:28.617944Z"
    }
   },
   "outputs": [],
   "source": [
    "latent_vectors = autoencoder.predict(X_test[:1000], output_latent=True)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "latent_2d = pca.fit_transform(latent_vectors)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=y[:1000].astype(int), cmap='tab10')\n",
    "plt.colorbar()\n",
    "plt.title('Latent Space Visualization (2D PCA)')\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e499fee7",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb013785",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-16T21:48:28.618944400Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "# 1. Reconstruction Error Metrics\n",
    "X_test_reconstructed = autoencoder.predict(X_test)\n",
    "X_train_reconstructed = autoencoder.predict(X_train)\n",
    "\n",
    "results['mse_test'] = mean_squared_error(X_test, X_test_reconstructed)\n",
    "results['mae_test'] = mean_absolute_error(X_test, X_test_reconstructed)\n",
    "results['mse_train'] = mean_squared_error(X_train, X_train_reconstructed)\n",
    "results['mae_train'] = mean_absolute_error(X_train, X_train_reconstructed)\n",
    "\n",
    "# 2. Feature Preservation\n",
    "correlations = []\n",
    "for i in range(X_test.shape[1]):\n",
    "    corr, _ = pearsonr(X_test[:, i], X_test_reconstructed[:, i])\n",
    "    if not np.isnan(corr):\n",
    "        correlations.append(corr)\n",
    "results['avg_feature_correlation'] = np.mean(correlations)\n",
    "\n",
    "# 3. Latent Space Analysis\n",
    "latent_train = autoencoder.predict(X_train, output_latent=True)\n",
    "latent_test = autoencoder.predict(X_test, output_latent=True)\n",
    "\n",
    "results['latent_skewness'] = np.mean([np.abs(np.mean(latent_test[:, i] ** 3))\n",
    "                                        for i in range(latent_test.shape[1])])\n",
    "results['latent_kurtosis'] = np.mean([np.mean(latent_test[:, i] ** 4) - 3\n",
    "                                        for i in range(latent_test.shape[1])])\n",
    "\n",
    "# 4. Compression Efficiency\n",
    "n_input_features = X_test.shape[1]\n",
    "n_latent_features = latent_test.shape[1]\n",
    "results['compression_ratio'] = n_input_features / n_latent_features\n",
    "\n",
    "pca = PCA(n_components=n_latent_features)\n",
    "pca.fit(latent_test)\n",
    "results['explained_variance_ratio'] = pca.explained_variance_ratio.sum()\n",
    "\n",
    "# 5. Distribution Matching\n",
    "def approximate_kl_divergence(p, q):\n",
    "    p = np.clip(p, 1e-10, 1)\n",
    "    q = np.clip(q, 1e-10, 1)\n",
    "    p = p / p.sum()\n",
    "    q = q / q.sum()\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "kl_divs = []\n",
    "n_features_to_check = min(10, X_test.shape[1])\n",
    "for i in range(n_features_to_check):\n",
    "    hist_orig, _ = np.histogram(X_test[:, i], bins=50, density=True)\n",
    "    hist_recon, _ = np.histogram(X_test_reconstructed[:, i], bins=50, density=True)\n",
    "    kl_divs.append(approximate_kl_divergence(hist_orig, hist_recon))\n",
    "results['avg_kl_divergence'] = np.mean(kl_divs)\n",
    "\n",
    "# 6. Visualizations\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.hist(X_test.ravel(), bins=50, alpha=0.5, label='Original', density=True)\n",
    "plt.hist(X_test_reconstructed.ravel(), bins=50, alpha=0.5, label='Reconstructed', density=True)\n",
    "plt.title('Distribution Comparison')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.hist(latent_test.ravel(), bins=50)\n",
    "plt.title('Latent Space Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447524f8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-16T21:48:28.618944400Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Evaluation Results:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
