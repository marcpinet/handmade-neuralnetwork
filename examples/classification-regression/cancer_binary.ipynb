{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple cancer binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T00:42:53.042954700Z",
     "start_time": "2024-09-23T00:42:52.377587600Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from neuralnetlib.preprocessing import StandardScaler\n",
    "from neuralnetlib.activations import Sigmoid, ReLU\n",
    "from neuralnetlib.layers import Input, Activation, Dense, BatchNormalization\n",
    "from neuralnetlib.callbacks import EarlyStopping\n",
    "from neuralnetlib.losses import BinaryCrossentropy\n",
    "from neuralnetlib.model import Model\n",
    "from neuralnetlib.optimizers import Adam\n",
    "from neuralnetlib.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from neuralnetlib.utils import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading a dataset (in this case, Breast Cancer dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T00:42:53.058954800Z",
     "start_time": "2024-09-23T00:42:53.043955400Z"
    }
   },
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T00:42:53.073964800Z",
     "start_time": "2024-09-23T00:42:53.059955400Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T00:42:53.089469800Z",
     "start_time": "2024-09-23T00:42:53.074963800Z"
    }
   },
   "outputs": [],
   "source": [
    "input_neurons = x_train.shape[1:][0]  # Cancer dataset has 30 features\n",
    "num_hidden_layers = 5  # Number of hidden layers\n",
    "hidden_neurons = 100  # Number of neurons in each hidden layer\n",
    "output_neurons = 1  # Binary classification-regression\n",
    "\n",
    "model = Model()\n",
    "model.add(Input(input_neurons))\n",
    "model.add(Dense(hidden_neurons, weights_init='he', random_state=42))\n",
    "model.add(Activation(ReLU()))\n",
    "\n",
    "for _ in range(num_hidden_layers - 1):\n",
    "    model.add(Dense(hidden_neurons, weights_init='he', random_state=42))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(ReLU()))\n",
    "\n",
    "model.add(Dense(output_neurons, random_state=42))\n",
    "model.add(Activation(Sigmoid()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T00:42:53.120469500Z",
     "start_time": "2024-09-23T00:42:53.090469800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\n",
      "-------------------------------------------------\n",
      "Layer 1: Input(input_shape=(30,))\n",
      "Layer 2: Dense(units=100)\n",
      "Layer 3: Activation(ReLU)\n",
      "Layer 4: Dense(units=100)\n",
      "Layer 5: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "Layer 6: Activation(ReLU)\n",
      "Layer 7: Dense(units=100)\n",
      "Layer 8: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "Layer 9: Activation(ReLU)\n",
      "Layer 10: Dense(units=100)\n",
      "Layer 11: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "Layer 12: Activation(ReLU)\n",
      "Layer 13: Dense(units=100)\n",
      "Layer 14: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "Layer 15: Activation(ReLU)\n",
      "Layer 16: Dense(units=1)\n",
      "Layer 17: Activation(Sigmoid)\n",
      "-------------------------------------------------\n",
      "Loss function: BinaryCrossentropy\n",
      "Optimizer: Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss_function=BinaryCrossentropy(), optimizer=Adam(learning_rate=0.0001))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-23T00:42:53.106471400Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================] 100% Epoch 1/40 - loss: 0.6905 -  - 0.04s\n",
      "[==============================] 100% Epoch 2/40 - loss: 0.6785 -  - 0.08s\n",
      "[==============================] 100% Epoch 3/40 - loss: 0.6621 -  - 0.07s\n",
      "[==============================] 100% Epoch 4/40 - loss: 0.6432 -  - 0.06s\n",
      "[==============================] 100% Epoch 5/40 - loss: 0.6218 -  - 0.06s\n",
      "[==============================] 100% Epoch 6/40 - loss: 0.5978 -  - 0.07s\n",
      "[==============================] 100% Epoch 7/40 - loss: 0.5711 -  - 0.06s\n",
      "[==============================] 100% Epoch 8/40 - loss: 0.5420 -  - 0.07s\n",
      "[==============================] 100% Epoch 9/40 - loss: 0.5118 -  - 0.06s\n",
      "[==============================] 100% Epoch 10/40 - loss: 0.4814 -  - 0.07s\n",
      "[==============================] 100% Epoch 11/40 - loss: 0.4520 -  - 0.06s\n",
      "[==============================] 100% Epoch 12/40 - loss: 0.4250 -  - 0.07s\n",
      "[==============================] 100% Epoch 13/40 - loss: 0.4006 -  - 0.06s\n",
      "[==============================] 100% Epoch 14/40 - loss: 0.3795 -  - 0.08s\n",
      "[==============================] 100% Epoch 15/40 - loss: 0.3621 -  - 0.07s\n",
      "[==============================] 100% Epoch 16/40 - loss: 0.3485 -  - 0.07s\n",
      "[==============================] 100% Epoch 17/40 - loss: 0.3385 -  - 0.07s\n",
      "[==============================] 100% Epoch 18/40 - loss: 0.3314 -  - 0.07s\n",
      "[==============================] 100% Epoch 19/40 - loss: 0.3268 -  - 0.06s\n",
      "[==============================] 100% Epoch 20/40 - loss: 0.3241 -  - 0.07s\n",
      "[==============================] 100% Epoch 21/40 - loss: 0.3226 -  - 0.06s\n",
      "[==============================] 100% Epoch 22/40 - loss: 0.3219 -  - 0.07s\n",
      "[==============================] 100% Epoch 23/40 - loss: 0.3218 -  - 0.08s\n",
      "[==============================] 100% Epoch 24/40 - loss: 0.3230 -  - 0.06s\n",
      "[==============================] 100% Epoch 25/40 - loss: 0.3265 -  - 0.07s\n",
      "[==============================] 100% Epoch 26/40 - loss: 0.3318 -  - 0.07s\n",
      "Early stopping triggered after epoch 26\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=5, min_delta=0.001, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=40, batch_size=48, random_state=42, plot_decision_boundary=True,\n",
    "          callbacks=[early_stopping])  # Here, the early stopping will stop the training if the loss does not decrease\n",
    "\n",
    "# You could specify a different metric because loss is the default one\n",
    "\n",
    "# In this context, accuracy_score would have stopped at epoch 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-23T00:43:20.128062300Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "loss, _ = model.evaluate(x_test, y_test)\n",
    "print(f'Test loss: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-23T00:43:20.129061700Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Printing some metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-23T00:43:20.130062400Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
