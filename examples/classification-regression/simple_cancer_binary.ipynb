{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple cancer binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T02:20:23.241854300Z",
     "start_time": "2024-04-24T02:20:22.458579600Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from neuralnetlib.preprocessing import StandardScaler\n",
    "from neuralnetlib.activations import Sigmoid, ReLU\n",
    "from neuralnetlib.layers import Input, Activation, Dense, BatchNormalization\n",
    "from neuralnetlib.callbacks import EarlyStopping\n",
    "from neuralnetlib.losses import BinaryCrossentropy\n",
    "from neuralnetlib.model import Model\n",
    "from neuralnetlib.optimizers import Adam\n",
    "from neuralnetlib.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from neuralnetlib.utils import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading a dataset (in this case, Breast Cancer dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T02:20:23.253855300Z",
     "start_time": "2024-04-24T02:20:23.241854300Z"
    }
   },
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T02:20:23.268853900Z",
     "start_time": "2024-04-24T02:20:23.255855300Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T02:20:23.283862200Z",
     "start_time": "2024-04-24T02:20:23.260853Z"
    }
   },
   "outputs": [],
   "source": [
    "input_neurons = x_train.shape[1:][0]  # Cancer dataset has 30 features\n",
    "num_hidden_layers = 5  # Number of hidden layers\n",
    "hidden_neurons = 100  # Number of neurons in each hidden layer\n",
    "output_neurons = 1  # Binary classification-regression\n",
    "\n",
    "model = Model()\n",
    "model.add(Input(input_neurons))\n",
    "model.add(Dense(hidden_neurons, weights_init='he', random_state=42))\n",
    "model.add(Activation(ReLU()))\n",
    "\n",
    "for _ in range(num_hidden_layers - 1):\n",
    "    model.add(Dense(hidden_neurons, weights_init='he', random_state=42))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(ReLU()))\n",
    "\n",
    "model.add(Dense(output_neurons, random_state=42))\n",
    "model.add(Activation(Sigmoid()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T02:20:23.289863200Z",
     "start_time": "2024-04-24T02:20:23.273854700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\n",
      "-------------------------------------------------\n",
      "Layer 1: Input(input_shape=(30,))\n",
      "Layer 2: Dense(units=100)\n",
      "Layer 3: Activation(ReLU)\n",
      "Layer 4: Dense(units=100)\n",
      "Layer 5: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "Layer 6: Activation(ReLU)\n",
      "Layer 7: Dense(units=100)\n",
      "Layer 8: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "Layer 9: Activation(ReLU)\n",
      "Layer 10: Dense(units=100)\n",
      "Layer 11: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "Layer 12: Activation(ReLU)\n",
      "Layer 13: Dense(units=100)\n",
      "Layer 14: BatchNormalization(momentum=0.99, epsilon=1e-08)\n",
      "Layer 15: Activation(ReLU)\n",
      "Layer 16: Dense(units=1)\n",
      "Layer 17: Activation(Sigmoid)\n",
      "-------------------------------------------------\n",
      "Loss function: BinaryCrossentropy\n",
      "Optimizer: Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss_function=BinaryCrossentropy(), optimizer=Adam(learning_rate=0.0001))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T02:20:37.879588900Z",
     "start_time": "2024-04-24T02:20:23.289863200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================] 100% Epoch 1/1000 - loss: 0.6905 -  - 0.06s\n",
      "[==============================] 100% Epoch 2/1000 - loss: 0.6785 -  - 0.05s\n",
      "[==============================] 100% Epoch 3/1000 - loss: 0.6621 -  - 0.05s\n",
      "[==============================] 100% Epoch 4/1000 - loss: 0.6433 -  - 0.05s\n",
      "[==============================] 100% Epoch 5/1000 - loss: 0.6219 -  - 0.05s\n",
      "[==============================] 100% Epoch 6/1000 - loss: 0.5981 -  - 0.05s\n",
      "[==============================] 100% Epoch 7/1000 - loss: 0.5717 -  - 0.05s\n",
      "[==============================] 100% Epoch 8/1000 - loss: 0.5433 -  - 0.05s\n",
      "[==============================] 100% Epoch 9/1000 - loss: 0.5139 -  - 0.04s\n",
      "[==============================] 100% Epoch 10/1000 - loss: 0.4846 -  - 0.05s\n",
      "[==============================] 100% Epoch 11/1000 - loss: 0.4565 -  - 0.04s\n",
      "[==============================] 100% Epoch 12/1000 - loss: 0.4308 -  - 0.05s\n",
      "[==============================] 100% Epoch 13/1000 - loss: 0.4077 -  - 0.04s\n",
      "[==============================] 100% Epoch 14/1000 - loss: 0.3877 -  - 0.04s\n",
      "[==============================] 100% Epoch 15/1000 - loss: 0.3708 -  - 0.05s\n",
      "[==============================] 100% Epoch 16/1000 - loss: 0.3571 -  - 0.04s\n",
      "[==============================] 100% Epoch 17/1000 - loss: 0.3464 -  - 0.05s\n",
      "[==============================] 100% Epoch 18/1000 - loss: 0.3382 -  - 0.05s\n",
      "[==============================] 100% Epoch 19/1000 - loss: 0.3317 -  - 0.06s\n",
      "[==============================] 100% Epoch 20/1000 - loss: 0.3268 -  - 0.06s\n",
      "[==============================] 100% Epoch 21/1000 - loss: 0.3232 -  - 0.05s\n",
      "[==============================] 100% Epoch 22/1000 - loss: 0.3206 -  - 0.05s\n",
      "[==============================] 100% Epoch 23/1000 - loss: 0.3186 -  - 0.05s\n",
      "[==============================] 100% Epoch 24/1000 - loss: 0.3171 -  - 0.05s\n",
      "[==============================] 100% Epoch 25/1000 - loss: 0.3160 -  - 0.05s\n",
      "[==============================] 100% Epoch 26/1000 - loss: 0.3158 -  - 0.05s\n",
      "[==============================] 100% Epoch 27/1000 - loss: 0.3167 -  - 0.05s\n",
      "[==============================] 100% Epoch 28/1000 - loss: 0.3190 -  - 0.05s\n",
      "[==============================] 100% Epoch 29/1000 - loss: 0.3217 -  - 0.05s\n",
      "[==============================] 100% Epoch 30/1000 - loss: 0.3249 -  - 0.05s\n",
      "Early stopping after 30 epochs.\n",
      "[==============================] 100% Epoch 31/1000 - loss: 0.3284 -  - 0.05s\n",
      "Early stopping after 31 epochs.\n",
      "[==============================] 100% Epoch 32/1000 - loss: 0.3320 -  - 0.05s\n",
      "Early stopping after 32 epochs.\n",
      "[==============================] 100% Epoch 33/1000 - loss: 0.3354 -  - 0.05s\n",
      "Early stopping after 33 epochs.\n",
      "[==============================] 100% Epoch 34/1000 - loss: 0.3386 -  - 0.05s\n",
      "Early stopping after 34 epochs.\n",
      "[==============================] 100% Epoch 35/1000 - loss: 0.3418 -  - 0.06s\n",
      "Early stopping after 35 epochs.\n",
      "[==============================] 100% Epoch 36/1000 - loss: 0.3452 -  - 0.05s\n",
      "Early stopping after 36 epochs.\n",
      "[==============================] 100% Epoch 37/1000 - loss: 0.3486 -  - 0.05s\n",
      "Early stopping after 37 epochs.\n",
      "[==============================] 100% Epoch 38/1000 - loss: 0.3520 -  - 0.05s\n",
      "Early stopping after 38 epochs.\n",
      "[==============================] 100% Epoch 39/1000 - loss: 0.3556 -  - 0.05s\n",
      "Early stopping after 39 epochs.\n",
      "[==============================] 100% Epoch 40/1000 - loss: 0.3593 -  - 0.05s\n",
      "Early stopping after 40 epochs.\n",
      "[==============================] 100% Epoch 41/1000 - loss: 0.3631 -  - 0.05s\n",
      "Early stopping after 41 epochs.\n",
      "[==============================] 100% Epoch 42/1000 - loss: 0.3669 -  - 0.05s\n",
      "Early stopping after 42 epochs.\n",
      "[==============================] 100% Epoch 43/1000 - loss: 0.3706 -  - 0.06s\n",
      "Early stopping after 43 epochs.\n",
      "[==============================] 100% Epoch 44/1000 - loss: 0.3740 -  - 0.04s\n",
      "Early stopping after 44 epochs.\n",
      "[==============================] 100% Epoch 45/1000 - loss: 0.3772 -  - 0.05s\n",
      "Early stopping after 45 epochs.\n",
      "[==============================] 100% Epoch 46/1000 - loss: 0.3801 -  - 0.04s\n",
      "Early stopping after 46 epochs.\n",
      "[==============================] 100% Epoch 47/1000 - loss: 0.3827 -  - 0.04s\n",
      "Early stopping after 47 epochs.\n",
      "[==============================] 100% Epoch 48/1000 - loss: 0.3849 -  - 0.04s\n",
      "Early stopping after 48 epochs.\n",
      "[==============================] 100% Epoch 49/1000 - loss: 0.3868 -  - 0.04s\n",
      "Early stopping after 49 epochs.\n",
      "[==============================] 100% Epoch 50/1000 - loss: 0.3885 -  - 0.04s\n",
      "Early stopping after 50 epochs.\n",
      "[==============================] 100% Epoch 51/1000 - loss: 0.3901 -  - 0.04s\n",
      "Early stopping after 51 epochs.\n",
      "[==============================] 100% Epoch 52/1000 - loss: 0.3917 -  - 0.05s\n",
      "Early stopping after 52 epochs.\n",
      "[==============================] 100% Epoch 53/1000 - loss: 0.3935 -  - 0.04s\n",
      "Early stopping after 53 epochs.\n",
      "[==============================] 100% Epoch 54/1000 - loss: 0.3954 -  - 0.04s\n",
      "Early stopping after 54 epochs.\n",
      "[==============================] 100% Epoch 55/1000 - loss: 0.3976 -  - 0.04s\n",
      "Early stopping after 55 epochs.\n",
      "[==============================] 100% Epoch 56/1000 - loss: 0.3999 -  - 0.04s\n",
      "Early stopping after 56 epochs.\n",
      "[==============================] 100% Epoch 57/1000 - loss: 0.4022 -  - 0.04s\n",
      "Early stopping after 57 epochs.\n",
      "[==============================] 100% Epoch 58/1000 - loss: 0.4047 -  - 0.04s\n",
      "Early stopping after 58 epochs.\n",
      "[==============================] 100% Epoch 59/1000 - loss: 0.4072 -  - 0.04s\n",
      "Early stopping after 59 epochs.\n",
      "[==============================] 100% Epoch 60/1000 - loss: 0.4097 -  - 0.04s\n",
      "Early stopping after 60 epochs.\n",
      "[==============================] 100% Epoch 61/1000 - loss: 0.4122 -  - 0.05s\n",
      "Early stopping after 61 epochs.\n",
      "[==============================] 100% Epoch 62/1000 - loss: 0.4147 -  - 0.05s\n",
      "Early stopping after 62 epochs.\n",
      "[==============================] 100% Epoch 63/1000 - loss: 0.4169 -  - 0.06s\n",
      "Early stopping after 63 epochs.\n",
      "[==============================] 100% Epoch 64/1000 - loss: 0.4188 -  - 0.05s\n",
      "Early stopping after 64 epochs.\n",
      "[==============================] 100% Epoch 65/1000 - loss: 0.4204 -  - 0.04s\n",
      "Early stopping after 65 epochs.\n",
      "[==============================] 100% Epoch 66/1000 - loss: 0.4218 -  - 0.04s\n",
      "Early stopping after 66 epochs.\n",
      "[==============================] 100% Epoch 67/1000 - loss: 0.4232 -  - 0.04s\n",
      "Early stopping after 67 epochs.\n",
      "[==============================] 100% Epoch 68/1000 - loss: 0.4243 -  - 0.05s\n",
      "Early stopping after 68 epochs.\n",
      "[==============================] 100% Epoch 69/1000 - loss: 0.4253 -  - 0.05s\n",
      "Early stopping after 69 epochs.\n",
      "[==============================] 100% Epoch 70/1000 - loss: 0.4261 -  - 0.04s\n",
      "Early stopping after 70 epochs.\n",
      "[==============================] 100% Epoch 71/1000 - loss: 0.4269 -  - 0.05s\n",
      "Early stopping after 71 epochs.\n",
      "[==============================] 100% Epoch 72/1000 - loss: 0.4275 -  - 0.05s\n",
      "Early stopping after 72 epochs.\n",
      "[==============================] 100% Epoch 73/1000 - loss: 0.4281 -  - 0.04s\n",
      "Early stopping after 73 epochs.\n",
      "[==============================] 100% Epoch 74/1000 - loss: 0.4287 -  - 0.05s\n",
      "Early stopping after 74 epochs.\n",
      "[==============================] 100% Epoch 75/1000 - loss: 0.4292 -  - 0.05s\n",
      "Early stopping after 75 epochs.\n",
      "[==============================] 100% Epoch 76/1000 - loss: 0.4297 -  - 0.05s\n",
      "Early stopping after 76 epochs.\n",
      "[==============================] 100% Epoch 77/1000 - loss: 0.4302 -  - 0.05s\n",
      "Early stopping after 77 epochs.\n",
      "[==============================] 100% Epoch 78/1000 - loss: 0.4307 -  - 0.05s\n",
      "Early stopping after 78 epochs.\n",
      "[==============================] 100% Epoch 79/1000 - loss: 0.4313 -  - 0.05s\n",
      "Early stopping after 79 epochs.\n",
      "[==============================] 100% Epoch 80/1000 - loss: 0.4318 -  - 0.06s\n",
      "Early stopping after 80 epochs.\n",
      "[==============================] 100% Epoch 81/1000 - loss: 0.4322 -  - 0.06s\n",
      "Early stopping after 81 epochs.\n",
      "[==============================] 100% Epoch 82/1000 - loss: 0.4326 -  - 0.06s\n",
      "Early stopping after 82 epochs.\n",
      "[==============================] 100% Epoch 83/1000 - loss: 0.4331 -  - 0.06s\n",
      "Early stopping after 83 epochs.\n",
      "[==============================] 100% Epoch 84/1000 - loss: 0.4336 -  - 0.05s\n",
      "Early stopping after 84 epochs.\n",
      "[==============================] 100% Epoch 85/1000 - loss: 0.4344 -  - 0.05s\n",
      "Early stopping after 85 epochs.\n",
      "[==============================] 100% Epoch 86/1000 - loss: 0.4352 -  - 0.05s\n",
      "Early stopping after 86 epochs.\n",
      "[==============================] 100% Epoch 87/1000 - loss: 0.4359 -  - 0.05s\n",
      "Early stopping after 87 epochs.\n",
      "[==============================] 100% Epoch 88/1000 - loss: 0.4366 -  - 0.05s\n",
      "Early stopping after 88 epochs.\n",
      "[==============================] 100% Epoch 89/1000 - loss: 0.4371 -  - 0.04s\n",
      "Early stopping after 89 epochs.\n",
      "[==============================] 100% Epoch 90/1000 - loss: 0.4376 -  - 0.05s\n",
      "Early stopping after 90 epochs.\n",
      "[==============================] 100% Epoch 91/1000 - loss: 0.4380 -  - 0.05s\n",
      "Early stopping after 91 epochs.\n",
      "[==============================] 100% Epoch 92/1000 - loss: 0.4383 -  - 0.05s\n",
      "Early stopping after 92 epochs.\n",
      "[==============================] 100% Epoch 93/1000 - loss: 0.4387 -  - 0.05s\n",
      "Early stopping after 93 epochs.\n",
      "[==============================] 100% Epoch 94/1000 - loss: 0.4391 -  - 0.05s\n",
      "Early stopping after 94 epochs.\n",
      "[==============================] 100% Epoch 95/1000 - loss: 0.4395 -  - 0.04s\n",
      "Early stopping after 95 epochs.\n",
      "[==============================] 100% Epoch 96/1000 - loss: 0.4397 -  - 0.05s\n",
      "Early stopping after 96 epochs.\n",
      "[==============================] 100% Epoch 97/1000 - loss: 0.4399 -  - 0.04s\n",
      "Early stopping after 97 epochs.\n",
      "[==============================] 100% Epoch 98/1000 - loss: 0.4400 -  - 0.04s\n",
      "Early stopping after 98 epochs.\n",
      "[==============================] 100% Epoch 99/1000 - loss: 0.4401 -  - 0.04s\n",
      "Early stopping after 99 epochs.\n",
      "[==============================] 100% Epoch 100/1000 - loss: 0.4402 -  - 0.05s\n",
      "Early stopping after 100 epochs.\n",
      "[==============================] 100% Epoch 101/1000 - loss: 0.4403 -  - 0.04s\n",
      "Early stopping after 101 epochs.\n",
      "[==============================] 100% Epoch 102/1000 - loss: 0.4405 -  - 0.05s\n",
      "Early stopping after 102 epochs.\n",
      "[==============================] 100% Epoch 103/1000 - loss: 0.4407 -  - 0.05s\n",
      "Early stopping after 103 epochs.\n",
      "[==============================] 100% Epoch 104/1000 - loss: 0.4409 -  - 0.05s\n",
      "Early stopping after 104 epochs.\n",
      "[==============================] 100% Epoch 105/1000 - loss: 0.4411 -  - 0.04s\n",
      "Early stopping after 105 epochs.\n",
      "[==============================] 100% Epoch 106/1000 - loss: 0.4412 -  - 0.05s\n",
      "Early stopping after 106 epochs.\n",
      "[==============================] 100% Epoch 107/1000 - loss: 0.4414 -  - 0.05s\n",
      "Early stopping after 107 epochs.\n",
      "[==============================] 100% Epoch 108/1000 - loss: 0.4416 -  - 0.04s\n",
      "Early stopping after 108 epochs.\n",
      "[==============================] 100% Epoch 109/1000 - loss: 0.4418 -  - 0.04s\n",
      "Early stopping after 109 epochs.\n",
      "[==============================] 100% Epoch 110/1000 - loss: 0.4420 -  - 0.04s\n",
      "Early stopping after 110 epochs.\n",
      "[==============================] 100% Epoch 111/1000 - loss: 0.4422 -  - 0.04s\n",
      "Early stopping after 111 epochs.\n",
      "[==============================] 100% Epoch 112/1000 - loss: 0.4425 -  - 0.04s\n",
      "Early stopping after 112 epochs.\n",
      "[==============================] 100% Epoch 113/1000 - loss: 0.4427 -  - 0.04s\n",
      "Early stopping after 113 epochs.\n",
      "[==============================] 100% Epoch 114/1000 - loss: 0.4430 -  - 0.05s\n",
      "Early stopping after 114 epochs.\n",
      "[==============================] 100% Epoch 115/1000 - loss: 0.4433 -  - 0.04s\n",
      "Early stopping after 115 epochs.\n",
      "[==============================] 100% Epoch 116/1000 - loss: 0.4435 -  - 0.04s\n",
      "Early stopping after 116 epochs.\n",
      "[==============================] 100% Epoch 117/1000 - loss: 0.4438 -  - 0.08s\n",
      "Early stopping after 117 epochs.\n",
      "[==============================] 100% Epoch 118/1000 - loss: 0.4441 -  - 0.05s\n",
      "Early stopping after 118 epochs.\n",
      "[==============================] 100% Epoch 119/1000 - loss: 0.4444 -  - 0.05s\n",
      "Early stopping after 119 epochs.\n",
      "[==============================] 100% Epoch 120/1000 - loss: 0.4447 -  - 0.05s\n",
      "Early stopping after 120 epochs.\n",
      "[==============================] 100% Epoch 121/1000 - loss: 0.4450 -  - 0.05s\n",
      "Early stopping after 121 epochs.\n",
      "[==============================] 100% Epoch 122/1000 - loss: 0.4454 -  - 0.05s\n",
      "Early stopping after 122 epochs.\n",
      "[==============================] 100% Epoch 123/1000 - loss: 0.4458 -  - 0.04s\n",
      "Early stopping after 123 epochs.\n",
      "[==============================] 100% Epoch 124/1000 - loss: 0.4461 -  - 0.05s\n",
      "Early stopping after 124 epochs.\n",
      "[==============================] 100% Epoch 125/1000 - loss: 0.4465 -  - 0.05s\n",
      "Early stopping after 125 epochs.\n",
      "[==============================] 100% Epoch 126/1000 - loss: 0.4469 -  - 0.06s\n",
      "Early stopping after 126 epochs.\n",
      "[==============================] 100% Epoch 127/1000 - loss: 0.4473 -  - 0.06s\n",
      "Early stopping after 127 epochs.\n",
      "[==============================] 100% Epoch 128/1000 - loss: 0.4478 -  - 0.05s\n",
      "Early stopping after 128 epochs.\n",
      "[==============================] 100% Epoch 129/1000 - loss: 0.4482 -  - 0.05s\n",
      "Early stopping after 129 epochs.\n",
      "[==============================] 100% Epoch 130/1000 - loss: 0.4487 -  - 0.05s\n",
      "Early stopping after 130 epochs.\n",
      "[==============================] 100% Epoch 131/1000 - loss: 0.4491 -  - 0.05s\n",
      "Early stopping after 131 epochs.\n",
      "[==============================] 100% Epoch 132/1000 - loss: 0.4496 -  - 0.04s\n",
      "Early stopping after 132 epochs.\n",
      "[==============================] 100% Epoch 133/1000 - loss: 0.4501 -  - 0.05s\n",
      "Early stopping after 133 epochs.\n",
      "[==============================] 100% Epoch 134/1000 - loss: 0.4505 -  - 0.05s\n",
      "Early stopping after 134 epochs.\n",
      "[==============================] 100% Epoch 135/1000 - loss: 0.4509 -  - 0.05s\n",
      "Early stopping after 135 epochs.\n",
      "[==============================] 100% Epoch 136/1000 - loss: 0.4514 -  - 0.05s\n",
      "Early stopping after 136 epochs.\n",
      "[==============================] 100% Epoch 137/1000 - loss: 0.4518 -  - 0.04s\n",
      "Early stopping after 137 epochs.\n",
      "[==============================] 100% Epoch 138/1000 - loss: 0.4522 -  - 0.04s\n",
      "Early stopping after 138 epochs.\n",
      "[==============================] 100% Epoch 139/1000 - loss: 0.4526 -  - 0.04s\n",
      "Early stopping after 139 epochs.\n",
      "[==============================] 100% Epoch 140/1000 - loss: 0.4530 -  - 0.05s\n",
      "Early stopping after 140 epochs.\n",
      "[==============================] 100% Epoch 141/1000 - loss: 0.4534 -  - 0.04s\n",
      "Early stopping after 141 epochs.\n",
      "[==============================] 100% Epoch 142/1000 - loss: 0.4538 -  - 0.05s\n",
      "Early stopping after 142 epochs.\n",
      "[==============================] 100% Epoch 143/1000 - loss: 0.4542 -  - 0.04s\n",
      "Early stopping after 143 epochs.\n",
      "[==============================] 100% Epoch 144/1000 - loss: 0.4545 -  - 0.04s\n",
      "Early stopping after 144 epochs.\n",
      "[==============================] 100% Epoch 145/1000 - loss: 0.4549 -  - 0.05s\n",
      "Early stopping after 145 epochs.\n",
      "[==============================] 100% Epoch 146/1000 - loss: 0.4552 -  - 0.05s\n",
      "Early stopping after 146 epochs.\n",
      "[==============================] 100% Epoch 147/1000 - loss: 0.4555 -  - 0.05s\n",
      "Early stopping after 147 epochs.\n",
      "[==============================] 100% Epoch 148/1000 - loss: 0.4557 -  - 0.04s\n",
      "Early stopping after 148 epochs.\n",
      "[==============================] 100% Epoch 149/1000 - loss: 0.4560 -  - 0.05s\n",
      "Early stopping after 149 epochs.\n",
      "[==============================] 100% Epoch 150/1000 - loss: 0.4562 -  - 0.04s\n",
      "Early stopping after 150 epochs.\n",
      "[==============================] 100% Epoch 151/1000 - loss: 0.4565 -  - 0.04s\n",
      "Early stopping after 151 epochs.\n",
      "[==============================] 100% Epoch 152/1000 - loss: 0.4568 -  - 0.04s\n",
      "Early stopping after 152 epochs.\n",
      "[==============================] 100% Epoch 153/1000 - loss: 0.4570 -  - 0.04s\n",
      "Early stopping after 153 epochs.\n",
      "[==============================] 100% Epoch 154/1000 - loss: 0.4573 -  - 0.04s\n",
      "Early stopping after 154 epochs.\n",
      "[==============================] 100% Epoch 155/1000 - loss: 0.4576 -  - 0.04s\n",
      "Early stopping after 155 epochs.\n",
      "[==============================] 100% Epoch 156/1000 - loss: 0.4579 -  - 0.04s\n",
      "Early stopping after 156 epochs.\n",
      "[==============================] 100% Epoch 157/1000 - loss: 0.4582 -  - 0.04s\n",
      "Early stopping after 157 epochs.\n",
      "[==============================] 100% Epoch 158/1000 - loss: 0.4585 -  - 0.04s\n",
      "Early stopping after 158 epochs.\n",
      "[==============================] 100% Epoch 159/1000 - loss: 0.4588 -  - 0.04s\n",
      "Early stopping after 159 epochs.\n",
      "[==============================] 100% Epoch 160/1000 - loss: 0.4590 -  - 0.05s\n",
      "Early stopping after 160 epochs.\n",
      "[==============================] 100% Epoch 161/1000 - loss: 0.4593 -  - 0.04s\n",
      "Early stopping after 161 epochs.\n",
      "[==============================] 100% Epoch 162/1000 - loss: 0.4596 -  - 0.04s\n",
      "Early stopping after 162 epochs.\n",
      "[==============================] 100% Epoch 163/1000 - loss: 0.4598 -  - 0.04s\n",
      "Early stopping after 163 epochs.\n",
      "[==============================] 100% Epoch 164/1000 - loss: 0.4601 -  - 0.04s\n",
      "Early stopping after 164 epochs.\n",
      "[==============================] 100% Epoch 165/1000 - loss: 0.4603 -  - 0.04s\n",
      "Early stopping after 165 epochs.\n",
      "[==============================] 100% Epoch 166/1000 - loss: 0.4606 -  - 0.04s\n",
      "Early stopping after 166 epochs.\n",
      "[==============================] 100% Epoch 167/1000 - loss: 0.4607 -  - 0.04s\n",
      "Early stopping after 167 epochs.\n",
      "[==============================] 100% Epoch 168/1000 - loss: 0.4610 -  - 0.05s\n",
      "Early stopping after 168 epochs.\n",
      "[==============================] 100% Epoch 169/1000 - loss: 0.4612 -  - 0.05s\n",
      "Early stopping after 169 epochs.\n",
      "[==============================] 100% Epoch 170/1000 - loss: 0.4614 -  - 0.05s\n",
      "Early stopping after 170 epochs.\n",
      "[==============================] 100% Epoch 171/1000 - loss: 0.4616 -  - 0.05s\n",
      "Early stopping after 171 epochs.\n",
      "[==============================] 100% Epoch 172/1000 - loss: 0.4618 -  - 0.05s\n",
      "Early stopping after 172 epochs.\n",
      "[==============================] 100% Epoch 173/1000 - loss: 0.4620 -  - 0.05s\n",
      "Early stopping after 173 epochs.\n",
      "[==============================] 100% Epoch 174/1000 - loss: 0.4621 -  - 0.05s\n",
      "Early stopping after 174 epochs.\n",
      "[==============================] 100% Epoch 175/1000 - loss: 0.4623 -  - 0.05s\n",
      "Early stopping after 175 epochs.\n",
      "[==============================] 100% Epoch 176/1000 - loss: 0.4625 -  - 0.06s\n",
      "Early stopping after 176 epochs.\n",
      "[==============================] 100% Epoch 177/1000 - loss: 0.4626 -  - 0.06s\n",
      "Early stopping after 177 epochs.\n",
      "[==============================] 100% Epoch 178/1000 - loss: 0.4628 -  - 0.06s\n",
      "Early stopping after 178 epochs.\n",
      "[==============================] 100% Epoch 179/1000 - loss: 0.4629 -  - 0.06s\n",
      "Early stopping after 179 epochs.\n",
      "[==============================] 100% Epoch 180/1000 - loss: 0.4630 -  - 0.06s\n",
      "Early stopping after 180 epochs.\n",
      "[==============================] 100% Epoch 181/1000 - loss: 0.4631 -  - 0.05s\n",
      "Early stopping after 181 epochs.\n",
      "[==============================] 100% Epoch 182/1000 - loss: 0.4632 -  - 0.05s\n",
      "Early stopping after 182 epochs.\n",
      "[==============================] 100% Epoch 183/1000 - loss: 0.4633 -  - 0.05s\n",
      "Early stopping after 183 epochs.\n",
      "[==============================] 100% Epoch 184/1000 - loss: 0.4634 -  - 0.05s\n",
      "Early stopping after 184 epochs.\n",
      "[==============================] 100% Epoch 185/1000 - loss: 0.4635 -  - 0.06s\n",
      "Early stopping after 185 epochs.\n",
      "[==============================] 100% Epoch 186/1000 - loss: 0.4636 -  - 0.05s\n",
      "Early stopping after 186 epochs.\n",
      "[==============================] 100% Epoch 187/1000 - loss: 0.4637 -  - 0.05s\n",
      "Early stopping after 187 epochs.\n",
      "[==============================] 100% Epoch 188/1000 - loss: 0.4638 -  - 0.05s\n",
      "Early stopping after 188 epochs.\n",
      "[==============================] 100% Epoch 189/1000 - loss: 0.4639 -  - 0.04s\n",
      "Early stopping after 189 epochs.\n",
      "[==============================] 100% Epoch 190/1000 - loss: 0.4640 -  - 0.05s\n",
      "Early stopping after 190 epochs.\n",
      "[==============================] 100% Epoch 191/1000 - loss: 0.4641 -  - 0.05s\n",
      "Early stopping after 191 epochs.\n",
      "[==============================] 100% Epoch 192/1000 - loss: 0.4642 -  - 0.05s\n",
      "Early stopping after 192 epochs.\n",
      "[==============================] 100% Epoch 193/1000 - loss: 0.4643 -  - 0.05s\n",
      "Early stopping after 193 epochs.\n",
      "[==============================] 100% Epoch 194/1000 - loss: 0.4644 -  - 0.05s\n",
      "Early stopping after 194 epochs.\n",
      "[==============================] 100% Epoch 195/1000 - loss: 0.4644 -  - 0.05s\n",
      "Early stopping after 195 epochs.\n",
      "[==============================] 100% Epoch 196/1000 - loss: 0.4645 -  - 0.04s\n",
      "Early stopping after 196 epochs.\n",
      "[==============================] 100% Epoch 197/1000 - loss: 0.4646 -  - 0.04s\n",
      "Early stopping after 197 epochs.\n",
      "[==============================] 100% Epoch 198/1000 - loss: 0.4647 -  - 0.04s\n",
      "Early stopping after 198 epochs.\n",
      "[==============================] 100% Epoch 199/1000 - loss: 0.4647 -  - 0.04s\n",
      "Early stopping after 199 epochs.\n",
      "[==============================] 100% Epoch 200/1000 - loss: 0.4648 -  - 0.05s\n",
      "Early stopping after 200 epochs.\n",
      "[==============================] 100% Epoch 201/1000 - loss: 0.4649 -  - 0.04s\n",
      "Early stopping after 201 epochs.\n",
      "[==============================] 100% Epoch 202/1000 - loss: 0.4650 -  - 0.04s\n",
      "Early stopping after 202 epochs.\n",
      "[==============================] 100% Epoch 203/1000 - loss: 0.4650 -  - 0.04s\n",
      "Early stopping after 203 epochs.\n",
      "[==============================] 100% Epoch 204/1000 - loss: 0.4651 -  - 0.04s\n",
      "Early stopping after 204 epochs.\n",
      "[==============================] 100% Epoch 205/1000 - loss: 0.4652 -  - 0.04s\n",
      "Early stopping after 205 epochs.\n",
      "[==============================] 100% Epoch 206/1000 - loss: 0.4653 -  - 0.04s\n",
      "Early stopping after 206 epochs.\n",
      "[==============================] 100% Epoch 207/1000 - loss: 0.4654 -  - 0.04s\n",
      "Early stopping after 207 epochs.\n",
      "[==============================] 100% Epoch 208/1000 - loss: 0.4655 -  - 0.04s\n",
      "Early stopping after 208 epochs.\n",
      "[==============================] 100% Epoch 209/1000 - loss: 0.4656 -  - 0.04s\n",
      "Early stopping after 209 epochs.\n",
      "[==============================] 100% Epoch 210/1000 - loss: 0.4657 -  - 0.04s\n",
      "Early stopping after 210 epochs.\n",
      "[==============================] 100% Epoch 211/1000 - loss: 0.4658 -  - 0.04s\n",
      "Early stopping after 211 epochs.\n",
      "[==============================] 100% Epoch 212/1000 - loss: 0.4659 -  - 0.04s\n",
      "Early stopping after 212 epochs.\n",
      "[==============================] 100% Epoch 213/1000 - loss: 0.4660 -  - 0.05s\n",
      "Early stopping after 213 epochs.\n",
      "[==============================] 100% Epoch 214/1000 - loss: 0.4661 -  - 0.04s\n",
      "Early stopping after 214 epochs.\n",
      "[==============================] 100% Epoch 215/1000 - loss: 0.4662 -  - 0.04s\n",
      "Early stopping after 215 epochs.\n",
      "[==============================] 100% Epoch 216/1000 - loss: 0.4663 -  - 0.04s\n",
      "Early stopping after 216 epochs.\n",
      "[==============================] 100% Epoch 217/1000 - loss: 0.4664 -  - 0.05s\n",
      "Early stopping after 217 epochs.\n",
      "[==============================] 100% Epoch 218/1000 - loss: 0.4665 -  - 0.05s\n",
      "Early stopping after 218 epochs.\n",
      "[==============================] 100% Epoch 219/1000 - loss: 0.4666 -  - 0.04s\n",
      "Early stopping after 219 epochs.\n",
      "[==============================] 100% Epoch 220/1000 - loss: 0.4667 -  - 0.05s\n",
      "Early stopping after 220 epochs.\n",
      "[==============================] 100% Epoch 221/1000 - loss: 0.4667 -  - 0.05s\n",
      "Early stopping after 221 epochs.\n",
      "[==============================] 100% Epoch 222/1000 - loss: 0.4668 -  - 0.05s\n",
      "Early stopping after 222 epochs.\n",
      "[==============================] 100% Epoch 223/1000 - loss: 0.4669 -  - 0.05s\n",
      "Early stopping after 223 epochs.\n",
      "[==============================] 100% Epoch 224/1000 - loss: 0.4670 -  - 0.05s\n",
      "Early stopping after 224 epochs.\n",
      "[==============================] 100% Epoch 225/1000 - loss: 0.4670 -  - 0.05s\n",
      "Early stopping after 225 epochs.\n",
      "[==============================] 100% Epoch 226/1000 - loss: 0.4671 -  - 0.05s\n",
      "Early stopping after 226 epochs.\n",
      "[==============================] 100% Epoch 227/1000 - loss: 0.4672 -  - 0.06s\n",
      "Early stopping after 227 epochs.\n",
      "[==============================] 100% Epoch 228/1000 - loss: 0.4673 -  - 0.06s\n",
      "Early stopping after 228 epochs.\n",
      "[==============================] 100% Epoch 229/1000 - loss: 0.4674 -  - 0.05s\n",
      "Early stopping after 229 epochs.\n",
      "[==============================] 100% Epoch 230/1000 - loss: 0.4675 -  - 0.05s\n",
      "Early stopping after 230 epochs.\n",
      "[==============================] 100% Epoch 231/1000 - loss: 0.4675 -  - 0.05s\n",
      "Early stopping after 231 epochs.\n",
      "[==============================] 100% Epoch 232/1000 - loss: 0.4676 -  - 0.06s\n",
      "Early stopping after 232 epochs.\n",
      "[==============================] 100% Epoch 233/1000 - loss: 0.4677 -  - 0.05s\n",
      "Early stopping after 233 epochs.\n",
      "[==============================] 100% Epoch 234/1000 - loss: 0.4678 -  - 0.05s\n",
      "Early stopping after 234 epochs.\n",
      "[==============================] 100% Epoch 235/1000 - loss: 0.4679 -  - 0.04s\n",
      "Early stopping after 235 epochs.\n",
      "[==============================] 100% Epoch 236/1000 - loss: 0.4679 -  - 0.04s\n",
      "Early stopping after 236 epochs.\n",
      "[==============================] 100% Epoch 237/1000 - loss: 0.4680 -  - 0.04s\n",
      "Early stopping after 237 epochs.\n",
      "[==============================] 100% Epoch 238/1000 - loss: 0.4680 -  - 0.04s\n",
      "Early stopping after 238 epochs.\n",
      "[==============================] 100% Epoch 239/1000 - loss: 0.4681 -  - 0.05s\n",
      "Early stopping after 239 epochs.\n",
      "[==============================] 100% Epoch 240/1000 - loss: 0.4682 -  - 0.04s\n",
      "Early stopping after 240 epochs.\n",
      "[==============================] 100% Epoch 241/1000 - loss: 0.4683 -  - 0.04s\n",
      "Early stopping after 241 epochs.\n",
      "[==============================] 100% Epoch 242/1000 - loss: 0.4683 -  - 0.04s\n",
      "Early stopping after 242 epochs.\n",
      "[==============================] 100% Epoch 243/1000 - loss: 0.4684 -  - 0.04s\n",
      "Early stopping after 243 epochs.\n",
      "[==============================] 100% Epoch 244/1000 - loss: 0.4685 -  - 0.04s\n",
      "Early stopping after 244 epochs.\n",
      "[==============================] 100% Epoch 245/1000 - loss: 0.4686 -  - 0.05s\n",
      "Early stopping after 245 epochs.\n",
      "[==============================] 100% Epoch 246/1000 - loss: 0.4687 -  - 0.04s\n",
      "Early stopping after 246 epochs.\n",
      "[==============================] 100% Epoch 247/1000 - loss: 0.4688 -  - 0.07s\n",
      "Early stopping after 247 epochs.\n",
      "[==============================] 100% Epoch 248/1000 - loss: 0.4689 -  - 0.04s\n",
      "Early stopping after 248 epochs.\n",
      "[==============================] 100% Epoch 249/1000 - loss: 0.4690 -  - 0.04s\n",
      "Early stopping after 249 epochs.\n",
      "[==============================] 100% Epoch 250/1000 - loss: 0.4691 -  - 0.04s\n",
      "Early stopping after 250 epochs.\n",
      "[==============================] 100% Epoch 251/1000 - loss: 0.4691 -  - 0.04s\n",
      "Early stopping after 251 epochs.\n",
      "[==============================] 100% Epoch 252/1000 - loss: 0.4692 -  - 0.04s\n",
      "Early stopping after 252 epochs.\n",
      "[==============================] 100% Epoch 253/1000 - loss: 0.4693 -  - 0.04s\n",
      "Early stopping after 253 epochs.\n",
      "[==============================] 100% Epoch 254/1000 - loss: 0.4694 -  - 0.04s\n",
      "Early stopping after 254 epochs.\n",
      "[==============================] 100% Epoch 255/1000 - loss: 0.4695 -  - 0.05s\n",
      "Early stopping after 255 epochs.\n",
      "[==============================] 100% Epoch 256/1000 - loss: 0.4696 -  - 0.04s\n",
      "Early stopping after 256 epochs.\n",
      "[==============================] 100% Epoch 257/1000 - loss: 0.4697 -  - 0.04s\n",
      "Early stopping after 257 epochs.\n",
      "[==============================] 100% Epoch 258/1000 - loss: 0.4698 -  - 0.04s\n",
      "Early stopping after 258 epochs.\n",
      "[==============================] 100% Epoch 259/1000 - loss: 0.4698 -  - 0.04s\n",
      "Early stopping after 259 epochs.\n",
      "[==============================] 100% Epoch 260/1000 - loss: 0.4699 -  - 0.04s\n",
      "Early stopping after 260 epochs.\n",
      "[==============================] 100% Epoch 261/1000 - loss: 0.4700 -  - 0.04s\n",
      "Early stopping after 261 epochs.\n",
      "[==============================] 100% Epoch 262/1000 - loss: 0.4701 -  - 0.04s\n",
      "Early stopping after 262 epochs.\n",
      "[==============================] 100% Epoch 263/1000 - loss: 0.4702 -  - 0.04s\n",
      "Early stopping after 263 epochs.\n",
      "[==============================] 100% Epoch 264/1000 - loss: 0.4702 -  - 0.04s\n",
      "Early stopping after 264 epochs.\n",
      "[==============================] 100% Epoch 265/1000 - loss: 0.4703 -  - 0.04s\n",
      "Early stopping after 265 epochs.\n",
      "[==============================] 100% Epoch 266/1000 - loss: 0.4704 -  - 0.04s\n",
      "Early stopping after 266 epochs.\n",
      "[==============================] 100% Epoch 267/1000 - loss: 0.4704 -  - 0.05s\n",
      "Early stopping after 267 epochs.\n",
      "[==============================] 100% Epoch 268/1000 - loss: 0.4705 -  - 0.04s\n",
      "Early stopping after 268 epochs.\n",
      "[==============================] 100% Epoch 269/1000 - loss: 0.4706 -  - 0.05s\n",
      "Early stopping after 269 epochs.\n",
      "[==============================] 100% Epoch 270/1000 - loss: 0.4706 -  - 0.05s\n",
      "Early stopping after 270 epochs.\n",
      "[==============================] 100% Epoch 271/1000 - loss: 0.4707 -  - 0.05s\n",
      "Early stopping after 271 epochs.\n",
      "[==============================] 100% Epoch 272/1000 - loss: 0.4708 -  - 0.05s\n",
      "Early stopping after 272 epochs.\n",
      "[==============================] 100% Epoch 273/1000 - loss: 0.4708 -  - 0.05s\n",
      "Early stopping after 273 epochs.\n",
      "[==============================] 100% Epoch 274/1000 - loss: 0.4708 -  - 0.06s\n",
      "Early stopping after 274 epochs.\n",
      "[==============================] 100% Epoch 275/1000 - loss: 0.4709 -  - 0.05s\n",
      "Early stopping after 275 epochs.\n",
      "[==============================] 100% Epoch 276/1000 - loss: 0.4709 -  - 0.05s\n",
      "Early stopping after 276 epochs.\n",
      "[==============================] 100% Epoch 277/1000 - loss: 0.4710 -  - 0.05s\n",
      "Early stopping after 277 epochs.\n",
      "[==============================] 100% Epoch 278/1000 - loss: 0.4711 -  - 0.05s\n",
      "Early stopping after 278 epochs.\n",
      "[==============================] 100% Epoch 279/1000 - loss: 0.4711 -  - 0.05s\n",
      "Early stopping after 279 epochs.\n",
      "[==============================] 100% Epoch 280/1000 - loss: 0.4712 -  - 0.05s\n",
      "Early stopping after 280 epochs.\n",
      "[==============================] 100% Epoch 281/1000 - loss: 0.4713 -  - 0.04s\n",
      "Early stopping after 281 epochs.\n",
      "[==============================] 100% Epoch 282/1000 - loss: 0.4713 -  - 0.04s\n",
      "Early stopping after 282 epochs.\n",
      "[==============================] 100% Epoch 283/1000 - loss: 0.4714 -  - 0.05s\n",
      "Early stopping after 283 epochs.\n",
      "[==============================] 100% Epoch 284/1000 - loss: 0.4714 -  - 0.04s\n",
      "Early stopping after 284 epochs.\n",
      "[==============================] 100% Epoch 285/1000 - loss: 0.4715 -  - 0.05s\n",
      "Early stopping after 285 epochs.\n",
      "[==============================] 100% Epoch 286/1000 - loss: 0.4715 -  - 0.04s\n",
      "Early stopping after 286 epochs.\n",
      "[==============================] 100% Epoch 287/1000 - loss: 0.4716 -  - 0.04s\n",
      "Early stopping after 287 epochs.\n",
      "[==============================] 100% Epoch 288/1000 - loss: 0.4716 -  - 0.04s\n",
      "Early stopping after 288 epochs.\n",
      "[==============================] 100% Epoch 289/1000 - loss: 0.4716 -  - 0.04s\n",
      "Early stopping after 289 epochs.\n",
      "[==============================] 100% Epoch 290/1000 - loss: 0.4717 -  - 0.04s\n",
      "Early stopping after 290 epochs.\n",
      "[==============================] 100% Epoch 291/1000 - loss: 0.4717 -  - 0.04s\n",
      "Early stopping after 291 epochs.\n",
      "[==============================] 100% Epoch 292/1000 - loss: 0.4717 -  - 0.05s\n",
      "Early stopping after 292 epochs.\n",
      "[==============================] 100% Epoch 293/1000 - loss: 0.4718 -  - 0.05s\n",
      "Early stopping after 293 epochs.\n",
      "[==============================] 100% Epoch 294/1000 - loss: 0.4718 -  - 0.04s\n",
      "Early stopping after 294 epochs.\n",
      "[==============================] 100% Epoch 295/1000 - loss: 0.4718 -  - 0.04s\n",
      "Early stopping after 295 epochs.\n",
      "[==============================] 100% Epoch 296/1000 - loss: 0.4718 -  - 0.04s\n",
      "Early stopping after 296 epochs.\n",
      "[==============================] 100% Epoch 297/1000 - loss: 0.4719 -  - 0.05s\n",
      "Early stopping after 297 epochs.\n",
      "[==============================] 100% Epoch 298/1000 - loss: 0.4719 -  - 0.05s\n",
      "Early stopping after 298 epochs.\n",
      "[==============================] 100% Epoch 299/1000 - loss: 0.4720 -  - 0.04s\n",
      "Early stopping after 299 epochs.\n",
      "[==============================] 100% Epoch 300/1000 - loss: 0.4720 -  - 0.04s\n",
      "Early stopping after 300 epochs.\n",
      "[==============================] 100% Epoch 301/1000 - loss: 0.4720 -  - 0.04s\n",
      "Early stopping after 301 epochs.\n",
      "[=====================---------] 70% Epoch 302/1000 - loss: 0.4735 -  - 0.03s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m early_stopping \u001B[38;5;241m=\u001B[39m EarlyStopping(patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, min_delta\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m, restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m48\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m42\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Programming\\Python\\Handmade NeuralNetwork\\neuralnetlib\\model.py:125\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x_train, y_train, epochs, batch_size, verbose, metrics, random_state, validation_data, callbacks)\u001B[0m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_batch\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    124\u001B[0m     y_batch \u001B[38;5;241m=\u001B[39m y_batch\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m--> 125\u001B[0m error \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_on_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    126\u001B[0m predictions_list\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictions)\n\u001B[0;32m    127\u001B[0m y_true_list\u001B[38;5;241m.\u001B[39mappend(y_batch)\n",
      "File \u001B[1;32m~\\Documents\\Programming\\Python\\Handmade NeuralNetwork\\neuralnetlib\\model.py:86\u001B[0m, in \u001B[0;36mModel.train_on_batch\u001B[1;34m(self, x_batch, y_batch)\u001B[0m\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m error\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m     84\u001B[0m     error \u001B[38;5;241m=\u001B[39m error[:, \u001B[38;5;28;01mNone\u001B[39;00m]\n\u001B[1;32m---> 86\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward_pass\u001B[49m\u001B[43m(\u001B[49m\u001B[43merror\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32m~\\Documents\\Programming\\Python\\Handmade NeuralNetwork\\neuralnetlib\\model.py:67\u001B[0m, in \u001B[0;36mModel.backward_pass\u001B[1;34m(self, error)\u001B[0m\n\u001B[0;32m     65\u001B[0m     error \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictions \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_true\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 67\u001B[0m     error \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward_pass\u001B[49m\u001B[43m(\u001B[49m\u001B[43merror\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(layer, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweights\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(layer, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124md_weights\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(layer, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124md_bias\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[1;32m~\\Documents\\Programming\\Python\\Handmade NeuralNetwork\\neuralnetlib\\layers.py:135\u001B[0m, in \u001B[0;36mDense.backward_pass\u001B[1;34m(self, output_error)\u001B[0m\n\u001B[0;32m    133\u001B[0m input_error \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(output_error, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights\u001B[38;5;241m.\u001B[39mT)\n\u001B[0;32m    134\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_weights \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput\u001B[38;5;241m.\u001B[39mT, output_error)\n\u001B[1;32m--> 135\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_bias \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_error\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m input_error\n",
      "File \u001B[1;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36msum\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:2298\u001B[0m, in \u001B[0;36msum\u001B[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m   2295\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m out\n\u001B[0;32m   2296\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\u001B[1;32m-> 2298\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrapreduction\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msum\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2299\u001B[0m \u001B[43m                      \u001B[49m\u001B[43minitial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhere\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:86\u001B[0m, in \u001B[0;36m_wrapreduction\u001B[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001B[0m\n\u001B[0;32m     83\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     84\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m reduction(axis\u001B[38;5;241m=\u001B[39maxis, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpasskwargs)\n\u001B[1;32m---> 86\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ufunc\u001B[38;5;241m.\u001B[39mreduce(obj, axis, dtype, out, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpasskwargs)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=5, min_delta=0.001, restore_best_weights=True)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1000, batch_size=48, random_state=42, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-24T02:20:37.875589300Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = model.evaluate(x_test, y_test)\n",
    "print(f'Test loss: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-24T02:20:37.877589Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Printing some metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-24T02:20:37.878590300Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
